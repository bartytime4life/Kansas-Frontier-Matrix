---
title: "ğŸ§¬ Kansas Frontier Matrix â€” Reliable Pipelines Architecture & Operations Guide (Diamondâ¹ Î© / CrownâˆÎ© Ultimate Certified)"
path: "docs/pipelines/reliable-pipelines.md"
version: "v11.0.0"
last_updated: "2025-11-20"
review_cycle: "Quarterly / Autonomous"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../releases/v11.0.0/sbom.spdx.json"
manifest_ref: "../../releases/v11.0.0/manifest.zip"
telemetry_ref: "../../releases/v11.0.0/focus-telemetry.json"
telemetry_schema: "../../schemas/telemetry/pipelines-reliable-v11.json"
governance_ref: "../standards/governance/ROOT-GOVERNANCE.md"
license: "CC-BY 4.0"
mcp_version: "MCP-DL v6.3"
markdown_protocol_version: "KFM-MDP v11.0.0"
status: "Active / Enforced"
doc_kind: "Architecture"
intent: "etl-reliability"
semantic_document_id: "kfm-pipelines-reliable-v11"
doc_uuid: "urn:kfm:docs:pipelines:reliable-v11"
machine_extractable: true
accessibility_compliance: "WCAG 2.1 AA+"
fair_category: "F1-A1-I1-R1"
care_label: "Public / Low-Risk"
immutability_status: "version-pinned"
---

<div align="center">

# ğŸ§¬ **Kansas Frontier Matrix â€” Reliable Pipelines Architecture & Operations Guide**  
`docs/pipelines/reliable-pipelines.md`

**Purpose:**  
Define the *authoritative, v11-certified* design and operational model for all ETL, AI, and lineage-secure pipelines in the Kansas Frontier Matrix. Enforces determinism, reproducibility, FAIR+CARE ethics, provenance via PROV-O, and Story Node / Focus Mode v3 compatibility.

</div>

---

# ğŸ“˜ Overview

Reliable pipelines are the **nervous system** of KFM v11: deterministic DAGs that transform raw multi-domain Kansas data into structured, ontology-aligned graph entities, STAC items, DCAT datasets, and narrative-ready Story Nodes.

This guide defines:

- Pipeline classes (Batch, Streaming, AI/ML)
- Deterministic rules & failure-domain isolation
- Reproducibility & metadata injection
- Lineage tracking (OpenLineage v2.5 + PROV-O)
- Schema enforcement (STAC 1.x, DCAT 3.0, CIDOC-CRM, GeoSPARQL, OWL-Time)
- Interaction with Focus Mode v3 and Story Nodes v3
- CI/CD validation for pipelines

---

# ğŸ—‚ Pipeline Stack Architecture

```text
src/pipelines/
â”‚
â”œâ”€â”€ batch/                 # Historical / static datasets
â”‚   â”œâ”€â”€ extract/           # Pure ingestion: download, checksum, freeze
â”‚   â”œâ”€â”€ transform/         # Normalization, harmonization, reprojection
â”‚   â””â”€â”€ load/              # Neo4j, STAC, DCAT, file registries
â”‚
â”œâ”€â”€ streaming/             # Real-time & incremental feeds
â”‚   â”œâ”€â”€ sensors/           # Weather, hydrology, hazards
â”‚   â”œâ”€â”€ watchers/          # File, HTTP, queue listeners
â”‚   â””â”€â”€ delta/             # Incremental graph updates
â”‚
â””â”€â”€ ai/                    # AI-driven enrichment and QC
    â”œâ”€â”€ nlp/               # NER, geocoding, summarization
    â”œâ”€â”€ inference/         # Predictive models (climate, hazards, patterns)
    â””â”€â”€ validators/        # Bias checks, uncertainty, explainability (SHAP/LIME)
```

**Rules:**

- No pipeline mutates source data.  
- All pipeline steps log PROV-O lineage.  
- All outputs are STAC/DCAT registered.  
- All entities map cleanly into Neo4j schema (CIDOC-CRM core).  

---

# ğŸ§© Pipeline Types

## ğŸ§± 1. Batch Pipelines
Used for large historic datasets (maps, census, treaties, hydrology records).

**Requirements:**

- Deterministic (fixed seed, fixed parameters).  
- Reproducible from raw â†’ processed with one command.  
- Output MUST include:
  - STAC Item(s)
  - DCAT Dataset entry
  - PROV-O activity chain
  - Checksums (SHA-256)
  - Spatial metadata (CRS, bbox)
  - Temporal metadata (start/end/precision)

## ğŸ”„ 2. Streaming Pipelines
For live or incremental data (Mesonet, USGS NWIS, NOAA hazard bulletins).

**Rules:**

- Must run idempotently.
- Support late-arriving data.
- Every increment is recorded as:
  - `prov:Activity`
  - Timeline event (OWL-Time)
  - Graph snapshot delta

## ğŸ¤– 3. AI/ML Pipelines
AI enrichments supplement but *never modify* raw or authoritative fields.

Includes:

- Named Entity Recognition (spaCy)
- Geocoding (GNIS, Nominatim)
- Summaries (Transformers)
- Pattern detection
- Focus Mode v3 reasoning models

**Guardrails:**

- FAIR+CARE ethical filters
- Explainability required
- No hallucinated facts â€” every claim tied to data provenance

---

# ğŸ›  Determinism & Reliability Rules

- No external nondeterministic calls without caching.
- Every transformation recorded in:
  - `data/processed/â€¦`
  - `data/stac/â€¦`
  - `neo4j` via Cypher upsert
- Failures isolated at node level â€” never allow DAG-wide collapse.
- Automatic rollback uses WAL checkpoints.

---

# ğŸ›° Metadata Injection (Mandatory)

Every pipeline MUST inject:

- STAC 1.x metadata fields
- DCAT 3.0 dataset descriptors
- PROV-O (`prov:Entity`, `prov:Activity`, `prov:Agent`)
- CRS (`EPSG:4326` unless otherwise required)
- Temporal extent (`start`, `end`, `precision`)
- FAIR+CARE ethics labels
- Quality & uncertainty metrics (for AI output)

---

# ğŸ§ª CI/CD Validation

All pipelines undergo:

- `stac-validate`
- `dcat-validate`
- `schema-lint`
- `prov-check`
- `mcp-lint`
- `faircare-audit`
- `geojson-lint`
- `crs-check`
- `bbox-check`

Pipeline PRs **cannot merge** unless all validations pass.

---

# ğŸ§­ Focus Mode v3 Integration

Pipeline outputs must support Focus Mode:

- Every entity has:
  - human-readable label  
  - canonical ID  
  - description  
  - links to related entities  

- AI-generated Focus summaries must include:
  - provenance links  
  - uncertainty estimates  
  - filtered (CARE-compliant) content  

---

# ğŸ§± Story Node v3 Integration

A pipeline may emit Story Nodes when:

- Data represents narrative-extractable content
- Spatial + temporal bounds are known
- Summary has validated provenance

Story Node JSON must match `story-node.schema.json`.

---

# ğŸ•° Version History

- **v11.0.0 â€” 2025-11-20**  
  First release under KFM-MDP v11.0.0. Full reliability architecture, lineage, focus-mode alignment.

---

# ğŸ”— Footer

**Back to Standards:** `docs/standards/README.md`  
**Back to Architecture:** `docs/architecture/system_overview.md`  
**Back to Root:** `/README.md`

