---
title: "ğŸš¦ KFM v11.2.4 â€” Eventâ€‘Driven Deterministic Ingestion & Promotion Pattern (Idempotent Â· WALâ€‘Safe Â· FAIR+CARE)"
path: "docs/pipelines/patterns/event-driven-deterministic-ingest.md"
version: "v11.2.4"
last_updated: "2025-12-07"

release_stage: "Stable Â· Governed"
lifecycle: "Long-Term Support (LTS)"
review_cycle: "Quarterly Â· Reliability + FAIR+CARE Councils"
content_stability: "stable"
backward_compatibility: "Backward compatible with v11.0.x patterns"

status: "Active / Enforced"
doc_kind: "Pattern"
header_profile: "standard"
footer_profile: "standard"

commit_sha: "<latest-commit-hash>"
previous_version_hash: "<previous-commit-hash-or-null>"
doc_integrity_checksum: "<sha256-of-this-file>"

sbom_ref: "releases/v11.2.4/sbom.spdx.json"
manifest_ref: "releases/v11.2.4/manifest.zip"
telemetry_ref: "releases/v11.2.4/patterns-telemetry.json"
telemetry_schema: "schemas/telemetry/patterns-event-driven-v1.json"
governance_ref: "docs/standards/governance/ROOT-GOVERNANCE.md"

license: "MIT"
mcp_version: "MCP-DL v6.3"
markdown_protocol_version: "KFM-MDP v11.2.4"
ontology_protocol_version: "KFM-OP v11"
stac_profile: "KFM-STAC v11"
dcat_profile: "KFM-DCAT v11"
prov_profile: "KFM-PROV v11"

fair_category: "F1-A1-I1-R1"
care_label: "CARE-compliant (auto-mask on)"
sensitivity: "Mixed (enable dynamic generalization & tribal review)"
classification: "Public / Internal (feature-flag cutover)"

provenance_chain:
  - "docs/standards/kfm_markdown_protocol_v11.2.4.md@v11.2.4"
  - "docs/pipelines/patterns/run-state/README.md@v11.2.4"
  - "docs/standards/lineage/openlineage-ci-integration.md@v11.2.4"

doc_uuid: "urn:kfm:doc:pipelines:patterns:event-driven-deterministic-ingest:v11.2.4"

test_profiles:
  - "markdown-frontmatter-v11"
  - "markdown-structure-v11"
  - "footer-governance-links-v11"
  - "pipeline-pattern-event-driven-deterministic-v1"

ci_integration: ".github/workflows/docs-lint.yml"

scope:
  domain: "multi-domain"
  applies_to:
    - "etl"
    - "stac"
    - "dcat"
    - "graph"
    - "lineage"
    - "provenance"
    - "telemetry"
    - "focus-mode"
  impacted_modules:
    - "docs/pipelines/patterns"
    - "src/pipelines/*"
    - "src/graph/*"
    - "src/api/*"
    - "data/raw/*"
    - "data/work/*"
    - "data/processed/*"
    - "data/stac/*"
    - "dist/provenance/*"
    - ".github/workflows/*"
---

<div align="center">

# ğŸš¦ **Eventâ€‘Driven Deterministic Ingestion & Promotion Pattern**  

**Triggers â†’ Orchestrate â†’ Stage â†’ Transform â†’ QA â†’ Canary â†’ Monitor â†’ Promote / Rollback**  
_Idempotent keys Â· Writeâ€‘Ahead Log Â· STAC/DCAT Â· PROVâ€‘O Â· Lineage Â· Energy/Cost Telemetry_

`docs/pipelines/patterns/event-driven-deterministic-ingest.md`

</div>

---

## ğŸ“˜ Overview

### Purpose

This pattern defines the **canonical KFM v11.2.4 approach** for turning any external change signal:

- Objectâ€‘store drops,  
- Dataset webhooks,  
- Scheduled cadence fallbacks  

into **deterministic, replayable ingestion & promotion runs** with:

- Idempotent execution,  
- WALâ€‘safe writes,  
- STAC/DCAT/PROVâ€‘aligned catalogs,  
- FAIR+CAREâ€‘aware masking and tribal review hooks,  
- Oneâ€‘click, featureâ€‘flagged promotion and rollback.

It must be used whenever a KFM pipeline:

- Reacts to **events** (not just cron), and  
- **Publishes** to canonical KFM data spaces:
  - `data/raw`, `data/work`, `data/processed`,  
  - `data/stac`, Neo4j graph, Story Node feeds.

### Goals

- Turn **triggers** into **RunEvents** with stable idempotency keys.  
- Enforce **deterministic transforms** (no hidden randomness or clock usage).  
- Capture **full provenance** (PROVâ€‘O + OpenLineage) and energy/cost telemetry.  
- Gate publication with **schema, QA, and CARE checks**.  
- Publish via **canary â†’ monitor â†’ promote/rollback** instead of direct writes.  

---

## ğŸ—‚ï¸ Directory Layout

This pattern governs layout and behavior, not individual pipelines, but a typical KFMâ€‘aligned structure is:

```text
ğŸ“ docs/
â””â”€â”€ ğŸ“ pipelines/
    â””â”€â”€ ğŸ“ patterns/
        â”œâ”€â”€ ğŸ“„ README.md                                   # Patterns index
        â”œâ”€â”€ ğŸ“„ run-state/README.md                         # Run-state pattern
        â””â”€â”€ ğŸ“„ event-driven-deterministic-ingest.md        # â† This file

ğŸ“ data/
â”œâ”€â”€ ğŸ“ raw/
â”‚   â””â”€â”€ ğŸ“ <dataset>/
â”‚       â””â”€â”€ ğŸ“ <window>/...                               # Event-aligned window (e.g., YYYY-MM-DD, run-id)
â”œâ”€â”€ ğŸ“ work/
â”‚   â””â”€â”€ ğŸ“ <dataset>/
â”‚       â””â”€â”€ ğŸ“ <run_id>/...                               # Intermediate, per-run staging
â”œâ”€â”€ ğŸ“ processed/
â”‚   â””â”€â”€ ğŸ“ <dataset>/
â”‚       â””â”€â”€ ğŸ“ <version>/...                              # Canonical processed outputs (versioned)
â””â”€â”€ ğŸ“ stac/
    â””â”€â”€ ğŸ“ <dataset>/
        â””â”€â”€ ğŸ“ <version>/
            â”œâ”€â”€ ğŸ“„ collection.json
            â””â”€â”€ ğŸ“„ item-*.json

ğŸ“ schemas/
â””â”€â”€ ğŸ“ telemetry/
    â”œâ”€â”€ ğŸ“„ patterns-event-driven-v1.json                  # This patternâ€™s telemetry schema
    â”œâ”€â”€ ğŸ“ tabular/
    â”‚   â””â”€â”€ ğŸ“„ <dataset>.schema.json                      # JSON Schema / Pydantic compatible
    â””â”€â”€ ğŸ“ geo/
        â””â”€â”€ ğŸ“„ <dataset>.geo.schema.json                  # Geometry & CRS rules

ğŸ“ src/
â”œâ”€â”€ ğŸ“ pipelines/
â”‚   â””â”€â”€ ğŸ“ <dataset>/
â”‚       â”œâ”€â”€ ğŸ“„ orchestrator.py                            # Event-driven orchestrator
â”‚       â”œâ”€â”€ ğŸ“„ validators.py                              # Schema + domain + CARE checks
â”‚       â”œâ”€â”€ ğŸ“„ stac_emit.py                               # STAC/DCAT emission helpers
â”‚       â””â”€â”€ ğŸ“„ wal.py                                     # Write-ahead log utilities (or shared lib)
â”œâ”€â”€ ğŸ“ graph/
â”‚   â””â”€â”€ ğŸ“ neo4j/
â”‚       â”œâ”€â”€ ğŸ“„ models.py                                  # Dataset/Run/Artifact node & rel types
â”‚       â””â”€â”€ ğŸ“„ emit.py                                    # Shadow + prod graph emitters
â””â”€â”€ ğŸ“ qa/
    â”œâ”€â”€ ğŸ“ great_expectations/                            # Optional expectations suites
    â””â”€â”€ ğŸ“ care_policies/                                 # H3 generalization & masking policies
```

Pipelines may reorganize internals, but **must not diverge** from the logical separation of:

- `raw` â†’ `work` â†’ `processed` â†’ `stac` â†’ `graph`, and  
- `docs` â†’ `schemas` â†’ `src` triad for documentation, schemas, and implementation.

---

## ğŸ§­ Context

KFMâ€™s pipeline backbone is:

> Deterministic ETL â†’ STAC/DCAT/PROV catalogs â†’ Neo4j knowledge graph â†’ API layer â†’ React/MapLibre/Cesium frontend â†’ Story Nodes â†’ Focus Mode

This pattern is the **eventâ€‘driven special case** of that backbone:

- Inputs are driven by **external events**, not just cron.  
- Multiple events may target the **same dataset and window**.  
- It must be possible to **replay** events and **rollback** bad promotions.  

It sits alongside:

- The **Runâ€‘State pattern** (`docs/pipelines/patterns/run-state/README.md`), and  
- The **OpenLineage CI Integration Standard** (`docs/standards/lineage/openlineage-ci-integration.md`),

and assumes:

- All runs are **run-state tracked**,  
- All runs **emit OpenLineage + PROVâ€‘O**,  
- All promotions are **feature-flagâ€‘controlled** and WALâ€‘backed.

---

## ğŸ§± Architecture

### High-level flow (conceptual)

```text
Triggers â†’ Event Bus â†’ Orchestrator â†’ Stage (raw) â†’ Transform (work/processed)
â†’ QA (schema + domain + CARE) â†’ Canary STAC/graph â†’ Monitors â†’ Promote / Rollback
```

Or step-wise:

1. **Triggers â†’ Event Bus**  
   - Sources: object store events, dataset webhooks, or cron fallbacks.  
   - Normalized into `RunEvent` with:
     - `source_uri`,  
     - `content_hash` (e.g., BLAKE3),  
     - logical `time_window` (e.g., [t0, t1)).  

2. **Orchestrator â†’ Deterministic Run**  
   - Derive **idempotency key**:
     - `idempotency_key = hash(source_uri + content_hash + time_window)`.  
   - Spawn pipeline with:
     - Fixed seeds,  
     - Pinned dependencies & containers,  
     - Run labels (dataset, window, env).  

3. **Stage â†’ Lake (Raw)**  
   - WALâ€‘guarded write to `data/raw/<dataset>/<window>/...`:
     - Download â†’ temp path â†’ checksum â†’ atomic rename.  
   - Capture:
     - Bytes, checksums, ETags, and any remote version IDs.  

4. **Transform â†’ Work / Processed**  
   - Transform nodes must be **pure** with respect to:
     - Inputs (raw files and configs),  
     - Seeds (explicit and logged).  
   - Intermediate artifacts:
     - `data/work/<dataset>/<run_id>/...`  
   - Final canonical outputs:
     - `data/processed/<dataset>/<version>/...`  

5. **Provenance + Telemetry**  
   - Emit **OpenLineage events** (START, COMPLETE/FAIL).  
   - Emit **PROVâ€‘O JSONâ€‘LD**:
     - Entities (inputs, outputs, configs),  
     - Activity (run),  
     - Agent (pipeline/CI).  
   - Emit **telemetry**:
     - Energy (kWh), carbon (kgCOâ‚‚e), cost (USD), records in/out.

6. **Quality Gates (hard fail on red)**  
   - Schema & type checks (tabular/geospatial).  
   - Domain QA (ranges, uniqueness, dedup, etc.).  
   - CARE masking and tribal review hooks where necessary.

7. **Publish (canary first)**  
   - Generate **STAC Collections/Items** (source-of-truth).  
   - Derive **DCAT 3.0 datasets/distributions** from STAC.  
   - Publish to:
     - **Canary STAC/DCAT** namespace,  
     - **Shadow Neo4j graph**.  

8. **Monitors â†’ Promote or Rollback**  
   - Monitors watch:
     - Availability,  
     - Schema & value diffs,  
     - Performance,  
     - User smoke tests.  
   - On green within a window:
     - Promote to **prod catalogs & graph**; flip feature flags.  
   - On red:
     - Trigger structured **rollback**:
       - Reset flags,  
       - Roll back graph pointer,  
       - Optionally purge invalid processed artifacts.

### Idempotent run contract (canonical pseudo-code)

```python
from blake3 import blake3

def derive_idempotency_key(source_uri: str, content_hash: str, time_window: str) -> str:
    return blake3(f"{source_uri}|{content_hash}|{time_window}".encode("utf-8")).hexdigest()

key = derive_idempotency_key(source_uri, content_hash, time_window)

with orchestrator.run(idempotency_key=key, seed=SEED) as run:
    wal.begin("stage_raw", inputs=[source_uri])
    paths = stage_raw_to_lake(source_uri, checksums=True)
    wal.commit("stage_raw", outputs=paths)

    qa.assert_schema(paths.raw)            # JSON Schema / pydantic
    qa.assert_geo_valid(paths.raw_geo)     # CRS + topology

    wal.begin("transform")
    art = transform(paths.raw, seed=SEED)
    wal.commit("transform", outputs=art)

    qa.assert_expectations(art)            # Domain rules (GE, etc.)
    care.apply_masking_if_needed(art)      # H3 / generalization rules

    prov.emit(run=run.id, inputs=[paths], outputs=[art])
    tel.emit(node="transform", energy_kwh=..., cost_usd=...)

    stac_emit.canary(art)
    graph.shadow(art)

    if monitors.green_within("30m"):
        promote(art)
        flags.cutover("dataset-prod", "on")
    else:
        rollback.from_wal(run.id)
        flags.cutover("dataset-prod", "off")
```

---

## ğŸ“¦ Data & Metadata

### Data tiers

- **Raw (`data/raw`)**  
  - Direct mirror of external payloads (optionally normalized to KFM codecs).  
  - Must be **immutable** for a given `(dataset, window, hash)` tuple.

- **Work (`data/work`)**  
  - Perâ€‘run temporary artifacts.  
  - May be cleaned according to retention policy, but WAL must remain long enough to support rollback windows.

- **Processed (`data/processed`)**  
  - Canonical, referenceable layers, versioned as:
    - `<dataset>/<semver-or-tag>/...`.  
  - Only these are considered â€œpublishedâ€ once promoted.

### Metadata & manifests

Every stage must write **machineâ€‘readable manifests** (JSON/YAML) containing:

- Inputs and outputs (paths, checksums, sizes),  
- Schema versions,  
- Run identifiers (`openlineage:runId`, `prov:Activity` IDs),  
- Validation & CARE status flags,  
- Energy/cost telemetry references.

These manifests are:

- Linked from STAC Item properties,  
- Linked from PROVâ€‘O bundles,  
- Discoverable through the metadata & provenance registry.

---

## ğŸŒ STAC, DCAT & PROV Alignment

### STAC (source-of-truth catalogs)

For each promoted dataset version, this pattern requires:

- A **STAC Collection** describing:
  - Dataset, spatial and temporal extent,  
  - Sources and license,  
  - KFM extensions (energy, lineage, CARE labels).  

- A set of **STAC Items** describing:
  - Individual assets (Parquet, NetCDF, GeoTIFF, etc.),  
  - Checksums (`checksum:multihash` or equivalent),  
  - Linkage to:
    - PROV bundles (`kfm:provenance_ref`),  
    - Telemetry (`kfm:telemetry_ref`),  
    - OpenLineage runs (`openlineage:runId`).

### DCAT (derived from STAC)

DCAT 3.0 datasets/distributions are:

- Generated from STAC via the KFM STACâ†’DCAT derivation standard,  
- Never manually authored in conflict with the STAC source-of-truth,  
- Used for external cataloging and interoperability.

### PROV-O & Lineage

OpenLineage and PROVâ€‘O work together:

- **OpenLineage**:
  - Runâ€‘centric event stream (START, COMPLETE/FAIL, inputs/outputs).  

- **PROVâ€‘O JSONâ€‘LD**:
  - Rich, graphâ€‘centric description of:
    - Entities: datasets, configs, code, manifests, audits,  
    - Activities: staging, transform, QA, publish, rollback,  
    - Agents: pipelines, CI, governance councils.

All promoted artifacts **must** be reachable in the PROV graph and include:

- `prov:wasGeneratedBy` (activities),  
- `prov:wasDerivedFrom` (earlier datasets or runs),  
- `prov:wasAssociatedWith` (agents).

---

## ğŸ§ª Validation & CI/CD

### QA gate matrix (examples)

| Dimension  | Checks (non-exhaustive)                                                                 |
|-----------|------------------------------------------------------------------------------------------|
| Tabular   | JSON Schema / pydantic, enum domains, null policy, PK/UK uniqueness, dedup              |
| Geo       | Geometry validity, CRS matches declared, area/extent sanity, topology rules             |
| Time      | OWLâ€‘Time alignment, no unintentional gaps/overlaps, ordered intervals                   |
| Domain    | Greatâ€‘Expectationsâ€‘style ranges, distributions, business rules                          |
| CARE      | Sensitive feature detection, H3 generalization, masking, and tribal review flags        |

All QA must be:

- **Automated & deterministic**,  
- Logged as part of run telemetry and PROV,  
- Binding for promotion decisions (red â†’ no promote).

### CI integration

Typical workflows (per dataset or shared):

- `event-driven-ingest.yml`  
  - Executes the pattern endâ€‘toâ€‘end for integration tests,  
  - Validates manifests, STAC, PROV, and QA behavior.

- `lineage.yml` (per lineage standard)  
  - Verifies OpenLineage & PROVâ€‘O completeness,  
  - Enforces the presence of `openlineage:runId` in STAC.

- `patterns-telemetry.yml`  
  - Aggregates patternâ€‘level telemetry into:
    - `releases/v11.2.4/patterns-telemetry.json`.

Failures in:

- Idempotency enforcement,  
- WAL correctness,  
- STAC/PROV completeness, or  
- CARE masking

are **shipâ€‘blockers** and must block merges/promotions.

---

## ğŸ§  Story Node & Focus Mode Integration

Although this pattern lives in pipelines, it is **directly visible** to narratives:

- Story Nodes referencing datasets must be able to:
  - Jump to **STAC/PROV entries** for the exact promoted version,  
  - See whether the last promotion passed QA and CARE checks,  
  - Understand rollback events (if a dataset was reverted).

- Focus Mode relies on:
  - Stable **dataset versions** and **promotion histories**,  
  - Trust indicators derived from QA and audit outcomes,  
  - The ability to filter out views based on nonâ€‘green promotions.

Because promotions are:

- Featureâ€‘flagged,  
- Graphâ€‘pointer controlled,  
- Versionâ€‘tagged,

Focus Mode can present:

- â€œCurrent production viewâ€ vs  
- â€œPrevious stable versionsâ€ (where Story Nodes may anchor to a specific version).

---

## âš– FAIR+CARE & Governance

This pattern is explicitly **CAREâ€‘aware**:

- `care_label: "CARE-compliant (auto-mask on)"` implies:
  - All eventâ€‘driven pipelines must:
    - Detect sensitive or sovereign features when joining with soil, hydrology, archaeology, etc.,  
    - Apply **data generalization** (e.g., H3, distance fuzzing) where policies require,  
    - Record masking and generalization decisions in PROV and audit logs.

- `sensitivity: "Mixed"` implies:
  - Some datasets may be fully public, others require:
    - Indigenous Data Governance Board (IDGB) review,  
    - Restricted STAC/ DCAT visibility or redacted distributions.

Governance responsibilities:

- **Reliability & Observability teams**  
  - Own WAL, idempotency, and rollback guarantees.  

- **FAIR+CARE Data Governance Council + IDGB**  
  - Own policies for:
    - Sensitive data detection,  
    - Masking strategies,  
    - Approval gates before certain datasets can be promoted.

Any pipeline implementation claiming to follow this pattern must:

- Pass governance review (design + implementation),  
- Be linked from the analytical metadata & provenance registry,  
- Be covered by audit reports under `docs/analyses/metadata/audit-reports/`.

---

## ğŸ•°ï¸ Version History

| Version  | Date       | Author / Steward        | Summary                                                                 |
|----------|------------|------------------------|-------------------------------------------------------------------------|
| v11.2.4  | 2025-12-07 | KFM Reliability Guild  | Initial KFM-MDP v11.2.4â€“aligned event-driven deterministic ingest & promotion pattern. |

---

<div align="center">

**Kansas Frontier Matrix (KFM v11)**  

[ğŸ“ Pipeline Patterns Index](./README.md) Â· [ğŸ“š Pipelines Overview](../README.md) Â· [âš–ï¸ Root Governance](../../../standards/governance/ROOT-GOVERNANCE.md)

</div>
