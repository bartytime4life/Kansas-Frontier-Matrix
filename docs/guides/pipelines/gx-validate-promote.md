---
title: "ğŸ§ª Kansas Frontier Matrix â€” Great Expectations Validate â†’ Promote Pipeline Guide (Diamondâ¹ Î© / CrownâˆÎ© Ultimate Certified)"
path: "docs/guides/pipelines/gx-validate-promote.md"
version: "v10.3.1"
last_updated: "2025-11-14"
review_cycle: "Quarterly Â· FAIR+CARE Council"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../../releases/v10.3.0/sbom.spdx.json"
manifest_ref: "../../../releases/v10.3.0/manifest.zip"
telemetry_ref: "../../../releases/v10.3.0/focus-telemetry.json"
telemetry_schema: "../../../schemas/telemetry/pipelines-gx-promote-v1.json"
governance_ref: "../../standards/governance/ROOT-GOVERNANCE.md"
license: "CC-BY 4.0"
mcp_version: "MCP-DL v6.3"
---

<div align="center">

# ğŸ§ª **Kansas Frontier Matrix â€” Great Expectations Validate â†’ Promote Pipeline Guide**  
`docs/guides/pipelines/gx-validate-promote.md`

**Purpose:**  
Define the **canonical KFM workflow** for validating datasets with **Great Expectations (GX)** and then **promoting** validated assets to the **Processed**, **Published**, and **Graph** layers with complete **FAIR+CARE**, **lineage**, **provenance**, and **telemetry** commitments.

This guide standardizes the Validateâ†’Promote pattern used by:  
- STAC ingestion pipelines  
- Remote sensing pipelines (LandsatLook, Sentinel-2, Sentinel-1)  
- Historical / tabular ETL pipelines  
- Hazard, drought, climate, and multi-temporal analysis pipelines  

</div>

---

## ğŸ“˜ Overview

The **GX Validate â†’ Promote pattern** ensures:

- Input data is fully validated before entering KFM storage  
- All promotions respect FAIR+CARE governance  
- Lineage and telemetry are bound at each step  
- Neo4j + STAC indexes + RDF exports only reference validated assets  
- All failures follow a standard quarantine + issue creation workflow

This guide defines:
1. **Directory model**  
2. **Validation â†’ promotion states**  
3. **GX check suite structure**  
4. **Governance and CARE forcing functions**  
5. **CI/CD triggers and blocking rules**  

---

## ğŸ—‚ï¸ Directory Layout (Authoritative)

~~~~~text
data/
â”œâ”€â”€ raw/                            # Incoming unverified data
â”œâ”€â”€ work/
â”‚   â”œâ”€â”€ tmp/                        # Intermediate transforms
â”‚   â”œâ”€â”€ staging/                    # GX-validated, schema-aligned data
â”‚   â””â”€â”€ processed/                  # Pre-publication outputs
â”œâ”€â”€ processed/                      # Certified FAIR+CARE datasets
â”œâ”€â”€ stac/                           # STAC Items/Collections (published)
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ validation/                 # GX summaries
â”‚   â”œâ”€â”€ fair/                       # CARE audits
â”‚   â””â”€â”€ audit/                      # Governance ledgers
â””â”€â”€ telemetry/
    â””â”€â”€ *.ndjson                    # Stage-by-stage telemetry
~~~~~

---

## ğŸ”„ Validate â†’ Promote Lifecycle

~~~~~mermaid
flowchart TD
  A["Raw / Incoming Data"] --> B["GX Checkpoint<br/>Schema Â· Ranges Â· Integrity"]
  B -->|PASS| C["Staging Layer<br/>Schema-Aligned Â· CARE-tagged"]
  B -->|FAIL| Q["Quarantine<br/>Issue Creation Â· Telemetry"]
  C --> D["Promotion Gate<br/>FAIR+CARE + Provenance Checks"]
  D -->|PASS| E["Processed Layer"]
  E --> F["Publish<br/>STAC Â· DCAT Â· Neo4j Â· RDF"]
  F --> G["Telemetry + Lineage<br/>Governance Ledger"]
~~~~~

---

## ğŸ§ª 1. Great Expectations Checkpoints

KFM standardizes GX checkpoints:

- **Schema Validation**  
- **Uniqueness Rules**  
- **Value Ranges**  
- **Required Fields**  
- **Geo-boundary checks** (if spatial)
- **Temporal rule checks** (OWL-Time alignment)
- **CARE rule checks** (combined with governance pipeline)
- **Link integrity** (STAC, DCAT, references)

### File structure:

~~~~~text
great_expectations/
â”œâ”€â”€ great_expectations.yml
â”œâ”€â”€ checkpoints/
â”‚   â”œâ”€â”€ <pipeline>_schema.yml
â”‚   â””â”€â”€ <pipeline>_integrity.yml
â””â”€â”€ expectations/
    â”œâ”€â”€ schema_<name>.json
    â”œâ”€â”€ ranges_<name>.json
    â””â”€â”€ integrity_<name>.json
~~~~~

### Promotion Condition  
A dataset **CANNOT** be promoted unless:

- All GX suites = **PASS**  
- No warnings exist  
- CARE rules pass  
- Provenance hashes recorded  

---

## ğŸ›¡ï¸ 2. Quarantine Workflow

If validation fails:

- Dataset batch is moved to:

~~~~~text
data/work/quarantine/<timestamp>/
~~~~~

- Generated files:
  - `failure_report.json`
  - `last_failure_summary.md`
  - Raw offending data files (optional)
- CI automatically opens a GitHub Issue (peter-evans/create-issue-from-file)
- Telemetry entry added (stage=validate, status=failure)

Quarantined data **must not** be used downstream.

---

## ğŸ§­ 3. Staging Layer Rules

Data in `data/work/staging/` is:

- Fully GX-validated  
- Schema-harmonized  
- CARE-labeled  
- Provenance-linked  
- Ready for promotion gating

Required metadata injected:

- `kfm:validation_version`
- `kfm:validated_at`
- `kfm:care_label`
- `kfm:checksum_sha256`
- `kfm:source_ids`
- Provenance chain reference

---

## âš–ï¸ 4. FAIR+CARE Promotion Gate

Promotion from `data/work/staging/` â†’ `data/processed/` requires:

### Mandatory Conditions

| Requirement | Description |
|------------|-------------|
| FAIR | STAC/DCAT fields complete, open format, linked metadata |
| CARE | sovereignty, sensitive AOIs masked, consent metadata present |
| Provenance | lineage record created & validated |
| Integrity | checksums match lineage records |
| Telemetry | validate telemetry exists & required fields present |

Promotion fails if **any** of these conditions are not met.

### Governance Check

Promotion gate uses:

~~~~~text
docs/reports/audit/data_provenance_ledger.json
~~~~~

The ledger receives:

- Dataset ID  
- Validation suite IDs  
- Telemetry summary  
- CARE decisions  
- Transformation log  

---

## ğŸ†™ 5. Promotion â†’ Processed Layer

Promotion writes:

~~~~~text
data/processed/<dataset_id>/<version>/
~~~~~

+ a `processed_manifest.json` containing:

- Version  
- Checksums  
- GX suite versions  
- Telemetry reference  
- CARE label  
- Provenance references  
- Linked STAC + DCAT IDs  

After promotion:

- Pre-registered STAC Items are created/updated  
- Neo4j graph nodes/edges built  
- RDF/GeoSPARQL exports constructed  

---

## ğŸŒ 6. Publish Phase (Optional Per Pipeline)

For pipelines that include publication:

- STAC Items written to `data/stac/published/items/**`  
- Collections updated  
- Neo4j nodes merged  
- RDF/JSON-LD published  
- Catalogs synchronized (STAC â†” DCAT)

All published items must be:

- Hash-locked (sha256)  
- Telemetry-linked  
- Listed in the governance ledger  

---

## ğŸ“¡ 7. Telemetry Requirements

Every stage MUST emit NDJSON:

~~~~~text
data/telemetry/<pipeline>.ndjson
~~~~~

Required fields:

- `stage`  
- `status`  
- `duration_ms`  
- `rows` / `pixels_processed`  
- `energy_wh`, `co2_g`  
- `care_violations`  
- `errors`  
- `stac_items`, `graph_nodes`, etc.  

Aggregated to:

~~~~~text
../../../releases/v10.3.0/focus-telemetry.json
~~~~~

CI (`telemetry-export.yml`) rejects missing fields.

---

## ğŸ§¬ 8. Lineage Requirements

Each pipeline stage MUST append lineage info validated by:

~~~~~text
src/pipelines/remote-sensing/lineage/schemas/lineage.schema.json
~~~~~

Required elements:

- PROV-O Activity  
- PROV-O Entity (source + outputs)  
- GeoSPARQL geometry (if spatial)  
- CARE attributes  
- STAC parent/child linkages  
- Transformation chain  

Lineage written to:

~~~~~text
data/processed/lineage/<dataset>/<version>.jsonld
~~~~~

---

## ğŸ§ª Local Developer Run (Recommended)

~~~~~bash
# 1. Validate
great_expectations checkpoint run <checkpoint>

# 2. Promote
python scripts/promote.py \
  --input data/work/staging/<dataset> \
  --output data/processed/<dataset>/<version>

# 3. Publish (optional)
python scripts/publish_stac.py
python scripts/publish_graph.py
~~~~~

---

## ğŸ› ï¸ CI/CD Integration

Promotion is blocked unless all workflows succeed:

- `stac-validate.yml`  
- `faircare-validate.yml`  
- `telemetry-export.yml`  
- `docs-lint.yml`  
- `data-contract-validate.yml`  
- `ai-model-audit.yml` (if AI-enabled)  

Failures automatically generate issues with pointers to quarantined data.

---

## ğŸ•°ï¸ Version History

| Version | Date       | Author | Summary |
|---------|------------|--------|---------|
| v10.3.1 | 2025-11-14 | Pipeline Governance Team | Initial Validateâ†’Promote workflow guide; aligned with GX v1.x, FAIR+CARE, telem. v3, KFM Markdown Protocol. |

---

<div align="center">

**Kansas Frontier Matrix â€” Validate â†’ Promote Pattern**  
FAIR+CARE ETL Ã— Deterministic Validation Ã— Reproducible Science Ã— Governance by Design  
Â© 2025 Kansas Frontier Matrix â€” CC-BY 4.0  

</div>

