---
title: "ğŸ“Š Kansas Frontier Matrix â€” Analytics Pipeline Guide (Diamondâ¹ Î© / CrownâˆÎ© Ultimate Certified)"
path: "docs/guides/pipelines/analytics-guide.md"
version: "v10.4.2"
last_updated: "2025-11-16"
review_cycle: "Quarterly Â· FAIR+CARE Council Oversight"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../../releases/v10.4.2/sbom.spdx.json"
manifest_ref: "../../../releases/v10.4.2/manifest.zip"
telemetry_ref: "../../../releases/v10.4.2/pipeline-telemetry.json"
telemetry_schema: "../../../schemas/telemetry/pipelines-analytics-guide-v1.json"
governance_ref: "../../standards/governance/ROOT-GOVERNANCE.md"
license: "CC-BY 4.0"
mcp_version: "MCP-DL v6.3"
markdown_protocol_version: "KFM-MDP v10.4.2"
status: "Active / Enforced"
doc_kind: "Guide"
intent: "analytics-pipelines"
fair_category: "F1-A1-I1-R1"
care_label: "C2-A2-R2-E1"
kfm_readme_template: "Platinum v7.1"
ci_enforced: true
---

<div align="center">

# ğŸ“Š **Kansas Frontier Matrix â€” Analytics Pipeline Guide**  
`docs/guides/pipelines/analytics-guide.md`

**Purpose**  
Define the **canonical architecture and governance pattern** for all analytics pipelines  
in the Kansas Frontier Matrix (KFM).  
Analytics pipelines consume validated data from `processed/`, apply **deterministic  
analysis models**, integrate **FAIR+CARE v2**, emit **lineage v2**, register results  
in the **Governance Ledger**, and publish **STAC/DCAT/Graph/RDF** artifacts when required.

This guide governs:
- Time-series analytics  
- Climate & drought indicators  
- Hazard models  
- Hydrology & remote-sensing analytics  
- AI-assisted analytics pipelines  
- Aggregation / summarization pipelines  

</div>

---

# ğŸ“˜ Overview

Analytics pipelines operate *after* ingestion + preprocessing + GX validation and  
transform certified `processed/` datasets into:

- Derived analytics layers (tabular, raster, vector)  
- Indicators (climate, hydrology, hazards)  
- Feature sets for AI pipelines  
- Summaries for Story Nodes  
- Aggregated or resampled geospatial layers  
- Multi-temporal composites  
- Metadata-rich outputs ready for publication  

All analytics pipelines must:

- Be **deterministic** (same input â†’ same output)  
- Emit **lineage v2** bundles  
- Integrate **CARE v2 governance** at every output  
- Emit **telemetry v2**  
- Pass CI governance checks  
- Produce **publish-ready** artifacts (STAC/DCAT/RDF) when applicable  

---

# ğŸ—‚ï¸ Directory Layout (Canonical Analytics Layer)

~~~text
src/pipelines/analytics/
â”œâ”€â”€ README.md                           # This guideâ€™s architecture for analytics
â”œâ”€â”€ config.py                           # Domain parameters, AOIs, periods, thresholds
â”œâ”€â”€ run_analytics.py                    # Main orchestrator
â”œâ”€â”€ steps/
â”‚   â”œâ”€â”€ load_inputs.py                  # Load processed datasets
â”‚   â”œâ”€â”€ spatial_ops.py                  # Spatial transformations (resample, clip, AOI)
â”‚   â”œâ”€â”€ temporal_ops.py                 # Rolling windows, aggregates, anomaly detection
â”‚   â”œâ”€â”€ models.py                       # Climate/hazard models, indices, regressions
â”‚   â”œâ”€â”€ indicators.py                   # Derived metrics (SPI, SPEI, NDVI, etc.)
â”‚   â”œâ”€â”€ summaries.py                    # Statistical summaries, trend extraction
â”‚   â”œâ”€â”€ governance.py                   # CARE v2 logic for analytics outputs
â”‚   â”œâ”€â”€ telemetry.py                    # Telemetry v2 emission
â”‚   â””â”€â”€ write_outputs.py                # Save outputs into data/processed + catalogs
â””â”€â”€ utils/
    â”œâ”€â”€ math_utils.py                   # Z-scores, rolling ops
    â”œâ”€â”€ geo_utils.py                    # Raster/Vector utilities
    â”œâ”€â”€ time_utils.py                   # Temporal handling
    â””â”€â”€ io_utils.py                     # I/O helpers
~~~

---

# ğŸ“Š Analytics Architecture (GitHub-Safe Mermaid)

```mermaid
flowchart TD

subgraph LOAD["Load Inputs"]
  A["Processed Inputs<br/>data/processed/<dataset>/<version>"]
end

subgraph ANALYTICS["Analytics Ops"]
  B["Spatial Ops<br/>clip Â· resample Â· join"]
  C["Temporal Ops<br/>rolling Â· anomaly Â· windows"]
  D["Models<br/>hazard Â· climate Â· hydrology"]
  E["Indicators<br/>SPI Â· SPEI Â· NDVI etc."]
end

subgraph OUTPUTS["Output Assembly"]
  F["Outputs<br/>tabular Â· raster Â· vector Â· summaries"]
end

subgraph GOVERN["Governance Layer"]
  G["CARE v2 Enforcement"]
  H["Provenance + Lineage v2"]
  I["Telemetry v2"]
end

subgraph PUBLISH["Publication"]
  J["STAC Â· DCAT Â· Neo4j Â· RDF (optional)"]
end

A --> B --> C --> D --> E --> F --> G --> H --> I --> J

classDef load fill:#ebf8ff,stroke:#2b6cb0,color:#1a365d;
classDef anal fill:#faf5ff,stroke:#805ad5,color:#553c9a;
classDef out fill:#f0fff4,stroke:#38a169,color:#22543d;
classDef gov fill:#fffbea,stroke:#dd6b20,color:#7b341e;
classDef pub fill:#fff5f5,stroke:#e53e3e,color:#742a2a;

class LOAD load;
class ANALYTICS anal;
class OUTPUTS out;
class GOVERN gov;
class PUBLISH pub;
````

---

# 1ï¸âƒ£ Load Inputs

Analytics pipelines **must** read from official:

```text
data/processed/<dataset>/<version>/
```

Inputs must include:

* `processed_manifest.json`
* Any rasters/vectors/tables (aligned to KFM schemas)
* Lineage v2
* CARE v2 metadata
* Telemetry references

Loading step MUST:

* Validate checksums and manifest integrity
* Validate careLabel + maskingStrategy
* Load lineage chain to support analysis metadata

---

# 2ï¸âƒ£ Spatial Operations

Spatial operations include:

* Clip to AOI
* Reproject (if needed)
* Resample (nearest/bilinear/cubic as appropriate)
* Spatial join
* Aggregation to H3 cells
* Mosaic / merge

Spatial ops must:

* Maintain CRS consistency
* Ensure no increase in resolution beyond source dataset
* Carry forward CARE v2 masking and sovereignty logic
* Emit intermediate telemetry

---

# 3ï¸âƒ£ Temporal Operations

Temporal operations include:

* Rolling mean/median
* Windowed variance
* Monthly/seasonal composites
* Year-over-year anomalies
* Breakpoint detection (climate trends)
* Time alignment (OWL-Time consistency)

Temporal ops must:

* Preserve monotonic timestamps
* Validate temporal models
* Carry temporal metadata into lineage

---

# 4ï¸âƒ£ Models (Hazards Â· Climate Â· Hydrology)

Analytics pipelines may implement domain models:

## 4.1 Hazard Models

* Drought index (SPI/SPEI)
* Flood risk indices
* Fire weather index
* Severe weather clusters

## 4.2 Climate Models

* Temperature anomaly detection
* Precipitation trend regression
* Heatwave modeling
* ENSO signal extraction

## 4.3 Hydrology Models

* Basin runoff estimation
* Streamflow anomaly detection
* Soil moisture modeling
* Snowpack/cryosphere indicators

All models must be:

* **Deterministic**
* Versioned (`model_version`)
* Explainable (model metadata into lineage)
* CARE v2 aware (mask sensitive watersheds or tribal areas as required)

---

# 5ï¸âƒ£ Indicators

Indicators (NDVI, EVI, SPI, SPEI, NDWI, etc.) must:

* Maintain physical meaning
* Be versioned (`indicator_version`)
* Carry metadata:

  * source datasets
  * derivation chain
  * units
  * resolution
  * temporal coverage

Indicators are saved under:

```text
data/processed/<indicator>/<version>/
```

and linked in lineage.

---

# 6ï¸âƒ£ Output Assembly

Outputs can include:

* **Tabular** (CSV/Parquet)
* **Raster** (COG GeoTIFF)
* **Vector** (GeoJSON/FlatGeobuf)
* **Summaries** (JSON)
* **Graphs/derived features**

Every output MUST:

* Include CARE v2 metadata
* Include lineage v2 reference
* Include telemetry reference
* Include checksums.txt
* Pass post-output sanity checks

---

# 7ï¸âƒ£ Governance Layer

Governance checks integrate:

## 7.1 CARE v2 Enforcement

* Propagate careLabel from inputs
* Apply new masking if outputs increase resolution or reveal new sensitive details
* Update `maskingStrategy` and `sovereigntyFlags`

## 7.2 Lineage v2

Analytics lineage must record:

* Inputs used
* Spatial + temporal transforms
* Models and indicator logic
* CARE decisions
* Telemetry summary

Stored in:

```text
data/processed/lineage/<analytics_type>/<version>.jsonld
```

## 7.3 Telemetry v2

Minimum fields:

* `stage: "analytics"`
* `duration_ms`
* `model_version` / `indicator_version`
* `rows_processed` / `pixels_processed`
* `energy_wh`, `co2_g`
* `care_violations`
* `errors`

---

# 8ï¸âƒ£ Publication (Optional Per Pipeline)

If analytics create publishable layers:

* Build STAC Item (+ update Collection)
* Build DCAT Dataset JSON-LD
* Create Neo4j nodes/edges
* Generate RDF GeoSPARQL triples

All require Promotion Gate compliance:

* proper CARE v2 masking
* complete lineage v2 bundle
* telemetry integration
* checksums
* governance ledger registration

---

# 9ï¸âƒ£ CI Enforcement

Analytics pipelines MUST pass:

| Workflow                   | Responsibility                   |
| -------------------------- | -------------------------------- |
| `analytics-validate.yml`   | Basic validation + schema checks |
| `faircare-validate.yml`    | CARE v2 governance               |
| `lineage-validate.yml`     | Lineage v2 JSON-LD validation    |
| `stac-validate.yml`        | STAC structure (if publishing)   |
| `dcat-validate.yml`        | DCAT validation (if publishing)  |
| `linked-data-validate.yml` | RDF/GeoSPARQL validation         |
| `telemetry-export.yml`     | Telemetry v2 validation          |
| `sbom-validate.yml`        | Supply-chain integrity           |
| `docs-lint.yml`            | Markdown protocol compliance     |

---

# ğŸ”Ÿ Developer Checklist

* [ ] Input datasets validated & in `processed/`
* [ ] CARE v2 metadata read + applied
* [ ] Spatial/temporal operations deterministic
* [ ] Model version recorded
* [ ] Lineage v2 bundle created
* [ ] Telemetry v2 emitted
* [ ] Governance ledger updated
* [ ] STAC/DCAT/RDF/Graph written (if required)
* [ ] All CI workflows green

---

# ğŸ•° Version History

| Version | Date       | Summary                                                                              |
| ------: | ---------- | ------------------------------------------------------------------------------------ |
| v10.4.2 | 2025-11-16 | Initial analytics-guide.md aligned to KFM v10.4.2; CARE v2, lineage v2, telemetry v2 |

---

<div align="center">

**Kansas Frontier Matrix â€” Analytics Pipeline Guide (v10.4.2)**
Deterministic Analytics Ã— FAIR+CARE v2 Ã— Lineage v2 Ã— Publishing Gate Compliance
Â© 2025 Kansas Frontier Matrix â€” CC-BY 4.0 Â· Diamondâ¹ Î© / CrownâˆÎ© Ultimate Certified

</div>
