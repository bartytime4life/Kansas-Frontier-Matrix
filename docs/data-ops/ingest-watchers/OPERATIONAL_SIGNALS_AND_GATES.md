---
title: "üõ∞Ô∏è KFM ‚Äî Operational Signals, Trigger Rules, QC Gates, and Provenance Attachments for Ingest Watchers"
path: "docs/data-ops/ingest-watchers/OPERATIONAL_SIGNALS_AND_GATES.md"
version: "v11.2.6"
last_updated: "2025-12-20"
release_stage: "Stable / Governed"
lifecycle: "Long-Term Support (LTS)"
review_cycle: "Quarterly ¬∑ Data-Ops & FAIR+CARE Council"
content_stability: "stable"
status: "Active / Canonical"
doc_kind: "Standard"
header_profile: "standard"
footer_profile: "standard"
intent: "kfm-ingest-watchers-operational-signals"
license: "CC-BY-4.0"
mcp_version: "MCP-DL v6.3"
markdown_protocol_version: "KFM-MDP v11.2.6"
ontology_protocol_version: "KFM-ONTO v4.1.0"
pipeline_contract_version: "KFM-PPC v11.0.0"
stac_profile: "KFM-STAC v1.0"
dcat_profile: "KFM-DCAT v1.0"
prov_profile: "KFM-PROV v1.0"
telemetry_schema: "KFM-TEL v1.2"
---

# üõ∞Ô∏è KFM ‚Äî Operational Signals, Trigger Rules, QC Gates, and Provenance Attachments for Ingest Watchers

## üéØ Purpose

This document defines **what an ingest watcher should observe**, **how it should decide**, and **what it must attach** so every data acceptance/rejection/quarantine event is:
- measurable (telemetry),
- enforceable (QC gates + contracts),
- explainable (signals + rules),
- and reproducible (PROV lineage + immutable artifacts).

In KFM, an ‚Äúingest watcher‚Äù is a lightweight control-plane loop (or event-driven function) that:
1) detects change or arrival,
2) fetches/normalizes,
3) evaluates signals + gates,
4) routes to **publish** or **quarantine**,
5) emits **PROV + STAC/DCAT updates + telemetry**.

---

## üß© Core Concepts

### 1) Signal vs Gate vs Trigger
- **Signal**: a measured indicator (numeric, boolean, categorical) describing data, system state, or upstream conditions.
- **Gate**: a hard decision boundary (PASS / FAIL / QUARANTINE / HOLD) evaluated from one or more signals.
- **Trigger**: what causes evaluation (schedule, webhook, file arrival, API ‚ÄúlastUpdated‚Äù, checksum delta, upstream revision notice).

### 2) Outcomes
- **PASS ‚Üí Publish** (write processed outputs, publish STAC Item/Collection updates, refresh DCAT dataset, emit PROV)
- **SOFT FAIL ‚Üí Quarantine** (store raw + diagnostics, attach reason codes, open workflow issue/alert)
- **HOLD ‚Üí Retry** (upstream incomplete / forecast cycle not done / rate-limit)
- **DROP ‚Üí Ignore** (duplicate, known bad revision, non-authoritative mirror)

---

## üß† Signal Taxonomy (What to Measure)

### A) Change & Revision Signals
These prevent ‚Äúsilent updates‚Äù from corrupting downstream truth.

1. **Revision Marker**
- Detect upstream flags: `status=preliminary/final`, `revision_id`, `last_modified`, `etag`, `generationTime`, ‚Äúprocessing_level‚Äù.
- If the same time interval is re-issued, treat as new revision, not duplicate.

2. **Schema Revision / Contract Drift**
- Field added/removed, type changed, enum expanded, unit changed.
- Parse headers, JSON schema, CSV columns, NetCDF vars, GeoTIFF tags, STAC extensions.

3. **Content Hash Delta**
- Stable hashing: whole-file SHA256, chunked hashes for large objects, row-group hashes for parquet.
- Hash delta without revision marker = suspicious (possible silent backfill).

4. **Backfill Window Growth**
- ‚ÄúNew data‚Äù includes historical windows beyond policy, e.g., upstream reprocessing for last 90 days.
- Track: `min_time_changed`, `max_time_changed`, and percentage changed.

**Recommended fields:**
- `kfm.signal.revision.kind` = {upstream_flag, etag, hash_delta, backfill_detected}
- `kfm.signal.revision.severity` = {info, warn, critical}

---

### B) Completeness & Timeliness Signals
1. **Timeliness Lag**
- `lag = now - expected_arrival_time`
- Distinguish: upstream delayed vs ingestion stalled.

2. **Coverage / Expected Count**
- For sensors: expected N observations per interval.
- For tiles/grids: expected scene count, expected band list.

3. **Null Density / Missingness**
- Overall and per critical field (e.g., timestamp, geometry, pm25, discharge_cfs).

4. **Forecast Cycle Completion**
- Only publish when all required cycle members exist (e.g., `t00z` + all lead times).
- Track: partial cycle vs complete cycle.

---

### C) Validity & Conformance Signals
1. **Type & Range Validity**
- Date parseable, coords numeric, values in physical plausibility bounds.

2. **Unit & CRS / Datum Validity**
- Units present and recognized, CRS declared, vertical datum known or resolvable.

3. **Semantic Validity**
- Controlled vocabulary checks (station type codes, method codes, qualifier flags).

4. **Geospatial Validity**
- Geometry is valid, within Kansas AOI bounds (or expected domain), no self-intersections.

---

### D) Consistency & Integrity Signals
1. **Primary Key / Natural Key Uniqueness**
- No duplicates for `(station_id, timestamp)` or `(scene_id)`.

2. **Referential Integrity**
- Observation references a known station; station references known provider; asset references known collection.

3. **Time Monotonicity**
- Timestamps non-decreasing per source stream; detect resets.

4. **Cross-field Consistency**
- Example: wind direction only valid when wind speed > 0 (domain-specific).

---

### E) Statistical & Anomaly Signals (Data ‚ÄúBehavior‚Äù)
1. **Distribution Shift**
- PSI, KL divergence, Wasserstein distance, z-score of feature moments vs baseline.
- Use rolling baselines (7d/30d) and seasonal baselines (same month last year).

2. **Spike / Dropout / Flatline**
- Flatline: variance ~ 0 for too long.
- Dropout: missing bursts.

3. **Outlier Density**
- fraction of points outside robust bounds (MAD-based, quantile fences).

4. **Neighbor Consensus**
- Compare station to nearby stations or grid cell climatology.
- Flag if persistent deviation beyond expected microclimate envelope.

---

### F) Identity & Churn Signals (Sensors, Stations, Providers)
1. **Relocation / Coordinate Jump**
- Sudden lat/lon change beyond threshold.
- Coupled with metadata changes (address, site name) increases confidence.

2. **Device Reset / Firmware Change**
- Repeated timestamp resets, new serial number, changed reporting cadence, changed precision.

3. **Dedup / Merge Candidate**
- Two ‚Äúdifferent‚Äù stations with near-identical time series + close geometry.

---

### G) Reliability & System Health Signals
1. **Fetcher Error Rate**
- HTTP 429/5xx, timeout frequency.

2. **Upstream SLA Breach**
- consecutive late cycles.

3. **Data Corruption Indicators**
- truncation, invalid gzip, parquet footer errors.

4. **Cost / Resource Spikes**
- unexpectedly large payload sizes, memory blowups.

---

## üß± QC Gates (Hard Decisions)

Below is a common gate stack that works across domains (air, hydro, geology rasters, catalogs).

### Gate 0 ‚Äî Trigger Eligibility
**Goal:** only run when meaningful.
- PASS if: new revision marker OR hash delta OR new time window.
- DROP if: duplicate event (idempotency key hit).

**Idempotency key** example:
`kfm_idem = sha256(source_id + collection_id + revision_id + time_window + fetch_params)`

---

### Gate 1 ‚Äî Contract & Schema Gate
**FAIL (Quarantine)** if any:
- missing required fields,
- type changes violating contract,
- unit changes without explicit revision event,
- CRS missing/invalid.

Outputs:
- `contract_diff.json`
- `schema_snapshot.json`
- `gate_1_report.json`

---

### Gate 2 ‚Äî Structural Integrity Gate
**FAIL (Quarantine)** if:
- invalid file structure,
- checksum mismatch,
- cannot parse essential formats.

Outputs:
- parsing logs
- checksum report
- minimal sample extraction

---

### Gate 3 ‚Äî Domain Validity Gate
**FAIL (Quarantine)** for hard physical impossibility.
Examples:
- negative precipitation,
- PM2.5 < 0 or absurdly high beyond instrument range (unless flagged exceptional + supported),
- discharge negative where not physically meaningful,
- geometry outside valid bounds for the dataset‚Äôs stated domain.

---

### Gate 4 ‚Äî Completeness & Timeliness Gate
**HOLD (Retry)** if:
- forecast cycle incomplete,
- expected batch member missing,
- upstream still ‚Äúpreliminary‚Äù when policy demands ‚Äúfinal‚Äù.

**SOFT FAIL (Quarantine)** if:
- persistent missingness beyond tolerance,
- too few observations in a publishing window.

---

### Gate 5 ‚Äî Consistency & Dedup Gate
**SOFT FAIL (Quarantine)** if:
- duplicates exceed threshold,
- key collisions,
- referential integrity breaks.

**PASS with annotation** if:
- duplicates are expected and deterministically resolved (document rule).

---

### Gate 6 ‚Äî Behavioral / Statistical Gate
**SOFT FAIL** if:
- distribution shift above threshold,
- flatline/spike patterns indicative of sensor fault,
- neighbor-consensus persistent deviations.

**PASS with flag** if:
- anomalies are plausible events and corroborated (e.g., wildfire smoke episode validated by multiple stations).

---

### Gate 7 ‚Äî Publish Gate (Promotion Saga)
Only **publish** if:
- all required gates pass,
- provenance bundle created,
- STAC/DCAT updates are consistent,
- telemetry emitted,
- signatures/attestations ready (if enabled).

---

## üß∑ Trigger Rules (When to Run What)

### 1) Polling Triggers
- **Interval polling**: every 5‚Äì15 min for realtime sensors; hourly/daily for batch.
- Conditional: increase frequency during known event windows.

### 2) Event Triggers
- Object store event (new file).
- Webhook from provider (new revision).
- Message bus (forecast cycle ready).

### 3) Hybrid Trigger Pattern
- Event triggers ingestion attempt.
- Polling verifies completeness and catches missed events.

---

## üîç Concrete Signal ‚Üí Gate Rule Examples

### Example A ‚Äî ‚ÄúRevision Marker‚Äù
**Signals**
- `etag_changed = true`
- `last_modified_changed = true`
- `hash_changed = true`

**Rules**
- If `hash_changed=true` AND `etag_changed=false` ‚Üí `Gate 0 = PASS`, but `Gate 1` gets ‚Äúsilent change‚Äù warning.
- If `revision_id` decreased or repeats with different hash ‚Üí quarantine with reason `REVISION_INCONSISTENT`.

---

### Example B ‚Äî ‚ÄúSensor Churn / Firmware‚Äù
**Signals**
- `cadence_change_ratio > 2.0`
- `precision_digits_changed = true`
- `timestamp_resets_detected = true`

**Rules**
- If ‚â•2 signals true within 24h ‚Üí `Gate 6 = SOFT FAIL` and create ‚Äúsensor state transition‚Äù annotation.
- If timestamp resets persist ‚Üí `Gate 3 = FAIL` (invalid time semantics).

---

### Example C ‚Äî ‚ÄúForecast Cycle Completion‚Äù
**Signals**
- `cycle_members_expected = 49`
- `cycle_members_present = 47`
- `cycle_age_minutes = 18`

**Rules**
- If `present < expected` AND `cycle_age < grace_period` ‚Üí `HOLD`.
- If `present < expected` AND `cycle_age >= grace_period` ‚Üí quarantine `INCOMPLETE_CYCLE`.

---

### Example D ‚Äî ‚ÄúNeighbor Consensus‚Äù
**Signals**
- `deviation_sigma = 4.5`
- `neighbors_corrob = false`
- `duration_hours = 6`

**Rules**
- If `deviation_sigma > 4` AND `duration_hours > 3` AND `neighbors_corrob=false` ‚Üí quarantine as likely sensor fault.
- If neighbors corroborate ‚Üí pass with ‚Äúevent plausible‚Äù flag.

---

## üßæ Provenance Attachments (What Must Be Emitted)

### 1) PROV Bundle (Minimum Viable Lineage)
Every ingest attempt produces a PROV graph with:
- **Entity**: raw artifact(s), normalized table(s), derived products (rasters, parquet, geojson), validation reports
- **Activity**: fetch, parse, normalize, validate, publish
- **Agent**: watcher service identity, CI runner, human approver (if any)

Minimum relations:
- `wasGeneratedBy` (product ‚Üê activity)
- `used` (activity ‚Üí inputs)
- `wasAssociatedWith` (activity ‚Üî agent)
- `wasDerivedFrom` (product ‚Üê input)
- `hadPlan` (activity ‚Üî pipeline config snapshot)

Persist as:
- `prov/run.jsonld` (or `prov/run.ttl`)
- `prov/summary.json` (human-friendly digest)

---

### 2) Validation Artifacts
For each run:
- `quality/expectations.json` (rules)
- `quality/validation_result.json` (results per expectation)
- `quality/metrics.json` (profiles: null rate, duplicates, drift stats)

---

### 3) Catalog Artifacts (STAC + DCAT)
- Update/create **STAC Item** for each asset and **STAC Collection** for grouping.
- Update **DCAT Dataset** and **Distribution** entries for discovery and governance.

---

### 4) Telemetry Artifacts
Emit consistent metrics/logs/traces for:
- run duration, bytes processed, rows/records, error classes
- gate decisions and reason codes
- drift scores, missingness, duplicates
- upstream SLA lag

---

### 5) Attestations & Integrity (Optional but Recommended)
- Produce signed build/proc provenance for artifacts (software + data processing), and attach signatures to release bundles.

---

## üß± Reason Codes (Standardize Your Decisions)

Define an enum used across gates, logs, and PROV annotations:

- `DUPLICATE_EVENT`
- `SCHEMA_BREAKING_CHANGE`
- `SCHEMA_NONBREAKING_CHANGE`
- `UNIT_CHANGE_UNANNOUNCED`
- `CRS_MISSING_OR_INVALID`
- `CHECKSUM_MISMATCH`
- `PARSE_ERROR`
- `PHYSICAL_IMPOSSIBILITY`
- `MISSINGNESS_EXCEEDED`
- `INCOMPLETE_CYCLE`
- `KEY_COLLISION`
- `REFERENTIAL_INTEGRITY_FAIL`
- `DISTRIBUTION_SHIFT_HIGH`
- `FLATLINE_DETECTED`
- `RELOCATION_SUSPECTED`
- `UPSTREAM_RATE_LIMIT`
- `UPSTREAM_OUTAGE`

Each reason code should have:
- severity: {info,warn,critical}
- default action: {pass,pass_with_flag,hold,quarantine,drop}
- remediation playbook pointer

---

## üß™ Implementation Patterns (Battle-Tested)

### Pattern 1 ‚Äî ‚ÄúTwo-Track Storage‚Äù
- Always persist **raw** (immutable).
- Persist **processed** only if publish gate passes.
- Persist **quarantine** with full diagnostics and replay metadata.

### Pattern 2 ‚Äî ‚ÄúDeterministic Replay‚Äù
- Persist config snapshot + seed + dependency versions + input hashes.
- A replay must reproduce outputs bitwise if upstream inputs unchanged.

### Pattern 3 ‚Äî ‚ÄúSoft Fail with Annotations‚Äù
Not every anomaly should block publication. Use:
- `pass_with_flag` when corroborated by context, neighbors, or external signals.
- Record the flag in STAC `properties` and DCAT `dcterms:conformsTo` / notes.

### Pattern 4 ‚Äî ‚ÄúBudgeted Verification‚Äù
Run cheap checks always; expensive checks conditionally:
- Always: schema, parse, checksum, basic ranges.
- Conditional: drift/neighbor checks when volume threshold met or on daily rollups.

---

## üì¶ Minimal Contract Template for a Watcher

A watcher contract should specify:
- data producer + endpoint(s)
- cadence + expected arrival
- schema + units + CRS
- required fields
- gate thresholds (missingness, duplicates, drift)
- quarantine routing + TTL + escalation
- publish rules (preliminary vs final)
- provenance requirements (what to attach)
- catalog requirements (STAC/DCAT mapping)

---

## üó∫Ô∏è Domain Notes (Quick Mappings)

### Air Quality (PM2.5 sensors)
High-value signals:
- flatline/spike, cadence shifts, relocation, neighbor-consensus, humidity bias flags.
Gates:
- strict timestamp integrity; quarantine for persistent sensor resets.

### Hydrology (streamflow gauges)
High-value signals:
- rating curve revision markers, provisional/final states, backfill windows, unit conversions.
Gates:
- hold if provisional policy requires final for certain products.

### Rasters / Remote Sensing
High-value signals:
- band completeness, nodata consistency, georeferencing validity, cloud-mask availability.
Gates:
- fail on missing CRS/transform; soft-fail on minor metadata warnings.

---

## ‚úÖ Operational Checklist (Per Run)

1) Trigger captured + idempotency key computed  
2) Fetch raw + capture ETag/Last-Modified + checksum  
3) Parse + schema snapshot + contract diff  
4) Profile metrics (nulls, dupes, ranges)  
5) Drift/anomaly checks (if enabled)  
6) Gate decision + reason codes  
7) Persist raw/processed/quarantine deterministically  
8) Emit PROV bundle + validation artifacts  
9) Update STAC/DCAT (publish only)  
10) Emit telemetry + alerts if thresholds crossed  

---

## üìö References

- PROV data model and PROV-O ontology for provenance graphs.
- Data cataloging via DCAT; geospatial asset metadata via STAC.
- Data quality checks and validation frameworks as inspiration for expectation/constraint patterns.
- OpenTelemetry conventions for consistent cross-service telemetry.

---

## üîó Footer

- üîô Back to Index: `docs/README.md`
- üß± Data-Ops: `docs/data-ops/README.md`
- üõ°Ô∏è Governance Charter: `docs/governance/README.md`
---
