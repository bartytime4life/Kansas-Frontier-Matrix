---
title: "üè∫ Kansas Frontier Matrix ‚Äî Archaeology Provenance Templates (Interaction Spheres)"
path: "docs/analyses/archaeology/datasets/cultural-landscapes/interaction-spheres/provenance/templates/README.md"
version: "v11.0.0"
last_updated: "2025-11-17"
review_cycle: "Annual / Autonomous ¬∑ FAIR+CARE Council"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../../../../releases/v11.0.0/sbom.spdx.json"
manifest_ref: "../../../../../releases/v11.0.0/manifest.zip"
telemetry_ref: "../../../../../releases/v11.0.0/focus-telemetry.json"
telemetry_schema: "../../../../../schemas/telemetry/archaeology-interaction-spheres-provenance-templates-v1.json"
governance_ref: "../../../../../docs/standards/governance/ROOT-GOVERNANCE.md"
license: "CC-BY 4.0"
mcp_version: "MCP-DL v6.3"
---

<div align="center">

# üè∫ **Kansas Frontier Matrix ‚Äî Archaeology Provenance Templates (Interaction Spheres)**  
`docs/analyses/archaeology/datasets/cultural-landscapes/interaction-spheres/provenance/templates/README.md`

**Purpose:**  
Define standard, MCP-compliant provenance templates for **archaeology interaction-sphere datasets**  
(Great Bend Aspect, Protohistoric Wichita, and related cultural landscapes). These templates ensure every  
dataset records **sources, transformations, QA, and graph links** in a way that is **FAIR+CARE aligned**,  
**STAC/DCAT/PROV-O compatible**, and ready for **Neo4j + Story Node + Focus Mode v3** integration.

[![Docs ¬∑ MCP-DL v6.3](https://img.shields.io/badge/Docs-MCP--DL_v6.3-blue)]()  
[![KFM-MDP v11.0](https://img.shields.io/badge/KFM%E2%80%93MDP-v11.0-informational)]()  
[![FAIR+CARE](https://img.shields.io/badge/FAIR%2BCARE-Compliant-gold)]()  
[![Domain ¬∑ Archaeology](https://img.shields.io/badge/Domain-Archaeology%20%2F%20Provenance-brown)]()  
[![Status ¬∑ Active](https://img.shields.io/badge/Status-Active-brightgreen)]()

</div>

---

## üìò Overview

This directory provides **canonical provenance templates** for all archaeology datasets under:

- `docs/analyses/archaeology/datasets/cultural-landscapes/interaction-spheres/**`
- (e.g. Great Bend Aspect, Protohistoric Wichita, and future interaction-sphere modules)

The templates:

- Encode **where data came from** (archives, repositories, field projects).  
- Capture **how data were transformed** (georeferencing, digitization, generalization, modeling).  
- Record **who did what, when, and with which tools** (MCP-style experiment / activity logging).  
- Align with **PROV-O** (Entity / Activity / Agent), **CIDOC-CRM** for cultural heritage,  
  **STAC 1.0** for spatio-temporal assets, **DCAT 3.0** for datasets, and **Story Node** schema for narratives.  
- Are designed to be **machine-validated in CI** and **hydrated into the Neo4j graph**.

Use these templates whenever you create or update an interaction-sphere dataset so that **every layer, table,  
and Story Node is fully traceable and reproducible**.

---

## üóÇ Directory Layout

```text
interaction-spheres/
‚îî‚îÄ‚îÄ provenance/
    ‚îî‚îÄ‚îÄ templates/
        ‚îú‚îÄ‚îÄ dataset-provenance.template.yml
        ‚îú‚îÄ‚îÄ sources-registry.template.csv
        ‚îú‚îÄ‚îÄ transformations-log.template.csv
        ‚îú‚îÄ‚îÄ qa-checklist.template.md
        ‚îú‚îÄ‚îÄ story-links.template.json
        ‚îî‚îÄ‚îÄ README.md  ‚Üê this file
````

**Files**

* `dataset-provenance.template.yml`
  High-level dataset provenance (who/what/when/why), DCAT/STAC/PROV-O aligned.

* `sources-registry.template.csv`
  Row-wise registry of **all input sources** (archives, GIS services, field notes, publications).

* `transformations-log.template.csv`
  Step-by-step record of ETL and analytical transformations, keyed to MCP experiments / scripts.

* `qa-checklist.template.md`
  Markdown checklist for **data quality, FAIR+CARE review, and archaeology-specific redaction rules**.

* `story-links.template.json`
  Machine-readable mapping between dataset elements and **Story Nodes / Focus Mode entities**.

---

## üß¨ Provenance Model & Standards

All templates here follow a common conceptual model:

* **Entity (PROV-O / CIDOC-CRM E73 / E31)**

  * Datasets, layers, tables, rasters, vector features.
  * Source documents (field forms, reports, digitized maps).

* **Activity (PROV-O / CIDOC-CRM E7 / E65)**

  * Georeferencing, digitization, generalization, aggregation, modeling.
  * MPC experiments (e.g. clustering, interpolation, network analysis).

* **Agent (PROV-O / CIDOC-CRM E39)**

  * People, teams, institutions, software agents (e.g. specific pipeline scripts).

* **Relations**

  * `prov:used` (activity uses entity)
  * `prov:wasGeneratedBy` (entity generated by activity)
  * `prov:wasAttributedTo` (entity attributed to agent)
  * Links to **Story Nodes** and **Focus Mode entities** by ID.

Standards alignment baked into templates:

* **STAC 1.0**: `id`, `datetime`, `bbox`, `geometry`, `assets`, `properties` hooks.
* **DCAT 3.0**: `dct:title`, `dct:description`, `dct:license`, `dct:provenance`, `dcat:distribution`.
* **CIDOC-CRM**: optional `cidoc_class`, `crm_relation` fields for advanced projects.
* **OWL-Time**: ISO datetimes + `precision` fields where only year/decade is known.
* **GeoSPARQL**: GeoJSON geometry ready for conversion to WKT.
* **FAIR+CARE**: explicit `rights`, `sensitivity`, and Indigenous data flags in YAML + QA template.

---

## üß© Template Types

### 1Ô∏è‚É£ Dataset-Level Provenance (YAML)

**File:** `dataset-provenance.template.yml`

Use this to describe an entire interaction-sphere dataset (e.g. ‚ÄúProtohistoric Wichita ‚Äî Trade Corridors v1.0‚Äù).

Key sections include (template will have TODO markers):

* `id`: stable dataset identifier (URN or UUID).
* `title`, `description`: human-readable label and abstract.
* `collection`: STAC collection id (e.g. `kfm-archaeology-interaction-spheres`).
* `spatial_extent`: bbox; `temporal_extent`: start/end ISO dates + `precision`.
* `license`, `rights`, `access_constraints`: including CARE notes.
* `lineage`: brief narrative of major processing stages.
* `sources_ref`: pointer(s) into `sources-registry.csv`.
* `transformations_ref`: pointer(s) into `transformations-log.csv`.
* `graph_links`: optional list of Neo4j labels/ids to be created/updated.

### 2Ô∏è‚É£ Sources Registry (CSV)

**File:** `sources-registry.template.csv`

One row per **input source** used to build or update the dataset.

Example columns:

* `source_id` ‚Äì local stable id (e.g. `KSHS_KM_00123`).
* `title` ‚Äì source title (map name, report title, etc.).
* `creator` ‚Äì person/org.
* `year` ‚Äì publication or observation year.
* `repository` ‚Äì KSHS, KU, USGS, tribal archive, etc.
* `access_uri` ‚Äì URL or catalog id.
* `license` ‚Äì source license / rights statement.
* `sensitivity` ‚Äì `public` / `restricted` / `generalize`.
* `notes` ‚Äì free text.

### 3Ô∏è‚É£ Transformations Log (CSV)

**File:** `transformations-log.template.csv`

Chronological record of **ETL and analytical steps**, referencing scripts and MCP experiments.

Example columns:

* `step_id` ‚Äì e.g. `T001`, `T002`.
* `activity_label` ‚Äì ‚ÄúGeorectify 1894 topo map‚Äù, ‚ÄúDigitize village polygons‚Äù, etc.
* `input_entities` ‚Äì list of `source_id` or dataset ids used.
* `output_entities` ‚Äì new dataset/layer ids created.
* `script_or_tool` ‚Äì Python module, QGIS alg, manual process.
* `experiment_id` ‚Äì link to MCP experiment doc (e.g. `EXP-ARCH-2025-03`).
* `run_date` ‚Äì ISO date.
* `operator` ‚Äì person or team name/initials.
* `qa_status` ‚Äì `pending`, `approved`, `rejected`.
* `notes`.

### 4Ô∏è‚É£ QA & FAIR+CARE Checklist (Markdown)

**File:** `qa-checklist.template.md`

Used to document **quality checks, ethical review, and archaeology-specific constraints**:

* Geometry & topology validation (no self-intersections, correct CRS).
* Attribute completeness & controlled vocabularies.
* Spatial / temporal generalization for sensitive sites (e.g. H3-level anonymization).
* CARE review:

  * consent, community consultation, authority to control, benefit sharing.
* Accessibility & documentation completeness.

### 5Ô∏è‚É£ Story / Focus Links (JSON)

**File:** `story-links.template.json`

Bridges dataset elements into **Story Nodes** and **Focus Mode v3**.

Typical structure:

* Mapping from dataset ids (layers, features, records) to:

  * `story_node_id` (per `story-node.schema.json`).
  * `focus_entity_ids` (Person / Place / Event ids in Neo4j).
  * Optional `narrative_snippet` seeds for auto-summarization.

---

## üß™ Usage Workflow

1. **Copy templates** into your dataset‚Äôs provenance directory:

   * e.g. `interaction-spheres/protohistoric-wichita/provenance/`

2. **Fill out `sources-registry.csv`**

   * Register all maps, reports, datasets, web services, and field sources.

3. **Fill out `transformations-log.csv`**

   * One row per ETL / modeling step; link to MCP experiment docs.

4. **Author `dataset-provenance.yml`**

   * Summarize scope, extents, key decisions, and high-level lineage.

5. **Complete `qa-checklist.md`**

   * Perform and record QA & CARE review; update `qa_status` in transformation log.

6. **Populate `story-links.json` (optional but recommended)**

   * Connect dataset content to Story Nodes and Focus Mode entities.

7. **Run validation** (see below).

   * Fix any schema or lint errors until CI passes.

8. **Commit & open PR**

   * Ensure provenance artifacts and dataset changes are in the same PR per MCP.

---

## üéØ Focus Mode & Story Node Integration

These templates are **Focus Mode v3 aware**:

* `dataset-provenance.yml` and `story-links.json` provide the hooks needed for:

  * **Focus Mode** to center on an interaction sphere dataset and surface:

    * related sites, time ranges, source documents, and key activities.
  * **Story Nodes** to:

    * reference datasets in their `spacetime` and `relations` sections.

* By using stable ids (`dataset_id`, `source_id`, `story_node_id`, `focus_entity_id`), the graph layer can:

  * Generate **site dossiers** that explain:

    * where polygons/points came from,
    * which sources support them,
    * which transformations and QA checks they passed.

* When Focus Mode renders a story about a Great Bend settlement cluster or a Protohistoric Wichita trade route:

  * It can **cite the exact provenance entries** from these templates, satisfying MCP‚Äôs explainability and
    CARE requirements.

---

## ‚úÖ Validation & CI Hooks

Provenance templates are validated through:

* **Schema checks**

  * YAML: JSON-schema-like validation using custom tooling.
  * CSV: header and required-column validation.
  * JSON: `story-links.template.json` checked against Story Node + local schema.

* **Make targets / scripts** (examples; actual names may differ in repo):

  * `make validate-provenance`
  * `python tools/validate_provenance.py`

* **CI**

  * PRs touching `provenance/**` must pass provenance validation jobs.
  * Failure to include or update provenance when modifying datasets should block merges (MCP docs-as-code rule).

---

## üîÑ Versioning & Governance

* Keep `version` and `last_updated` in this README and filled templates current.
* For each dataset provenance file:

  * Update its internal `version` when changing content or lineage.
  * Note breaking changes in the dataset‚Äôs own README / changelog.
* Governance and review:

  * Archaeology domain leads review provenance annually (or on major releases).
  * FAIR+CARE Council can mandate additional fields or redaction rules over time.

---

## üï∞ Version History

| Version | Date       | Author               | Summary                                                              |
| ------- | ---------- | -------------------- | -------------------------------------------------------------------- |
| v11.0.0 | 2025-11-17 | Lead Programmer (AI) | Initial creation of interaction-spheres provenance templates README. |

---
