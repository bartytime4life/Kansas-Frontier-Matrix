<!-- ğŸ“ File: mcp/traceability/dashboards/schemas/README.md -->

# ğŸ“Š Traceability Dashboard Schemas (MCP) ğŸ§¬

![JSON Schema](https://img.shields.io/badge/JSON%20Schema-2020--12-blue)
![Dashboards](https://img.shields.io/badge/dashboards-ğŸ“ˆ-informational)
![Traceability](https://img.shields.io/badge/traceability-â›“ï¸-success)
![Policy Gates](https://img.shields.io/badge/policy%20gates-fail--closed-critical)
![Provenance](https://img.shields.io/badge/provenance-STAC%20%2B%20DCAT%20%2B%20PROV-brightgreen)

> [!IMPORTANT]
> This folder is the **schema registry** for the telemetry, manifests, and reports that power **traceability dashboards** across KFM (Kansas Frontier Matrix) and MCP (Master Coder Protocol).  
> If it shows up in a dashboard, it must be **machine-validatable** and **back-traceable** to evidence. ğŸ§¾âœ…

---

## ğŸ§­ Where we are

```text
ğŸ“¦ mcp/
 â””â”€ ğŸ§¬ traceability/
     â””â”€ ğŸ“Š dashboards/
         â””â”€ ğŸ§¾ schemas/   ğŸ‘ˆ you are here
```

---

## ğŸ¯ Purpose

This directory defines **dashboard-facing data contracts** (JSON Schemas) for:

- ğŸ“œ **Telemetry** (append-only NDJSON events)  
- ğŸ§ª **Run manifests** (exact pipeline inputs/outputs + hashes)  
- ğŸ§­ **Provenance & lineage** (STAC + DCAT + PROV cross-links)  
- ğŸ§± **Graph integrity** (weekly graph health checks, schema drift, orphan/dangling refs)  
- ğŸ” **Policy & governance** (OPA/Conftest decisions, fail-closed gates, audit trail)  
- ğŸ§  **AI traceability** (Focus Mode citations, drift, governance ledger entries)  
- ğŸ§µ **Narrative traceability** (Pulse Threads, evidence manifests, concept activations)

These schemas are the â€œshape of truthâ€ dashboards rely onâ€”so dashboards can be **reliable**, **comparable**, and **portable** across environments (local/dev/staging/prod). ğŸ§°ğŸ“¦

---

## ğŸ§¬ Why schemas matter here

KFMâ€™s architecture is explicitly **contract-first** and **provenance-first**â€”anything presented in the UI or AI responses must be traceable back to cataloged sources, using open standards like **STAC**, **DCAT**, and **PROV**.[^kfm-contract]  
That same rule applies to dashboards: dashboards are â€œUI for operations,â€ so they must also be **provable**.

---

## ğŸ—ºï¸ Traceability â†’ Dashboards: high-level dataflow

```mermaid
flowchart LR
  A[ğŸ—‚ï¸ Sources] --> B[âš™ï¸ Pipeline Run]
  B --> C[ğŸ“œ telemetry.ndjson]
  B --> D[ğŸ§ª run_manifest.json]
  B --> E[ğŸ§­ Evidence Triplet<br/>STAC + DCAT + PROV]

  D --> F[ğŸ” Policy Gates<br/>(OPA/Conftest)]
  E --> F

  E --> G[ğŸ•¸ï¸ Neo4j Knowledge Graph]
  G --> H[ğŸ§± Graph Health Check Report]

  F --> I[ğŸ“˜ Governance Ledger]
  C --> J[ğŸ“Š Dashboards]
  D --> J
  F --> J
  H --> J
  I --> J

  G --> K[ğŸ§‘â€ğŸ’» UI Panels]
  G --> L[ğŸ¤– Focus Mode]
  L --> M[ğŸ§¾ Answer Trace + Citations]
  M --> J
```

---

## ğŸ“¦ What belongs in this folder

âœ… **YES** (dashboard contract schemas)
- `*.schema.json` files for dashboard payloads/events/manifests/reports  
- A â€œcommon envelopeâ€ schema used by most payloads  
- Minimal example payloads (small + realistic) for CI validation

âŒ **NO** (belongs elsewhere)
- Full STAC/DCAT/PROV canonical schemas (we *reference* them; donâ€™t duplicate)  
- Raw telemetry/event logs (those are artifacts produced by runs)  
- UI component code (dashboards consume schemas, not define them)

---

## ğŸ“ Schema conventions

### 1) Schema draft + IDs
- Target: **JSON Schema Draft 2020-12** (unless a specific consumer requires otherwise)
- Every schema should include:
  - `$schema`
  - `$id`
  - `title`
  - `type`
  - `required`
  - `additionalProperties` (prefer `false` for dashboard contracts)

### 2) Versioning rules (SemVer)
- `schema_version`: `"MAJOR.MINOR.PATCH"`
- Breaking change â†’ bump MAJOR
- Additive change â†’ bump MINOR
- Fix/clarify â†’ bump PATCH

### 3) Deterministic & replayable
Subsystem contracts emphasize **deterministic pipelines**, validation gates, and stable â€œshape rulesâ€ for the graph.[^subsystem-contracts]  
Dashboards should be able to replay history by ingesting:
- `telemetry.ndjson` (event stream)
- `run_manifest.json` (exact artifacts + hashes)
- report artifacts (graph health, policy decisions, etc.)

### 4) Cross-link everything
Every dashboard payload must link to at least one of:
- `run_id` (pipeline run identity)
- `dataset_id` / catalog IDs
- `artifact.digest` (content-addressed identity)
- PROV IDs (`prov.activity_id`, `prov.entity_id`, `prov.agent_id`)

---

## ğŸ§± Common envelope (recommended)

Most dashboard payloads should follow a shared envelope shape (either via `$ref` or copy/paste for early MVP).

**Recommended fields**:

| Field | Type | Why it exists |
|---|---:|---|
| `schema` | string | Canonical schema name (`kfm.trace.telemetry_event`) |
| `schema_version` | string | SemVer for compatibility |
| `ts` | string (date-time) | Event/report timestamp |
| `env` | object | build/release context (`git_sha`, `deployment`, etc.) |
| `run_id` | string | Correlates everything to a pipeline run |
| `correlation_id` | string | Joins across services (API â†” pipeline â†” UI) |
| `actor` | object | human/agent/service identity |
| `severity` | string | `DEBUG`/`INFO`/`WARN`/`ERROR` |
| `labels` | object | small, indexed tags for dashboards |

> [!TIP]
> **Dashboards love stable keys.** Prefer stable identifiers (`run_id`, `dataset_id`, `digest`) over human text.

---

## ğŸ§¾ Schema inventory

> Status legend: âœ… MVP | ğŸ§ª Experimental | ğŸ§­ Roadmap

| Schema file (proposed) | Status | Producer | Dashboard consumers | Notes |
|---|---:|---|---|---|
| `telemetry_event.schema.json` | âœ… | pipeline/agents | pipeline health, latency, failures | Append-only NDJSON events for run activity[^ndjson] |
| `run_manifest.schema.json` | âœ… | pipeline/agents | reproducibility, lineage | Tracks input/output artifacts + canonical digest + idempotency key[^run-manifest] |
| `evidence_triplet.schema.json` | âœ… | catalog builder | provenance coverage | STAC + DCAT + PROV alignment contract[^evidence-triplet] |
| `policy_decision.schema.json` | âœ… | policy gate | compliance dashboard | OPA/Conftest decisions; fail-closed semantics[^policy-gates] |
| `governance_ledger_entry.schema.json` | âœ… | governance layer | audit dashboard | Immutable ledger for AI outputs + decisions[^gov-ledger] |
| `graph_health_report.schema.json` | âœ… | scheduled job | graph integrity dashboard | Weekly health checks, schema drift, orphan/dangling edges[^graph-health] |
| `graph_schema_contract.schema.json` | âœ… | graph team | drift detection | Expected labels/properties types; used to detect â€œhand editsâ€[^graph-health] |
| `focus_answer_trace.schema.json` | âœ… | AI layer | trust dashboard | Answer â†’ citations â†’ datasets â†’ PROV activities[^ai-trace] |
| `model_drift_report.schema.json` | ğŸ§ª | AI eval job | trust dashboard | drift + citation coverage + performance[^focus-telemetry] |
| `pulse_thread.schema.json` | ğŸ§­ | narrative service | narrative dashboard | Mini-stories with provenance & â€œtrust but verifyâ€ controls[^pulse] |
| `evidence_manifest.schema.json` | âœ… | narrative service | narrative dashboard | Manifest (often YAML) describing exact evidence & transformations[^evidence-manifest] |
| `concept_activation.schema.json` | ğŸ§ª | AI/narrative | research dashboard | Tracks â€œconceptual attention nodesâ€ activation for explainability[^concepts] |
| `artifact_attestation.schema.json` | ğŸ§­ | build/release | supply-chain dashboard | OCI/ORAS artifacts + Cosign signatures for reports/manifests[^oci] |

---

## ğŸ“Š Dashboard panels mapped to schemas

| Dashboard panel | Key questions it answers | Schemas |
|---|---|---|
| âš™ï¸ Pipeline Health | Whatâ€™s running? What failed? How long? | `telemetry_event`, `run_manifest` |
| ğŸ§­ Provenance Coverage | What % of layers have STAC/DCAT/PROV? | `evidence_triplet`, `policy_decision` |
| ğŸ§± Graph Integrity | Orphans? Dangling edges? Schema drift? | `graph_health_report`, `graph_schema_contract` |
| ğŸ” Compliance & Governance | What was blocked? Why? Who approved? | `policy_decision`, `governance_ledger_entry` |
| ğŸ¤– Focus Mode Trust | Are answers cited? Any drift/regressions? | `focus_answer_trace`, `model_drift_report` |
| ğŸ§µ Narrative Integrity | Do Pulse Threads link to evidence manifests? | `pulse_thread`, `evidence_manifest` |
| ğŸ§¾ Supply Chain Integrity | Are artifacts signed? Which digest is deployed? | `artifact_attestation`, `run_manifest` |

---

## ğŸ§ª Validation, CI, and â€œfail closedâ€ behavior

Policy and governance gates are described as automated checks (e.g., Conftest/OPA) that **fail closed**â€”if rules fail or evidence is missing, the pipeline should block publication.[^policy-gates]

Recommended CI checks for this folder:
1. âœ… JSON Schema validity check (draft 2020-12)
2. âœ… Example payload validation against schemas
3. âœ… Backward compatibility check (for non-breaking changes)
4. âœ… â€œNo unknown fieldsâ€ enforcement for dashboard contracts
5. âœ… Lint rules (naming, required fields, timestamps)

---

## ğŸ” Supply-chain integrity (optional but powerful)

Project proposals include storing and distributing **report artifacts** (run manifests, graph health checks, etc.) as **OCI artifacts**, moved via **ORAS** and signed via **Cosign**.[^oci]

Why dashboards care:
- Dashboards can verify the digest + signature before trusting a report
- Report history becomes content-addressable and tamper-evident
- Makes it easier to share QA artifacts across environments/regions

---

## ğŸ§  AI + UI traceability: contract expectations

### Focus Mode traceability
AI system plans emphasize that results should be linked to sources, and that AI outputs can be logged to an immutable governance ledger for audit.[^ai-trace][^gov-ledger]

Dashboards should expect:
- `answer_id` (stable)
- `citations[]` with stable IDs/digests
- `datasets[]` referenced by catalog IDs
- `prov.activity_id` linking analysis steps
- `policy_decision_id` (if gated)
- `confidence` fields (and a â€œverifyâ€ affordance)

### UI dashboards & provenance
UI documentation describes â€œstandard schemasâ€ and linking each visualization back to source metadata, plus dashboard integrations for monitoring and administration.[^ui-standard][^ui-dashboard]

---

## ğŸ§µ Narrative traceability: Pulse Threads & evidence manifests

Pulse Threads / narrative patterns propose **mini-stories** and â€œtrust but verify,â€ where story nodes link to an `evidence_manifest` and PROV bundle.[^pulse][^evidence-manifest]

Dashboards should answer:
- Which narratives lack evidence manifests?
- Which evidence items are missing digests?
- Which narratives cite datasets not present in the catalog?
- Which narratives changed without updated evidence?

---

## ğŸ§© Adding a new schema (checklist)

1. ğŸ§¾ Create `your_schema_name.schema.json`
2. ğŸ§° Use the common envelope (or document deviations)
3. ğŸ§ª Add **at least 2 example payloads**:
   - âœ… happy path
   - âŒ failure/edge case (e.g., missing evidence)
4. ğŸ”— Ensure every payload links to a `run_id` and at least one stable artifact/dataset identity
5. ğŸ” If a policy gate applies, include the policy decision reference
6. âœ… Update the **Schema Inventory** table above

---

## ğŸ—‚ï¸ Suggested folder layout (future-friendly)

```text
ğŸ§¾ schemas/
 â”œâ”€ README.md
 â”œâ”€ ğŸ§© common/
 â”‚   â””â”€ envelope.schema.json
 â”œâ”€ ğŸ“œ events/
 â”‚   â””â”€ telemetry_event.schema.json
 â”œâ”€ ğŸ§ª manifests/
 â”‚   â”œâ”€ run_manifest.schema.json
 â”‚   â”œâ”€ evidence_triplet.schema.json
 â”‚   â””â”€ evidence_manifest.schema.json
 â”œâ”€ ğŸ§± reports/
 â”‚   â”œâ”€ graph_health_report.schema.json
 â”‚   â””â”€ model_drift_report.schema.json
 â”œâ”€ ğŸ” governance/
 â”‚   â”œâ”€ policy_decision.schema.json
 â”‚   â””â”€ governance_ledger_entry.schema.json
 â””â”€ ğŸ§ª examples/
     â”œâ”€ telemetry_event.ok.json
     â”œâ”€ telemetry_event.fail.json
     â””â”€ ...
```

---

## ğŸ§¾ Example payloads (copy/paste starters)

<details>
<summary><strong>ğŸ“œ Telemetry event (NDJSON line)</strong></summary>

```json
{
  "schema": "kfm.trace.telemetry_event",
  "schema_version": "1.0.0",
  "ts": "2026-01-23T17:15:12Z",
  "env": { "deployment": "dev", "git_sha": "abc123" },
  "run_id": "run_2026-01-23T17:14:58Z_8f31",
  "correlation_id": "corr_6b9a",
  "severity": "INFO",
  "event_type": "pipeline.step.complete",
  "step": { "name": "catalog.publish", "duration_ms": 1423 },
  "artifact": { "uri": "s3://kfm/audits/run_.../run_manifest.json", "digest": "sha256:..." },
  "labels": { "pipeline": "intake", "dataset_id": "kfm.dataset.ks.usgs_gauges" }
}
```
</details>

<details>
<summary><strong>ğŸ§ª Run manifest (determinism + hashing)</strong></summary>

```json
{
  "schema": "kfm.trace.run_manifest",
  "schema_version": "1.0.0",
  "ts": "2026-01-23T17:16:00Z",
  "run_id": "run_2026-01-23T17:14:58Z_8f31",
  "idempotency_key": "sha256:9a8b...",
  "canonical_digest": "sha256:9a8b...",
  "config_hash": "sha256:4f1c...",
  "input_artifacts": [
    { "uri": "https://example.gov/data/source.zip", "digest": "sha256:1111..." }
  ],
  "output_artifacts": [
    { "uri": "s3://kfm/catalog/stac/item.json", "digest": "sha256:2222..." }
  ],
  "policy_decisions": ["pol_2026-01-23_01"],
  "prov": { "activity_id": "prov:run_8f31", "agent_id": "kfm:agent:intake_bot" }
}
```
</details>

<details>
<summary><strong>ğŸ§± Graph health report (weekly)</strong></summary>

```json
{
  "schema": "kfm.trace.graph_health_report",
  "schema_version": "1.0.0",
  "ts": "2026-01-23T00:00:00Z",
  "run_id": "healthcheck_2026-01-23",
  "graph": { "db": "neo4j", "snapshot_digest": "sha256:aaaa..." },
  "counts": { "nodes": 124533, "edges": 851220 },
  "integrity": {
    "orphan_nodes": 12,
    "dangling_edges": 3,
    "constraint_violations": 0,
    "schema_drift": { "new_properties": ["kfm:foo"], "missing_required": [] }
  },
  "artifacts": [
    { "uri": "docs/reports/qa/graph_health/2026-01-23/summary.md", "digest": "sha256:bbbb..." },
    { "uri": "docs/reports/qa/graph_health/2026-01-23/index.csv", "digest": "sha256:cccc..." }
  ],
  "severity": "WARN"
}
```
</details>

---

## ğŸ“š Project doc pack used (quick links)

> [!NOTE]
> The bullets below intentionally include **chat â€œfileciteâ€ markers** so you can open the exact uploaded source docs from this conversation.  
> If you paste this README into the repo, you can safely remove this whole `<details>` section later. âœ‚ï¸

<details>
<summary><strong>ğŸ“ Sources (chat artifacts)</strong></summary>

### Core KFM system docs
-  [oai_citation:0â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt) `Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf`
-  [oai_citation:1â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj) `ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf`
-  [oai_citation:2â€¡Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf](file-service://file-G71zNoWKxsoSW44iwZaaCC) `Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf`
-  [oai_citation:3â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T) `Document Refinement Request (Pulse Threads / Graph Health / OCI ideas)`

### Additional KFM references discovered in the pack
-  [oai_citation:4â€¡Kansas-Frontier-Matrix Design Audit â€“ Gaps and Enhancement Opportunities.pdf](file-service://file-TkRzAfTnxCYDUHauCf1NcH) `Kansas-Frontier-Matrix Design Audit â€“ Gaps and Enhancement Opportunities.pdf`
-  [oai_citation:5â€¡Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf](file-service://file-64djFYQUCmxN1h6L6X7KUw) `Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf`
-  [oai_citation:6â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32) `Scientific Method _ Research _ Master Coder Protocol Documentation.pdf`

### PDF â€œresource librariesâ€ (background / implementation references)
-  [oai_citation:7â€¡Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf](file-service://file-RrXMFY7cP925exsQYermf2) `AI Concepts & more.pdf`
-  [oai_citation:8â€¡Various programming langurages & resources 1.pdf](file-service://file-4wp3wSSZs7gk5qHWaJVudi) `Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf`
-  [oai_citation:9â€¡Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf](file-service://file-RshcX5sNY2wpiNjRfoP6z6) `Various programming langurages & resources 1.pdf`
-  [oai_citation:10â€¡AI Concepts & more.pdf](file-service://file-K6BctJjeUwvyCahLf9qdwr) `Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf`

</details>

---

## ğŸ§¾ Evidence notes (footnotes)

[^kfm-contract]: KFM explicitly adopts **contract-first** and **provenance-first** rules; â€œanything that shows up in UI or Focus Modeâ€ must be traceable, and open standards (STAC/DCAT/PROV) are called out as the backbone for metadata + lineage. [oai_citation:11â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
[^subsystem-contracts]: The subsystem contract description highlights deterministic ETL, schema validation gates, and stable contracts that downstream UI/dashboards rely on. [oai_citation:12â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU) [oai_citation:13â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
[^ndjson]: Telemetry is described as an append-only JSON Lines (NDJSON) stream that can feed dashboards/audits. [oai_citation:14â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
[^run-manifest]: Run manifests are proposed as canonical JSON (e.g., `data/audits/<run_id>/run_manifest.json`) with an idempotency key and canonical digest (RFC 8785 canonicalization + hash). [oai_citation:15â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
[^evidence-triplet]: The intake spec references an evidence approach aligned with STAC/DCAT/PROV and treats provenance as non-optional for publishing and consumption. [oai_citation:16â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj) [oai_citation:17â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
[^policy-gates]: Policy is described as automated governance gates (Conftest/OPA) that can fail closed when provenance or required constraints are missing; this also includes STAC/DCAT/PROV completeness expectations. [oai_citation:18â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T) [oai_citation:19â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)
[^graph-health]: Weekly graph health checks and report artifacts (e.g., `docs/reports/qa/graph_health/...`) are proposed, including checks like orphan nodes, dangling edges, and schema drift detection. [oai_citation:20â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj) [oai_citation:21â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
[^ai-trace]: The AI system overview emphasizes traceable, evidence-backed answers and linking results back to sources for transparency. [oai_citation:22â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi) [oai_citation:23â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)
[^gov-ledger]: The AI system overview proposes logging outputs and decisions into an immutable governance ledger for auditability. [oai_citation:24â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)
[^focus-telemetry]: The intake guide discusses QA/metrics and Focus Mode telemetry (e.g., citation coverage, drift), feeding monitoring dashboards. [oai_citation:25â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
[^ui-standard]: The UI overview calls out that visualizations should link to their source metadata and that components rely on standard schemas for extensibility.
[^ui-dashboard]: The UI overview also discusses dashboard integration (health monitoring, administrative views, â€œKansas Environmental Dashboardâ€ concept). [oai_citation:26â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt)
[^pulse]: Pulse Threads / conceptual attention nodes / narrative pattern detection are described as narrative + provenance constructs meant to be tracked and surfaced with verification affordances. [oai_citation:27â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T) [oai_citation:28â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
[^concepts]: Conceptual Attention Nodes / activation tracking is described as a way to surface why the system highlights certain themes (an explainability signal dashboards can aggregate). [oai_citation:29â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
[^evidence-manifest]: Evidence manifests (often YAML) are described as explicit inventories of supporting material and transformations, shown in the UI via â€œView Evidence,â€ with stable IDs/checksums and PROV links back into the graph. [oai_citation:30â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
[^oci]: Proposals include storing/managing artifacts (manifests/reports) as OCI artifacts and signing them with Cosign (supply-chain integrity). [oai_citation:31â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
[^mcp-traceability-matrix]: MCP documentation recommends a traceability matrix linking experiment IDs/features to code version, data/model versions, and result referencesâ€”this folderâ€™s schemas are designed to feed that table and keep it automatable. [oai_citation:32â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32) [oai_citation:33â€¡Kansas-Frontier-Matrix Design Audit â€“ Gaps and Enhancement Opportunities.pdf](file-service://file-TkRzAfTnxCYDUHauCf1NcH)
