# ğŸ§º MCP Harvests â€” Data Intake & Provenance Pipelines

![MCP](https://img.shields.io/badge/MCP-harvests-000000?logo=github)
![Provenance](https://img.shields.io/badge/provenance-first-success)
![Pipeline](https://img.shields.io/badge/pipeline-deterministic%20%26%20idempotent-blue)
![Metadata](https://img.shields.io/badge/metadata-STAC%20%7C%20DCAT%20%7C%20PROV-brightgreen)
![Ethics](https://img.shields.io/badge/ethics-FAIR%20%26%20CARE-purple)

> **Harvests** are **reproducible, reviewable intake jobs** that pull data from external sources and turn it into **KFM-ready artifacts** â€” **raw â†’ processed â†’ catalog â†’ provenance**.  
> Think: â€œ**the map behind the map**â€ ğŸ—ºï¸ğŸ” â€” every layer can be traced back to where it came from and how it was produced.

---

## ğŸ§­ What lives in `mcp/harvests/`

This folder is the **home of harvest definitions**, runbooks, and (optionally) code stubs for turning a source into:

- âœ… **Immutable inputs** (raw source files)
- âœ… **Deterministic outputs** (processed datasets)
- âœ… **Evidence-first metadata** (catalog artifacts)
- âœ… **Lineage** (provenance documents)
- âœ… **Validation + QA** (tests, checksums, schema checks)

If a dataset is in the platform, there should be a harvest (or a chain of harvests) that can **reproduce it end-to-end**.

---

## ğŸ§  Why â€œHarvestsâ€ (and not â€œETL scriptsâ€)

Harvests implement the platformâ€™s core governance values:

- **Provenance-first transparency** (no black boxes)
- **FAIR + CARE** data ethics ğŸ›¡ï¸
- **Human-in-the-loop** review for sensitive or high-impact layers
- **Deterministic & idempotent** pipelines (same input â†’ same output)

---

## ğŸ“¦ Expected artifact flow (Raw â†’ Processed â†’ Catalog)

A harvest is expected to follow this data flow pattern:

```
data/raw/        # immutable source drops (downloaded or deposited)
data/work/       # scratch / intermediate outputs (safe to delete/rebuild)
data/processed/  # stable, versioned, shareable outputs
data/catalog/    # discovery metadata (STAC + DCAT, etc.)
data/provenance/ # lineage (PROV documents, run manifests)
```

> âœ‹ **No manual edits** to `data/processed/` (or databases) as a â€œquick fixâ€.  
> Fixes happen in **code/config**, then re-run the harvest so the change is repeatable.

---

## ğŸ§¾ The Harvest Contract (what every harvest must declare)

Each harvest should provide a **machine-readable manifest** (YAML or JSON) plus a human-readable runbook.

### âœ… Minimum manifest fields

- `id`: stable harvest identifier (kebab-case recommended)
- `kind`: `dataset` | `catalog` | `documents` | `simulation-inputs` (extendable)
- `source`: URLs, contacts, publisher, license, attribution
- `inputs`: expected files/types + checksums (if available)
- `outputs`: dataset IDs + output formats
- `crs`: spatial reference (if geospatial)
- `extent`: bbox/time range when known
- `sensitivity`: `public` | `restricted` | `sensitive` + handling rules
- `steps`: fetch â†’ transform â†’ validate â†’ load â†’ emit_metadata
- `metadata`: which artifacts are emitted (STAC/DCAT/PROV)
- `provenance`: run-id, parameters, software + model versions (if AI-assisted)

### ğŸ§‘â€ğŸ« Minimum runbook (`runbook.md`)

- What the dataset is and why we ingest it
- How to run locally (and expected runtime)
- Known caveats / limitations
- Validation checklist and acceptance criteria
- Troubleshooting

---

## ğŸ§± Standard metadata output: the â€œevidence tripletâ€ ğŸ§¬

Every dataset harvest should emit a **catalog triplet**:

1. **STAC** (spatial/temporal, assets, links, licensing)
2. **DCAT** (dataset catalog record for portals/indexers)
3. **PROV** (lineage: inputs, parameters, code version, timestamps)

This is what makes layers **findable** and **auditable**, and enables external catalog harvesting too.

---

## ğŸ” Pipeline roles (how harvests are usually composed)

Harvests tend to follow these roles:

- ğŸ‘€ **Watcher** â€” detects new inputs or schedules work
- ğŸ§  **Planner** â€” decides what to run (full refresh vs incremental)
- ğŸƒ **Executor** â€” runs the job in a controlled environment
- ğŸ“¥ **Fetcher** â€” downloads / receives raw inputs
- ğŸ§¹ **Transformer** â€” cleans, normalizes, converts formats, reprojects
- âœ… **Validator** â€” schema checks, geometry validity, QA gates
- ğŸ§° **Loader** â€” writes processed artifacts + (optionally) loads DB/graph
- ğŸ·ï¸ **Metadata Emitter** â€” writes STAC/DCAT/PROV

### ğŸ—ºï¸ Lifecycle diagram

```mermaid
flowchart TD
  W[ğŸ‘€ Watcher] --> P[ğŸ§  Planner]
  P --> E[ğŸƒ Executor]
  E --> F[ğŸ“¥ Fetcher]
  F --> R[(data/raw)]
  R --> T[ğŸ§¹ Transformer]
  T --> X[(data/work)]
  X --> V[âœ… Validator]
  V --> O[(data/processed)]
  O --> L[ğŸ§° Loader]
  L --> M[ğŸ·ï¸ Metadata Emitter]
  M --> C[(data/catalog)]
  M --> PV[(data/provenance)]
```

---

## ğŸ§ª Quality gates (non-negotiables)

Before a harvest can be considered â€œgoodâ€, it should pass:

### âœ… Data quality

- Basic sanity checks (row counts, null ratios, bounds)
- Duplicate detection / stable IDs
- Deterministic outputs (same inputs â†’ same hashes)

### ğŸ—ºï¸ Geospatial integrity (if applicable)

- CRS explicitly known (no â€œmystery projectionâ€)
- Geometry validity checks
- Bounding box sanity (Kansas extent, if Kansas-specific)
- Prefer cloud-friendly formats where appropriate (e.g., COGs for rasters)

### ğŸ“š Metadata completeness

- License, attribution, source links
- STAC/DCAT/PROV present and internally consistent
- Provenance references include code/config versions

---

## ğŸ›¡ï¸ Governance & safety (FAIR + CARE in practice)

Harvests must respect:

- **Sensitive datasets** (e.g., vulnerable site locations, private data)
- **Aggregation rules** (when precision must be reduced)
- **Access policies** (public vs restricted layers)
- **Auditability** (every transformation is logged and reproducible)

> If a harvest touches sensitive material: **default to â€œrestrict + documentâ€** âœ…  
> Then add explicit policy + review steps before publication.

---

## ğŸ¤– AI-assisted harvests (Focus Mode friendly)

Some harvests will include AI-assisted steps like:

- OCR / transcription
- entity extraction (places, events, people)
- semantic tagging
- embeddings for retrieval

### Rules of the road ğŸ§­

- AI is **advisory**, not autonomous
- Every output must still be **evidence-backed**
- Record model + parameters in provenance (especially if using local LLMs)

> If you use a local model runtime (e.g., Ollama), treat the model like a dependency:
> version it, log it, and make outputs reproducible.

---

## ğŸ§° Adding a new harvest (checklist)

### 1) Create the harvest folder ğŸ—‚ï¸

Example pattern:

```
mcp/harvests/
  <harvest_id>/
    harvest.yaml
    runbook.md
    src/
    tests/
```

### 2) Register the source ğŸ§¾

- Add/append the source record in your `data/sources/*.json`
- Include license + attribution
- Include a stable source ID

### 3) Implement the pipeline steps ğŸ§±

At minimum:

- fetch â†’ raw
- transform â†’ processed
- validate
- emit STAC/DCAT/PROV

### 4) Add QA + reproducibility hooks âœ…

- deterministic IDs
- stable sorting
- fixed random seeds (if any)
- checksums for downloaded inputs where possible

### 5) Write the runbook ğŸ§‘â€ğŸ«

Make it easy for someone else to re-run your work.

### 6) Submit PR with proof ğŸ“Œ

PR should include:

- manifest + runbook
- produced metadata artifacts
- validation evidence (logs, small summaries, test output)

---

## ğŸ§· A tiny manifest example (starter template)

```yaml
id: kansas_wind_farms
kind: dataset
version: "2026-01-26"
source:
  name: "Example Publisher"
  license: "CC-BY-4.0"
  url: "https://example.org/datasets/wind_farms"
inputs:
  - type: "zip"
    expected: "wind_farms.zip"
outputs:
  - dataset_id: "kfm.energy.wind_farms"
    format: "geojson"
spatial:
  crs: "EPSG:4326"
  extent_bbox: [-102.05, 36.99, -94.59, 40.00]
metadata:
  emit: ["stac", "dcat", "prov"]
governance:
  sensitivity: "public"
  notes: "No restricted fields present."
```

---

## ğŸ§¯ Common anti-patterns (please donâ€™t ğŸ™ƒ)

- âŒ â€œI fixed it in the DB directlyâ€
- âŒ output without provenance
- âŒ â€œtrust me broâ€ datasets (no source license/attribution)
- âŒ silent coordinate changes (reprojection without documenting CRS)
- âŒ non-deterministic joins / unstable sorting
- âŒ AI-generated facts without citations

---

## ğŸ“š Project reference library (design + research shelf)

> These documents define the bigger system expectations that harvests should align with.

<details>
<summary>ğŸ“ Click to expand</summary>

### ğŸ§­ Core KFM architecture docs
- Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf
- Kansas Frontier Matrix (KFM) â€“ Comprehensive Platform Overview and Roadmap.pdf
- Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf
- ğŸ“š Kansas Frontier Matrix (KFM) â€“ Expanded Technical & Design Guide.pdf
- Kansas Frontier Matrix (KFM) â€“ Comprehensive UI System Overview (Technical Architecture Guide).pdf
- Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf
- KFM AI Infrastructure â€“ Ollama Integration Overview.pdf

### ğŸ§° Engineering + research bundles (PDF portfolios)
- AI Concepts & more.pdf
- Various programming langurages & resources 1.pdf
- Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf
- Mapping-Modeling-Python-Git-HTTP-CSS-Docker-GraphQL-Data Compression-Linux-Security.pdf
- Geographic Information-Security-Git-R coding-SciPy-MATLAB-ArcGIS-Apache Spark-Type Script-Web Applications.pdf
- Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf

</details>

---

## ğŸ¤ Contributing

- Keep harvests **small, composable, and reviewable**
- Prefer **config-driven** behavior over hardcoded constants
- Treat metadata + provenance as **first-class outputs**
- If youâ€™re unsure: ship a minimal â€œmanifest + fetch + metadataâ€ first, then iterate

---

## âœ… Definition of Done (DoD) for a Harvest

- [ ] Manifest exists and is complete
- [ ] Runbook exists and is clear
- [ ] Inputs stored under `data/raw/`
- [ ] Outputs stored under `data/processed/`
- [ ] STAC/DCAT/PROV emitted and linked
- [ ] Validation checks pass
- [ ] Provenance references code/config versions
- [ ] Governance/sensitivity documented
- [ ] Re-running yields the same outputs (or explainable version bump)

---

ğŸ§¡ Welcome to the Frontier â€” ship harvests that **anyone can reproduce**.