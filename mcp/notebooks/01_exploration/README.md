<!--
Path: mcp/notebooks/01_exploration/README.md
Purpose: Early-stage â€œlab benchâ€ notebooks for Kansas Frontier Matrix (KFM) exploration work.
-->

# ğŸ§ª 01 â€” Exploration Notebooks (MCP)

![MCP](https://img.shields.io/badge/MCP-Master%20Coder%20Protocol-111827)
![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-orange?logo=jupyter)
![Python](https://img.shields.io/badge/Python-3.11%2B-blue?logo=python)
![PostGIS](https://img.shields.io/badge/PostGIS-Spatial%20SQL-2f5d9b?logo=postgresql)
![Neo4j](https://img.shields.io/badge/Neo4j-Knowledge%20Graph-008cc1?logo=neo4j)
![Provenance](https://img.shields.io/badge/Provenance%E2%80%91first-Auditable-success)

> ğŸ§­ **North Star:** This folder is the *lab bench* for turning KFM questions into **reproducible evidence** â†’ **decisions** â†’ **tickets / ADRs** â†’ **pipelines / Story Nodes**.

---

## ğŸ§  What this folder is for

Use `01_exploration` notebooks when you need to:

- ğŸ” Validate an assumption (data, UI flow, AI behavior, performance, governance rule)
- ğŸ§ª Prototype a pipeline step (ingest â†’ validate â†’ transform â†’ publish)
- ğŸ—ºï¸ Stress-test spatial queries, tiles, time filtering, or 3D scene constraints
- ğŸ§µ Explore narrative concepts (Story Nodes, Pulse Threads, Conceptual Attention Nodes)
- ğŸ¤– Experiment with **Focus Mode** retrieval + citation rules (without â€œmystery outputsâ€)
- ğŸ§¾ Produce â€œevidence artifactsâ€ that can graduate into the repo (tests, configs, docs)

Notebooks here are **allowed to be messy**, but they must be **traceable**.

---

## ğŸ“ Folder layout

```text
mcp/notebooks/01_exploration/
â”œâ”€ ğŸ“„ README.md                         # ğŸ‘ˆ you are here ğŸ“Œ What â€œExplorationâ€ covers + conventions + promotion path
â”œâ”€ ğŸ§© 00_templates/                     # ğŸ§© Reusable notebook/report skeletons (starter ipynb + md templates)
â”œâ”€ ğŸ““ 01_notebooks/                     # ğŸ““ The actual .ipynb files (exploration work, spikes, prototypes)
â”œâ”€ ğŸ“¦ _artifacts/                       # ğŸ“¦ Notebook outputs (commit only whatâ€™s useful/reproducible)
â”‚  â”œâ”€ ğŸ“ˆ figures/                       # ğŸ“ˆ Plots, screenshots, diagrams generated by notebooks
â”‚  â”œâ”€ ğŸ“ reports/                       # ğŸ“ Writeups/experiment reports (Markdown/PDF) derived from results
â”‚  â”œâ”€ ğŸ“¤ exports/                       # ğŸ“¤ Data outputs (JSON/GeoJSON/CSV/STAC/PROV) produced for reuse
â”‚  â””â”€ ğŸ§¾ manifests/                     # ğŸ§¾ Run context: env, inputs, seeds, checksums, provenance pointers
â”œâ”€ ğŸ§¯ _scratch/                         # ğŸ§¯ Throwaway scratchpads (do not commit by default; no governance guarantees)
â””â”€ ğŸ“š _refs/                            # ğŸ“š Local reference extracts used during exploration (optional)
   â””â”€ ğŸ“– books/                         # ğŸ“– Extracted PDFs from â€œportfolioâ€ packs (keep licensing/attribution clear)
```

âœ… **Commit-friendly:** notebooks, small artifacts, run manifests, short reports  
ğŸš« **Avoid committing:** secrets, API keys, large raw datasets, unreviewed sensitive data

---

## âœ… Notebook contract (lightweight but strict)

Every exploration notebook should include the following **top cells** (copy/paste these headings):

1. **ğŸ¯ Question**
   - What are we trying to learn / prove / decide?

2. **ğŸ“¦ Inputs**
   - Dataset IDs (or paths), schema/contracts used, API endpoints, graph queries, etc.

3. **ğŸ” Repro Steps**
   - â€œRun orderâ€ + required environment variables (redacted), seeds, versions.

4. **ğŸ“¤ Outputs**
   - What files you wrote to `_artifacts/` (and why they matter)

5. **ğŸ§¾ Evidence & Decision**
   - What did we observe? What do we decide next? (link to issue/ADR if available)

### ğŸ§¾ Run Manifest (recommended)

At minimum, write a small JSON next to your outputs:

- `run_id`
- `timestamp`
- `inputs` (dataset IDs, commit hash if relevant)
- `env` (python version, major libs)
- `random_seeds`
- `checksums` for exported artifacts

---

## ğŸš€ Quick start

> If your environment is already set up, jump straight to **Notebook Backlog** below.

1) Create/activate environment  
```bash
python -m venv .venv
source .venv/bin/activate
python -m pip install -U pip
```

2) Install project requirements  
```bash
# prefer the repoâ€™s standard install path (requirements/uv/poetry/etc.)
pip install -r requirements.txt
```

3) Launch Jupyter  
```bash
jupyter lab
```

4) Start with:
- `01_notebooks/00_env_smoke_test.ipynb` âœ…
- then pick an exploration track below ğŸ¯

---

## ğŸ§­ KFM exploration tracks

| Track | What you explore | Typical outputs |
|------:|------------------|-----------------|
| 1ï¸âƒ£ | **Data intake & provenance** (contracts, STAC/DCAT/PROV, deterministic ETL) | manifests, sample catalogs, validation reports |
| 2ï¸âƒ£ | **PostGIS spatial reality** (queries, indexing, tiling, temporal filters) | SQL notebooks, EXPLAIN plans, tile benchmarks |
| 3ï¸âƒ£ | **Knowledge graph semantics** (Neo4j ontology, provenance graph, relationship patterns) | Cypher queries, graph shape checks, node/edge audits |
| 4ï¸âƒ£ | **UI + Story Nodes** (map states, timeline integration, narrative playback) | Story Node folders, JSON configs, authoring experiments |
| 5ï¸âƒ£ | **Focus Mode AI** (retrieval, citations, â€œno black box answersâ€) | RAG traces, citation coverage metrics, prompt hardening notes |
| 6ï¸âƒ£ | **Real-time + streaming** (watchers, polling patterns, dashboards) | ingestion simulations, SLA checks, anomaly prototypes |
| 7ï¸âƒ£ | **Governance & ethics** (FAIR+CARE, sensitivity tagging, fail-closed checks) | policy test cases, redaction demos, review workflows |
| 8ï¸âƒ£ | **Modeling & analytics** (Bayesian, forecasting, simulation ingestion) | model cards, parameter logs, reproducible runs |

---

## ğŸ“Œ Suggested notebook backlog (starter set)

> Use these names so the folder stays sortable and searchable ğŸ”

### ğŸ§© Setup & plumbing
- [ ] `00_env_smoke_test.ipynb` â€” confirm Python deps + DB connectivity (dev only)
- [ ] `01_contracts_and_catalog_walkthrough.ipynb` â€” contract-first + minimal catalog item
- [ ] `02_prov_run_manifest_playground.ipynb` â€” generate PROV-style run logs + checksums

### ğŸ—ºï¸ Spatial + time
- [ ] `10_postgis_spatial_queries.ipynb` â€” bounding boxes, buffers, joins, index sanity
- [ ] `11_temporal_filters_and_timeline.ipynb` â€” time slicing patterns for layers/tiles

### ğŸ§¬ Graph semantics
- [ ] `20_neo4j_graph_shape_audits.ipynb` â€” detect orphan nodes, broken provenance chains
- [ ] `21_conceptual_attention_nodes.ipynb` â€” prototype concept hubs + linking rules

### ğŸ§µ Narratives
- [ ] `30_story_node_authoring.ipynb` â€” generate Story Node folder + JSON map state
- [ ] `31_pulse_threads_microstories.ipynb` â€” prototype â€œmicro-story + evidenceâ€ objects

### ğŸ¤– Focus Mode AI
- [ ] `40_focus_mode_rag_playground.ipynb` â€” retrieval sources + citation coverage scoring
- [ ] `41_prompt_security_and_guardrails.ipynb` â€” injection tests + safe tool calling

### âš–ï¸ Governance & safety
- [ ] `50_sensitivity_redaction_patterns.ipynb` â€” location fuzzing / role-based access demos
- [ ] `51_policy_pack_test_cases.ipynb` â€” policy-as-code experiments (fail closed)

### ğŸ“ˆ Analytics / simulation
- [ ] `60_bayesian_modeling_sandbox.ipynb` â€” Bayesian primer + small KFM-relevant example
- [ ] `61_simulation_ingestion_stub.ipynb` â€” â€œkfm-sim-runâ€ style deterministic outputs

---

## ğŸ§± When an exploration â€œgraduatesâ€ ğŸ

A notebook should be promoted when it becomes:

- âœ… repeatable (no hidden steps)
- âœ… parameterized (inputs/config are explicit)
- âœ… testable (unit tests or at least validation checks exist)
- âœ… governance-friendly (provenance + sensitivity handled)
- âœ… useful to others (docs or template extracted)

### Promotion targets
- ğŸ§° **Pipeline template** (cookiecutter-style skeleton)
- ğŸ§ª **Test suite** (validators, policy checks, regression tests)
- ğŸ§¾ **Docs** (guide / ADR / how-to)
- ğŸ—ºï¸ **Story Node(s)** (narrative + map states)
- ğŸ¤– **Focus Mode skill** (retrieval tool + citation enforcement)

---

## ğŸ§° Practical guardrails (so we donâ€™t create â€œmystery systemsâ€)

### ğŸ”’ Data handling
- Keep **raw evidence immutable** (treat `data/raw/` as read-only)
- Never â€œhand-editâ€ processed outputs without capturing the change in code/config
- Store **sensitivity level + license + provenance** alongside every dataset/layer

### ğŸ§ª Determinism
- Record seeds (randomness is allowed, *untracked randomness is not*)
- If you canâ€™t reproduce a result: mark it as **non-actionable**

### ğŸ¤– AI experiments
- Focus Mode prototypes must:
  - cite sources (and refuse when sources are missing)
  - log retrieval inputs/outputs
  - avoid leaking secrets via prompts/tools

---

## ğŸ—ºï¸ Geospatial + WebGL reference usage

Some project â€œreference packsâ€ are **PDF portfolios** (they look like 1-page PDFs in GitHub).
To use them locally, either open them in Adobe Reader **or extract embedded docs**:

```bash
# List embedded attachments
pdfdetach -list "Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf"

# Extract all attachments into a folder
mkdir -p _refs/books/geospatial
pdfdetach -saveall -o _refs/books/geospatial "Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf"
```

Repeat the same pattern for:
- AI concepts pack ğŸ¤–
- data management + Bayesian pack ğŸ§ ğŸ“ˆ
- programming languages pack ğŸ› ï¸

---

## ğŸ“š Project docs this folder is built from

Keep these in mind while exploring (they define the â€œrailsâ€):

- **Architecture & features:** Story Nodes, timeline, UI/API boundaries, storage split (PostGIS + graph)
- **Data intake guide:** provenance-first ingestion, deterministic ETL, contracts, governance checks
- **UI system overview:** 2D/3D maps, narrative playback, layer management, Focus Mode UX, offline/AR
- **AI system overview:** Focus Mode architecture, retrieval/citation enforcement, W-P-E agents, security layers
- **Latest ideas & proposals:** roadmap-level features (policy pack, PROV+devops integration, reproducible research)
- **Innovative concepts:** AR storytelling, 4D digital twins, cultural protocols, sensitivity-aware sharing
- **Additional ideas:** Pulse Threads, Conceptual Attention Nodes, monitoring/audits, artifact signing patterns
- **Reference libraries:** AI foundations, geospatial/WebGL, data science/Bayesian, multi-language engineering

---

## ğŸ§¾ Glossary (shared vocabulary)

- **Story Node** ğŸ§­: A narrative step that pairs text with an explicit map state (layers + camera).
- **Focus Mode** ğŸ¤–: AI assistant mode that answers with evidence + citations, grounded in KFM data.
- **Pulse Thread** ğŸ§µ: A â€œmicro-storyâ€ tied to real-time or evolving evidence, reviewable and exportable.
- **Conceptual Attention Node** ğŸ§ : A graph â€œconcept hubâ€ that anchors queries, narratives, and AI focus.
- **W-P-E** ğŸ•µï¸â€â™‚ï¸ğŸ—ºï¸âš™ï¸: Watcher â†’ Planner â†’ Executor agent workflow for automation (with governance gates).
- **FAIR+CARE** âš–ï¸: Governance principles for data reuse *and* ethical control/benefit.

---

## ğŸ§· Definition of Done (for a â€œgoodâ€ exploration)

A notebook is â€œdoneâ€ when it ships **one or more** of:

- ğŸ“¦ an artifact in `_artifacts/` that supports a decision
- ğŸ§¾ a run manifest (inputs/outputs/checksums) proving reproducibility
- ğŸ”§ a refactor plan into a pipeline step + tests
- ğŸ§µ a narrative object (Story Node / Pulse Thread) ready for review
- ğŸ§  a clear next action (issue/ADR/ticket) with evidence attached

---

<details>
<summary>ğŸ—’ï¸ Optional: Experiment report template (copy/paste)</summary>

```markdown
# Experiment: <short name>

## ğŸ¯ Question
## ğŸ”¬ Method
## ğŸ“¦ Inputs
## âœ… Checks (validation / policy / QA)
## ğŸ“Š Results
## ğŸ§¾ Evidence links (artifacts)
## ğŸ§  Interpretation
## âœ… Decision
## ğŸ§¯ Risks / Open Questions
## â¡ï¸ Next steps
```

</details>
