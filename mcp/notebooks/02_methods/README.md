According to a document from 2026-01-20, this notebook pack defines the repeatable â€œmethods layerâ€ that bridges exploratory work and KFMâ€™s evidence-first pipelines.

# ğŸ§ª `02_methods` â€” Methods Notebooks (MCP)

![Notebook Pack](https://img.shields.io/badge/Notebook%20Pack-02__methods-blue)
![MCP](https://img.shields.io/badge/MCP-Master%20Coder%20Protocol-black)
![Evidence](https://img.shields.io/badge/Principle-Evidence--first-success)
![Metadata](https://img.shields.io/badge/Artifacts-STAC%20%7C%20DCAT%20%7C%20PROV-informational)

> **Goal:** turn ideas into **repeatable, evidence-backed methods** âœ…  
> **Outcome:** methods that can be **promoted** into `pipelines/` + catalogs (**STAC/DCAT/PROV**) + graph + API + UI ğŸ§¬ğŸ—ºï¸ğŸ¤–

---

## ğŸ” Quick navigation

- [What belongs here](#-what-belongs-here)
- [How this connects to the KFM â€œdata spineâ€](#-how-this-connects-to-the-kfm-data-spine)
- [Folder contract](#-folder-contract)
- [Method notebook template](#-method-notebook-template)
- [Method lanes](#-method-lanes)
- [Promotion path](#-promotion-path-notebook--pipeline)
- [Governance, quality gates, and safety](#-governance-quality-gates-and-safety)
- [Resource portfolios](#-resource-portfolios)
- [Project docs used](#-project-docs-used-to-define-this-pack)

---

## âœ… What belongs here

This folder is for **methods** â€” notebooks that are:

- ğŸ” **Re-runnable** (top-to-bottom, from a clean kernel)
- ğŸ§¾ **Explicit** about inputs, outputs, assumptions, and limitations
- ğŸ§¬ **Provenance-friendly** (ready to become STAC/DCAT/PROV + graph references)
- ğŸ§ª **Repeatable techniques** (not just one-off exploration)
- ğŸ§© **Composable** (a method can later become a pipeline step or reusable module)

> Think: â€œmethod notebookâ€ = a **documented technique**, not a dumping ground.

---

## ğŸš« What does NOT belong here

- âŒ Long-lived, manual â€œpet notebooksâ€ that only run on one machine
- âŒ Hidden data edits (no mystery transformations with no lineage)
- âŒ Copy-pasted data blobs committed into the notebook outputs
- âŒ Anything that bypasses the â€œdata spineâ€ (raw â†’ work â†’ processed â†’ catalogs â†’ graph â†’ API â†’ UI)
- âŒ Claims with no evidence trail (especially AI-generated text without source context)

---

## ğŸ§¬ How this connects to the KFM â€œdata spineâ€

KFMâ€™s core philosophy is **pipeline traceability** and **catalog-driven discovery**.

```mermaid
flowchart LR
  A[ğŸ§± data/raw] --> B[ğŸ§° data/work]
  B --> C[ğŸ data/processed]
  C --> D[ğŸ“š catalogs: STAC + DCAT + PROV]
  D --> E[ğŸ•¸ï¸ graph]
  E --> F[ğŸ§© API layer]
  F --> G[ğŸ—ºï¸ UI: Map + Story Nodes + Focus Mode]
```

**Methods notebooks live here:** right at the boundary between ğŸ§° `data/work` and ğŸ `data/processed`.  
They are where we validate **how** a transformation should work before it becomes a production pipeline.

---

## ğŸ“¦ Folder contract

### ğŸ“¥ Inputs (what you read)

You should pull inputs from one of these patterns:

- `data/raw/<domain>/...` for original ingested sources
- `data/work/<domain>/...` for intermediate/staging products
- `catalogs/...` / `data/stac/...` / `data/catalog/...` / `data/prov/...` if youâ€™re **deriving from published boundary artifacts**

### ğŸ“¤ Outputs (what you write)

A methods notebook should write outputs in a **predictable** layout that supports review + promotion.

Recommended convention:

```text
data/
â””â”€ ğŸ§ª work/
   â””â”€ ğŸ““ notebooks/
      â””â”€ ğŸ§ª <method_id>/                 # Method/workflow identifier (e.g., ndvi_composite.v1, geocode_spike.v0)
         â””â”€ ğŸ·ï¸ <run_id>/                  # One execution run (time-stamped or UUID; immutable once finalized)
            â”œâ”€ ğŸ§¾ run_manifest.json        # Run ledger: who/what/when + inputs/outputs + tool versions + checksums
            â”œâ”€ ğŸ›ï¸ params.json              # Parameters used for this run (AOI, dates, thresholds, seeds, options)
            â”œâ”€ ğŸªµ logs.txt                 # Captured logs (stdout/stderr); sanitize before committing/sharing
            â”œâ”€ ğŸ–¼ï¸ previews/                # Quicklook outputs (PNG/HTML) for fast review without rerunning
            â””â”€ ğŸ“¦ outputs/                 # Candidate artifacts produced by the run (promote to processed/ when accepted)
```

> If your notebook is producing something â€œpublishableâ€, treat it like a first-class dataset:
> it should be promotable to `data/processed/<domain>/...` **with** metadata artifacts.

---

## ğŸ§¾ Method notebook template

Use this as a lightweight standard. You can paste this into the **first Markdown cell**.

<details>
<summary><strong>ğŸ“„ Template (copy/paste)</strong></summary>

```markdown
# ğŸ§ª Method: <human-readable title>

## ğŸ†” Method ID
- `method_id`: `M02-<LANE>-<###>` (example: `M02-GEO-001`)
- `status`: `draft | validated | promoted`

## ğŸ¯ Research question
What are we trying to learn or prove?

## ğŸ“¥ Inputs
- dataset IDs / file paths
- expected schema(s)
- spatial/temporal scope

## ğŸ§° Procedure
- steps (numbered)
- tools/libraries
- parameters (with defaults)

## âœ… Validation
- checks performed
- expected ranges
- failure modes

## ğŸ“¤ Outputs
- files produced
- where they are written
- â€œpromotion notesâ€ (how to turn this into a pipeline step)

## ğŸ§  Notes & limitations
- assumptions
- known gaps
- next steps

## ğŸ§¾ Evidence & provenance hooks
- run_id
- git commit / branch
- environment snapshot
- link to STAC/DCAT/PROV (if generated)
```

</details>

---

## ğŸ§° Method lanes

This folder is organized by **lanes** (you can implement as subfolders or naming conventions).

### ğŸ—ºï¸ GEO lane â€” raster/vector/geospatial processing

Typical methods:

- ğŸ§­ georeferencing & rectification
- ğŸ§± tiling/vector tiles, PMTiles, raster pyramids
- ğŸ—ƒï¸ PostGIS spatial queries, spatial joins, buffers
- ğŸ›°ï¸ remote sensing preprocessing, COG workflows
- â³ time-slicing layers for historical timelines

**Good output shapes:** GeoParquet, GeoJSON, COGs, tilesets + STAC metadata.

---

### ğŸ•¸ï¸ GRAPH lane â€” knowledge graph + ontology mapping

Typical methods:

- ğŸ§· entity resolution & dedup
- ğŸ§¾ schema alignment (CIDOC-CRM / PROV-O / GeoSPARQL style patterns)
- ğŸ”— relationship extraction (document â†” place â†” event â†” source)
- ğŸ§ª query notebooks (Cypher) with â€œexplainableâ€ result sets

**Golden rule:** graph nodes should reference catalog artifacts (IDs, DOIs, STAC Item IDs) rather than embedding bulky data.

---

### ğŸ¤– AI lane â€” NLP / CV / retrieval / evaluation

Typical methods:

- ğŸ§  OCR â†’ clean â†’ segment â†’ entity extraction â†’ linking
- ğŸ§­ retrieval (vector + graph hybrid), prompt/eval harnesses
- ğŸ§ª model comparison notebooks (accuracy + failure analysis)
- ğŸª explainability hooks (why the model answered / what evidence it used)

**If text is AI-generated:** label it, cite the evidence trail, and keep a human-review step before anything becomes â€œgoverned narrativeâ€.

---

### ğŸ“– STORY lane â€” narratives, Story Nodes, UI-ready bundles

Typical methods:

- ğŸ§· build/validate Story Node Markdown + JSON state (map camera, layer activation, timeline position)
- ğŸ§¾ evidence manifests for every claim
- ğŸ—ºï¸ map-state previews (screenshots/exports)
- ğŸ” â€œnarrative lintâ€ (broken dataset IDs, missing citations, sensitivity flags)

---

### ğŸ›°ï¸ SIM lane â€” simulation, forecasting, scenario modeling

Typical methods:

- ğŸŒ¦ï¸ bias correction & uncertainty tracking
- ğŸ§ª scenario generation (with clear assumptions)
- ğŸ“ˆ validation against observed data
- ğŸ§¾ provenance bundles for any derived datasets

---

## ğŸ” Promotion path: notebook â†’ pipeline

When a method is ready, promote it like this:

1. âœ… **Stabilize the method**
   - parameterize it (no hardcoded machine paths)
   - add deterministic controls (seed, stable sort orders, fixed CRS conversions)

2. ğŸ§© **Extract reusable code**
   - move core logic into `pipelines/` (or a shared library module)
   - keep notebook as â€œhow to use / how to validateâ€

3. ğŸ“š **Produce boundary artifacts**
   - STAC (items/collections)
   - DCAT (dataset entry)
   - PROV (lineage bundle)

4. ğŸ•¸ï¸ **Graph ingest (by reference)**
   - store relationships + IDs that point back to catalogs

5. ğŸ§© **Expose through API**
   - redaction & sensitivity checks happen here

6. ğŸ—ºï¸ **Surface in UI**
   - map layer + Story Nodes + Focus Mode evidence bundle

---

## ğŸ›¡ï¸ Governance, quality gates, and safety

### âœ… Minimum â€œDefinition of Doneâ€ for a methods notebook

- [ ] Runs top-to-bottom from a clean kernel
- [ ] Has a clear **method ID** and **status**
- [ ] Produces `run_manifest.json` (or equivalent)
- [ ] Writes outputs into a run-scoped folder
- [ ] Includes validation checks + failure notes
- [ ] Includes promotion notes (what becomes a pipeline step)
- [ ] Does not leak sensitive coordinates/PII
- [ ] Any AI-generated narrative is labeled and reviewable

### ğŸ” Sensitive data handling (baseline)

If a dataset is sensitive:

- ğŸ§Š generalize/fuzz locations (donâ€™t expose exact points)
- ğŸ”’ require access controls (donâ€™t publish publicly by default)
- ğŸ·ï¸ tag sensitivity + license constraints in metadata
- âš ï¸ UI should warn or hide restricted layers

---

## ğŸ“š Resource portfolios

Several project references are delivered as **PDF Portfolios** (multi-document bundles).  
These are intentionally included as â€œoffline librariesâ€ for methods development.

- ğŸ¤– **AI Concepts & more** (AI + ML references)
- ğŸ—ºï¸ **Maps / Google Maps / Virtual Worlds / WebGL** (geo + visualization references)
- ğŸ§  **Data Management / Data Science / Bayesian Methods** (data engineering + inference references)
- ğŸ§° **Programming Languages & Resources** (language/tooling references)

> Tip: if your environment canâ€™t view PDF Portfolios directly, extract embedded files first (or open in Acrobat).

---

## ğŸ“ Project docs used to define this pack

These files define the expectations, architecture, UI contract, and governance model that methods notebooks must align with:

- ğŸ“˜ **KFM â€” Comprehensive Technical Documentation**
- ğŸ§± **KFM â€” Comprehensive Architecture, Features, and Design**
- ğŸ§­ğŸ¤– **KFM â€” AI System Overview**
- ğŸ–¥ï¸ **KFM â€” Comprehensive UI System Overview**
- ğŸ“š **KFM â€” Data Intake (Technical & Design Guide)**
- ğŸŒŸ **KFM â€” Latest Ideas & Future Proposals**
- ğŸ’¡ **Innovative Concepts to Evolve KFM**
- ğŸ§  **Additional Project Ideas**
- ğŸ§ª **Scientific Method / Research / Master Coder Protocol (MCP) Documentation**
- ğŸ—ºï¸ **KFM Open-Source Geospatial Historical Mapping Hub Design**
- ğŸ§¾ **MASTER_GUIDE / Markdown Guide v13** (data spine + governance patterns)
- ğŸ“¦ **PDF Portfolios:** AI / Maps-WebGL / Data Mgmt-Bayesian / Programming Resources

---

## ğŸ¤ Contributing (tiny checklist)

- âœ… keep notebooks small and purpose-driven
- âœ… prefer â€œmethodâ€ notebooks here; put one-off logs in `mcp/experiments/`
- âœ… add/refresh the method metadata cell + summary cell
- âœ… ensure outputs are written under `data/work/notebooks/<method_id>/<run_id>/`
- âœ… link the method to related SOPs (if any) ğŸ“œ

Happy building ğŸ§­âœ¨
