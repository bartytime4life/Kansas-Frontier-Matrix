# ğŸ““ MCP Notebooks (Kansasâ€‘Matrixâ€‘System / KFM) ğŸ§ªğŸ—ºï¸

![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-orange?logo=jupyter)
![Python](https://img.shields.io/badge/Python-Geo%20%26%20AI-blue?logo=python)
![R](https://img.shields.io/badge/R-EDA%20%26%20QC-276DC3?logo=r)
![STAC](https://img.shields.io/badge/STAC-Asset%20Catalog-2ea44f)
![DCAT](https://img.shields.io/badge/DCAT-Dataset%20Discovery-6f42c1)
![W3C%20PROV](https://img.shields.io/badge/W3C%20PROV-Lineage%20Ready-000000)
![PostGIS](https://img.shields.io/badge/PostGIS-Geo%20DB-336791?logo=postgresql)
![Neo4j](https://img.shields.io/badge/Neo4j-Knowledge%20Graph-008CC1?logo=neo4j)
![MapLibre](https://img.shields.io/badge/MapLibre-2D%20Maps-00B3B3)
![Cesium](https://img.shields.io/badge/Cesium-3D%20Globe-2E6EF7)
![WebGL](https://img.shields.io/badge/WebGL-3D%20Viz%20Prototypes-ff69b4?logo=webgl)
![Papermill](https://img.shields.io/badge/Papermill-Parameterized-4B8BBE)
![OPA%2FRego](https://img.shields.io/badge/OPA%2FRego-Policy%20Gates-7d4cdb)
![CI](https://img.shields.io/badge/CI-GitHub%20Actions-2088FF?logo=githubactions)

> ğŸ§­ **What lives here:** reproducible notebooks that explore data, validate assumptions, prototype methods, and **produce evidence artifacts** that can graduate into governed datasets + catalogs (STAC/DCAT/PROV) + graph + APIs + UI + Story/Focus.
>
> ğŸ§  **Mental model:** notebooks are *research instruments* + *design receipts* â€” not a dumping ground.
>
> ğŸ§± **KFM invariant:** **no narrative or UI feature leapfrogs evidence**. Everything flows through the canonical pipeline.

---

## ğŸ§­ Table of Contents
- [ğŸ§  How notebooks fit the KFM pipeline](#-how-notebooks-fit-the-kfm-pipeline)
- [ğŸ—ºï¸ Folder map (with intent)](#ï¸-folder-map-with-intent)
- [ğŸš€ Quickstart (local + reproducible)](#-quickstart-local--reproducible)
- [ğŸ§± Notebook contract](#-notebook-contract)
- [ğŸ“¦ Outputs & artifacts](#-outputs--artifacts)
- [ğŸ” Lifecycle: Notebook â†’ Evidence â†’ Graph/API â†’ UI â†’ Story/Focus](#-lifecycle-notebook--evidence--graphapi--ui--storyfocus)
- [ğŸ“‚ Folder guide](#-folder-guide)
- [âœ… Lightweight QA gates (high ROI)](#-lightweight-qa-gates-high-roi)
- [ğŸ§¾ Evidence artifact pack (when promoting results)](#-evidence-artifact-pack-when-promoting-results)
- [ğŸ“š Reference-to-folder map (project library)](#-reference-to-folder-map-project-library)
- [âœ… PR checklist (for notebook contributions)](#-pr-checklist-for-notebook-contributions)
- [âœ¨ North star](#-north-star)

---

## ğŸ§  How notebooks fit the KFM pipeline

> [!IMPORTANT]
> **Pipeline ordering is absolute (nonâ€‘negotiable):**  
> **ETL â†’ STAC/DCAT/PROV catalogs â†’ Neo4j graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode**

Notebooks live primarily in the **ETL / Evidence** stage (MCP = â€œMethods & Computational Experimentsâ€), and they should either:
- stay as **exploration receipts**, or
- **graduate** into pipelines + catalog artifacts + governed UI exposure.

```mermaid
flowchart LR
  subgraph MCP["ğŸ§ª MCP (Methods & Computational Experiments)"]
    N["ğŸ““ Notebooks\nEDA Â· methods Â· sim Â· viz prototypes"] --> E["ğŸ“¦ Evidence artifacts\n(processed outputs + receipts)"]
  end

  E --> C["ğŸŒ Catalogs\nSTAC + DCAT + PROV"]
  C --> G["ğŸ•¸ï¸ Graph\nNeo4j (references catalogs)"]
  G --> A["ğŸ”Œ APIs\ncontract-first + redaction"]
  A --> U["ğŸ—ºï¸ UI\nReact Â· MapLibre Â· (opt) Cesium"]
  U --> S["ğŸ§¾ Story Nodes\n(governed narratives)"]
  S --> F["ğŸ” Focus Mode\nprovenance-linked context bundle"]
```

**Two rules to tattoo on your brain ğŸ§ ğŸª¡**
1. ğŸ§¾ **Evidence-first:** if itâ€™s a claim, it must be traceable to a **cataloged source** (or it doesnâ€™t ship).
2. ğŸš§ **API boundary:** the UI doesnâ€™t talk directly to the graph or raw stores â€” it goes through governed APIs.

---

## ğŸ—ºï¸ Folder map (with intent)

```text
mcp/notebooks/
â”œâ”€ ğŸ“Œ 00_templates/                 # starting points (clean, reusable)
â”œâ”€ ğŸ” 01_exploration/               # EDA + QC + audit notebooks
â”œâ”€ ğŸ§ª 02_methods/                   # algorithms + baselines + eval harnesses
â”œâ”€ ğŸ—ºï¸ 03_geospatial/                # vector/raster/STAC experiments
â”œâ”€ ğŸ›°ï¸ 04_remote_sensing/            # EO workflows + export recipes
â”œâ”€ ğŸ§¯ 05_simulation/                # modeling/simulation + V&V harnesses
â”œâ”€ ğŸŒ 06_viz_web/                   # WebGL / UI / interaction prototypes
â”œâ”€ ğŸ§± 07_data_engineering/          # Postgres/PostGIS, ETL spikes, scaling tests
â”œâ”€ ğŸ›¡ï¸ 08_security_defensive/        # defensive security reviews (authorized only)
â”œâ”€ âš–ï¸ 09_governance_ethics/         # FAIR/CARE, sovereignty, impact notes
â””â”€ README.md                        # ğŸ‘ˆ you are here
```

> [!TIP]
> **Where â€œpublishedâ€ stuff belongs:**  
> - Data outputs â†’ `data/work/<domain>/â€¦` and `data/processed/<domain>/â€¦`  
> - Catalog artifacts â†’ `data/stac/â€¦`, `data/catalog/dcat/â€¦`, `data/prov/â€¦`  
> - Story Nodes â†’ `docs/reports/story_nodes/â€¦` (draft â†’ published workflow)

---

## ğŸš€ Quickstart (local + reproducible)

### 1) Open notebooks
- VS Code + Jupyter extension *or* JupyterLab.

### 2) Environment (pick one; pin it) ğŸ§ª
- `venv` / `conda` / `uv` are all fine â€” **prefer one per branch of work**.
- Keep geo stacks pinned (GDAL/PROJ/rasterio/pyproj can drift).
- If youâ€™re building notebooks that should be â€œoneâ€‘click runnableâ€ later (Binder/JupyterHub), keep deps minimal + explicit.

### 3) Data access (no mystery paths) ğŸ—ƒï¸
- Prefer governed sources:
  - **STAC** (assets),
  - **PostGIS/PostgreSQL** (features + vector tiles),
  - **Parquet/COG/PMTiles** (cloudâ€‘friendly artifacts),
  - curated exports (e.g., EO exports).
- Notebooks should **not** hide â€œmystery local paths.â€
  - âœ… Use relative repo paths (`../../data/...`)
  - âœ… Or env vars (`KFM_DATA_ROOT`, `DATABASE_URL`)
  - âŒ Avoid `/Users/alice/Desktop/...`

---

## ğŸ§± Notebook contract

### âœ… Mustâ€‘haves (nonâ€‘negotiable)
- **Clear title + scope** (first cell): what question are we answering?
- **Inputs + provenance**:
  - dataset IDs (example IDs below),
  - STAC Item/Collection IDs or file references,
  - query snippets (SQL/CQL),
  - source URL references (if raw ingestion).
- **Parameters cell** (tag `parameters` if using papermill).
- **Determinism**:
  - fixed RNG seeds where relevant (`numpy.random.default_rng(seed)`),
  - stable sorting before joins/aggregations,
  - log environment + package versions if outcomes depend on it.
- **Outputs**:
  - write to predictable locations (see [Outputs & artifacts](#-outputs--artifacts)).
- **Conclusion block**:
  - what we learned,
  - what failed,
  - what to do next,
  - **promote or archive** decision.

### ğŸ§¾ KFMâ€‘specific contract (donâ€™t break the pipeline)
- **Raw data is immutable**:
  - treat `data/raw/â€¦` as readâ€‘only evidence (no inâ€‘place edits).
- **If you publish a dataset (or AI output), you must mint receipts**:
  - STAC + DCAT + PROV (the â€œevidence tripletâ€).
- **Classification & sovereignty propagate**:
  - no derivative artifact can be less restricted than its inputs.
- **UI access goes through APIs**:
  - prototypes can mock locally, but promotion requires API contracts.

---

## ğŸ§¾ Dataset IDs & naming (recommended)

> [!NOTE]
> Use stable dataset IDs early â€” they become the glue across catalogs, graph, APIs, UI, and Focus Mode.

Examples seen in KFM docs:
- `kfm.ks.landcover.2000_2020.v1`
- `kfm.ks.drought_index.1900_2020.v1`

**Guideline (practical):**
- `kfm.<region>.<theme>.<dataset>.<time_or_variant>.v<integer>`

---

## ğŸ“¦ Outputs & artifacts

### Tier 1: notebook-local artifacts (OK to commit small) ğŸ“
Use this when youâ€™re still exploring, comparing methods, or prototyping UI visuals.

```text
mcp/notebooks/<folder>/<topic>/
â”œâ”€ notebook.ipynb
â”œâ”€ outputs/
â”‚  â”œâ”€ figures/
â”‚  â”œâ”€ tables/
â”‚  â”œâ”€ logs/
â”‚  â””â”€ receipts/         # run manifest + hashes (lightweight)
â””â”€ notes.md             # optional: decisions, caveats, TODOs
```

**Rule of thumb:** commit small artifacts that explain decisions; keep heavy rasters/tiles out of git unless the repo is explicitly using LFS/DVC.

### Tier 2: governed evidence artifacts (publishable) ğŸ§±âœ…
If results are meant to feed **graph/API/UI/Story/Focus**, put them in canonical places:

```text
data/
â”œâ”€ <domain>/
â”‚  â”œâ”€ raw/              # immutable inputs
â”‚  â”œâ”€ work/             # intermediate outputs
â”‚  â””â”€ processed/        # final, served outputs
â”œâ”€ stac/
â”‚  â”œâ”€ collections/
â”‚  â””â”€ items/
â”œâ”€ catalog/
â”‚  â””â”€ dcat/
â””â”€ prov/                # provenance bundles (per dataset/run)
```

---

## ğŸ” Lifecycle: Notebook â†’ Evidence â†’ Graph/API â†’ UI â†’ Story/Focus

```mermaid
flowchart LR
  T["ğŸ“Œ Template"] --> X["ğŸ” Exploration\n(QC + audit)"]
  X --> M["ğŸ§ª Methods\n(baselines + eval)"]
  M --> P["ğŸ“¦ Evidence artifact\n(data/processed + STAC/DCAT/PROV)"]
  P --> KG["ğŸ•¸ï¸ Graph ingest\n(Neo4j refs catalogs)"]
  KG --> API["ğŸ”Œ API\n(OpenAPI/GraphQL + redaction)"]
  API --> UI["ğŸ—ºï¸ UI\nMapLibre/Cesium + timeline"]
  UI --> SN["ğŸ§¾ Story Node\n(governed narrative)"]
  SN --> FM["ğŸ” Focus Mode\ncontext bundle + citations"]
```

**Promotion signals (graduate a notebook):**
- âœ… repeatable runs (fresh kernel, topâ€‘toâ€‘bottom),
- âœ… deterministic outputs (or differences explained),
- âœ… inputs/outputs governed + traceable,
- âœ… STAC/DCAT/PROV produced (if publishable),
- âœ… performance understood (time/memory/IO),
- âœ… falsification plan (what would disprove this?),
- âœ… integration path exists (pipeline/module/API/UI).

---

## ğŸ“‚ Folder guide

<details>
<summary><b>ğŸ“Œ 00_templates/ â€” starting points (clean, reusable)</b></summary>

**Use for:** canonical notebook scaffolds (copy â†’ run â†’ replace).  
**Includes (recommended):**
- ğŸ” EDA/QC template (missingness, distributions, spatial sanity checks)
- ğŸ§ª Method baseline template (train/validate/report + ablation slots)
- ğŸ—ºï¸ Geo template (CRS checks, reprojection, bbox/geometry, tiling)
- ğŸ§¯ Simulation template (assumptions, calibration, V&V hooks)
- ğŸ§¾ Evidence artifact template (writes STAC/DCAT/PROV stubs + run manifest)

**Tip:** if a notebook is copied more than twice, it becomes a template. ğŸ˜„

</details>

<details>
<summary><b>ğŸ” 01_exploration/ â€” EDA + QC + audit notebooks</b></summary>

**Use for:** first contact with a dataset (or validating a new ingestion).  
**Typical outputs:** QC report, plots, summary tables, anomaly lists, data dictionary notes.

**Good fits:**
- Distribution checks, missingness heatmaps, outlier catalogs
- Spatial QC: CRS consistency, geometry validity, coverage gaps
- Temporal QC: cadence, timezones, duplicates, suspicious discontinuities
- Catalog QA: â€œdoes the STAC/DCAT/PROV reflect what we actually produced?â€

</details>

<details>
<summary><b>ğŸ§ª 02_methods/ â€” algorithms + baselines + eval harnesses</b></summary>

**Use for:** modeling experiments that need to be benchmarked and compared.  
**Typical outputs:** baseline metrics, calibration curves, error analysis, robustness checks.

**Examples:**
- Regression baselines (OLS/Ridge/Lasso, robust regression)
- Bayesian baselines (priors â†’ posteriors â†’ decision framing)
- NLP/Extraction baselines (e.g., entity extraction from historical text)
- Focus Mode evaluation notebooks (retrieval quality + citation integrity)

</details>

<details>
<summary><b>ğŸ—ºï¸ 03_geospatial/ â€” vector/raster/STAC experiments</b></summary>

**Use for:** geospatial transformations, raster math, vector ops, STAC packaging.  
**Typical outputs:** GeoParquet/GeoJSON prototypes, COG/PMTiles prototypes, STAC Items/Collections drafts.

**Validate these behaviors:**
- CRS correctness (store it; donâ€™t assume it)
- Bounding boxes & geometries consistent across transforms
- Raster metadata (shape/transform) preserved + documented
- Outputs are â€œtileâ€‘readyâ€:
  - COG/tiles/PMTiles for rasters,
  - optimized parquet + indexes for vectors

**PostGIS sanity patterns ğŸ§°**
- Geometry validity checks (`ST_IsValid`, `ST_IsValidDetail`)
- Spatial joins and attribution tests
- Index impact (GiST/SPâ€‘GiST) on query latency

</details>

<details>
<summary><b>ğŸ›°ï¸ 04_remote_sensing/ â€” EO workflows + export recipes</b></summary>

**Use for:** EO workflows, sensor comparisons, export patterns, QA masks.  
**Typical outputs:** export recipes, band math notebooks, validation plots, STAC-ready assets.

**Keep it disciplined:**
- Log dataset IDs + date ranges + masking logic
- Track scale/CRS for every export
- Write â€œwhat changedâ€ notes when switching sensors/products

</details>

<details>
<summary><b>ğŸ§¯ 05_simulation/ â€” modeling/simulation + V&amp;V harnesses</b></summary>

**Use for:** simulation spikes + verification/validation scaffolding.  
**Typical outputs:** parameter sweeps, sensitivity analysis, calibration runs, validation reports.

**Practical V&amp;V mindset:**
- State assumptions clearly (units, boundaries, invariants)
- Compare against known solutions / invariants when possible
- Treat â€œmodel worksâ€ as a testable claim, not a vibe ğŸ˜„

**When simulations become evidence artifacts:** package them like datasets (catalog + provenance + uncertainty).

</details>

<details>
<summary><b>ğŸŒ 06_viz_web/ â€” WebGL / UI / interaction prototypes</b></summary>

**Use for:** interactive prototypes (WebGL, 2Dâ†”3D, timeline UX, Story Node playback).  
**Typical outputs:** proofâ€‘ofâ€‘concept demos, interaction notes, performance profiles.

**Common patterns:**
- MapLibre 2D + optional Cesium 3D transitions (camera paths)
- Layer toggles, time sliders, narrative annotations
- Provenance overlays (â€œmap beyond the mapâ€ â€” what am I looking at and why?)
- Offline/field prototypes (data packs, reduced basemaps, lowâ€‘bandwidth modes)
- AR concept experiments (museum / field overlays)

</details>

<details>
<summary><b>ğŸ§± 07_data_engineering/ â€” Postgres/PostGIS, ETL spikes, scaling tests</b></summary>

**Use for:** schema experiments, ETL prototypes, indexing benchmarks, catalog generation.  
**Typical outputs:** SQL notebooks, migration drafts, indexing benchmarks, query recipes.

**Focus areas:**
- PostGIS geometry types + indexes (GiST/SPâ€‘GiST)
- Vector tile strategies (e.g., generating MVT from PostGIS)
- Parquet partitioning + predicate pushdown
- Managed data promotion (raw â†’ work â†’ processed)
- Hardware-aware scaling: identify what breaks first (IO, memory, compute)

</details>

<details>
<summary><b>ğŸ›¡ï¸ 08_security_defensive/ â€” defensive security reviews (authorized only)</b></summary>

**Use for:** threat modeling, hardening checklists, dependency audits, logging/monitoring design.

> [!WARNING]
> ğŸ§· **Strict boundary: defensive-only.**  
> No exploit development, no payloads, no â€œhow to break in.â€  
> Any testing beyond local toy targets requires **explicit written authorization**.

Useful notebook themes:
- secrets scanning results & remediation notes
- SBOM / dependency risk snapshots
- policy gate evaluations (OPA/Rego) for new artifacts
- query auditing patterns (privacy + inference controls)

</details>

<details>
<summary><b>âš–ï¸ 09_governance_ethics/ â€” FAIR/CARE, sovereignty, impact notes</b></summary>

**Use for:** governance docs, ethical risk assessments, policy-aware design notes.  
**Typical outputs:** model cards, data use memos, provenance policies, impact analyses.

**Good fits:**
- â€œWhat should we not build?â€ ğŸš«
- Consent/provenance constraints & cultural protocols
- Bias & accountability notes for models and map outputs
- Human-centered framing for narrative UX
- Privacy-preserving releases (aggregation, kâ€‘anonymity, differential privacy where appropriate)

</details>

---

## âœ… Lightweight QA gates (high ROI)

These checks keep notebooks from becoming brittle pipelines:

- **Metadata completeness:** capture CRS / bbox / geometry for geo outputs
- **Evidence triplet readiness:** if publishable â†’ STAC + DCAT + PROV produced
- **Link integrity:** STAC/DCAT references resolvable; no dead anchors
- **Schema drift protection:** validate against JSON Schemas / profiles when available
- **Determinism:** stable seeds + stable ordering + logged versions
- **Policy gates (fail-closed):** classification propagation, sovereignty constraints
- **Secrets safety:** no tokens, no private endpoints, no â€œoopsâ€ credentials

---

## ğŸ§¾ Evidence artifact pack (when promoting results)

When a notebook result is meant to become a **first-class KFM evidence artifact**, produce:

### 1) The data product ğŸ“¦
- stored under `data/processed/<domain>/...` (or canonical storage),
- referenced by STAC/DCAT distributions.

### 2) The evidence triplet ğŸŒ
- **STAC** (Collection + Item(s)) â†’ describes assets
- **DCAT** (Dataset entry) â†’ discoverability
- **PROV** (lineage bundle) â†’ inputs, steps, agents, params, hashes

### 3) A run manifest (MCP receipt) ğŸ§¾
A tiny JSON file that makes reproduction realistic:

```json
{
  "run_id": "2026-01-19__landcover_qc__<gitsha>",
  "notebook": "mcp/notebooks/01_exploration/landcover_qc/notebook.ipynb",
  "dataset_ids": ["kfm.ks.landcover.2000_2020.v1"],
  "inputs": [
    {"type": "stac_item", "id": "â€¦"},
    {"type": "file", "path": "data/raw/â€¦", "sha256": "â€¦"}
  ],
  "outputs": [
    {"type": "data", "path": "data/processed/â€¦", "sha256": "â€¦"},
    {"type": "stac_item", "path": "data/stac/items/â€¦"},
    {"type": "dcat", "path": "data/catalog/dcat/â€¦"},
    {"type": "prov", "path": "data/prov/â€¦"}
  ],
  "params": {"seed": 42, "notes": "â€¦"}
}
```

> [!TIP]
> If it canâ€™t be explained + reproduced from the manifest and receipts, itâ€™s not ready to ship.

---

## ğŸ“š Reference-to-folder map (project library)

> ğŸ§  This repo includes a curated project library. Use it to shape notebook design, governance, and promotion readiness.

| Project file ğŸ“š | Primary notebook home ğŸ§­ | What to borrow ğŸ§© |
|---|---|---|
| **ğŸ“š KFM Data Intake â€“ Technical & Design Guide** | ğŸ§± 07_data_engineering / ğŸ” 01_exploration | Raw immutability, managed promotion (rawâ†’workâ†’processed), ingestion gates, evidence triplet expectations |
| **KFM â€“ Comprehensive Architecture, Features, and Design** | ğŸ§± 07_data_engineering / ğŸŒ 06_viz_web | Canonical subsystem boundaries, metadata-as-code, CI validation mindset |
| **KFM â€“ Comprehensive Technical Documentation** | ğŸ“Œ 00_templates / ğŸ§± 07_data_engineering / ğŸŒ 06_viz_web | Pipeline determinism, catalog QA tooling, UI behavior patterns, performance notes |
| **KFM â€“ Comprehensive UI System Overview** | ğŸŒ 06_viz_web / ğŸ—ºï¸ 03_geospatial | Layer registry thinking, timeline UX, Story Node playback, provenance overlays, offline/mobile direction |
| **KFM â€“ AI System Overview ğŸ§­ğŸ¤–** | ğŸ§ª 02_methods / âš–ï¸ 09_governance_ethics | Focus Mode grounding + citations, retrieval evaluation, guardrails, model cards + explainability expectations, oneâ€‘click notebook vision |
| **Innovative Concepts to Evolve KFM** | ğŸŒ 06_viz_web / ğŸ§¯ 05_simulation / âš–ï¸ 09_governance_ethics | 4D digital twin concepts, AR storytelling, participatory archive patterns, cultural protocol enforcement, GeoXAI ideas |
| **ğŸŒŸ Latest Ideas & Future Proposals** | ğŸŒ 06_viz_web / ğŸ›°ï¸ 04_remote_sensing | AR + live sensor concepts, provenance overlay UX, future interaction patterns |
| **Openâ€‘Source Geospatial Historical Mapping Hub Design** | ğŸ“Œ 00_templates / ğŸ§ª 02_methods | MCP experiment tracking patterns, DVC/LFS ideas, model cards placement (`mcp/model_cards/`) |
| **Scientific Method / Master Coder Protocol Documentation** | ğŸ“Œ 00_templates | Reproducible coding practices, experiment tracking, notebook â†’ script conversion patterns |
| **Design Audit â€“ Gaps and Enhancement Opportunities** | ğŸ” 01_exploration / ğŸŒ 06_viz_web | Backlog seeds for missing data sources, storytelling gaps, and MCP integration improvements |
| **Data Mining Concepts & Applications** | ğŸ›¡ï¸ 08_security_defensive / âš–ï¸ 09_governance_ethics | Privacy concepts (query auditing, differential privacy), safe release patterns for sensitive outputs |
| **Python Geospatial Analysis Cookbook (PostGIS patterns)** | ğŸ—ºï¸ 03_geospatial / ğŸ§± 07_data_engineering | Practical PostGIS QA recipes, geometry validity, spatial joins, performance hygiene |
| **AI Concepts & more (PDF portfolio)** | ğŸ§ª 02_methods / âš–ï¸ 09_governance_ethics | General AI/ML reference stack; use for baselines + eval ideas (treat as reference, not authority) |
| **Maps/GoogleMaps/Virtual Worlds/Geospatial WebGL (PDF portfolio)** | ğŸŒ 06_viz_web / ğŸ—ºï¸ 03_geospatial | 3D/virtual world patterns, cartographic + WebGL reference stack |
| **Data Management / Architectures / Bayesian Methods (PDF portfolio)** | ğŸ§± 07_data_engineering / ğŸ§ª 02_methods | Data architecture patterns, Bayesian thinking, governance + scaling reference stack |
| **Various programming languages & resources (PDF portfolio)** | ğŸ“Œ 00_templates | â€œGrab bagâ€ language notes for quick context (Python/R/JS/etc.) |

---

## âœ… PR checklist (for notebook contributions)

- [ ] Notebook runs top-to-bottom in a clean kernel â™»ï¸
- [ ] Inputs + provenance stated (dataset IDs, STAC IDs, queries, sources) ğŸ§¾
- [ ] Outputs written predictably (`outputs/` for local; `data/work|processed` for publishable) ğŸ“¦
- [ ] Deterministic seeds set (if stochastic) ğŸ²
- [ ] Key plots/tables saved (not only inline) ğŸ–¼ï¸
- [ ] â€œConclusion + next stepâ€ section added âœ…
- [ ] If geospatial: CRS + bbox + geometry validated and recorded ğŸ—ºï¸
- [ ] If publishable: STAC + DCAT + PROV created/updated ğŸŒ
- [ ] If sensitive: classification/sovereignty constraints respected (no leakage) ğŸ›¡ï¸
- [ ] If security-related: defensive-only, authorization assumptions explicit ğŸ”’

---

## âœ¨ North star

**Notebooks should make the project more coherent, not more complicated.**  
If a notebook canâ€™t be explained in 3 sentences, split it. ğŸ˜„
