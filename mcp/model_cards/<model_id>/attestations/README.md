# ğŸ§¾ Attestations (Evidence Pack) â€” `<model_id>`

> **Goal:** make every model release **verifiable**, **auditable**, and **traceable** endâ€‘toâ€‘end (data â†’ pipeline â†’ artifact â†’ UI/answers). ğŸ”—ğŸ§¬

This folder is the **attestation hub** for the model in `mcp/model_cards/<model_id>/`.

It exists so that **anyone** (maintainers, auditors, contributors) can answer:

- âœ… *What exactly is the model artifact Iâ€™m using?* (digest, version, build inputs)
- âœ… *Who/what produced it?* (CI run + maintainer signâ€‘off when required)
- âœ… *What governance & security checks did it pass?* (policy gates, secrets scan, safety checks)
- âœ… *What data + evaluations support it?* (datasets, metrics, known limitations)

---

## ğŸ§­ Quick links

- [ğŸ“ Folder layout](#-folder-layout)
- [âœ… Attestation matrix](#-attestation-matrix)
- [ğŸ” Verification recipes](#-verification-recipes)
- [ğŸ¤– Agent & CI expectations](#-agent--ci-expectations)
- [ğŸ§  How this ties into Focus Mode + Story Nodes](#-how-this-ties-into-focus-mode--story-nodes)
- [ğŸ›¡ï¸ Governance, privacy, sensitivity](#ï¸-governance-privacy-sensitivity)
- [ğŸš¨ Revocation & rollback](#-revocation--rollback)
- [ğŸ§¾ Glossary](#-glossary)

---

## ğŸ“ Folder layout

> Keep it boring, repeatable, and machine-checkable ğŸ˜„

<details>
<summary><strong>ğŸ—‚ï¸ Recommended structure</strong></summary>

```text
mcp/model_cards/<model_id>/
â”œâ”€ README.md                         # ğŸ“Œ Model Card (human-facing)
â”œâ”€ eval/                             # ğŸ“Š Eval reports + experiment artifacts
â”‚  â””â”€ <release>/...
â””â”€ attestations/
   â”œâ”€ README.md                       # (this file)
   â”œâ”€ index.json                      # ğŸ§¾ machine-readable catalog
   â”œâ”€ slsa/                           # ğŸ”— build provenance (SLSA/in-toto style)
   â”œâ”€ sbom/                           # ğŸ“¦ SPDX / CycloneDX
   â”œâ”€ policy/                         # ğŸ›¡ï¸ OPA/Conftest reports (fail-closed)
   â”œâ”€ data/                           # ğŸ§¬ dataset provenance bundles (STAC/DCAT/PROV)
   â”œâ”€ security/                       # ğŸ” vuln scans, secrets scans, prompt-gate outputs
   â””â”€ human/                          # ğŸ‘¤ approvals / sign-off receipts
```

</details>

---

## âœ… Attestation matrix

> [!IMPORTANT]
> If a **required** row is missing for a release, treat that release as **NOT promotionâ€‘eligible**.

| Category | What it proves | Typical format | Where | Required? |
|---|---|---:|---|:--:|
| ğŸ”— Build provenance | How artifact was produced (inputs, toolchain, CI run) | `*.intoto.jsonl` / `*.json` | `slsa/` | âœ… |
| ğŸ“¦ SBOM | What software is inside (deps, versions) | SPDX / CycloneDX | `sbom/` | âœ… |
| ğŸ›¡ï¸ Policy gate report | Governance checks passed (failâ€‘closed) | JSON / text report | `policy/` | âœ… |
| ğŸ§¬ Data provenance bundle | Which datasets were used (and their lineage) | STAC/DCAT/PROV | `data/` | âœ… (if model depends on KFM data) |
| ğŸ“Š Evaluation bundle | Performance + limitations + metric definition | Markdown + artifacts | `../eval/` | âœ… |
| ğŸ” Security scan output | No secrets, acceptable vulnerabilities | JSON reports | `security/` | âœ… |
| ğŸ‘¤ Human approval | Maintainer + authority-to-control approvals | signed note / receipt | `human/` | âš ï¸ conditional |

---

## ğŸ§¾ `index.json` (recommended)

`index.json` is the **attestation catalog**: one place for tools & humans to find evidence.

```json
{
  "model_id": "<model_id>",
  "release": "<semver-or-date>",
  "artifacts": [
    {
      "name": "model",
      "digest": "sha256:<...>",
      "oci_ref": "<optional: registry/repo@sha256:...>",
      "attestations": {
        "slsa": ["slsa/<digest>.intoto.jsonl"],
        "sbom": ["sbom/<digest>.spdx.json"],
        "policy": ["policy/<release>.conftest.json"],
        "security": ["security/<release>.scans.json"],
        "eval": ["../eval/<release>/report.md"],
        "data": ["data/<bundle_id>/prov.jsonld"]
      }
    }
  ]
}
```

---

## ğŸ” Verification recipes

> These are **patterns**, not sacred commands. Prefer your installed toolâ€™s `--help`.

### 1) âœ… Digest match
- Confirm the artifact digest referenced in the **Model Card** matches the actual file / OCI digest.
- Confirm that digest appears in `attestations/index.json`.

### 2) ğŸ” Verify signatures / attestations (OCI mode)
If artifacts are stored in an **OCI registry**, signatures and attestations may exist as **OCI referrers**.

```bash
# Examples (pseudo):
cosign verify <oci_ref>
cosign verify-attestation <oci_ref> --type slsaprovenance
```

### 3) ğŸ›¡ï¸ Verify policy gates (failâ€‘closed)
```bash
# Example (pseudo):
conftest test ./data ./mcp ./docs -p ./policy
```

### 4) ğŸ§¬ Verify dataset lineage
- Each dataset referenced by the model should have:
  - catalog metadata (STAC/DCAT) ğŸ“š
  - provenance (PROV) ğŸ§¬
  - sensitivity + license fields ğŸ·ï¸

---

## ğŸ¤– Agent & CI expectations

KFMâ€™s automation patterns assume:

- **Agents can open PRs** but **must never autoâ€‘merge** ğŸ”’
- **Policy gates apply equally** to humans and agents âœ…
- Agent actions can be **signed** (Sigstore/Cosign or equivalent) âœï¸
- Agent and pipeline steps should appear in provenance as a first-class `prov:Agent` when applicable ğŸ§¬

**Nice-to-have (strongly recommended):**
- a **run manifest** per CI/pipeline run (tool versions, source URLs, record counts, errors)
- stable **hashing/canonicalization** so the run itself has a deterministic identifier (useful for â€œsame input â†’ same outputâ€ expectations)

---

## ğŸ§  How this ties into Focus Mode + Story Nodes

KFMâ€™s AI outputs should be:

- ğŸ§‘â€âš–ï¸ **Advisory-only** (no autonomous action)
- ğŸ“š **Evidence-first** (source-cited claims)
- âœ… **Governance-checked** (policy enforcement before returning output)

Attestations are the *artifact-side* mirror of that same trust model:

- Focus Mode can cite **what model** produced a response (digest + release)
- the UI can surface **why a layer/claim is trusted** (source metadata + provenance)
- Story Nodes can carry **evidence manifests** (citations + checksums) that reference the same provenance bundles stored here

---

## ğŸ›¡ï¸ Governance, privacy, sensitivity

> [!WARNING]
> Even â€œderivedâ€ outputs can leak sensitive information. Treat **model outputs** as publishable artifacts that may require privacy review.

Recommended controls:
- âœ… sensitivity classification tags on datasets & outputs
- âœ… geo-obfuscation/generalization when required
- âœ… query auditing / inference controls for high-risk outputs
- âœ… k-anonymity / differential-privacy-style approaches when publishing aggregates (when appropriate)
- âœ… authority-to-control approvals for culturally sensitive data

---

## ğŸš¨ Revocation & rollback

Mistakes happen. A safe release process plans for rollback:

- Maintain **versioned artifacts** (prefer content-addressed digests)
- Maintain a **â€œlatestâ€ pointer** that can be repointed back to a known-good digest
- If sensitive data leaks:
  - revoke access quickly (classification flip)
  - remove/purge offending artifacts
  - record the incident + remediation as an attestation (audit trail)

---

## ğŸ§¾ Glossary

- **SLSA / in-toto**: build provenance frameworks (who built what, from what)
- **SBOM**: software bill of materials (SPDX / CycloneDX)
- **OPA / Conftest**: policy-as-code + CI enforcement
- **STAC / DCAT / PROV**: catalogs + provenance for data and processes
- **OCI Registry**: content-addressed artifact storage (models, tiles, datasets)
- **Cosign**: artifact signing & attestation tool (often paired with OCI registries)

---

## ğŸ“ Reference library (nonâ€‘normative, but useful ğŸ“š)

This repo also carries large â€œlibraryâ€ style references (AI concepts, data management, maps/WebGL, programming resources). They inform implementation choices, but **this README is the normative spec** for what must ship in an evidence pack.

âœ… If you add new reference books, consider updating your library manifest/index so contributors can discover them.
