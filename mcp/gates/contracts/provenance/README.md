# Provenance Contract â›“ï¸ğŸ§¬  
<!-- mcp/gates/contracts/provenance/README.md -->

<p align="center">
  <img alt="KFM Provenance" src="https://img.shields.io/badge/KFM-Provenance--First-1f6feb">
  <img alt="Fail Closed" src="https://img.shields.io/badge/Gates-Fail--Closed-critical">
  <img alt="Evidence Triplet" src="https://img.shields.io/badge/Evidence-STAC%20%2B%20DCAT%20%2B%20PROV-8250df">
  <img alt="W3C PROV" src="https://img.shields.io/badge/Standard-W3C%20PROV--O-0b7285">
  <img alt="FAIR+CARE" src="https://img.shields.io/badge/Governance-FAIR%20%2B%20CARE-2ea043">
</p>

> âœ… **Rule of the Frontier:** If it ships, it has provenance.  
> ğŸ”’ This contract is enforced by MCP gates (CI + runtime policy). Missing/invalid lineage **blocks merge/publish/serve**.

---

## ğŸ¯ Purpose

This folder defines the **Provenance Gate Contract** for the Kansas Frontier Matrix (KFM) and its **MCP** (Methods & Computational Experiments) layer.

The contract standardizes how we **represent, validate, and enforce lineage** for:

- ğŸ—ºï¸ **Datasets & map layers** (raw â†’ processed â†’ published)
- ğŸ§ª **ETL runs, simulations, and analyses** (reproducible computation)
- ğŸ§µ **Story Nodes / Pulse Threads** (claims â†’ evidence manifests)
- ğŸ¤– **Focus Mode answers** (citations required; AI outputs logged)
- ğŸ”§ **DevOps actions** (PRs, approvals, rollbacks, provenance repairs)
- ğŸ“¦ **Packaged artifacts** (e.g., OCI registry artifacts + signatures)

It is built around the **evidence triplet**: **STAC + DCAT + PROV**, plus a deterministic **run manifest**.

---

## ğŸ§  Core Principles (Nonâ€‘Negotiables)

### 1) Evidenceâ€‘First (No Mystery Layers) ğŸ§¾
- Every published layer must be traceable to source material and transformations.
- â€œUnknown originâ€ content is not allowed in the graph, UI, or AI responses.

### 2) Immutability & Trust Boundaries ğŸ§±
- `data/raw/` is treated as **readâ€‘only evidence**: never overwrite bytes.
- All transformations occur downstream (`data/work/`, `data/processed/`) and are recorded.

### 3) Deterministic, Configâ€‘Driven ETL â™»ï¸
- Same inputs + same config/code â‡’ same outputs (idempotent where possible).
- Manual edits to processed outputs are disallowed unless captured as a controlled activity.

### 4) Failâ€‘Closed Governance Gates ğŸ”
- If a check cannot be completed, the gate fails **closed** (blocks the change).
- Policies evolve via PR review; exceptions are explicit and versioned.

### 5) AI Is Advisoryâ€‘Only ğŸ¤
- AI can suggest, summarize, draft â€” but provenance and publication remain **governed**.
- Focus Mode must **refuse** to answer if it cannot cite evidence.

---

## ğŸ§© What This Contract Controls

### Contract scope
This contract applies to **any publishable unit** (â€œartifactâ€) entering KFM systems:

- A dataset version (raw + processed + catalogs)
- A derived product (tileset, GeoParquet, model output, index map)
- A Story Node / Pulse Thread publication
- A Focus Mode answer (especially when cached/persisted)
- A computational run (MCP run) producing evidence artifacts
- A rollback / retraction / correction event

### Out of scope (for this contract)
- Full domain ontology semantics (handled by graph/ontology contracts)
- UI layout, theming, component behavior (handled by UI contracts)
- Access control/roles (handled by authz policies, though provenance must record agents)

---

## ğŸ“¦ The Provenance Bundle (Required Artifacts)

A **Provenance Bundle** is the minimum set of files that makes an artifact:

- auditable âœ…
- reproducible â™»ï¸
- linkable across STAC/DCAT/PROV ğŸ”—
- safe to publish under policy ğŸ›¡ï¸

### âœ… Required files (minimum)
| File | Purpose | Notes |
|---|---|---|
| `prov.jsonld` | Machineâ€‘readable lineage graph (W3C PROVâ€‘O) | Must identify Activity/Entities/Agents |
| `run_manifest.json` | Deterministic execution record | Includes inputs, tool versions, counts, environment |
| `checksums.sha256` | Tamper evidence for bundle contents | Must include hashes for the above files |

### â­ Strongly recommended (policy may require by context)
| File | Purpose |
|---|---|
| `sbom.spdx.json` or `sbom.cdx.json` | Supplyâ€‘chain traceability for code/env |
| `attestation.intoto.jsonl` | Inâ€‘toto provenance / build attestation |
| `signature.(cosign|sigstore).json` | Artifact signing / chain of custody |
| `evidence_manifest.(yml|json)` | Narrative claim â†’ evidence mapping (Story Nodes) |
| `catalog_refs.json` | Links to STAC item IDs + DCAT dataset IDs for this bundle |

---

## ğŸ”— Crossâ€‘Layer Linkage (STAC + DCAT + PROV)

KFM treats **catalogs as published boundary artifacts**. This contract requires the **linkage** to be explicit.

### Required linkage expectations
At minimum, each bundle MUST allow the system to traverse:

1. **STAC** (spatial asset / item / collection)  
2. **DCAT** (dataset metadata, license, distributions)  
3. **PROV** (lineage: who/what/when/how)  
4. **Run manifest** (exact reproducible execution details)

### Practical rule of thumb
If a PR adds/changes **processed data**, it MUST also add/modify:

- a corresponding **STAC** entry,
- a corresponding **DCAT** entry,
- a corresponding **PROV** record,
- and the **run manifest + checksums** that tie everything together.

---

## ğŸ§¬ Provenance Data Model (PROVâ€‘O, KFM Profile)

We use **W3C PROVâ€‘O** concepts:

- **Entity**: a thing (file, dataset, recordset, tileset, answer, story)
- **Activity**: an action/process (ETL run, reproject, merge, generate answer)
- **Agent**: who/what did it (human, CI runner, service account, AI agent)

### KFM profile conventions (recommended)
To keep provenance queryable across the platform, we recommend a consistent ID scheme:

- Entity IDs: `urn:kfm:entity:<type>:<stable_id>@<version>`
- Activity IDs: `urn:kfm:activity:<pipeline_name>:<run_id>`
- Agent IDs: `urn:kfm:agent:<user_or_service>:<id>`

â€¦and KFM extensions such as:

- `kfm:classification` / `kfm:sensitivity`
- `kfm:license_spdx`
- `kfm:run_id`
- `kfm:canonical_digest` (ties to run manifest hash)
- `kfm:source_urls` (where inputs originated)
- `kfm:policy_pack_version`

---

## ğŸ§¾ Run Manifest Requirements (Reproducibility Backbone)

A `run_manifest.json` MUST be sufficient to reproduce (or at least audit) the activity.

### Minimum recommended fields
```json
{
  "run_id": "RUN-2026-01-22T120000Z-ABCD",
  "pipeline": "kfm-etl-water-gauges",
  "started_at": "2026-01-22T12:00:00Z",
  "ended_at": "2026-01-22T12:05:12Z",
  "source_urls": ["https://example.gov/data.csv"],
  "inputs": [{"path": "data/raw/usgs/data.csv", "sha256": "â€¦"}],
  "outputs": [{"path": "data/processed/usgs/gauges.parquet", "sha256": "â€¦"}],
  "tool_versions": {"python": "3.12.1", "gdal": "3.8.4"},
  "summary_counts": {"records_in": 1200, "records_out": 1198, "errors": 2},
  "canonical_digest": "sha256:â€¦",
  "idempotency_key": "sha256:â€¦"
}
```

> ğŸ§  Why the digest fields matter:  
> Canonical JSON + SHAâ€‘256 turns the manifest into a **selfâ€‘fingerprinting object** you can reference from PROV and the graph.

---

## âœ… Gate Checks (What the Provenance Gate Enforces)

> ğŸ”’ **Failâ€‘closed by default**: if a check canâ€™t be verified, the gate blocks.

### Gate check categories
| Category | Gate checks (examples) |
|---|---|
| Presence | Bundle contains required files |
| Schema | `prov.jsonld` and `run_manifest.json` are valid, parseable, and conform to profile/schema |
| Integrity | `checksums.sha256` matches actual file contents |
| Referential | PROV references valid Entity/Activity/Agent IDs; links to run manifest digest; catalog refs resolve |
| Governance | License present + approved; sensitivity/classification present; no secrets or disallowed terms |
| AI safety | Focus Mode outputs must include citations; AI activities are marked as AIâ€‘assisted |
| Auditability | All publishable artifacts map to a PROV activity; rollback/retractions are explicit activities |

### Common â€œgate closedâ€ failure reasons ğŸš«
- Missing `prov.jsonld` for a new/changed processed dataset
- No license metadata / invalid license identifier
- Run manifest missing `tool_versions` or cannot be hashed consistently
- PROV references an Entity that doesnâ€™t exist (broken lineage chain)
- Checksums donâ€™t match (tamper / accidental regeneration)
- Narrative/story references evidence that isnâ€™t in the manifest

---

## ğŸ—‚ï¸ Suggested Bundle Placement (KFM + MCP)

> âœ… This contract is enforced wherever provenance is stored â€” these are conventions for consistency.

### Data lifecycle bundles (KFM)
- `data/prov/<dataset_id>/<version>/...`  ğŸ“¦ (bundle directory)
- `data/catalog/stac/...`  ğŸ—ºï¸ (STAC outputs)
- `data/catalog/dcat/...`  ğŸ§¾ (DCAT outputs)
- `data/audits/<run_id>/run_manifest.json`  ğŸ§ª (run audits)

### Experiment/run bundles (MCP)
- `mcp/runs/<run_id>/provenance/...`  ğŸ§¬  
- `mcp/runs/<run_id>/model_card.md`  ğŸªª  
- `mcp/runs/<run_id>/artifacts/...`  ğŸ“¦  

---

## ğŸ—ºï¸ Endâ€‘toâ€‘End Provenance Flow (Canonical Pipeline)

```mermaid
flowchart LR
  Raw["data/raw (immutable) ğŸ§±"] --> Work["data/work â™»ï¸"]
  Work --> Proc["data/processed âœ…"]
  Proc --> Catalog["STAC + DCAT ğŸ“š"]
  Catalog --> Prov["PROV (prov.jsonld) â›“ï¸"]
  Prov --> Graph["Neo4j Evidence Graph ğŸ”—"]
  Graph --> API["Contracted APIs ğŸ§©"]
  API --> UI["Map UI + Layer Provenance ğŸ”"]
  UI --> Story["Story Nodes / Pulse Threads ğŸ§µ"]
  Story --> Focus["Focus Mode ğŸ¤–"]
  Focus --> Ledger["Governance Ledger ğŸ“œ"]
```

---

## ğŸ§µ Story Nodes & Evidence Manifests (Narrative Provenance)

Narrative content is treated as **machineâ€‘ingestible storytelling**.

### Required behavior
- Every claim in a Story Node MUST map to evidence references.
- Evidence MUST resolve to cataloged items/entities (datasets, documents, images).

### Recommended file
`evidence_manifest.yml` (or JSON) accompanying the Story Node.

Example (minimal):
```yaml
story_id: SN-1951-FLOOD-TOPEKA
version: 1.0.0
claims:
  - id: C1
    text_span: "â€¦"
    evidence:
      - entity: "urn:kfm:entity:dataset:usgs_water_levels@2026.01"
        locator: "dcat:dataset:USGS-NWIS"
      - entity: "urn:kfm:entity:doc:topeka_archive_letter_1951@1"
        locator: "stac:item:doc-1951-001"
```

---

## ğŸ¤– Focus Mode (AI) Provenance Rules

Focus Mode is governed like any other subsystem.

### Hard rules
- **No citations â†’ no answer.**
- AIâ€‘generated suggestions MUST be marked as AIâ€‘assisted and logged.
- Answers based on dynamic queries (e.g., realâ€‘time readings) MUST still record:
  - the input entities used (with timestamps),
  - the agent,
  - the activity that produced the answer.

### Recommended PROV pattern for AI answers
- Entity: the question (or request)
- Activity: â€œanswer_generationâ€
- Entities used: cited datasets/docs + any dynamic query results
- Entity generated: the answer (persisted record, if stored)
- Agent: AI system + supervising user (if applicable)

---

## ğŸ”§ DevOps, Rollbacks, and Provenance Repair

The contract supports **transparent undo**:

- Rollbacks are modeled as explicit PROV Activities.
- Retracted datasets/layers remain in lineage but marked as superseded/retracted.
- â€œProvenance repairâ€ is allowed only as governed, auditable maintenance work.

> ğŸ§¯ If you need to fix provenance after the fact: **add a repair activity**; donâ€™t rewrite history.

---

## ğŸ› ï¸ How to Comply (Contributor Checklist)

### When you add/change processed data âœ…
- [ ] Raw inputs saved in `data/raw/` (immutable)
- [ ] Transformations are code/config driven
- [ ] Run manifest generated + hashed
- [ ] PROV record references run manifest digest and inputs/outputs
- [ ] STAC + DCAT updated and crossâ€‘linked
- [ ] Checksums file matches bundle contents
- [ ] License + sensitivity tags present
- [ ] CI gates pass (schema + policy + integrity)

### When you publish narrative content ğŸ§µ
- [ ] Evidence manifest exists and resolves
- [ ] Claims have citations
- [ ] Any AI assistance is explicitly marked

### When you publish AI outputs ğŸ¤–
- [ ] Every claim has citations
- [ ] Output is logged/traceable
- [ ] OPA/runtime policy accepts the response

---

## ğŸ§· Versioning & Compatibility

- This contract SHOULD follow **SemVer**.
- Profile/schema changes that break consumers require a **major** bump.
- Policy changes that tighten enforcement may be minor/patch, but should be announced.

### Recommended IDs
- Contract ID: `mcp.gates.contracts.provenance`
- Profile ID: `kfm-prov` (with explicit version tag)

---

## ğŸ“š Standards & References (External)

- **W3C PROVâ€‘O** (entities, activities, agents)
- **STAC** (spatial cataloging)
- **DCAT** (dataset cataloging)
- **RFC 8785** (JSON Canonicalization Scheme)
- **SPDX / CycloneDX** (SBOM formats)
- **inâ€‘toto / SLSA** (supply chain attestations)

---

## ğŸ§¯ Troubleshooting

<details>
<summary><strong>â€œGate closed: missing provenance for changed data/processed outputâ€</strong></summary>

- Ensure a bundle exists for the dataset version you changed.
- Add/update `run_manifest.json`, `prov.jsonld`, and `checksums.sha256`.
- Confirm PROV `used` references include the raw inputs and config/code plan.

</details>

<details>
<summary><strong>â€œGate closed: checksums mismatchâ€</strong></summary>

- Recompute the SHAâ€‘256 hashes after generating outputs.
- Ensure no tooling auto-formats JSON post-hash (canonicalize first).

</details>

<details>
<summary><strong>â€œGate closed: Story Node evidence does not resolveâ€</strong></summary>

- Verify each referenced dataset/doc exists in catalogs.
- Use stable IDs and ensure the correct version is cited.

</details>

---

## ğŸ§­ See Also (Inside This Repo)

> ğŸ—‚ï¸ These pointers assume the canonical v13 layout.

- `docs/MASTER_GUIDE_v13.md` (canonical pipeline + governance invariants)
- `data/raw/README.md` (trust boundary rules)
- `data/prov/` (published provenance store)
- `schemas/` (STAC/DCAT/PROV/story schemas)
- `src/pipelines/` (ETL code and deterministic transforms)
- `src/graph/` (ingest lineage into Neo4j)
- `web/` (Layer Provenance UI + citations display)
- `docs/reports/story_nodes/` (governed narrative content)
- `mcp/` (runs, notebooks, model cards, experiment tracking)

---

## âœ… Definition of Done

This contract is â€œdoneâ€ when:

- A contributor can add a dataset/run/story and pass the gate on the first try âœ…
- The graph can ingest provenance without guessing or manual patching ğŸ”—
- The UI can display â€œLayer Provenanceâ€ for any active layer ğŸ”
- Focus Mode can cite evidence or refuses safely ğŸ¤–
- Rollbacks and repairs are transparent and auditable ğŸ§¯

---
