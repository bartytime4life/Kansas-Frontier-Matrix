# â›“ï¸ Provenance Contract (KFM-PROV) â€” MCP Gate

![Status](https://img.shields.io/badge/status-draft-orange)
![Profile](https://img.shields.io/badge/profile-KFM--PROV%20v11.0.0-blue)
![Format](https://img.shields.io/badge/format-JSON--LD%20%2F%20PROV--O-blueviolet)
![Principle](https://img.shields.io/badge/principle-evidence--first-brightgreen)
![Policy](https://img.shields.io/badge/policy-fail--closed-red)
![Gate](https://img.shields.io/badge/gate-OPA%20%2B%20Conftest-informational)

ğŸ“ **Location:** `mcp/gates/contracts/data/schema/provenance/`  
ğŸ¯ **Purpose:** Make lineage **mandatory**, **machine-verifiable**, and **user-visible** across KFM (data â†’ graph â†’ API â†’ UI â†’ AI).

> [!IMPORTANT]
> **No mystery layers.** If an output canâ€™t be traced to inputs + process + agent, it **doesnâ€™t ship**.

---

<details>
<summary>ğŸ“š Table of Contents</summary>

- [Why this exists](#-why-this-exists)
- [How provenance fits KFM](#-how-provenance-fits-kfm)
- [Evidence Triplet](#-evidence-triplet)
- [What this contract covers](#-what-this-contract-covers)
- [Expected folder contents](#-expected-folder-contents)
- [KFM-PROV model](#-kfm-prov-model)
  - [Core PROV types](#core-prov-types)
  - [KFM extensions](#kfm-extensions)
  - [Required invariants](#required-invariants)
- [IDs, namespaces, and linking](#-ids-namespaces-and-linking)
- [Run manifest binding](#-run-manifest-binding)
- [Gate rules (what fails the build)](#-gate-rules-what-fails-the-build)
- [UI + Focus Mode requirements](#-ui--focus-mode-requirements)
- [Sensitivity, CARE, and privacy](#-sensitivity-care-and-privacy)
- [Streaming + simulation considerations](#-streaming--simulation-considerations)
- [Local validation](#-local-validation)
- [Examples](#-examples)
- [References (project docs)](#-references-project-docs)
- [Definition of Done](#-definition-of-done)

</details>

---

## ğŸ§­ Why this exists

KFMâ€™s platform philosophy is **provenance-first** and **contract-first**:

- âœ… Every dataset has a **data contract** (metadata + schema + processing steps).
- âœ… Every derived output includes a **lineage record** (inputs â†’ process â†’ agent).
- âœ… Every UI/AI surface can explain **where the information came from** (citations, license, preparation summary).
- âœ… CI enforces this with **fail-closed gates** (schema + completeness + ethics).

This directory is the **authoritative contract** for the provenance side of that promise.

---

## ğŸ§© How provenance fits KFM

KFMâ€™s pipeline treats data as evidence with explicit trust boundaries:

- `data/raw/` is **immutable evidence** (never edited in place).
- deterministic ETL produces outputs into `data/work/` then `data/processed/`.
- publication requires â€œboundary artifactsâ€ (catalog + lineage) before the dataset is usable downstream.

This provenance contract is the â€œlineage boundary artifactâ€ that unlocks:

- ğŸ§  **Neo4j ingest** (graph edges back to catalogs)
- ğŸ”Œ **API contracts & redaction** (classification-aware delivery)
- ğŸ—ºï¸ **UI attribution & layer provenance**
- ğŸ¤– **Focus Mode citations + audit panel** (XAI / governance flags)

---

## ğŸ”— Evidence Triplet

KFM publishes data using an evidence triplet:

- ğŸ›°ï¸ **STAC** â€” geospatial assets + item/collection metadata  
- ğŸ“‡ **DCAT** â€” discovery/catalog metadata (license, publisher, access)  
- â›“ï¸ **PROV** â€” lineage + chain-of-custody (how it was produced)

```mermaid
flowchart LR
  A[ğŸ“¥ Raw Sources<br/>data/raw/] --> B[ğŸ§ª ETL + Normalization<br/>data/work/]
  B --> C[ğŸ—„ï¸ Curated Outputs<br/>data/processed/]

  C --> D[ğŸ›°ï¸ STAC<br/>data/stac/]
  C --> E[ğŸ“‡ DCAT<br/>data/catalog/dcat/]
  C --> F[â›“ï¸ PROV<br/>data/prov/]

  D --> G[ğŸ§  Neo4j Knowledge Graph]
  E --> G
  F --> G

  G --> H[ğŸ”Œ API Layer<br/>(contracts + redaction)]
  H --> I[ğŸ—ºï¸ UI + ğŸ¤– Focus Mode<br/>(citations + attribution)]
```

> [!NOTE]
> â€œEvidence-firstâ€ means the metadata isnâ€™t optional garnish â€” itâ€™s part of the deliverable. ğŸ½ï¸

---

## âœ… What this contract covers

This contract defines a **KFM-PROV profile** used for:

- ğŸ“¦ Dataset and layer production lineage (ETL runs, transforms, reprojections, joins)
- ğŸ§  Analysis / modeling outputs as first-class datasets (simulations, bias correction, OCR corpora)
- ğŸ¤– AI outputs (Focus Mode answers and generated narratives) with **mandatory citations**
- ğŸ” Governance events (classification decisions, approvals, redactions)
- ğŸ§° CI/CD & DevOps provenance (optional but supported): PR â†’ PROV graph records, build attestations

---

## ğŸ“ Expected folder contents

This README is the **spec**; schema/policy files live alongside it.

```text
mcp/gates/contracts/data/schema/provenance/
â”œâ”€ ğŸ“˜ README.md                      # you are here
â”œâ”€ ğŸ§¾ kfm-prov.schema.json            # JSON Schema for KFM-PROV bundles (JSON-LD)
â”œâ”€ ğŸ§  kfm-prov.context.jsonld         # JSON-LD context extensions (kfm namespace)
â”œâ”€ ğŸ§¾ run-manifest.schema.json        # schema for per-run manifest (audit trail)
â”œâ”€ ğŸ§¾ evidence-manifest.schema.json   # schema for Story Node evidence manifests
â”œâ”€ ğŸ§¾ agent-action.schema.json        # schema for agent actions (Watcher/Planner/Executor)
â”œâ”€ ğŸ§ª examples/
â”‚  â”œâ”€ minimal.bundle.jsonld
â”‚  â”œâ”€ dataset-etl.bundle.jsonld
â”‚  â”œâ”€ streaming-query.bundle.jsonld
â”‚  â”œâ”€ story-node.bundle.jsonld
â”‚  â””â”€ pr-activity.bundle.jsonld
â””â”€ âœ… tests/
   â”œâ”€ fixtures/
   â””â”€ expected-failures/
```

> [!TIP]
> Keep schemas tiny and composable. Prefer `$ref` over mega-files. ğŸ§±

---

## ğŸ§¬ KFM-PROV model

### Core PROV types

We model provenance using **W3C PROV** (PROV-O semantics, serialized as JSON-LD):

- **Entity** â€” a thing (file, dataset, table, STAC item, DCAT record, model output, AI answer)
- **Activity** â€” something that happens (ingest run, transform, query, simulation, export)
- **Agent** â€” who/what did it (human contributor, CI bot, pipeline container, AI agent)

### KFM extensions

KFM extends PROV with fields needed for enforcement and UX:

**KFM envelope fields (recommended):**
- `kfm:profile` â€” `"kfm-prov/11.0.0"`
- `kfm:bundle_id` â€” stable ID for this PROV bundle
- `kfm:dataset_id` â€” canonical dataset ID (matches STAC/DCAT)
- `kfm:run_id` â€” pipeline run identifier (ties to run manifest)
- `kfm:policy_pack_version` â€” governance policy pack version used
- `kfm:classification` â€” sensitivity level (public/internal/restricted/etc)
- `kfm:license` â€” license identifier (must match DCAT)
- `kfm:artifacts` â€” digests/URIs for produced outputs (sha256, OCI digest, etc)
- `kfm:signatures` â€” optional signature refs (cosign/in-toto/SLSA)

**Agent typing (recommended):**
- `kfm:agent_type`: `human | pipeline | ci | watcher | planner | executor | ai`
- `kfm:role`: e.g., `maintainer`, `contributor`, `reviewer`, `system`

**AI outputs (required if AI involved):**
- `kfm:citations` â€” machine-readable citations (dataset IDs / graph entities / doc refs)
- `kfm:explainability` â€” optional pointers to audit-panel data (features, graph edges, flags)
- `kfm:governance_flags` â€” e.g., `sensitive_data_notice`, `bias_flag`, `needs_review`

### Required invariants

These are the invariants the **gate** enforces (see [Gate rules](#-gate-rules-what-fails-the-build)):

1. **Every published dataset has lineage**  
   If `data/processed/**` changes, a matching `data/prov/**` update must exist.

2. **Every output entity has a generator activity**  
   Each produced Entity must have `prov:wasGeneratedBy` â†’ Activity.

3. **Each activity declares inputs**  
   Activities must enumerate `prov:used` Entities (including raw sources + configs).

4. **Each activity is tied to an agent**  
   Activity must link to `prov:wasAssociatedWith` Agent (human or system).

5. **License + sensitivity exist before UI/Graph**  
   Missing `license` or `classification` is a block.

6. **AI citations are mandatory**  
   If Focus Mode produces an answer/story and cannot cite, the correct behavior is **refusal**.

---

## ğŸ†” IDs, namespaces, and linking

### ID patterns (recommended)

Use stable, dereferenceable-ish URNs (or URLs if your deployment has them):

- `urn:kfm:dataset:<domain>.<name>.<version>`
- `urn:kfm:run:<timestamp-or-ulid>`
- `urn:kfm:activity:<run_id>#<step>`
- `urn:kfm:entity:<content-hash-or-path>`
- `urn:kfm:agent:<user-or-service>`

### Linking across STAC + DCAT + PROV

**One dataset = one canonical ID**:

- STAC: `id` or `properties["kfm:dataset_id"]`
- DCAT: `dct:identifier` (or equivalent)
- PROV: `kfm:dataset_id`

> [!IMPORTANT]
> If these IDs diverge, citations break and the UI loses attribution. Keep them in lock-step. ğŸ”—

---

## ğŸ§¾ Run manifest binding

Every pipeline or simulation run should emit a **Run Manifest** (audit trail) that the PROV bundle references.

**Goals:**
- reproducibility (inputs + tool versions + config)
- integrity (canonical digest / idempotency key)
- reviewability (summary counts, errors, warnings)

### Minimal run-manifest fields (recommended)

- `run_id`
- `run_time`
- `idempotency_key`
- `canonical_digest` (self-fingerprinting hash)
- `source_urls[]`
- `tool_versions{}` (gdal, tippecanoe, python, node, etc)
- `summary_counts{}` (rows in/out, errors, warnings)
- `outputs[]` (paths + digests)

> [!NOTE]
> Canonicalization (RFC 8785) + SHA-256 is recommended so hashes are stable across environments. ğŸ”’

---

## ğŸš¦ Gate rules (what fails the build)

These checks are designed to run in:
- âœ… CI (Conftest/OPA policy pack)
- âœ… ingestion pipelines (validator library)
- âœ… agent PR workflows (Watcher/Planner/Executor parity)

### Gate matrix

| Gate ID | What it checks | Typical trigger | Fail behavior |
|---|---|---|---|
| `KFM-PROV-001` | Processed data updated without provenance update | PR changes `data/processed/**` | **Block merge** |
| `KFM-PROV-002` | PROV bundle schema invalid | any PROV file changed | **Block merge** |
| `KFM-PROV-003` | Missing license/classification | new dataset or layer | **Block merge** |
| `KFM-PROV-004` | Missing/invalid links to STAC/DCAT IDs | metadata changes | **Block merge** |
| `KFM-PROV-005` | Missing run manifest binding | pipeline outputs | **Block merge** (or warn in dev) |
| `KFM-PROV-006` | AI output lacks citations | Focus Mode/story output | **Refuse output** + block publish |

> [!CAUTION]
> â€œFail closedâ€ is intentional. If something doesnâ€™t pass, it **does not** enter the system. ğŸ›‘

---

## ğŸ§  UI + Focus Mode requirements

### UI: provenance is visible, not hidden ğŸ—ºï¸

UI surfaces should be able to read this contract to show:

- Layer source + license (Layer Info)
- Full active-layer citations list (Layer Provenance panel)
- Auto-generated attribution text on exports (screenshots, share links, story exports)

### Focus Mode: citations + auditability ğŸ¤–

Focus Mode MUST:
- cite sources for every factual claim (datasets, docs, graph entities)
- refuse if it cannot derive from available evidence
- optionally expose an audit panel: factors/edges used + governance flags

> [!IMPORTANT]
> AI output is treated as a derived artifact â€” it must carry lineage like any other output.

### Story Nodes: evidence manifests ğŸ“–

When producing narratives, attach:

- a human-readable short citations block (3â€“7 lines)
- a machine-readable evidence manifest (YAML/JSON)
- an embedded PROV snippet linking story â†’ evidence â†’ creation activity

This makes narratives **machine-verifiable** and **exportable with trust**.

---

## ğŸ” Sensitivity, CARE, and privacy

KFM governance requires:
- explicit sensitivity labeling
- respectful handling of culturally sensitive / restricted data
- auditability of redaction and approvals

Recommended fields:
- `kfm:classification`: `public | internal | restricted | embargoed`
- `kfm:access_policy`: `rbac:<role>` / `terms:<id>` / `approval:<workflow>`
- `kfm:redaction`: method + reason + approver agent (if applied)

> [!NOTE]
> CARE emphasizes **collective benefit** and **authority to control**. Provenance must record *who approved what* and *why*.

---

## ğŸŒŠ Streaming + simulation considerations

### Streaming / live data

If data is real-time:
- provenance is still required
- you may batch provenance into an append-only ledger (NDJSON) for high-throughput streams
- dynamic query results should be captured as Activities that `prov:used` the specific reading(s) with timestamps

### Simulation / modeling

For simulations (e.g., deterministic scenario runners):
- capture input datasets, model code version, parameters, seeds
- store produced diffs, updated STAC, and PROV lineage
- treat model outputs as **first-class datasets** (same workflow, same gates)

---

## ğŸ§° Local validation

> [!TIP]
> Keep local checks fast so contributors can run them before pushing. âš¡

Suggested developer loop:
1. Validate JSON/JSON-LD against schema
2. Validate cross-links (STAC/DCAT/PROV IDs)
3. Run OPA policies (fail closed)

Example commands (adjust to your toolchain):

```bash
# 1) Schema validation (example placeholders)
check-jsonschema --schemafile mcp/gates/contracts/data/schema/provenance/kfm-prov.schema.json data/prov/**/*.jsonld

# 2) Policy gate (Conftest + OPA)
conftest test --policy mcp/gates/policy --data mcp/gates/data .
```

---

## ğŸ§ª Examples

<details>
<summary>ğŸ§¾ Minimal PROV bundle (JSON-LD)</summary>

```json
{
  "@context": [
    "https://www.w3.org/ns/prov.jsonld",
    {
      "kfm": "urn:kfm:",
      "dataset": "urn:kfm:dataset:",
      "run": "urn:kfm:run:",
      "activity": "urn:kfm:activity:",
      "agent": "urn:kfm:agent:",
      "entity": "urn:kfm:entity:",
      "sha256": "urn:hash:sha256:"
    }
  ],
  "@id": "run:01J0EXAMPLE",
  "@type": "prov:Bundle",
  "kfm:profile": "kfm-prov/11.0.0",
  "kfm:dataset_id": "dataset:hydrology.river_gauges.v1",
  "prov:agent": {
    "agent:kfm-ci": {
      "prov:type": "prov:SoftwareAgent",
      "kfm:agent_type": "ci",
      "kfm:role": "system"
    }
  },
  "prov:activity": {
    "activity:01J0EXAMPLE#ingest": {
      "prov:startedAtTime": "2026-01-23T12:00:00Z",
      "prov:endedAtTime": "2026-01-23T12:03:10Z",
      "prov:wasAssociatedWith": "agent:kfm-ci"
    }
  },
  "prov:entity": {
    "entity:usgs-nwis.json": {
      "prov:type": "prov:Entity",
      "kfm:source_url": "https://example.invalid/usgs/nwis",
      "kfm:license": "public-domain"
    },
    "entity:river_gauges.parquet": {
      "prov:type": "prov:Entity",
      "kfm:artifact_path": "data/processed/hydrology/river_gauges.parquet",
      "kfm:digest": "sha256:DEADBEEF..."
    }
  },
  "prov:used": {
    "_:use1": {
      "prov:activity": "activity:01J0EXAMPLE#ingest",
      "prov:entity": "entity:usgs-nwis.json",
      "prov:role": "input"
    }
  },
  "prov:wasGeneratedBy": {
    "_:gen1": {
      "prov:entity": "entity:river_gauges.parquet",
      "prov:activity": "activity:01J0EXAMPLE#ingest"
    }
  }
}
```

</details>

<details>
<summary>ğŸ§‘â€ğŸ’» DevOps provenance (PR as PROV Activity)</summary>

When enabled, PRs can be recorded as PROV:

- PR = `prov:Activity`
- commits = `prov:Entity`
- author/reviewer/CI = `prov:Agent`

This makes â€œwhich code version produced this dataset?â€ queryable in the same provenance graph.

</details>

---

## ğŸ“š References (project docs)

These documents informed this contract (keep this list updated as the project evolves):

### ğŸ§± Core KFM architecture & governance
- *Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design*
- *Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation*
- *ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals*
- *Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM)*
- *Additional Project Ideas*

### ğŸ§­ UI & AI behavior (provenance must be user-visible)
- *Kansas Frontier Matrix â€“ Comprehensive UI System Overview*
- *Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–*

### ğŸ“¥ Data intake & metadata standards
- *ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide*
- *Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design*

### ğŸ§° Supporting reference packs (libraries / portfolios)
- *AI Concepts & more* (PDF portfolio)
- *Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas* (PDF portfolio)
- *Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl* (PDF portfolio)
- *Various programming langurages & resources 1* (PDF portfolio)
- *KFM python geospatial analysis cookbook*
- *Data Mining Concepts & applictions*
- *Comprehensive Markdown Guide_ Syntax, Extensions, and Best Practices*
- *MARKDOWN_GUIDE_v13*

---

## âœ… Definition of Done

When adding or modifying a dataset/layer, you should be able to check all boxes:

- [ ] Raw sources live under `data/raw/<domain>/` and are treated immutable ğŸ“¥
- [ ] Outputs live under `data/processed/<domain>/` ğŸ—„ï¸
- [ ] STAC updated in canonical location (`data/stac/...`) ğŸ›°ï¸
- [ ] DCAT updated in canonical location (`data/catalog/dcat/...`) ğŸ“‡
- [ ] PROV bundle written to canonical location (`data/prov/...`) â›“ï¸
- [ ] PROV bundle validates against `kfm-prov.schema.json` âœ…
- [ ] License + classification present and consistent across metadata ğŸ”
- [ ] Run manifest exists and is referenced by PROV ğŸ§¾
- [ ] If AI generated/assisted, output includes citations or refuses ğŸ¤–
- [ ] Policy gates pass locally and in CI ğŸš¦

---

> [!TIP]
> Provenance isnâ€™t bureaucracy â€” itâ€™s the **feature** that makes KFM trustworthy. ğŸ§ âœ¨

