# ğŸ§ª MCP Gates & Contracts â€” Example Payloads ğŸ“¦

![Contracts](https://img.shields.io/badge/Contracts-First-blue)
![Gates](https://img.shields.io/badge/Policy%20Gates-Fail--Closed-critical)
![Evidence](https://img.shields.io/badge/Evidence-Triplet%20STAC%20%2B%20DCAT%20%2B%20PROV-success)
![AI](https://img.shields.io/badge/AI-Focus%20Mode%20Requires%20Citations-important)

> [!NOTE]
> This folder is **fixtures + living documentation** for how KFM payloads must look when passing through **policy gates** and **contract schemas** (schema-first + evidence-first + provenance-first).  
> If a payload canâ€™t pass a gate, **it shouldnâ€™t enter the system**. âœ…â¡ï¸ğŸš« (Fail-closed)

---

## ğŸ§­ What lives here?

`mcp/` in KFM is the **Methods, Controls & Processes** layer (internal governance + SOPs). This path specifically houses **example payloads** used to validate:

- **Contracts** (JSON Schema / typed models) âœ…
- **Gates** (policy-as-code checks like OPA/Rego + Conftest) ğŸ›¡ï¸
- **Evidence-first publishing** (STAC + DCAT + PROV â€œtripletâ€) ğŸ§¾ğŸ§¾ğŸ§¾
- **AI safety rules** (Focus Mode outputs must include citations or refuse) ğŸ¤–ğŸ“š
- **Classification + ethics rules** (FAIR + CARE, sensitive data handling) âš–ï¸

These ideas are consistent across the KFM architecture + AI overview + data intake design docs. (See sources at bottom.) ğŸ“š

---

## ğŸ§© Quick Nav

- [ğŸ“ Suggested folder layout](#-suggested-folder-layout)
- [ğŸ§¾ The Evidence Triplet](#-the-evidence-triplet-stac--dcat--prov)
- [ğŸ›¡ï¸ Gate expectations](#ï¸-gate-expectations)
- [ğŸ·ï¸ Naming & versioning](#ï¸-naming--versioning)
- [ğŸ§¬ Recommended payload envelope](#-recommended-payload-envelope)
- [âœ… How to validate locally](#-how-to-validate-locally)
- [â• Adding a new payload (MCP workflow)](#-adding-a-new-payload-mcp-workflow)
- [ğŸ” Redaction & ethics checklist](#-redaction--ethics-checklist)
- [ğŸ“š Design sources](#-design-sources-project-files)

---

## ğŸ“ Suggested folder layout

> [!TIP]
> Your actual payload set may differ, but **keeping categories consistent** makes gates/contracts easier to reason about and keeps CI deterministic.

```text
mcp/gates/contracts/examples/payloads/
â”œâ”€ ğŸ§± ingest/                 # ğŸ§± Pipeline/run + intake fixtures (manifests, run_context, checksums, fetch receipts)
â”œâ”€ ğŸ§¾ catalogs/               # ğŸ§¾ Evidence triplet fixtures: STAC/DCAT/PROV examples that must validate together
â”œâ”€ ğŸ•¸ï¸ graph/                  # ğŸ•¸ï¸ Knowledge-graph fixtures (ingest payloads, node/edge batches, mutation receipts)
â”œâ”€ ğŸ¤– ai/                     # ğŸ¤– Focus Mode fixtures (request/answer envelopes, citations, redaction notices)
â”œâ”€ ğŸ§­ ui/                     # ğŸ§­ UI fixtures (layer registry, story node configs, timeline configs, offline packs)
â”œâ”€ ğŸ•µï¸ privacy/                # ğŸ•µï¸ Privacy fixtures (query auditing, inference-control signals, sensitivity labels)
â”œâ”€ ğŸ”’ security/               # ğŸ”’ Security fixtures (SBOMs, attestations, OCI refs, signature pointers)
â””â”€ ğŸ›°ï¸ agents/                 # ğŸ›°ï¸ WPE fixtures (Watcher/Planner/Executor requests, plans, receipts, decisions)
```

---

## ğŸ§¾ The Evidence Triplet (STAC + DCAT + PROV)

KFM treats data as **publishable** only when the â€œevidence tripletâ€ is present:

- **STAC** (asset-level geospatial catalog) ğŸ—ºï¸
- **DCAT** (dataset-level catalog + discoverability) ğŸ§¾
- **PROV** (how it was produced + lineage) ğŸ§¬

This triplet is described in the intake guide and is core to â€œevidence-first publishing.â€ The catalog pattern is also referenced in broader system docs and architecture principles. ğŸ“š

### ğŸ”— Relationship overview (mental model)

```mermaid
flowchart LR
  Raw[ğŸ“¥ Raw inputs] --> Pipe[âš™ï¸ Pipeline Activity]
  Pipe --> Art[ğŸ“¦ Processed artifacts]
  Art --> STAC[ğŸ—ºï¸ STAC Item/Collection]
  Art --> DCAT[ğŸ§¾ DCAT Dataset/Distribution]
  Pipe --> PROV[ğŸ§¬ PROV Activity/Entity/Agent]
  STAC --> KG[ğŸ•¸ï¸ Knowledge Graph]
  DCAT --> KG
  PROV --> KG
  KG --> UI[ğŸ§­ UI/API]
  KG --> AI[ğŸ¤– Focus Mode]
  AI --> UI
```

### âœ… What our example payloads should demonstrate

- **STAC payloads**: geometry/bbox, time coverage, assets, links, plus KFM-specific required fields (ex: `kfm:dataset_id`, `kfm:classification`)  
- **DCAT payloads**: dataset description, license, contact/attribution, distributions, links to STAC + artifacts  
- **PROV payloads**: pipeline run activity + associations to tools/agents + derived-from relationships to sources  

> [!IMPORTANT]
> Streaming / â€œreal-timeâ€ data is still governed: itâ€™s â€œmany small datasets over time,â€ and policy requires provenance + classification before graph/UI use (and therefore before payloads are â€œpublishableâ€). â±ï¸ğŸ§¬

---

## ğŸ›¡ï¸ Gate expectations

KFM uses automated policy gates at **data ingestion**, **AI inference**, and **publication** time. Minimum gates described in v13 docs include checks for:

- **Schema validation** (contract compliance) âœ…
- **STAC/DCAT/PROV completeness** (required metadata exists) ğŸ§¾
- **License presence** (no unknown license) ğŸ“œ
- **Sensitivity classification** (and proper handling of sensitive data) ğŸ·ï¸ğŸ”
- **Provenance completeness** (inputs + processing declared) ğŸ§¬
- **AI citations requirement** (Focus Mode must cite sources or refuse) ğŸ¤–ğŸ“š
- **Supply chain security** (signatures/attestations where applicable) ğŸ”’
- **Privacy controls** (query auditing / inference control / differential privacy patterns) ğŸ•µï¸

### â€œFail closedâ€ gate chain (illustrative)

```mermaid
flowchart TB; P[ğŸ“¦ Payload] --> S[âœ… Schema Gate]; S --> M[ğŸ§¾ Metadata Gate]; M --> L[ğŸ“œ License Gate]; L --> C[ğŸ·ï¸ Classification Gate]; C --> V[ğŸ§¬ Provenance Gate]; V --> A[ğŸ¤– AI Citation Gate - if AI output]; A --> X[ğŸš€ Allowed to publish or use];
```

> [!WARNING]
> Many payload examples should exist in **pairs**:
> - âœ… **pass** example: minimal valid + realistic  
> - âŒ **fail** example: intentionally violates a single rule (so the gate error is obvious)

### ğŸ§ª Common â€œfailâ€ scenarios to keep fixtures sharp

| Gate | Typical fail payload reason | Why we keep it |
|---|---|---|
| Schema | missing required field / wrong type | contract-first enforcement |
| STAC/DCAT/PROV | missing linkage or required metadata | evidence-first publishing |
| License | absent/unknown license | legal + reuse safety |
| Classification | not labeled / mislabeled | safety + governance |
| Provenance | missing run activity or sources | auditability + trust |
| AI citation | answer has no citations | prevents hallucinated â€œfactsâ€ |
| Security | missing attestation / signature metadata | supply-chain trust |
| Privacy | query enables inference / privacy budget exceeded | protects sensitive info |

---

## ğŸ·ï¸ Naming & versioning

### âœ… Recommended filename shape

Use filenames that communicate **intent + expected outcome** at a glance:

```text
<domain>.<kind>.<scenario>.<expected>.<spec>.json

Examples:
catalogs.stac_item.minimal.pass.kfm-v13.json
catalogs.dcat_dataset.missing_license.deny.kfm-v13.json
ai.focus_answer.no_citations.deny.kfm-v13.json
privacy.query_audit.inference_risk.deny.kfm-v13.json
```

### âœ… Recommended scenario vocabulary

- `minimal` / `typical` / `edge`
- `missing_<field>` / `invalid_<field>` / `bad_<rule>`
- `pass` / `deny` / `warn`

> [!TIP]
> Keep failure cases â€œsingle-causeâ€ (one violation per payload) so itâ€™s crystal-clear which gate triggered.

---

## ğŸ§¬ Recommended payload envelope

Some gates want to evaluate **context + payload** together (who, when, environment, intended use). If your runner supports it, use a light envelope:

```json
{
  "kind": "kfm.payload_fixture",
  "spec_version": "kfm-v13",
  "id": "fixture:catalogs:stac_item:ellis_co_1894_map:minimal:pass",
  "meta": {
    "scenario": "minimal",
    "expected": {
      "decision": "allow",
      "gates": ["schema", "metadata", "license", "classification", "provenance"]
    },
    "notes": "Small STAC Item demonstrating kfm:dataset_id + kfm:classification."
  },
  "context": {
    "environment": "ci",
    "actor": "contributor",
    "intended_use": "publish"
  },
  "payload": { "â€¦": "your real STAC/DCAT/PROV/AI/etc object here" }
}
```

If your system expects **raw objects** (pure STAC / pure DCAT / pure PROV), thatâ€™s fine tooâ€”just keep fixtures *adaptable* and document assumptions in `meta.notes`.

---

## ğŸ¤– AI payload notes (Focus Mode)

Focus Mode is explicitly designed to be **advisory, evidence-backed**, and **citation-required**. Your example payloads should cover:

- âœ… A â€œgoodâ€ answer that includes:
  - **citations** pointing to catalog entries (DCAT/STAC) and/or documents
  - enough metadata to render â€œWhy you should trust thisâ€ in the UI
- âŒ A â€œbadâ€ answer that:
  - has **no citations** â†’ must be denied/refused by policy gate

> [!IMPORTANT]
> If the AI cannot provide a source, that is a **policy violation** and it should refuse the answer.

Also include a fixture for â€œdynamic queryâ€ answers (real-time data) that still logs provenance of which reading was used. â±ï¸ğŸ§¬

---

## ğŸ§­ UI & Story payload notes

The UI design emphasizes **inspectability**: users should be able to click a layer or story claim and see **where it came from**.

Your fixtures can include:

- Layer registry entries (how layers appear in map UI) ğŸ—ºï¸
- Timeline/event references â³
- Story node evidence manifests ğŸ“š
- â€œData provenance tooltipâ€ payloads (what the UI displays in a provenance panel) ğŸ”

### ğŸ§¾ Story Nodes: evidence manifests (strongly recommended)

Story Nodes should behave like â€œresearch paper mini-objectsâ€:
- structured references
- checksums
- PROV links
- agent attribution (human/AI-assisted)

This supports auditing questions like â€œwhich stories used this dataset?â€ and enables graph traversal between claims and sources. ğŸ“Œ

---

## ğŸ•µï¸ Privacy fixtures (query auditing + inference control)

KFMâ€™s governance and security posture expects **privacy-aware behavior**, especially around sensitive datasets (PII, endangered sites, culturally sensitive locations, etc.).

Include fixtures that demonstrate:

- âœ… permitted queries (aggregated outputs, low inference risk)
- âŒ denied queries when inference risk is detected (query auditing / inference control)
- âœ… differential privacy style responses (optional) when appropriate

> [!NOTE]
> These fixtures donâ€™t require implementing DP immediatelyâ€”**but they set the contract shape** so gates and UI can evolve without breaking changes.

---

## ğŸ”’ Security fixtures (supply chain + artifact provenance)

KFM plans for strong auditability and supply chain security:
- artifacts stored in standard ways (e.g., OCI-like distribution patterns)
- signatures + attestations (SBOM / in-toto provenance style)
- provenance attached to artifacts and referenced from catalogs

Fixtures here help ensure policies can enforce â€œtrust before publish.â€ âœ…ğŸ”

---

## âœ… How to validate locally

> [!TIP]
> Exact commands vary by repo tooling, but the validation stack is usually:
> **(1) Schema validation** âœ **(2) Policy gates** âœ **(3) Expected decision checks**

### 1) Schema validation (contracts)

Options (pick what the repo standardizes on):

- `ajv` (JS/TS)
- Python `jsonschema`
- typed-model validation (Pydantic/Zod/etc.)

**Example (AJV):**
```bash
npx ajv validate -s mcp/gates/contracts/schemas/<schema>.json -d mcp/gates/contracts/examples/payloads/**/*.json
```

**Example (Python jsonschema):**
```bash
python -m jsonschema -i "mcp/gates/contracts/examples/payloads/<payload>.json" "mcp/gates/contracts/schemas/<schema>.json"
```

### 2) Policy gates (OPA / Conftest)

Policy packs are typically evaluated via Conftest over JSON/YAML inputs:

```bash
conftest test mcp/gates/contracts/examples/payloads -p tools/validation/policy
```

### 3) Expected decisions (golden tests)

Recommended patterns:
- embed expected outcome in `meta.expected`
- or store alongside as `<payload>.expected.json`

---

## â• Adding a new payload (MCP workflow)

This repo treats engineering + research like a scientific method loop (MCP): **hypothesis â†’ test â†’ evidence â†’ iteration**. ğŸ§ªğŸ“ˆ

### âœ… Contribution checklist

1. **Pick the contract** youâ€™re targeting (or add a new one).
2. Add **one pass** and **one fail** payload:
   - pass = minimal realistic
   - fail = single-cause violation
3. Ensure fixtures include:
   - license ğŸ“œ
   - classification ğŸ·ï¸
   - provenance links ğŸ§¬
   - citations where required ğŸ¤–ğŸ“š
4. Run validation locally (schema + gates).
5. Update any index docs if present.

### ğŸ§° â€œDone meansâ€¦â€

- [ ] Contract validates âœ…  
- [ ] Gate results match expected outcome ğŸ›¡ï¸  
- [ ] No sensitive data leaked ğŸ”  
- [ ] IDs are stable + deterministic where required â™»ï¸  
- [ ] Failure cases are single-cause and readable ğŸ§¯  

---

## ğŸ” Redaction & ethics checklist

KFM documentation emphasizes:
- classification tagging
- coordinate generalization for sensitive sites
- access control for restricted datasets
- CARE/Indigenous data sovereignty considerations where relevant

So in fixtures:

âœ… **Do**
- use synthetic or heavily redacted examples
- fuzz/aggregate sensitive coordinates
- include classification tags consistently
- include license + attribution fields

ğŸš« **Donâ€™t**
- include real secrets, keys, tokens
- include PII about living people
- include exact locations of sensitive sites unless explicitly permitted and the payload is marked/restricted

> [!WARNING]
> If you *must* model sensitive behavior, do it with **fake data** and a **deny** expected outcome.

---

## ğŸ“š Design sources (project files)

<details>
<summary>ğŸ—‚ï¸ Click to expand â€” documents used to shape these payload conventions</summary>

### Core KFM architecture + governance
- Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf  
  :contentReference[oaicite:0]{index=0} :contentReference[oaicite:1]{index=1} :contentReference[oaicite:2]{index=2}
- Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf  
  :contentReference[oaicite:3]{index=3} :contentReference[oaicite:4]{index=4} :contentReference[oaicite:5]{index=5}
- Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf  
  :contentReference[oaicite:6]{index=6} :contentReference[oaicite:7]{index=7}
- Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf  
  :contentReference[oaicite:8]{index=8} :contentReference[oaicite:9]{index=9} :contentReference[oaicite:10]{index=10}

### Evidence-first intake + catalogs
- ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf  
  :contentReference[oaicite:11]{index=11} :contentReference[oaicite:12]{index=12} :contentReference[oaicite:13]{index=13}

### Ideation + extensions (story nodes, artifacts, supply chain, WPE agents)
- ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals.docx.pdf  
  :contentReference[oaicite:14]{index=14} :contentReference[oaicite:15]{index=15}
- Additional Project Ideas.pdf  
  :contentReference[oaicite:16]{index=16} :contentReference[oaicite:17]{index=17}
- Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf  
  :contentReference[oaicite:18]{index=18} :contentReference[oaicite:19]{index=19}

### MCP methodology + audit guidance
- Scientific Method _ Research _ Master Coder Protocol Documentation.pdf  
  :contentReference[oaicite:20]{index=20}
- Kansas-Frontier-Matrix Design Audit â€“ Gaps and Enhancement Opportunities.pdf  
  :contentReference[oaicite:21]{index=21} :contentReference[oaicite:22]{index=22}

### Supporting resource packs (PDF portfolios / references)
- AI Concepts & more.pdf  
  :contentReference[oaicite:23]{index=23}
- Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf  
  :contentReference[oaicite:24]{index=24}
- Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf  
  :contentReference[oaicite:25]{index=25}
- Various programming langurages & resources 1.pdf  
  :contentReference[oaicite:26]{index=26}

### Extra design inputs encountered in project files
- Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf  
  :contentReference[oaicite:27]{index=27}
- Data Mining Concepts & applictions.pdf  
  :contentReference[oaicite:28]{index=28} :contentReference[oaicite:29]{index=29}
- MARKDOWN_GUIDE_v13.md.gdoc  
  :contentReference[oaicite:30]{index=30}
- Comprehensive Markdown Guide_ Syntax, Extensions, and Best Practices.docx  
  :contentReference[oaicite:31]{index=31}

</details>

---

## ğŸ§¾ Maintainer note

If you change a gate or contract, **update or add at least one fixture** here (ideally both pass & fail).  
These payloads are your **unit tests for governance**. ğŸ›¡ï¸âœ…

---

