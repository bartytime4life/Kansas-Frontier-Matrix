# 01 â€” Data Intake Gate ğŸ“¥ğŸ§¾

![MCP Gate](https://img.shields.io/badge/MCP%20Gate-01%20Data%20Intake-2ea44f)
![Provenance First](https://img.shields.io/badge/provenance-first-blue)
![Evidence Triplet](https://img.shields.io/badge/STAC%20%7C%20DCAT%20%7C%20PROV-evidence%20triplet-7b42f6)
![Fail Closed](https://img.shields.io/badge/policy-fail--closed-red)
![FAIR+CARE](https://img.shields.io/badge/FAIR%20%2B%20CARE-governance-orange)

> **Goal:** Turn *any* raw source into **governed, reproducible, auditable** KFM-ready artifacts â€” by passing it through a chain of **Gates** that enforce the KFM invariants:
> - âœ… **Raw is immutable**
> - âœ… **ETL is deterministic + idempotent**
> - âœ… **Nothing is â€œpublishedâ€ until the Evidence Triplet exists (STAC + DCAT + PROV)**
> - âœ… **No downstream layer can bypass the governed API boundary**
> - âœ… **Classification/sensitivity propagates end-to-end** ğŸ”’

---

## ğŸ§­ What this example demonstrates

This example is a reference implementation of the **KFM Data Intake Pipeline** expressed as an **MCP Gate** workflow:

- ğŸ“¥ **Raw ingest** with `source.json` + `checksums.sha256`
- ğŸš¦ **Basic validation (â€œingestion gateâ€)** + telemetry ledger (append-only NDJSON)
- ğŸ§ª **Deterministic transforms** into standardized outputs
- ğŸ›°ï¸ **Catalog emission** (the â€œevidence tripletâ€: STAC + DCAT + PROV)
- ğŸ•¸ï¸ **Graph ingestion readiness** (catalogs â†’ graph; no â€œmystery nodesâ€)
- ğŸ” **Policy-as-code** (OPA/Rego via Conftest; fail-closed; secrets scanning)
- ğŸ§© **Downstream consumption** patterns (API â†’ UI â†’ Story Nodes â†’ Focus Mode)

---

## ğŸ“Œ Table of contents

- [Quickstart](#-quickstart)
- [Pipeline at a glance](#-pipeline-at-a-glance)
- [Folder layout](#-folder-layout)
- [Gate chain](#-gate-chain)
- [Contracts](#-contracts)
- [Artifacts](#-artifacts)
- [Policy hooks](#-policy-hooks)
- [UI + Focus Mode consumption](#-ui--focus-mode-consumption)
- [Extensions](#-extensions)
- [Troubleshooting](#-troubleshooting)
- [Reference docs used](#-reference-docs-used)
- [Appendix: PDF portfolio extraction](#-appendix-pdf-portfolio-extraction)

---

## âš¡ Quickstart

> This folder is an **example**. Your repo may already have a â€œgate runnerâ€ CLI.
> Use the snippets below as the *expected behavior* and *expected outputs* for any runner you wire up.

### Option A â€” Run with a generic runner (suggested convention)

```bash
# from repo root
cd mcp/gates/examples/01-data-intake

# run the example against a dataset intake spec
# (replace the command with your repo's actual runner)
python -m mcp.gates.run \
  --example 01-data-intake \
  --config ./datasets/example.dataset.yml \
  --out ./out
```

### Option B â€” Validate outputs only (CI-friendly)

```bash
# Validate schemas + policy pack + catalog link integrity
python -m mcp.gates.validate --root ./out
conftest test ./out --policy ../../../policy
```

---

## ğŸ—ºï¸ Pipeline at a glance

```mermaid
flowchart LR
  A["External Sources ğŸŒ"] --> B["Raw Snapshot ğŸ“¥\nsource.json + checksums.sha256"]
  B --> C["Ingestion Gate ğŸš¦\nquick validate + telemetry"]
  C --> D["ETL Work ğŸ§ª\n(data/work)"]
  D --> E["Processed Outputs ğŸ“¦\n(data/processed)"]
  E --> F["Evidence Triplet ğŸ›°ï¸\nSTAC + DCAT + PROV"]
  F --> G["Graph Ingestion Ready ğŸ•¸ï¸\nNeo4j bulk import or API sync"]
  G --> H["Governed API ğŸ”\ncontracts + redaction"]
  H --> I["Map UI ğŸ—ºï¸\nReact + MapLibre (+ Cesium)"]
  I --> J["Story Nodes ğŸ“–\n(governed narratives)"]
  J --> K["Focus Mode ğŸ¤–\n(evidence-linked answers)"]
```

ğŸ’¡ **Key invariant:** No stage may consume data that hasnâ€™t passed the previous stageâ€™s formal outputs and checks.

---

## ğŸ§± Folder layout

This example writes everything into `./out/` so itâ€™s safe to run locally.  
In a full KFM repo, these structures typically map to top-level `data/*` directories.

```text
mcp/gates/examples/01-data-intake/
â”œâ”€ README.md ğŸ“˜
â”œâ”€ datasets/
â”‚  â””â”€ example.dataset.yml ğŸ§¾
â”œâ”€ fixtures/
â”‚  â””â”€ sample_input.csv ğŸ§ª
â””â”€ out/  (generated) ğŸ—ï¸
   â”œâ”€ data/
   â”‚  â”œâ”€ raw/<domain>/<dataset_id>/<run_id>/        ğŸ“¥
   â”‚  â”‚  â”œâ”€ source.json
   â”‚  â”‚  â”œâ”€ checksums.sha256
   â”‚  â”‚  â””â”€ <original files...>
   â”‚  â”œâ”€ work/<domain>/<dataset_id>/<run_id>/       ğŸ§ª
   â”‚  â””â”€ processed/<domain>/<dataset_id>/<version>/ ğŸ“¦
   â”œâ”€ stac/
   â”‚  â”œâ”€ collections/<collection_id>.json ğŸ›°ï¸
   â”‚  â””â”€ items/<item_id>.json            ğŸ›°ï¸
   â”œâ”€ catalogs/
   â”‚  â””â”€ dcat/<dataset_id>.jsonld        ğŸ§­
   â”œâ”€ prov/
   â”‚  â””â”€ <run_id>.prov.jsonld            ğŸ§¾
   â”œâ”€ audits/
   â”‚  â””â”€ <run_id>/run_manifest.json      ğŸ§¾
   â””â”€ telemetry/
      â””â”€ intake.ndjson                   ğŸ“ˆ
```

---

## ğŸš¦ Gate chain

Think of each Gate as a **hard contract boundary** with a pass/fail result, plus emitted artifacts.

| Gate | Name | Why it exists | Minimum outputs |
|---:|---|---|---|
| 00 | **Contract Gate** ğŸ§¾ | Enforce required dataset fields (ID, license, sensitivity, contacts, etc.) | validated config |
| 01 | **Fetch + Receipt Gate** ğŸŒ | Pull raw bytes (or record pointer/receipt) in a reproducible way | receipt, raw bytes |
| 02 | **Raw Snapshot Gate** ğŸ“¥ | Make raw immutable & tamper-evident | `source.json`, `checksums.sha256` |
| 03 | **Ingestion Validation Gate** ğŸš¦ | Catch corrupt/malformed data early + log telemetry | ledger entry + sanity checks |
| 04 | **Deterministic ETL Gate** ğŸ§ª | Normalize, reproject, clean, chunk (idempotent) | `data/work/*`, `data/processed/*` |
| 05 | **Evidence Triplet Gate** ğŸ›°ï¸ | No publishing without catalogs + lineage | STAC + DCAT + PROV |
| 06 | **Policy Gate** ğŸ” | Governance + FAIR/CARE + secrets scanning (fail-closed) | policy report |
| 07 | **Promote/Publish Gate** ğŸš€ | â€œTransactionalâ€ publish: either all artifacts land, or nothing does | final outputs |

---

## ğŸ§¾ Contracts

### 1) Dataset intake spec (example)

Your dataset intake YAML is the **human-friendly contract**. Keep it small, explicit, versioned.

```yaml
# datasets/example.dataset.yml
dataset_id: kfm.example.hydro.river_gauges
domain: hydro
version: "2026-01-23"
title: "Example River Gauges (Demo)"
description: "Demo dataset for the 01-data-intake gate chain."

source:
  kind: file
  path: "./fixtures/sample_input.csv"
  # If kind=http, include url + headers strategy (no secrets committed)

license:
  spdx: "CC-BY-4.0"
  attribution: "Example Provider"

sensitivity:
  classification: public   # public | sensitive | confidential | restricted
  notes: "No sensitive attributes."

processing:
  crs_target: "EPSG:4326"
  output_formats:
    - geojson
    - geoparquet
  steps:
    - kind: parse_csv
    - kind: normalize_columns
    - kind: validate_geometry
    - kind: reproject

catalog:
  stac:
    collection_id: "kfm.hydro.river_gauges"
  dcat:
    publisher: "Kansas Frontier Matrix (KFM)"
    themes: ["hydrology", "monitoring"]
```

### 2) `source.json` (raw provenance stub)

At raw ingest time, we store **just enough** to prove what was fetched, how, when, and under what constraints.

```json
{
  "dataset_id": "kfm.example.hydro.river_gauges",
  "retrieved_at": "2026-01-23T00:00:00Z",
  "method": "local_file_copy",
  "source": {
    "kind": "file",
    "path": "./fixtures/sample_input.csv"
  },
  "license": {
    "spdx": "CC-BY-4.0",
    "attribution": "Example Provider"
  },
  "sensitivity": {
    "classification": "public"
  },
  "checksums": {
    "sha256": {
      "sample_input.csv": "..."
    }
  }
}
```

### 3) `checksums.sha256` (tamper evidence)

```text
# checksums.sha256
<sha256>  sample_input.csv
```

---

## ğŸ“¦ Artifacts

### âœ… â€œEvidence Tripletâ€ is the publishing boundary

This is the single most important rule in KFM-style intake:

- **STAC** â†’ describes geospatial assets (extent, time, checksums, assets)
- **DCAT** â†’ describes dataset discovery metadata (publisher, license, distributions)
- **PROV** â†’ describes lineage (inputs, processing activities, agents)

> If the triplet doesnâ€™t exist, the dataset is **not** considered part of the platform.

---

## ğŸ” Policy hooks

This example is designed to be compatible with a **Policy Pack** (OPA/Rego via Conftest) that:

- fails closed (PR blocked if policy fails) ğŸš«
- enforces required metadata (license, provider, sensitivity)
- blocks secrets from being committed (regex scans / allowlist)
- enforces **classification propagation** (outputs cannot be less restricted than inputs)

### Minimal policy expectations (human-readable)

- âœ… Every dataset must declare a **license** and **attribution**
- âœ… Every dataset must declare a **sensitivity classification**
- âœ… Every published dataset must have **STAC + DCAT + PROV**
- âœ… No artifacts are promoted if a gate fails
- âœ… No credentials or tokens are committed anywhere

---

## ğŸ—ºï¸ UI + Focus Mode consumption

### UI trust contract (â€œthe map behind the mapâ€) ğŸ§­

Once a dataset passes all gates:

- the **UI loads it via the governed API** (never direct graph queries)
- the **legend / layer info** can show **Source + License** (from DCAT)
- a **Layer Info / Provenance panel** can show where it came from + how it was prepared

### Focus Mode (evidence-linked answers) ğŸ¤–

When the assistant answers a question, it should:

- **cite** the exact datasets / catalog records used
- refuse if it canâ€™t support the answer with evidence
- optionally surface explainability (why the answer was produced, what relationships mattered)

---

## ğŸ§¬ Extensions

### 1) Streaming / rapid updates â±ï¸

Treat streaming as â€œmany small datasets over timeâ€:

- append-only ingest (no silent rewrites)
- checkpoint/rollups (daily/hourly) as stable artifacts
- still emit at least a **stub provenance record** before UI display

### 2) OCI artifact distribution (fast + signed) ğŸ“¦ğŸ”

For large artifacts (PMTiles, GeoParquet, COGs):

- push artifacts to an OCI registry (ORAS)
- sign with Cosign
- reference immutable digests from STAC/DCAT
- attach PROV as a referrer/attestation

> This is how you get content-addressable, reproducible distribution without stuffing git with huge binaries.

### 3) Graph health checks ğŸ•¸ï¸âœ…

Automate detection of:
- orphan nodes (missing links between STAC/DCAT/PROV)
- ingestion lag (SLA breaches for streaming sources)
- suspicious hubs or broken provenance chains

### 4) Watcher â†’ Planner â†’ Executor agents ğŸ‘€ğŸ§ âš™ï¸

If youâ€™re automating intake:
- **Watcher** detects new data
- **Planner** prepares a change *only if policy allows*
- **Executor** runs gates + attaches attestations (SBOM/SLSA) + opens a PR (never auto-merge)

---

## ğŸ§¯ Troubleshooting

### â€œMy dataset exists, but itâ€™s not visible in the UIâ€
Checklist:
- Did STAC + DCAT + PROV get generated? ğŸ›°ï¸
- Did policy pass (fail-closed)? ğŸ”
- Did graph ingestion run (if your UI needs graph discovery)? ğŸ•¸ï¸
- Is the dataset classification restricting it? ğŸ”’

### â€œI need to add a new domainâ€
Follow the canonical lifecycle pattern:
- `raw/` â†’ `work/` â†’ `processed/` â†’ catalogs â†’ graph â†’ API â†’ UI â†’ story/focus  
â€¦and keep domain data isolated under its own folder.

---

## ğŸ“š Reference docs used

These are the project docs this example aligns with (and is meant to operationalize):

### Core KFM specs ğŸ“˜
- **ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide** (raw ingest, ingestion gate, evidence triplet, telemetry)
- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design** (layering, hybrid PostGIS + graph, standards, governance)
- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation** (API/UI structure, MapLibre/Cesium notes)
- **Kansas Frontier Matrix â€“ Comprehensive UI System Overview** (UI transparency, provenance surfacing, offline packs)
- **Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–** (Focus Mode citations + explainability)
- **ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals** (Watcher/Planner/Executor, FAIR/CARE enforcement, supply chain attestations)
- **Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM)** (forward-looking extensions)
- **Additional Project Ideas** (OCI artifact distribution, canonical run manifests, policy gate patterns)

### Research binders (PDF portfolios) ğŸ“š
These are â€œdeep referenceâ€ portfolios containing embedded books/notes:
- **AI Concepts & more.pdf** ğŸ¤–
- **Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf** ğŸ—ºï¸
- **Various programming langurages & resources 1.pdf** ğŸ§°
- **Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf** ğŸ—„ï¸

---

## ğŸ§· Appendix: PDF portfolio extraction

Some project PDFs are **portfolios** (a single PDF that contains embedded PDFs).  
If you want to inspect whatâ€™s inside:

```bash
python - << 'PY'
from pypdf import PdfReader

paths = [
  "AI Concepts & more.pdf",
  "Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf",
  "Various programming langurages & resources 1.pdf",
  "Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf",
]

for p in paths:
  r = PdfReader(p)
  atts = list(r.attachment_list)
  print(f"\n== {p} ==")
  print("attachments:", len(atts))
  for a in atts[:12]:
    print(" -", a.name)

PY
```

> Tip ğŸ§ : If you want extraction-by-topic (e.g., â€œgeoprocessingâ€, â€œgoogle mapsâ€, â€œbayesianâ€), build a small script that filters attachment names and exports only those into `docs/research/extracted/`.

---

