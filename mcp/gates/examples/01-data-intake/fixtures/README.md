# ğŸ§ª Fixtures â€” Example `01-data-intake` (Gate Playground)

![Fixtures](https://img.shields.io/badge/fixtures-deterministic-brightgreen)
![Gate](https://img.shields.io/badge/gate-data%20intake-blue)
![Metadata](https://img.shields.io/badge/metadata-STAC%20%7C%20DCAT%20%7C%20PROV-orange)
![Policy](https://img.shields.io/badge/policy-FAIR%20%2B%20CARE-purple)
![Scope](https://img.shields.io/badge/scope-public%20%26%20safe-lightgrey)

> [!IMPORTANT]
> This folder is the **test bench** for proving *data intake rules* with **small, deterministic fixture packs**.  
> If a dataset (even a toy one) canâ€™t pass **license + metadata + provenance** requirements here, it doesnâ€™t get to â€œgraduateâ€ into real ingestion.

---

<details>
<summary>ğŸ“Œ Table of Contents</summary>

- [ğŸ¯ Why fixtures exist](#-why-fixtures-exist)
- [ğŸ—‚ï¸ Fixture pack contract](#ï¸-fixture-pack-contract)
- [ğŸ” Pipeline mental model](#-pipeline-mental-model)
- [ğŸ§¾ Boundary artifacts](#-boundary-artifacts)
- [ğŸ›¡ï¸ Governance & policy gates](#ï¸-governance--policy-gates)
- [ğŸ§¬ Fixture types we want coverage for](#-fixture-types-we-want-coverage-for)
- [ğŸ“¦ Adding a new fixture pack](#-adding-a-new-fixture-pack)
- [ğŸ§° Helpful geospatial conversion recipes](#-helpful-geospatial-conversion-recipes)
- [ğŸ§  AI/analysis fixtures](#-aianalysis-fixtures)
- [ğŸ§· Troubleshooting](#-troubleshooting)
- [ğŸ“š Reference docs that shaped this contract](#-reference-docs-that-shaped-this-contract)

</details>

---

## ğŸ¯ Why fixtures exist

KFM-style ingestion is not â€œjust load filesâ€ â€” itâ€™s **managed promotion**:

- ğŸ“¥ Raw â†’ ğŸ§ª Work â†’ âœ… Processed  
- ğŸ›°ï¸ STAC + ğŸ“š DCAT + ğŸ”— PROV must exist **before** anything can safely feed the graph/API/UI
- ğŸ§¾ Policies behave like tests: a failed license/provenance/sensitivity rule blocks â€œpublishingâ€

These fixtures are designed to **force the contract** early â€” *before* we scale up with real data, streaming feeds, OCR corpora, or AI-derived layers.

> [!NOTE]
> The core premise: a â€œliving atlasâ€ only stays trustworthy if every layer can answer **â€œwhere did this come from?â€** and **â€œwhat changed?â€** â€” with receipts.

---

## ğŸ—‚ï¸ Fixture pack contract

Each fixture is a **self-contained directory** (a â€œfixture packâ€) with:

- âœ… tiny inputs (safe to commit)
- âœ… deterministic expected outputs
- âœ… integrity hashes
- âœ… run metadata (so failures are debuggable and reproducible)

### ğŸ“ Suggested layout (per fixture pack)

```text
fixtures/ ğŸ§ª
â””â”€ ğŸ§© <fixture-id>/                     # ğŸ§© One end-to-end fixture bundle (inputs â†’ expected outputs + receipts)
   â”œâ”€ ğŸ“„ README.md                      # ğŸ“˜ What this fixture proves, how to run it, and what â€œsuccessâ€ means
   â”œâ”€ ğŸ“¥ input/                         # ğŸ“¥ Inputs for the fixture (keep tiny, deterministic, license-cleared)
   â”‚  â”œâ”€ ğŸ§¾ sources/                    # ğŸ§¾ Source descriptors (where data came from, license, retrieval notes)
   â”‚  â”‚  â””â”€ ğŸ§¾ source.json              # Source contract (id, URL/URI, license, timestamps, checksums/pointers)
   â”‚  â””â”€ ğŸ“¦ raw/                        # ğŸ“¦ Small raw sample files (immutable snapshot boundary)
   â”‚     â””â”€ ğŸ“¦ <small-sample-filesâ€¦>    # Tiny artifacts only (no large rasters/tiles; use pointers/receipts instead)
   â”œâ”€ âœ… expected/                      # âœ… Expected outputs (golden results used for regression testing)
   â”‚  â”œâ”€ ğŸ§¼ processed/                  # ğŸ§¼ Expected processed artifacts (normalized/cleaned outputs)
   â”‚  â”‚  â””â”€ âœ… <expected-processed-outputsâ€¦>
   â”‚  â”œâ”€ ğŸ›°ï¸ stac/                       # ğŸ›°ï¸ Expected STAC metadata (collection + item snapshots)
   â”‚  â”‚  â”œâ”€ ğŸ§¾ item.json                # STAC Item referencing produced assets + roles/links
   â”‚  â”‚  â””â”€ ğŸ§¾ collection.json          # STAC Collection describing the dataset/product
   â”‚  â”œâ”€ ğŸ“š dcat/                       # ğŸ“š Expected DCAT discovery metadata (dataset + distributions)
   â”‚  â”‚  â””â”€ ğŸ§¾ dataset.jsonld           # DCAT Dataset/Distribution record (license/access/links)
   â”‚  â”œâ”€ ğŸ”— prov/                       # ğŸ”— Expected provenance/lineage bundle (PROV-O JSON-LD)
   â”‚  â”‚  â””â”€ ğŸ§¬ğŸ§¾ lineage.jsonld          # PROV entities/activities/agents connecting inputs â†’ outputs
   â”‚  â”œâ”€ ğŸ›¡ï¸ policies/                   # ğŸ›¡ï¸ Expected policy evaluation outputs (OPA/Conftest results)
   â”‚  â”‚  â””â”€ ğŸ§ªğŸ§¾ results.json            # Pass/fail + findings (codes/severities) for this fixture
   â”‚  â””â”€ ğŸ•¸ï¸ graph/                      # ğŸ•¸ï¸ Expected graph import artifacts (optional)
   â”‚     â””â”€ ğŸ•¸ï¸ğŸ“„ import.cypher          # Cypher import script or expected mutation statements
   â””â”€ ğŸƒ run/                           # ğŸƒ Run receipts for reproducing/verifying this fixture
      â”œâ”€ ğŸ§¾ğŸ” run_manifest.json          # Run manifest: commands, params, tool versions, IO, digests, timestamps
      â””â”€ ğŸ”ğŸ“„ checksums.sha256           # sha256 sums for input/expected artifacts (tamper detection)
```

### âœ… Minimal required files

| Path | Required | What it proves ğŸ§ª |
|---|---:|---|
| `input/sources/source.json` ğŸ§¾ | âœ… | Source URL / license / expected schema (metadata-as-code) |
| `input/raw/*` ğŸ“¦ | âœ… | Immutable raw sample (tiny) |
| `expected/processed/*` ğŸ§¼ | âœ… | What the pipeline *should* produce |
| `expected/stac/*` ğŸ›°ï¸ | âœ… | Spatial/temporal catalog boundary artifact |
| `expected/dcat/*` ğŸ“š | âœ… | Dataset-level catalog boundary artifact |
| `expected/prov/*` ğŸ”— | âœ… | Lineage boundary artifact (inputs â†’ activity â†’ outputs) |
| `run/run_manifest.json` ğŸ§¾ | âœ… | Reproducible run record for the gate |
| `run/checksums.sha256` ğŸ” | âœ… | Tamper evidence + deterministic verification |
| `expected/policies/*` ğŸ›¡ï¸ | â›³ optional | Policy outcomes (license/sensitivity/provenance-first) |
| `expected/graph/*` ğŸ•¸ï¸ | â›³ optional | Downstream semantic registration (Neo4j import) |

> [!TIP]
> If your runner currently expects different filenames, keep the **conceptual contract** intact (inputs + expected outputs + hashes + run record), then map paths in code.

---

## ğŸ” Pipeline mental model

These fixtures mirror the intended system flow:

```mermaid
flowchart LR
  A[ğŸ“¥ Raw Inputs] --> B[ğŸ§ª Work / Transform];
  B --> C[âœ… Processed Outputs];
  C --> D[ğŸ›°ï¸ STAC + ğŸ“š DCAT];
  C --> E[ğŸ”— PROV Lineage];
  D --> F[ğŸ•¸ï¸ Knowledge Graph];
  E --> F;
  F --> G[ğŸŒ API];
  G --> H[ğŸ—ºï¸ UI - Map + Timeline + Stories];
  H --> I[ğŸ¤– Focus Mode - cited answers];
```

Key idea: **nothing â€œpublishesâ€ without the boundary artifacts** (catalog + provenance).

---

## ğŸ§¾ Boundary artifacts

### ğŸ›°ï¸ STAC (asset-level)

Use STAC Items/Collections to describe:

- ğŸ“ spatial extent (bbox/geometry)
- â³ temporal coverage (datetime/start/end)
- ğŸ“¦ assets (COG/GeoParquet/GeoJSON/etc)
- ğŸ·ï¸ license + attribution + lineage pointers

### ğŸ“š DCAT (dataset-level)

DCAT is the â€œcatalog front doorâ€:

- dataset title/description
- themes/tags
- publisher/source
- distribution links (files/API)
- access constraints / sensitivity markers

### ğŸ”— PROV (lineage)

PROV ties it together:

- **Entities**: raw files, processed outputs, derived artifacts
- **Activities**: transform steps (OCR, reproject, aggregate, tile, model run)
- **Agents**: pipeline tool, contributor, (optionally) AI model/system

> [!IMPORTANT]
> Derived/AI outputs (OCR corpora, simulated rasters, AI-predicted layers) are **first-class datasets**: they must live like any other processed output (cataloged + provenanced), not as â€œmisc files.â€

---

## ğŸ›¡ï¸ Governance & policy gates

Fixtures must explicitly test the rules we want to enforce:

### âœ… License & attribution (FAIR)

- Every fixture must declare:
  - license identifier (or â€œunknownâ€ that triggers failure)
  - attribution text
  - source URL(s) / archive reference(s)

### ğŸ” Sensitivity / access constraints (CARE)

Include at least one fixture scenario that exercises:

- redaction/obfuscation âœ…
- â€œrestrictedâ€ classification âœ…
- safe defaults (deny-by-default) âœ…

> [!WARNING]
> Never put real sensitive info in fixtures. Use synthetic data, coarse aggregation, or anonymized samples.

### ğŸ§¾ Provenance-first publishing

Even streaming/real-time examples should have at least **stub provenance** before being treated as displayable data.

---

## ğŸ§¬ Fixture types we want coverage for

A healthy fixture library covers the platformâ€™s real shape â€” not just happy paths.

| Fixture type | Example inputs ğŸ“¥ | Expected outputs âœ… | Gate behaviors to prove ğŸ§ª |
|---|---|---|---|
| ğŸ—ºï¸ Vector | GeoJSON/CSV | cleaned GeoJSON/GeoParquet + STAC/DCAT/PROV | schema checks, bbox/time extent, naming |
| ğŸ›°ï¸ Raster (scanned map) | small TIFF/PNG | COG + STAC asset metadata | georef metadata, tiling/overviews, lineage |
| ğŸ“„ Document/OCR | PDF/text snippet | extracted text + entities + PROV | evidence artifact treatment, traceability |
| â±ï¸ Streaming snapshot | NDJSON/CSV â€œtickâ€ | STAC item per tick + DCAT feed + stub PROV | â€œmany small datasetsâ€ pattern, timestamp immutability |
| ğŸ§ª Simulation result | small raster/table | processed outputs + catalog + PROV activity | promotion only after validation (transaction semantics) |
| ğŸ” Sensitive dataset | synthetic points | redacted output + policy result | CARE checks, access constraints enforced |
| ğŸ§µ Story/evidence (optional) | markdown + manifest | validated manifest + PROV links | citation discipline + auditability |

---

## ğŸ“¦ Adding a new fixture pack

### 1) Pick an ID ğŸ·ï¸

Use stable, sortable IDs:

- `f01_vector_basic`
- `f02_raster_cog_min`
- `f03_doc_ocr_stub`
- `f04_stream_tick`
- `f05_sensitive_redaction`

### 2) Add the source manifest ğŸ§¾

Your `input/sources/source.json` should include (at minimum):

- `source_url`
- `retrieved_at` (ISO-8601)
- `license`
- `expected_schema` (human description or machine schema ref)
- `notes` (optional)

> [!TIP]
> When real datasets are large, the manifest can be the â€œsource of truthâ€ and fixtures can store only tiny representative samples.

### 3) Add tiny raw data ğŸ“¦

- Keep raw samples **small** (ideally KBâ€“few MB)
- Treat raw as immutable (append-only philosophy)

### 4) Define expected outputs âœ…

Your `expected/` folder should reflect:

- processed outputs (cleaned, reprojected, transformed)
- STAC/DCAT/PROV â€œboundary artifactsâ€
- optional policy evaluation outcomes

### 5) Add integrity hashes ğŸ”

Create/update `run/checksums.sha256` including **all** relevant files.

### 6) Add run metadata ğŸ§¾

`run/run_manifest.json` should capture:

- fixture ID
- toolchain versions (when relevant)
- input/output digests
- policy pack version/digest (if applicable)
- timestamps + determinism notes

> [!NOTE]
> A strong pattern is to use **canonical JSON** before hashing (e.g., RFC 8785 JSON Canonicalization Scheme) so digests are stable across formatting.

### âœ… Definition of Done (fixture PR checklist)

- [ ] `input/sources/source.json` has license + URL + retrieved_at
- [ ] `input/raw/` contains only safe, tiny samples
- [ ] `expected/processed/` matches what the pipeline should output
- [ ] STAC + DCAT + PROV exist and reference each other meaningfully
- [ ] `run/checksums.sha256` verifies all relevant files
- [ ] `run/run_manifest.json` documents how/why outputs were produced
- [ ] If sensitive: redaction present + policy expectations included
- [ ] If AI-derived: provenance includes model/tool + parameters (as feasible)

---

## ğŸ§° Helpful geospatial conversion recipes

These are convenient when *building* fixtures locally (keep outputs tiny).

### ğŸ›°ï¸ Convert GeoTIFF â†’ COG (Cloud-Optimized GeoTIFF)

```bash
gdal_translate \
  -co TILED=YES \
  -co COPY_SRC_OVERVIEWS=YES \
  input.tif output_cog.tif
```

### ğŸ—ºï¸ Convert Shapefile â†’ GeoJSON

```bash
ogr2ogr -f GeoJSON output.geojson input.shp
```

### ğŸ§¼ Reproject a raster

```bash
gdalwarp -t_srs EPSG:4326 input.tif output_4326.tif
```

> [!TIP]
> Prefer EPSG:4326 for small interop fixtures unless a test specifically targets projection behavior.

---

## ğŸ§  AI/analysis fixtures

If a fixture includes OCR, NER/geoparsing, or model inference outputs:

- Treat outputs as **datasets** (not â€œnotesâ€)
- Store them under `expected/processed/`
- Catalog them (STAC/DCAT) and trace them (PROV)
- Label them as derived/AI-generated to preserve transparency

Optional (but excellent): include a tiny `model_card.md` ğŸ“„ or equivalent metadata for the model/tool used.

---

## ğŸ§· Troubleshooting

### â€œWhy does this gate care about metadata so much?â€ ğŸ¤”

Because downstream components (graph, API, UI, Focus Mode) depend on the catalog/provenance boundary artifacts to:

- show attributions in UI layers
- enable time slider behavior (temporal extent)
- allow â€œmap behind the mapâ€ inspection
- let an AI assistant cite sources rather than hallucinate

### â€œMy fixture is too bigâ€ ğŸ“¦

- Shrink it (crop raster, sample rows, simplify geometry)
- Store **only** manifests and tiny representative samples in fixtures
- For large artifacts, use an external artifact store (e.g., OCI registry/LFS) and keep hashes + pointers here

---

## ğŸ“š Reference docs that shaped this contract

These concepts and requirements are aligned with the broader KFM system design:

- ğŸ—ï¸ Architecture flow: Raw â†’ ETL â†’ Catalog/Provenance â†’ Graph â†’ API â†’ UI â†’ Focus Mode  
- ğŸ›°ï¸ â€œSTAC + DCAT + PROVâ€ as required publishing boundary artifacts  
- ğŸ§ª Managed promotion + transactional pipeline semantics (avoid half-baked catalog states)  
- ğŸ§¾ Evidence-first narratives and manifests (optional fixture type)  
- ğŸ›¡ï¸ Policies as tests (FAIR/CARE enforcement)  
- ğŸ§° Practical geospatial tooling (GDAL/OGR/QGIS/PostGIS)  
- ğŸ”¬ Reproducibility patterns (run logs, immutable raw data)

> [!NOTE]
> Keep this README â€œcontract-first.â€ If the runner implementation evolves, update the *mapping*, not the principles.

