# ðŸ§¾ `dev_prov` Scripts â€” Developer Provenance Toolkit (MCP)

![Provenance](https://img.shields.io/badge/provenance-first%20âœ…-2ea44f)
![W3C PROV-O](https://img.shields.io/badge/W3C-PROV--O-2b579a)
![STAC](https://img.shields.io/badge/STAC-metadata-blue)
![DCAT](https://img.shields.io/badge/DCAT-catalog-blueviolet)
![OPA + Conftest](https://img.shields.io/badge/OPA%20%2B%20Conftest-policy--as--code-orange)
![OCI](https://img.shields.io/badge/OCI-artifacts-555)
![Sigstore Cosign](https://img.shields.io/badge/Sigstore-Cosign-6f42c1)
![Neo4j](https://img.shields.io/badge/Neo4j-graph-018bff)
![PostGIS](https://img.shields.io/badge/PostGIS-geo-2c7fb8)

> [!IMPORTANT]
> **KFM is â€œprovenance-first.â€** If a change produces or updates *data, narratives, models, or AI outputs*, the change should also ship **lineage evidence** (PROV) and **catalog metadata** (STAC/DCAT), then pass **policy gates** before promotion. âœ…

---

## ðŸ“ Where you are

This README documents the scripts living under:

- ðŸ“ `mcp/` â†’ Master Coder Protocol / methods / reproducible workbench ðŸ§ª  
- ðŸ“ `dev_prov/` â†’ developer provenance (code + data + AI + CI lineage) ðŸ§¬  
- ðŸ“ `scripts/` â†’ small, boring CLIs that **generate, validate, package, and publish** provenance artifacts ðŸ§¾

---

## ðŸ§  What these scripts are for

These scripts exist to make provenance **easy to do correctly** and **hard to skip**.

They support (at minimum):

- ðŸ§¬ **PROV lineage** for datasets, model runs, derived outputs, and AI outputs  
- ðŸ—‚ï¸ **Catalog metadata** alignment (STAC + DCAT + references into PROV)  
- ðŸ§¾ **Run Manifests** (deterministic â€œwhat ran, what it used, what it producedâ€)  
- ðŸ§¾ **Evidence Manifests** (claims â†’ citations â†’ datasets/docs/graph entities)  
- ðŸ§· **Policy gates** (OPA + Conftest) for provenance-first publishing + FAIR/CARE  
- ðŸ§ª **Graph health checks** (integrity, constraints, drift detection)  
- ðŸ“¦ **OCI artifact publishing** (ORAS) + ðŸ” **signing/attestation** (Cosign/SLSA)  

---

## ðŸ—ºï¸ Big-picture flow (how provenance moves through KFM)

```mermaid
flowchart LR
  A[data/raw ðŸ§±] --> B[data/processed ðŸ§¼]
  B --> C[STAC/DCAT/PROV ðŸ—‚ï¸ðŸ§¬]
  C --> D[Neo4j CSV import ðŸ§ ]
  D --> E[UI layers + Story Nodes ðŸ—ºï¸ðŸ“–]
  E --> F[Focus Mode answers ðŸ§ ðŸ’¬ (with citations)]

  subgraph dev_prov_scripts[dev_prov scripts ðŸ§¾]
    S1[run_manifest ðŸ§¾] --> C
    S2[evidence_manifest ðŸ§·] --> E
    S3[validate + policy âœ…] --> C
    S4[publish_oci + sign ðŸ”] --> G[(OCI Registry ðŸ“¦)]
  end
```

---

## ðŸ“¦ Folder map (recommended structure)

> [!NOTE]
> Your repo may vary. Treat this as the **target convention** so policy + CI + humans all agree on where artifacts live.

```text
ðŸ“¦ mcp/dev_prov/
â””â”€ ðŸ“ scripts/
   â”œâ”€ ðŸ“„ README.md                      ðŸ‘ˆ you are here
   â”œâ”€ ðŸ prov_pr_to_jsonld.py            (GitHub PR â†’ PROV-O JSON-LD)
   â”œâ”€ ðŸ make_run_manifest.py            (pipeline run manifest + digests)
   â”œâ”€ ðŸ make_evidence_manifest.py        (claims/citations pack for Story Nodes / Pulse Threads)
   â”œâ”€ ðŸ validate_prov_bundle.py          (schema + policy validation)
   â”œâ”€ ðŸ graph_health_check.py            (Neo4j integrity checks + report output)
   â”œâ”€ ðŸš oci_push.sh                     (publish artifacts via ORAS)
   â”œâ”€ ðŸš oci_sign.sh                     (cosign sign + attach attestations)
   â””â”€ ðŸ“ schemas/
      â”œâ”€ ðŸ“„ run_manifest.schema.json
      â””â”€ ðŸ“„ evidence_manifest.schema.json
```

---

## ðŸš€ Quickstart

### 1) Prereqs (local dev)
Pick the subset you need:

- ðŸ Python (for JSON/JSON-LD generation + validation)
- ðŸ§° `jq` / `yq` (helpful for inspection)
- ðŸ›¡ï¸ `conftest` (OPA policy checks)
- ðŸ“¦ `oras` (OCI artifact push/pull)
- ðŸ” `cosign` (sign artifacts + attach attestations)
- ðŸ§  Neo4j access (for graph health checks)

> [!TIP]
> Keep scripts **dependency-light**. CI should be able to run these in a minimal container.

### 2) Run a script (pattern)
From repo root:

```bash
# example pattern â€” update to match your actual filenames/entrypoints
python mcp/dev_prov/scripts/make_run_manifest.py --help
python mcp/dev_prov/scripts/validate_prov_bundle.py --help
```

---

## ðŸ§© Script contract (make every script â€œCI-friendlyâ€)

All scripts in this folder should follow these rules:

1. âœ… **Deterministic output**  
   - stable ordering, no random IDs, no timestamps unless explicitly part of the contract  
2. â™»ï¸ **Idempotent**  
   - rerunning with same inputs yields identical files (byte-for-byte if possible)  
3. ðŸ§¾ **Machine output first**  
   - write artifacts to `--out` paths  
   - human logs go to stderr  
4. ðŸ§ª **Exit codes matter**  
   - `0` pass, `1` validation fail, `2+` runtime error  
5. ðŸ”’ **Fail-closed**  
   - missing provenance or missing citations should be a hard error in validation mode  
6. ðŸ§· **Include trace hooks**  
   - link outputs to dataset IDs, run IDs, graph IDs, PR IDs, etc.

---

## ðŸ§± Core artifacts (contracts)

### ðŸ§¾ Run Manifest
A Run Manifest is a *deterministic ledger* of a pipeline run.

It should capture:

- ðŸ†” `run_id` (stable + meaningful)
- ðŸ§© pipeline name + version
- ðŸ§¾ inputs (URLs, dataset IDs, digests)
- ðŸ“¦ outputs (paths + digests)
- ðŸ§¬ link to PROV entity/activity IDs
- ðŸ§· policy results (pass/fail + rule IDs)
- ðŸ” signatures / attestation references (optional but recommended)

**Example (shape only):**
```json
{
  "run_id": "kfm.run.2026-02-01.purpleair.v2",
  "pipeline": {
    "name": "pipelines/purpleair_ingest",
    "version": "git:abcdef123"
  },
  "inputs": [
    {
      "type": "url",
      "uri": "https://example.gov/data.csv",
      "digest": "sha256:..."
    }
  ],
  "outputs": [
    {
      "path": "data/processed/air_quality/purpleair.parquet",
      "digest": "sha256:..."
    },
    {
      "path": "data/prov/air_quality/purpleair.prov.jsonld",
      "digest": "sha256:..."
    }
  ],
  "policy": {
    "conftest": {
      "passed": true,
      "ruleset": "tools/validation/policy/"
    }
  },
  "attestations": {
    "oci_ref": "oci://registry/org/kfm/purpleair:2026-02-01",
    "cosign": {
      "signed": true,
      "bundle_ref": "oci://...#attestation"
    }
  }
}
```

---

### ðŸ§· Evidence Manifest
Evidence Manifests are for **Story Nodes**, **Pulse Threads**, and anything narrative.

They should tie:

- âœï¸ a claim / statement / paragraph
- ðŸ”— to citations (datasets, documents, graph entities)
- ðŸ§¬ to provenance context (PROV IDs + dataset IDs)
- ðŸ§­ to sensitivity / access classification (FAIR/CARE, cultural protocols)

**Example (shape only):**
```json
{
  "story_id": "story.dust_bowl.county.douglas",
  "claims": [
    {
      "id": "c1",
      "text": "Douglas County experienced severe drought impacts in the 1930s.",
      "citations": [
        { "type": "dataset", "dataset_id": "kfm.ks.climate.drought.v1" },
        { "type": "document", "doc_id": "doc.dustbowl_report.1936" }
      ],
      "links": {
        "prov": "prov:Entity:kfm.focus.answer.123",
        "graph_entities": ["kg:County:Douglas_KS", "kg:Event:DustBowl_1930s"]
      },
      "governance": {
        "sensitivity": "public",
        "care_tags": []
      }
    }
  ]
}
```

---

### ðŸ§¬ PROV JSON-LD (W3C PROV-O)
PROV is the lineage backbone:

- **Entity** = data/artifact (dataset, file, model output, AI answer)  
- **Activity** = process (pipeline run, PR merge, AI generation step)  
- **Agent** = actor (human, bot, CI system, reviewer)  

**DevOps integration (key dev_prov idea):**
- PRs become **PROV Activities**
- commits become **PROV Entities**
- authors/reviewers become **PROV Agents**
- relationships (`prov:used`, `prov:wasAssociatedWith`, `prov:wasGeneratedBy`) connect them

---

## âœ… Validation & policy gates

These scripts should be callable in CI to enforce rules like:

- ðŸ§± **Pipeline ordering** (no â€œlater-stageâ€ artifacts without â€œearlier-stageâ€ outputs)
- ðŸ§¬ **Provenance-first publishing** (data changes require matching PROV updates)
- ðŸ§· **Evidence rules** (AI outputs + Story Nodes must include citations)
- ðŸ§­ **Sensitivity rules** (CARE/cultural protocol tags enforce differential access)

**Typical local check pattern:**
```bash
# update these paths to match repo structure
conftest test -p tools/validation/policy data/prov data/stac data/catalog/dcat
```

> [!TIP]
> Pair policy checks with **schema validation** (JSON Schema) and **content validation** (e.g., required fields + stable IDs).

---

## ðŸ“¦ Publishing artifacts to OCI (optional but powerful)

KFM can treat provenance bundles like container artifacts:

- ðŸ“¦ publish with **ORAS**
- ðŸ” sign with **Cosign**
- ðŸ§¬ attach PROV JSON-LD / run manifests as referrers/attestations
- ðŸ” use registry permissions for restricted datasets

**Workflow sketch:**
```bash
# push a bundle (data + metadata)
./mcp/dev_prov/scripts/oci_push.sh \
  --artifact-dir data/audits/kfm.run.2026-02-01.purpleair.v2 \
  --ref oci://registry/org/kfm/purpleair:2026-02-01

# sign + attach attestations
./mcp/dev_prov/scripts/oci_sign.sh \
  --ref oci://registry/org/kfm/purpleair:2026-02-01
```

---

## ðŸ§  Focus Mode + UI integration (why citations matter)

Focus Mode and the UI are designed so that:

- ðŸ’¬ AI answers are **context-aware** (map layers, selected feature, timeline)  
- ðŸ§· Every answer includes **clickable citations** (datasets/docs/entities)  
- ðŸ§¬ Derived outputs (including AI summaries) carry PROV lineage so audits can trace â€œwhyâ€  

**Practical outcome:**  
If the AI canâ€™t cite evidence, it should *refuse* rather than hallucinate. âœ…

---

## ðŸ§­ Sensitivity, CARE, and cultural protocols

Provenance is not only â€œwhere it came fromâ€ â€” it also includes:

- ðŸ§­ sensitivity level (public / sensitive / restricted)
- ðŸª¶ cultural protocols and community-defined access rules
- ðŸ§‘â€ðŸ¤â€ðŸ§‘ credit to contributors and knowledge holders

Your dev_prov artifacts should carry these governance tags so:

- policy can enforce them automatically âœ…  
- UI can apply redaction/obfuscation where required ðŸ•¶ï¸  
- exports can include appropriate provenance summaries ðŸ“Ž  

---

## ðŸ§° Adding a new script (checklist)

When you add a script to this folder:

- [ ] Give it a **single responsibility** (generate *or* validate *or* publish)
- [ ] Add `--help`, `--in`, `--out`, and `--strict`
- [ ] Make outputs deterministic + idempotent â™»ï¸
- [ ] Add a tiny fixture under `mcp/dev_prov/scripts/fixtures/` (if used)
- [ ] Add CI wiring (or document how CI calls it)
- [ ] Update the **Script Catalog** section in this README âœ…

---

## ðŸ“š Project docs this folder implements

These scripts operationalize the design described across KFMâ€™s docs:

- ðŸ“˜ **Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation**  
- ðŸ—ï¸ **KFM â€“ Comprehensive Architecture, Features, and Design**  
- ðŸ§­ðŸ¤– **KFM â€“ AI System Overview** (citations + PROV enforcement + policy pack)  
- ðŸ–¥ï¸ **KFM â€“ Comprehensive UI System Overview** (citations UX + evidence-first UI)  
- ðŸ“¥ **KFM Data Intake â€“ Technical & Design Guide** (STAC/DCAT/PROV pipeline + W-P-E)  
- ðŸ’¡ **Additional Project Ideas** (OCI artifacts, run manifests, pulse ideas)  
- ðŸŒŸ **Latest Ideas & Future Proposals** (idempotency, kill-switch, supply-chain attestations)  
- ðŸ§­ **Innovative Concepts to Evolve KFM** (sensitivity-aware governance, AR/digital twins, GeoXAI)

Reference compendiums (deep background / curated reading ðŸ“š):
- ðŸ¤– **AI Concepts & more** (portfolio)
- ðŸ—ºï¸ **Maps / Google Maps / Virtual Worlds / Geospatial WebGL** (research pack)
- ðŸ§° **Various programming languages & resources** (portfolio)
- ðŸ§  **Data Management / Architectures / Data Science / Bayesian Methods** (portfolio)

> [!NOTE]
> If a PDF is a *portfolio* or not text-indexed, consider extracting the relevant sub-docs into `/docs/` as markdown over time for easier cross-linking and automation.
