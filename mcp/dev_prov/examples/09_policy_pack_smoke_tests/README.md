# ğŸ§ª Example 09 â€” Policy Pack Smoke Tests âš–ï¸

![Example](https://img.shields.io/badge/example-09-blue)
![Module](https://img.shields.io/badge/module-mcp%2Fdev__prov-orange)
![Policy](https://img.shields.io/badge/policy-OPA%20%2B%20Rego-6e40c9)
![Runner](https://img.shields.io/badge/tests-Conftest-0aa)
![Governance](https://img.shields.io/badge/governance-FAIR%20%2B%20CARE-success)
![Posture](https://img.shields.io/badge/security-fail--closed-critical)
![Provenance](https://img.shields.io/badge/provenance-first-âœ…-informational)

ğŸ“ **Path:** `mcp/dev_prov/examples/09_policy_pack_smoke_tests/`

> [!NOTE]
> This example provides a **fast, deterministic â€œsmoke testâ€ harness** for KFMâ€™s policy packs (OPA/Rego + Conftest).  
> The intent is simple: **if policies are broken, or if governance can be bypassed, we find out immediately** â€” locally and in CI.

---

## ğŸ¯ What this example is for

This example is built to help `mcp/dev_prov` teams validate that:

- âœ… The **policy pack compiles** (no broken Rego, no missing imports, no namespace drift)
- âœ… â€œGoldenâ€ fixtures still **PASS** (allowed) and **FAIL** (denied) as expected
- âœ… Deny messages remain **stable + actionable** (ex: `KFM-PROV-001: ...`)
- âœ… KFMâ€™s **nonâ€‘negotiables** remain enforceable:
  - **provenance-first**
  - **canonical pipeline ordering**
  - **API boundary**
  - **evidence-first outputs** (AI + narrative)
  - **failâ€‘closed** posture

---

## ğŸ§  Why smoke tests (not just unit tests)?

Policy packs are *governance as code*. That means they are **production safety rails** â€” not documentation.

Smoke tests give you:

- ğŸš¦ **Early warning** when a policy change accidentally weakens governance
- ğŸ” **Repeatability** (MCP mindset): same inputs â†’ same outcomes
- ğŸ§· **Regression protection** for â€œsocial contractsâ€ (FAIR/CARE, sovereignty, security)
- ğŸ§© A clear path to scale: add a fixture â†’ lock in expected behavior

> [!TIP]
> Treat these fixtures like **golden experiments**: they encode â€œwhat must always be trueâ€ about KFM.

---

## ğŸ“¦ What gets tested (recommended coverage)

You can tailor this to your repo, but these are the **KFM-aligned domains** this example expects to cover:

| Domain ğŸ§± | What we smoke-test âœ… | Example fixture idea ğŸ§ª |
|---|---|---|
| ğŸ§¬ Provenance-first | Derived data changes require PROV updates | processed CSV without matching `data/prov/*` |
| ğŸ§­ Pipeline ordering | No later stage without earlier stage artifacts | graph export added but no STAC/DCAT/PROV |
| ğŸ§¾ FAIR metadata | license/provider/contact required | DCAT missing license / provider |
| ğŸª¶ CARE / sovereignty | sensitivity labels + propagation | culturally sensitive dataset lacking `care_label` |
| ğŸ¤– AI output governance | AI answers must be labeled + cited | Focus Mode answer missing citations |
| ğŸ§µ Story Nodes / Pulse | evidence manifest present + resolvable | Story Node missing `evidence_manifest` |
| ğŸ” Secrets / security | block obvious secrets in configs | â€œAWS key-likeâ€ strings in JSON/YAML |
| ğŸ§¾ dev_prov run manifests | schema present + canonical digest | run_manifest missing `tool_versions` / digest |

---

## ğŸ—‚ï¸ Suggested folder layout (inside this example)

Use this as a **reference layout** to keep smoke tests clean and discoverable:

```text
mcp/dev_prov/examples/09_policy_pack_smoke_tests/
â”œâ”€ ğŸ“˜ğŸ“„ README.md                      # ğŸ“˜ What this pack tests + how to run locally/CI + expected pass/fail signals
â”œâ”€ ğŸ§ª fixtures/                        # ğŸ§ª Policy test fixtures (known-pass/known-fail) used by conftest/OPA
â”‚  â”œâ”€ âœ… pass/                          # âœ… Fixtures that MUST pass (baseline â€œgoodâ€ examples)
â”‚  â”‚  â”œâ”€ âœ…ğŸ§¾ dcat.valid.json            # Valid DCAT record (license, distributions, links present)
â”‚  â”‚  â”œâ”€ âœ…ğŸ§¾ stac.valid.json            # Valid STAC object (profile-compliant; links resolvable)
â”‚  â”‚  â”œâ”€ âœ…ğŸ“ story_node.valid.md        # Valid Story Node markdown (front-matter + citations policy satisfied)
â”‚  â”‚  â””â”€ âœ…ğŸ§¾ run_manifest.valid.json    # Valid run manifest (ids, timestamps, inputs/outputs, hashes present)
â”‚  â””â”€ âŒ fail/                          # âŒ Fixtures that MUST fail (proves policies catch regressions)
â”‚     â”œâ”€ âŒğŸ§¾ dcat.missing_license.json   # Missing/invalid license â†’ should be denied
â”‚     â”œâ”€ âŒğŸ§¬ğŸ§¾ prov.missing_for_processed_change.json # Processed change without PROV linkage â†’ should be denied
â”‚     â”œâ”€ âŒğŸ¤–ğŸ§¾ ai_answer.no_citations.json # AI output with no citations â†’ should be denied (evidence-first)
â”‚     â””â”€ âŒğŸ”’ğŸ§¾ secrets.detected.yaml     # Secret-like content fixture â†’ should be denied by secret/PII policies
â”œâ”€ ğŸ“¥ inputs/                          # Inputs describing â€œwhat changedâ€ (used to scope which policies run)
â”‚  â””â”€ ğŸ“¥ğŸ§¾ pr_changed_files.sample.json  # Sample PR file-change list used by gate runner routing logic
â””â”€ âš™ï¸ scripts/                         # Helper scripts to execute the smoke suite consistently
   â””â”€ âš™ï¸ğŸ§ªğŸ“„ smoke.sh                    # Runs conftest/OPA against fixtures and exits non-zero on unexpected results
```

> [!NOTE]
> The exact filenames donâ€™t matter â€” consistency and intent do.  
> Keep fixtures tiny, explicit, and named like â€œwhat should happen.â€

---

## ğŸš€ Quickstart

### 1) Pick your policy pack directory ğŸ¯

KFM docs commonly describe policy packs living in one of these locations:

- `api/scripts/policy/` (CI governance pack)
- `tools/validation/policy/` (validation/runtime policy pack)

Set a `POLICY_DIR` that matches **your repoâ€™s** structure:

```bash
# from repo root
export POLICY_DIR="api/scripts/policy"
# OR
export POLICY_DIR="tools/validation/policy"
```

### 2) Run the smoke tests ğŸ§ª

#### Option A â€” helper script (if present)
```bash
bash mcp/dev_prov/examples/09_policy_pack_smoke_tests/scripts/smoke.sh
```

#### Option B â€” direct Conftest execution
```bash
# PASS fixtures should produce zero denies
conftest test \
  -p "$POLICY_DIR" \
  mcp/dev_prov/examples/09_policy_pack_smoke_tests/fixtures/pass

# FAIL fixtures should produce denies (this should FAIL the command)
conftest test \
  -p "$POLICY_DIR" \
  mcp/dev_prov/examples/09_policy_pack_smoke_tests/fixtures/fail
```

#### Option C â€” OPA compile / unit tests (optional, but recommended)
If your policy pack includes `_test.rego` tests:

```bash
opa test "$POLICY_DIR" -v
```

---

## âœ… Expected behavior

### âœ… â€œpass/â€ fixtures
- should return **0 denies**
- should not require waivers
- should remain stable over time

### âŒ â€œfail/â€ fixtures
- should return **1+ denies**
- denies should include:
  - a **stable rule id** (ex: `KFM-PROV-001`)
  - a **human-friendly message**
  - (optional) a remediation hint

<details>
<summary>ğŸ“Œ Example deny message style</summary>

```text
FAIL - prov.missing_for_processed_change.json - KFM-PROV-001:
Processed data changed without matching PROV update.
Fix: add/refresh the related PROV bundle under data/prov/...
```
</details>

---

## ğŸ§© Adding a new smoke test

### Add a fixture
1. Decide whether itâ€™s **PASS** or **FAIL**
2. Put it under:
   - `fixtures/pass/` âœ…  (should remain compliant)
   - `fixtures/fail/` âŒ  (should be denied)

### Lock the behavior
- Run the suite and confirm it behaves the way you intend.
- If your deny message format changed, fix the policy output (preferable) rather than â€œteachingâ€ fixtures to accept vague output.

> [!TIP]
> Fixtures should be **minimal**: one violation per fixture, unless youâ€™re explicitly testing bundling behavior.

---

## ğŸ§¾ Waivers policy (use sparingly)

KFM-style governance expects waivers to be:

- â³ **time-bound** (expiration date)
- ğŸ§¾ **justified** (why this is acceptable temporarily)
- ğŸ¯ **scoped** (rule id + file scope, not â€œdisable everythingâ€)

> [!WARNING]
> If you add a waiver, you are making a governance exception.  
> Treat it like a production incident workaround: tracked, reviewed, and removed.

---

## ğŸ” CI integration sketch (GitHub Actions)

Add a fast job that runs on PRs:

```yaml
name: policy-pack-smoke
on:
  pull_request:

jobs:
  smoke:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      # Install conftest/opa however your repo standardizes tooling
      # (pinned versions recommended)
      - name: Run Policy Pack Smoke Tests
        run: |
          export POLICY_DIR="api/scripts/policy"
          conftest test -p "$POLICY_DIR" mcp/dev_prov/examples/09_policy_pack_smoke_tests/fixtures/pass
          # fail fixtures should DENY; invert expectation if you assert denies via a script
          conftest test -p "$POLICY_DIR" mcp/dev_prov/examples/09_policy_pack_smoke_tests/fixtures/fail && exit 1 || exit 0
```

> [!TIP]
> For the â€œfail fixtures should failâ€ step, itâ€™s cleaner to wrap it in `scripts/smoke.sh` so the CI logic stays readable.

---

## ğŸ”’ What â€œgoodâ€ looks like (governance signals)

This example should make it easy to confirm:

- âœ… Policy pack denies **pipeline bypass** attempts
- âœ… Policy pack denies **missing provenance** for derived artifacts
- âœ… Policy pack denies **unsourced AI outputs**
- âœ… Policy pack denies **metadata incompleteness** (license/provider)
- âœ… Policy pack denies **sensitive data mishandling**
- âœ… Policy pack denies **secret leakage**
- âœ… dev_prov artifacts (run manifests, attestations) remain **valid inputs** to governance

---

## ğŸ“š Design inputs used for this example

This example is aligned with KFMâ€™s documented approach to:

- ğŸ§­ **canonical pipeline ordering** (ETL â†’ catalogs â†’ graph â†’ APIs â†’ UI â†’ narratives â†’ Focus Mode)
- ğŸ§¬ **provenance-first** enforcement + failâ€‘closed posture
- âš–ï¸ **OPA/Rego policy packs** executed via **Conftest**
- ğŸ§¾ **evidence-first narratives** (Story Nodes, evidence manifests, citations)
- ğŸ¤– **AI citations as a hard gate**
- ğŸ” **security + supply-chain hygiene**
- ğŸ§ª **MCP reproducibility workflows** (docs-first, repeatable experiments, traceable outputs)

<details>
<summary>ğŸ—ƒï¸ Project docs & reference material (for deeper context)</summary>

- ğŸ“˜ Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation
- ğŸ¤– Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–
- ğŸ§­ Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design
- ğŸ—ºï¸ Kansas Frontier Matrix â€“ Comprehensive UI System Overview
- ğŸ“¥ KFM Data Intake â€“ Technical & Design Guide
- ğŸ’¡ Innovative Concepts to Evolve KFM
- ğŸ§  AI Concepts & more
- ğŸ—ƒï¸ Data Management Theories / Architectures / Data Science (Bayesian, etc.)
- ğŸŒ Maps / Virtual Worlds / Archaeological CG / Geospatial WebGL
- ğŸ§° Various programming languages & resources
- ğŸŒŸ Latest Ideas & Future Proposals
- ğŸ§µ Additional Project Ideas (Pulse Threads, evidence manifests, run manifests)
- ğŸ§ª Scientific Method / Research / Master Coder Protocol documentation
</details>

---

## âœ… Acceptance checklist (keep this green)

- [ ] Policy pack compiles (`opa test` or equivalent compile check)
- [ ] PASS fixtures: no denies
- [ ] FAIL fixtures: denies fire reliably
- [ ] Denies contain stable rule IDs (ex: `KFM-PROV-001`)
- [ ] Waivers are time-bound + justified (if any)
- [ ] CI runs this suite on every PR touching policies or governed artifacts

---

## ğŸ§­ Related links (repo-local)

> These are *intended* repo paths based on the KFM architecture docs. Adjust if your tree differs.

- `../../../../api/scripts/policy/README.md` ğŸ§¾
- `../../../../docs/MASTER_GUIDE_v13.md` ğŸ§­
- `../../../../docs/guides/pipelines/` ğŸ› ï¸
- `../../../../mcp/` ğŸ§ª
- `../../../../schemas/` ğŸ“

---
