# ğŸ›°ï¸ STAC Items â€” Evidence Bundle (`01_dataset_evidence_triplet`)

![Example](https://img.shields.io/badge/example-01__dataset__evidence__triplet-6c757d)
![STAC](https://img.shields.io/badge/STAC-Items%20(1.0.x)-2b8a3e)
![DCAT](https://img.shields.io/badge/DCAT-partner%20artifact-1f6feb)
![PROV](https://img.shields.io/badge/W3C%20PROV-partner%20artifact-8b5cf6)
![Policy](https://img.shields.io/badge/policy-fail--closed%20gates-cc0000)
![FAIR+CARE](https://img.shields.io/badge/principles-FAIR%20%2B%20CARE-0ea5e9)

> ğŸ¯ **Purpose:** This folder contains **STAC Item JSON** documents that make up the **â€œSTACâ€ leg** of the **STAC + DCAT + PROV â€œevidence tripletâ€** used by KFM-style, provenance-first ingestion pipelines.

---

## ğŸ§© Where this fits in the Evidence Triplet

KFMâ€™s stance is **contract-first + provenance-first**: anything that appears in the UI or AI â€œFocus Modeâ€ must be **traceable to cataloged sources** and **provable processing** (no â€œmystery layersâ€).  
Thatâ€™s why the system uses **three linked standards**:

- **ğŸ›°ï¸ STAC (this folder)** â†’ *asset-level* spatiotemporal metadata (what file(s) exist, where/when they apply)
- **ğŸ·ï¸ DCAT** â†’ *dataset-level* discovery metadata (title, publisher/provider, license, access, citation)
- **ğŸ§¾ PROV** â†’ *lineage & reproducibility* (which inputs + steps produced these assets)

```mermaid
flowchart LR
  A[Raw sources] --> B[Pipeline / Ingest Run]
  B --> C[STAC Items<br/>assets + bbox + datetime]
  B --> D[DCAT Dataset<br/>license + publisher + access]
  B --> E[PROV Record<br/>inputs + activity + agents]
  C --> F[Graph / Index]
  D --> F
  E --> F
  F --> G[API]
  G --> H[UI + Focus Mode]
```

---

## ğŸ“¦ What belongs in `evidence/stac/items/`

âœ… **One JSON file per STAC Item** (granule/asset/observation). Typical â€œitemsâ€ represent:

- ğŸ—ºï¸ A geospatial layer output (COG, GeoJSON, MBTiles, vector tiles, etc.)
- ğŸ“ˆ A time-slice (e.g., â€œlandcover_1990â€, â€œlandcover_1991â€, â€¦)
- â±ï¸ A streaming â€œmicro-batchâ€ observation (sensor reading, event point, etc.)
- ğŸ§  A derived artifact (model output raster, inferred features, extracted mentions-as-points)

> GitHub tip: Items should be portable. Prefer **relative** `href` targets for assets when building a self-contained evidence bundle.

---

## ğŸ—‚ï¸ Expected sibling structure (typical)

Even if your example bundle is minimal, this is the common layout pattern:

```text
evidence/
  stac/
    catalog.json              # STAC root (optional but recommended)
    collections/              # STAC Collections (recommended)
      <collection>.json
    items/                    # âœ… YOU ARE HERE
      README.md
      <item>.json
      <item>.json
```

---

## âœ… Item Contract (Core + KFM Profile)

### 1) STAC Core fields (minimum expected)

Every Item should include:

- `stac_version`
- `type: "Feature"`
- `id`
- `geometry` + `bbox`
- `properties`
  - `datetime` **or** `start_datetime` + `end_datetime`
- `assets` (at least one)
- `links`
- `collection` (when using collections)

### 2) KFM-required extensions/properties (profile-driven)

KFM links STAC/DCAT/PROV together and enforces additional governance fields. Common â€œmust-havesâ€ include:

- `properties.kfm:dataset_id` â†’ canonical dataset identifier
- `properties.kfm:classification` â†’ public/internal/restricted/etc (governance + UI behavior)
- `properties.kfm:provenance_ref` **or** `properties.kfm:prov_activity_id` â†’ pointer/ID to the PROV activity that produced this item  
  *(can also be represented as a `link`â€”see below)*

> âš–ï¸ Policies are generally **fail-closed**: missing required metadata, missing PROV/DCAT links, missing license in DCAT, or sensitivity/classification violations should block merges/releases.

---

## ğŸ”— Linking the Triplet (STAC â‡„ DCAT â‡„ PROV)

KFMâ€™s standards are explicitly **cross-linked**, so a consumer can traverse:

**Item â†’ Dataset (DCAT) â†’ Lineage (PROV)** and back.

### Recommended `links` pattern

Use normal STAC link relations where applicable, plus â€œbridgeâ€ links to DCAT/PROV:

- `self`, `root`, `parent`, `collection`
- `describedby` â†’ DCAT dataset record (discovery metadata)
- `via` or a custom rel (project-defined) â†’ PROV record (lineage)

> ğŸ§  Why this matters: the knowledge graph typically mirrors this as nodes like **Dataset (DCAT)**, **Asset (STAC)**, and **Activity/Run (PROV)** with explicit edges between them.

<details>
<summary><strong>ğŸ“ Example: links array (template)</strong></summary>

```json
{
  "links": [
    { "rel": "self", "href": "./item--EXAMPLE.json", "type": "application/geo+json" },
    { "rel": "collection", "href": "../collections/example-collection.json", "type": "application/json" },
    { "rel": "root", "href": "../catalog.json", "type": "application/json" },

    { "rel": "describedby", "href": "../../dcat/datasets/example-dataset.jsonld", "type": "application/ld+json", "title": "DCAT Dataset" },
    { "rel": "via", "href": "../../prov/runs/example-run.prov.jsonld", "type": "application/ld+json", "title": "PROV Run / Lineage" }
  ]
}
```
</details>

---

## ğŸ§¾ Assets: Conventions that keep bundles portable

### Asset keys
Pick stable, boring keys:

- `data` (primary)
- `metadata` (aux)
- `thumbnail`
- `tiles` / `mvt` / `mbtiles` (if applicable)
- `doc` (if the â€œassetâ€ is a source document)

### Asset fields (recommended)
For each asset:

- `href` (prefer relative paths inside the bundle)
- `type` (MIME)
- `roles` (e.g., `["data"]`, `["metadata"]`)
- `title` and `description` (human-friendly UI labels)
- If available: checksums + sizes (helps integrity + provenance)

> ğŸ§· Provenance-friendly bundles often include a run manifest / checksum strategy so assets can be verified and tied to immutable run IDs.

---

## ğŸ—ºï¸ Geospatial conventions (so everything renders correctly)

- ğŸŒ **CRS:** STAC GeoJSON geometry is typically **WGS84 / EPSG:4326**.
- ğŸ“¦ If your pipeline works in projected CRS (common in PostGIS), transform for export:
  - PostGIS patterns like `ST_Transform(..., 4326)` + `ST_AsGeoJSON(...)` are standard for producing GeoJSON geometries.
- ğŸ§± Large data: store heavy rasters as COGs; store vector layers as GeoJSON/DB tables; serve tiles as MVT where needed.

> UI stacks like MapLibre/Leaflet (2D) and â€œtime sliderâ€ layer toggling benefit from clean temporal fields in Items, enabling â€œspace + timeâ€ exploration.

---

## âš–ï¸ Sensitivity, sovereignty & privacy (non-negotiables)

KFMâ€™s governance model typically enforces:

- **FAIR + CARE** alignment (open science + ethical/community-respecting use)
- **Classification propagation**: outputs canâ€™t become â€œless restrictiveâ€ than inputs
- **UI safeguards**: sensitive locations may require generalization/blurring at certain zoom levels
- **Provenance completeness**: no display/usage without provenance artifacts

Optional (future-friendly) privacy patterns that pair well with metadata-rich catalogs:

- **Generalization / suppression** for sensitive coordinates
- **Query auditing** and inference-control strategies for protected datasets
- **Differential privacy** for aggregate views (when appropriate)

---

## ğŸ§ª Validation & CI gates (how to keep Items â€œmergeableâ€)

KFM-style pipelines typically run **policy + schema checks** on every PR:

### â€œDefinition of Doneâ€ âœ…
- [ ] Item JSON validates as STAC Item
- [ ] Item links to **DCAT** and **PROV** artifacts
- [ ] `kfm:dataset_id` and `kfm:classification` present
- [ ] Assets include stable `href` + `type` (+ checksum/size if available)
- [ ] No broken links
- [ ] No secrets / tokens / credentials accidentally committed
- [ ] Gate passes **fail-closed** policy pack rules

<details>
<summary><strong>ğŸ§° Typical toolchain (examples)</strong></summary>

- STAC validation via `pystac` / `stac-validator`
- Schema checks + link checks
- Policy-as-code via **OPA + Conftest** (Rego rules), e.g.:
  - â€œEvery dataset must have a licenseâ€
  - â€œSTAC/DCAT/PROV completeness requiredâ€
  - â€œAI outputs must include citationsâ€
  - â€œNo secrets in diffsâ€
</details>

---

## ğŸ§¾ Dev provenance (`dev_prov`) â€” tie Items to PRs & runs

This example sits under `mcp/dev_prov/â€¦`, so we explicitly encourage â€œdevelopment provenanceâ€ links:

- Treat merges/PRs as provenance-relevant **Activities**
- Treat commits/build outputs as provenance-relevant **Entities**
- Treat authors/reviewers/bots as provenance-relevant **Agents**

Practical win: you can answer questions like  
â€œWhich PR produced this STAC Item, and who reviewed it?â€  
by traversing Item â†’ PROV â†’ dev activity.

> Bonus pattern: deterministic pipeline runs can generate a **run manifest**, canonicalize it (RFC 8785), hash it, and use that digest as an immutable activity identifier that can be referenced from PROV and/or Item properties.

---

## ğŸš€ Extensions & future-proofing

As KFM expands (AR/4D digital twins, richer simulations, richer storytelling), Items can grow via STAC extensions and extra properties:

- ğŸ›°ï¸ `proj:*` for projection metadata
- ğŸŸ© `raster:*` for raster bands
- ğŸ›°ï¸ `eo:*` for Earth observation-ish assets
- ğŸ§  ML/model metadata (and â€œmodel cardsâ€ stored as linked assets)
- ğŸ“– Story / narrative anchors (link Items to story nodes that cite sources)

---

## ğŸ“š Project docs & reference library (used to shape this folderâ€™s contract)

These are the core project documents that motivated the conventions above:

- ğŸ“˜ **KFM Data Intake â€“ Technical & Design Guide** (triplet integration, profiles, streaming Items)
- ğŸ§­ **KFM Comprehensive Architecture / Features / Design** (policy gates, FAIR+CARE, governance)
- ğŸ§¾ **KFM Comprehensive Technical Documentation** (contract-first + provenance-first, no â€œmystery layersâ€)
- ğŸ–¥ï¸ **KFM UI System Overview** (user-visible provenance per layer / â€œmap behind mapâ€ behavior)
- ğŸ¤– **KFM AI System Overview** (policy pack, dev-provenance, citations & compliance)
- ğŸ’¡ **Innovative Concepts** (AR/4D trajectory + cultural protocols)
- ğŸ§ª **Scientific Method / Master Coder Protocol** (reproducibility mindset for runs & artifacts)
- ğŸ—ºï¸ **Open-source Geospatial Mapping Hub Design + Geo/Python Cookbook** (COGs, GeoJSON export, PostGIS patterns)
- ğŸ“¦ **Reference Portfolios** (AI concepts, programming resources, mapping/webgl, data mgmt/Bayesian methods)

> ğŸ§  Bottom line: **STAC Items here arenâ€™t â€œjust metadata.â€** Theyâ€™re the evidence backbone that makes UI + AI outputs trustworthy, reproducible, and governable.

