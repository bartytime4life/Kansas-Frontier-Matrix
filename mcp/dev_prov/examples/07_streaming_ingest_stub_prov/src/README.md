# ğŸ“¡ 07 â€” Streaming Ingest Stub + PROV (src)

![Example](https://img.shields.io/badge/example-07_streaming__ingest__stub__prov-blue)
![MCP](https://img.shields.io/badge/MCP-dev__prov-8A2BE2)
![Standards](https://img.shields.io/badge/metadata-STAC%20%7C%20DCAT%20%7C%20PROV-orange)
![Pattern](https://img.shields.io/badge/pattern-micro--batch%20%2B%20idempotent-success)
![Governance](https://img.shields.io/badge/governance-OPA%20%2B%20Conftest-important)

> [!IMPORTANT]
> This is a **stub / example provider**: it demonstrates *how* KFM expects streaming ingestion to behave (contracts âœ…, provenance âœ…, governance âœ…), not a production-grade connector.

---

## ğŸ§­ What this example is

This folder contains the **source implementation** for a streaming ingestion pattern that:
- polls or receives **real-time observations** (e.g., sensor readings, GTFS-RT vehicle positions),
- processes them in **micro-batches / windows**,
- writes to a storage adapter (stubbed or local),
- emits the KFM â€œevidence tripletâ€ artifacts:
  - ğŸ—‚ï¸ **STAC** (items/collections for geospatial/time indexing)
  - ğŸ·ï¸ **DCAT** (dataset/attribution + catalog exposure)
  - ğŸ§¬ **PROV** (lineage + chain-of-custody)
- produces an auditable **Run Manifest** per ingestion window,
- stays **append-only** and **idempotent** (exactly-once semantics per logical batch).

If youâ€™re building *any* â€œlive layerâ€ in KFM (rivers, transit, weather stations, traffic, simulations), this is the pattern to copy.

---

## ğŸ§  Mental model (KFM-style)

### Streaming data is â€œmany small datasets over timeâ€
KFM treats a stream as a rapid series of small ingests â€” each one must still be:
- validated,
- traceable,
- attributable,
- and safe to surface in the UI.

### Provenance is not optional (even for real-time)
Real-time layers must still have at least a **stub provenance record** before theyâ€™re used in graph/UI workflows.

---

## ğŸ“ Whatâ€™s in this folder

> [!NOTE]
> File names may vary slightly depending on the language/runtime used in your repo; the roles below are the â€œshapeâ€ this example intends.

```text
ğŸ“¦ src/
â”œâ”€ ğŸ“„ README.md                      ğŸ‘ˆ you are here
â”œâ”€ ğŸ§  main.(ts|py)                   entrypoint (CLI/dev runner)
â”œâ”€ ğŸ›°ï¸ watcher.(ts|py)                poll/subscribe to a live feed (ETag/Last-Modified aware)
â”œâ”€ ğŸªŸ windowing.(ts|py)              micro-batch/window builder + checkpoints
â”œâ”€ ğŸ§ª validate.(ts|py)               schema + range checks (pre-policy)
â”œâ”€ ğŸ§° policy_gate.(ts|py)            OPA/Conftest hooks (or local equivalent)
â”œâ”€ ğŸ§¬ prov.(ts|py)                   PROV JSON-LD builder (Activity/Entity/Agent)
â”œâ”€ ğŸ—‚ï¸ stac.(ts|py)                   STAC Item/Collection builder
â”œâ”€ ğŸ·ï¸ dcat.(ts|py)                   DCAT Dataset + Catalog entries
â”œâ”€ ğŸ§¾ run_manifest.(ts|py)           Run Manifest + canonical digest
â”œâ”€ ğŸ—ƒï¸ adapters/
â”‚  â”œâ”€ ğŸ§± store_stub.(ts|py)          writes to local files (default)
â”‚  â””â”€ ğŸ›°ï¸ postgis.(ts|py)             (optional) PostGIS insert adapter
â””â”€ âœ… __tests__/                      smoke tests: determinism + idempotency + schema
```

---

## ğŸš€ Quickstart

> [!TIP]
> This example is commonly run in two modes:
> 1) **mock stream** (replay NDJSON/JSON lines)
> 2) **poll a real endpoint** (HTTP, GTFS-RT, sensor API)

### 1) Mock stream replay (recommended)
```bash
# from the example root (one level above src/)
# (choose the package manager/runtime used by the repo)
npm install
npm run dev -- --source mock --in ./fixtures/observations.ndjson --out ./out
```

### 2) Poll a real endpoint
```bash
npm run dev -- \
  --source http \
  --url "https://example.gov/api/live" \
  --poll-interval-ms 60000 \
  --window-seconds 60 \
  --out ./out
```

---

## âš™ï¸ Configuration

| Variable / Flag | Example | Why it matters |
|---|---:|---|
| `--poll-interval-ms` | `60000` | how often the watcher polls (avoid overloading sources) |
| `--window-seconds` | `60` | window size for micro-batch processing |
| `--state-file` | `./state.json` | checkpoint for last-seen ETag/timestamp/sequence |
| `--out` | `./out` | where artifacts are written (stub store) |
| `--dataset-id` | `usgs_nwis_river_gauges` | stable dataset identity for DCAT/STAC grouping |
| `--sensitivity` | `public` / `restricted` | drives policy gate + API/UI access behaviors |

> [!WARNING]
> **Do not** use â€œnow()â€ or random IDs in artifact identifiers.  
> Determinism + idempotency are the whole point of this example.

---

## ğŸ—ï¸ Architecture (end-to-end)

```mermaid
flowchart LR
  A[ğŸŒ Live Source<br/>(API / GTFS-RT / Sensor)] --> B[ğŸ›°ï¸ Watcher<br/>(ETag / Last-Modified / since=...)]
  B --> C[ğŸªŸ Window Buffer<br/>(micro-batch)]
  C --> D[ğŸ§ª Validate<br/>(schema + range)]
  D --> E[ğŸ§¾ Run Manifest<br/>(canonical digest)]
  E --> F[ğŸ§¬ PROV JSON-LD<br/>(Activity/Entity/Agent)]
  D --> G[ğŸ—ƒï¸ Store Adapter<br/>(stub / PostGIS)]
  G --> H[ğŸ—‚ï¸ STAC Items]
  G --> I[ğŸ·ï¸ DCAT Dataset]
  H --> J[ğŸ§  Graph Update (optional)]
  I --> J
  J --> K[ğŸ—ºï¸ UI / API<br/>Real-time Layer + Focus Mode]
  F --> J
```

---

## ğŸ§¾ Outputs (what gets emitted)

Each ingestion **window** should produce a small, reviewable â€œbundleâ€:

```text
ğŸ“¦ out/
â””â”€ ğŸ§¾ audits/
   â””â”€ <run_id>/
      â”œâ”€ run_manifest.json          âœ… what/when/inputs/outputs + canonical digest
      â”œâ”€ prov.jsonld                âœ… lineage bundle (W3C PROV)
      â”œâ”€ stac_item_<...>.json        âœ… one-per-observation or one-per-snapshot
      â”œâ”€ stac_collection.json        âœ… optional grouping
      â”œâ”€ dcat_dataset.json           âœ… dataset attribution + access + license
      â””â”€ metrics.json               âœ… optional telemetry summary
```

> [!NOTE]
> The *UI* and *Focus Mode* should never have to â€œguessâ€ source attribution.  
> **DCAT** is where â€œSource: ___â€ and licensing comes from.

---

## ğŸ§¬ Provenance contract (PROV mapping)

This example keeps provenance simple and consistent.

### Entities (prov:Entity)
- **Input entity**: raw payload retrieved from the live source (or decoded protobuf)
- **Observation entity**: normalized observation record (lat/lon/time/value)
- **Output entity**: inserted row(s) / artifact(s) written for the window

### Activity (prov:Activity)
- `fetch_live_data`
- `decode_and_normalize`
- `validate_window`
- `append_to_store`
- `publish_catalog_artifacts`

### Agent (prov:Agent)
- `watcher_bot` (the automated daemon)
- `pipeline_runtime` (runner identity)
- optional: `ci_bot` / `github_actions` if run via CI

> [!TIP]
> If you later integrate â€œPR â†’ PROV Graphâ€ dev provenance, you can link:
> - the **run activity** to the **PR activity**, and
> - the **output entities** to the **merge commit entity**.

---

## ğŸ” Idempotency + determinism (non-negotiable)

### Idempotency key
Each logical window should have a stable key. Typical recipe:
- stable dataset id
- window start/end timestamps
- source cursor (ETag / Last-Modified / sequence number)
- canonical digest of the run manifest (recommended)

### Deterministic manifest digest
The manifest should be canonicalized (e.g., RFC 8785) before hashing so reruns produce the same digest.

âœ… Good outcomes:
- retries donâ€™t duplicate rows
- concurrent triggers donâ€™t overlap
- PR diffs stay clean (reviewable)

---

## ğŸ›¡ï¸ Policy gates (OPA/Conftest-friendly)

Even in â€œreal-time,â€ KFM governance applies.

Recommended checks (keep them cheap and fast):
- âœ… DCAT must include a license + publisher/source attribution
- âœ… STAC items must include geometry + datetime + stable id
- âœ… PROV must connect the Activity to both inputs and outputs (no orphaned lineage)
- âœ… Sensitivity classification present and respected
- âœ… Range checks (e.g., water level not negative; lat/lon valid)
- âœ… Schema validation for the emitted JSON artifacts

> [!IMPORTANT]
> Treat policy gates like tests: failing gates should block promotion to â€œlive.â€

---

## ğŸ—ºï¸ UI + API integration (how this becomes a â€œlive layerâ€)

A â€œreal-timeâ€ map layer usually works like this:
- API serves â€œlatest pointsâ€ or â€œpoints since timestampâ€
- PostGIS makes the query fast with spatial + time indexes
- UI labels the layer with **source attribution** from DCAT

Optional enhancements:
- push updates via WebSockets instead of polling
- show a â€œminutes since last seenâ€ health indicator per feed

---

## ğŸ¤– Focus Mode integration (why PROV matters beyond ingest)

When Focus Mode answers a real-time question, it will:
1. find the relevant station/entity in the graph,
2. fetch the latest reading (dynamic query),
3. answer with **citations**,
4. still log a PROV record tying the answer to the specific reading used.

This is how KFM stays â€œlivingâ€ *and* auditable.

---

## ğŸ§  Extension ideas (turn this stub into a powerhouse)

<details>
  <summary><b>ğŸ“Œ Add anomaly detection â†’ Pulse Threads</b></summary>

- attach a lightweight detector to the window output
- when thresholds trigger, generate a draft Pulse Thread:
  - include an **Evidence Manifest**
  - include PROV tying the narrative to the exact windows/observations
- route to human review before publishing
</details>

<details>
  <summary><b>ğŸ“¦ Push artifacts to an OCI registry + sign them</b></summary>

- store STAC/DCAT/PROV + binary artifacts in OCI (ORAS)
- attach PROV JSON-LD as a referrer
- sign with Cosign for chain-of-custody
</details>

<details>
  <summary><b>ğŸ›°ï¸ Swap the stub store for PostGIS + Neo4j</b></summary>

- write observations into PostGIS (append-only)
- upsert feed/station nodes into Neo4j
- link artifacts to datasets/places for discovery
</details>

---

## âœ… MCP â€œDefinition of Doneâ€ checklist (for extending this example)

- [ ] New source has a **contract** (schema + required metadata)
- [ ] Watcher uses **ETag/Last-Modified/since** to avoid refetching
- [ ] Windowing is deterministic (stable boundaries)
- [ ] Idempotency key prevents duplicates (retry-safe)
- [ ] Run Manifest created + hashed (canonical digest)
- [ ] PROV JSON-LD links inputs â†’ activity â†’ outputs
- [ ] STAC + DCAT emitted (no mystery layers)
- [ ] Policy gate passes locally + in CI
- [ ] Basic telemetry exists (counts, errors, latency)
- [ ] Tests cover â€œrerun produces identical outputsâ€

---

## ğŸ§¯ Troubleshooting

- **Duplicate rows**  
  â†’ your idempotency key is unstable (often due to timestamps or unordered JSON)

- **Artifacts differ across reruns**  
  â†’ remove randomness/time-based IDs; canonicalize JSON before hashing

- **UI shows a layer but no source attribution**  
  â†’ DCAT dataset is missing or not linked to the layer config

- **Graph has â€œorphanâ€ PROV nodes**  
  â†’ your PROV bundle is missing `used` or `wasGeneratedBy` edges

---

## ğŸ“š Glossary (quick)

- **Watcher** ğŸ›°ï¸: persistent poller/daemon that collects new observations  
- **Window / Micro-batch** ğŸªŸ: a small time slice processed as one unit  
- **Run Manifest** ğŸ§¾: auditable record of a pipeline run (inputs/outputs/versions)  
- **Idempotent ingest** ğŸ”: processing the same logical batch twice does not duplicate it  
- **Evidence triplet** ğŸ§¬ğŸ—‚ï¸ğŸ·ï¸: PROV + STAC + DCAT working together  

---

### ğŸ§¡ Motto

> â€œReal-time is fine. **Mystery layers are not.**â€
