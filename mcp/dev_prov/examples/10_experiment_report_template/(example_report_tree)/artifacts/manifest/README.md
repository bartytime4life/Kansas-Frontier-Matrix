# ğŸ§¾ Artifact Manifest (Dev Provenance) â€” `artifacts/manifest/`

![Template](https://img.shields.io/badge/template-experiment%20report-blue)
![Provenance](https://img.shields.io/badge/provenance-PROV--O-6f42c1)
![Catalog](https://img.shields.io/badge/catalog-STAC%20%7C%20DCAT-0b7285)
![Policy%20Gates](https://img.shields.io/badge/policy%20gates-OPA%20%2B%20Conftest-orange)
![Supply%20Chain](https://img.shields.io/badge/supply%20chain-cosign%20%7C%20SLSA-success)

> ğŸ§­ **Purpose:** This folder defines the **single source of truth** for *what artifacts exist* in this experiment report, *where they live*, and *how to verify them* (checksums + lineage + licensing + sensitivity).
>
> If itâ€™s not in the manifest, itâ€™s not â€œofficial.â€ âœ…

---

## âœ¨ What this manifest unlocks

- ğŸ” **Reproducibility:** re-run the experiment and verify outputs match (hashes + run identifiers)
- ğŸ§¾ **Auditability:** answer â€œwhat produced this file?â€ (inputs â†’ processing â†’ outputs)
- ğŸ§  **AI-ready citations:** enable assistants (Focus Mode / report agents) to cite artifacts without guessing
- ğŸ›¡ï¸ **Governance & safety:** enforce â€œfail-closedâ€ rules (no license? no provenance? blocked.)
- ğŸ“¦ **Distribution:** optionally publish artifacts via OCI-style registries (signed, versioned, portable)

---

## ğŸ“ Folder contract

This template assumes the manifest sits beside (or references) the reportâ€™s generated outputs.

```text
(example_report_tree)/
â””â”€ artifacts/ ğŸ§°
   â”œâ”€ manifest/ ğŸ§¾
   â”‚  â”œâ”€ README.md                  ğŸ‘ˆ you are here
   â”‚  â”œâ”€ manifest.json              âœ… canonical artifact index (recommended)
   â”‚  â”œâ”€ manifest.schema.json       ğŸ§¬ JSON Schema for validation (recommended)
   â”‚  â”œâ”€ checksums.sha256           ğŸ” hash list for all artifacts (recommended)
   â”‚  â”œâ”€ prov.jsonld                ğŸ§µ W3C PROV run + derivations (optional but ideal)
   â”‚  â”œâ”€ sbom.spdx.json             ğŸ§± SBOM for build/runtime deps (optional)
   â”‚  â””â”€ attestations/              ğŸ·ï¸ signatures / in-toto / SLSA (optional)
   â””â”€ ... other artifact folders ...
```

> ğŸ§© You can keep artifacts *anywhere* under the report tree â€” the manifest is the map.  
> The only rule: **the manifest must be able to resolve every artifact reference**.

---

## âœ… Nonâ€‘negotiables (template policy)

Use this checklist as your â€œdefinition of doneâ€:

- [ ] Every artifact has a **stable ID** (`artifact_id`)
- [ ] Every artifact has a **content hash** (`sha256` or stronger)
- [ ] Every artifact declares **license**
- [ ] Every artifact declares **sensitivity / access intent** (public / internal / restricted / confidential)
- [ ] Every derived artifact links to **inputs + process/run** (PROV, run_id, or equivalent)
- [ ] If an artifact is used in a narrative/analysis, it has **citation metadata**
- [ ] Validation is **automated** (Schema + Policy Gates) and **fails closed**

---

## ğŸ§¬ Manifest format

### Canonical file
Prefer **JSON** for deterministic validation and stable signing:

- `manifest.json` âœ… canonical
- (Optional) `manifest.schema.json` ğŸ§¬
- (Optional) `prov.jsonld` ğŸ§µ

### Versioning rules
- `manifest_version` is **semver**
- Additive fields are allowed (backwards-compatible)
- Breaking schema changes require a version bump and migration notes

---

## ğŸ§¾ Recommended `manifest.json` shape (opinionated)

> This is a **template** shape: adjust fields as needed, but keep the *core invariants* (IDs, hashes, provenance).

```json
{
  "manifest_version": "1.0.0",
  "generated_at": "2026-01-22T00:00:00Z",

  "report": {
    "report_id": "exp_railroads_vs_settlement_001",
    "title": "Railroads vs Settlement (Kansas) â€” Experiment #001",
    "authors": ["@you"],
    "tags": ["kfm", "experiment", "geospatial", "provenance"]
  },

  "run": {
    "run_id": "run_2026_01_22__a1b2c3",
    "run_time": "2026-01-22T00:00:00Z",
    "idempotency_key": "railroads_vs_settlement__v1__seed_1337",
    "canonical_digest": "sha256:REPLACE_ME"
  },

  "environment": {
    "repo": {
      "url": "REPLACE_ME",
      "commit": "REPLACE_ME",
      "dirty": false
    },
    "runtime": {
      "os": "linux",
      "python": "3.11",
      "containers": [
        { "name": "api", "image": "REPLACE_ME", "digest": "sha256:REPLACE_ME" }
      ]
    }
  },

  "artifacts": [
    {
      "artifact_id": "dataset/railroads_1870_vector",
      "kind": "dataset",
      "role": "input",
      "path": "../../data/railroads_1870.geojson",
      "media_type": "application/geo+json",
      "sha256": "REPLACE_ME",
      "size_bytes": 123456,
      "created_at": "2026-01-22T00:00:00Z",

      "license": { "spdx": "CC-BY-4.0", "url": "REPLACE_ME" },
      "sensitivity": "public",

      "citations": [
        {
          "label": "Source dataset / archive name",
          "uri": "REPLACE_ME",
          "accessed_at": "2026-01-22"
        }
      ],

      "provenance": {
        "prov_ref": "prov.jsonld#entity_railroads_1870",
        "derived_from": []
      },

      "catalog": {
        "stac_item": "REPLACE_ME",
        "dcat_dataset": "REPLACE_ME"
      },

      "validation": {
        "schema": "REPLACE_ME",
        "policy_pack": "REPLACE_ME",
        "passed": true,
        "reports": []
      }
    },

    {
      "artifact_id": "figure/railroads_vs_settlement_heatmap",
      "kind": "figure",
      "role": "output",
      "path": "../figures/heatmap.png",
      "media_type": "image/png",
      "sha256": "REPLACE_ME",
      "size_bytes": 98765,
      "created_at": "2026-01-22T00:10:00Z",

      "license": { "spdx": "CC-BY-4.0" },
      "sensitivity": "public",

      "provenance": {
        "prov_ref": "prov.jsonld#entity_heatmap_png",
        "derived_from": ["dataset/railroads_1870_vector"]
      },

      "notes": "Generated from notebook notebooks/analysis.ipynb"
    }
  ]
}
```

---

## ğŸ§± Artifact record â€œmust-haveâ€ fields

| Field | Why it exists | â€œFail closedâ€ rule |
|------|----------------|-------------------|
| `artifact_id` | Stable reference for linking & citations | Must be unique |
| `path` / `uri` | Where the artifact can be fetched | Must resolve |
| `sha256` | Integrity check & immutability anchor | Must exist for binaries |
| `license` | Legal clarity & safe reuse | Missing â†’ block |
| `sensitivity` | Controls exposure + privacy posture | Missing â†’ block |
| `provenance` | Explains lineage + derivations | Missing for derived outputs â†’ block |
| `citations[]` | Human-facing source trace | Required for public-facing claims |

---

## ğŸ” Linking to STAC / DCAT / PROV (recommended)

If your artifacts are geospatial or cataloged datasets, keep **standard hooks**:

- ğŸ—ºï¸ **STAC**: item/collection links for spatial assets (rasters, vectors, tiles, etc.)
- ğŸ§¾ **DCAT**: dataset-level catalog entry (publisher, license, update cadence, contacts)
- ğŸ§µ **PROV**: lineage graph describing inputs â†’ activity â†’ outputs

> ğŸ“Œ Even if you donâ€™t publish a full catalog in this experiment template, adding these fields now makes it â€œdrop-in compatibleâ€ with catalog-driven platforms later. ğŸ§ 

---

## ğŸ”’ Validation & Policy Gates

Your CI (or local tooling) should validate:

1. ğŸ§¬ **Schema** (JSON Schema / Pydantic model)
2. ğŸ§¾ **Completeness** (licenses, sensitivity, provenance references present)
3. ğŸ” **Integrity** (hashes match file contents)
4. ğŸ”— **Resolution** (paths/URIs exist and are accessible in the report tree)
5. ğŸ§  **Citation discipline** (anything referenced by narrative/AI has a citation entry)

> ğŸ›‘ **Policy mindset:** â€œIf a check canâ€™t be performed, fail closed.â€

---

## ğŸ›¡ï¸ Signing & publishing artifacts (optional, but powerful)

If you want artifacts to be portable across systems/environments:

- Publish artifacts to an **OCI-compatible registry** (like container images, but for data & reports)
- Attach:
  - ğŸ·ï¸ signatures (cosign)
  - ğŸ§± SBOM (SPDX)
  - ğŸ§µ PROV JSON-LD as an attestation / referrer
  - âœ… run manifest & canonical digest

This gives you: **verifiable origin**, **version history**, **easy transfers**, and **registry UIs** for browsing. ğŸ“¦

---

## ğŸ§© Integration points (how other parts consume this)

### ğŸ—ºï¸ UI / map layers
Use the manifest to generate:
- layer attribution strings
- â€œLayer Infoâ€ panels
- export footnotes / credits

### ğŸ§  AI assistant (Focus Mode / report agents)
Use the manifest to:
- retrieve sources deterministically
- attach citations automatically
- refuse unsupported claims (no sources = no answer)

### ğŸ“š Story Nodes / narratives
Use the manifest as the **citation backbone**:
- every inline citation should map to an artifact or external source entry
- CI can validate â€œno broken referencesâ€ ğŸ”—

### ğŸ¤– Wâ€‘Pâ€‘E automation (optional)
A Watcherâ€“Plannerâ€“Executor agent can:
- detect missing metadata
- propose manifest patches
- open PRs (never auto-merge) âœ…

---

## ğŸ§¯ Common mistakes (and how to avoid them)

- âŒ **â€œWe generated a file but forgot to list it.â€**  
  âœ… Treat manifest updates as part of the pipeline output.

- âŒ **Hashes donâ€™t match after re-running.**  
  âœ… Ensure deterministic outputs, record run seeds, pin tool versions.

- âŒ **No license / unclear license.**  
  âœ… Always include SPDX identifiers when possible.

- âŒ **Sensitive data leaked in â€œpublicâ€ outputs.**  
  âœ… Use `sensitivity` + redaction/generalization + policy gates.

---

## ğŸ§ª Nice-to-have extras (future-proofing)

- ğŸ§¾ `CHANGELOG.md` for artifact schema evolution
- ğŸ“¦ â€œOffline packâ€ entries for field use (bundled tiles + story content)
- ğŸ›°ï¸ Support for AR-ready assets (lightweight geometry + media previews)
- ğŸ“ˆ Evaluation metrics artifacts (model cards, benchmarks, audit panels)

---

## ğŸ TL;DR

**The manifest is the contract.**  
It is how we keep experiments: **reproducible ğŸ”, auditable ğŸ§¾, trustworthy ğŸ›¡ï¸, and AI-citeable ğŸ§ **.
