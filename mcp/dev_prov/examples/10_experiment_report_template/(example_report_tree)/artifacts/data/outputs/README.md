# ğŸ“¦ Experiment Outputs (Data Artifacts)

![Status](https://img.shields.io/badge/status-template-2ea44f)
![Provenance](https://img.shields.io/badge/provenance-STAC%20%2B%20DCAT%20%2B%20PROV-6f42c1)
![Rigor](https://img.shields.io/badge/ethos-no%20black%20boxes-111111)
![KFM](https://img.shields.io/badge/aligned%20with-KFM%20docs-0b7285)

> [!IMPORTANT]
> This directory contains **machine-generated outputs** for an experiment run (datasets, tiles, reports, manifests, audits).  
> **Treat outputs as immutable artifacts**: if you need to change something, rerun the pipeline and emit a new output version.

---

## ğŸ¯ Purpose

This folder is the **artifact store** for the experiment report template:

- âœ… **Publishable results** (processed datasets, tilesets, exports, figures)
- âœ… **Provenance & audit companions** (run manifests, checksums, evidence manifests, lineage)
- âœ… **UI-ready exports** (Story Nodes, snapshots, offline packs, simulation results)
- âœ… **AI-ready exports** (Focus Mode transcripts + citations + audit panels)

KFM alignment in one sentence: **everything here must be traceable to evidence, processing steps, and governance decisions** â€” no â€œblack boxâ€ outputs.

---

## âœ… What belongs here

- ğŸ§¾ **Manifests**: `run_manifest.json`, `source.json`, `checksums.sha256`, `telemetry.ndjson`
- ğŸ§¬ **Catalog triplet**: STAC + DCAT + PROV (stored under `meta/`)
- ğŸ—ºï¸ **Geospatial outputs**: GeoParquet, COGs, vector tiles (PMTiles), 3D Tiles
- ğŸ§  **Models & analytics artifacts**: model cards, evaluation metrics, drift reports
- ğŸ¤– **AI artifacts**: evidence-backed answers, retrieved context, governance flags
- ğŸ“– **Narrative artifacts**: Story Nodes (markdown + JSON config), narrative playback bundles
- ğŸ§ª **QA artifacts**: validation reports, schema checks, graph health checks, policy pack results
- ğŸ” **Governance artifacts**: sensitivity labels, access tier manifests, obfuscation logs
- ğŸ“¦ **Distribution artifacts**: OCI-style packaging metadata, signatures/attestations (optional)

---

## ğŸš« What does *not* belong here

- âŒ Raw â€œas-receivedâ€ evidence (keep in raw evidence folders / receipts; do not overwrite originals)
- âŒ One-off manual edits to derived data (edit pipeline code/config instead; regenerate deterministically)
- âŒ Secrets (tokens, private keys, credentials)
- âŒ Unattributed exports (if it canâ€™t be traced, it canâ€™t ship)

---

## ğŸ§­ â€œNo Skipping Stagesâ€ (KFM pipeline mindset)

> [!TIP]
> If your workflow resembles **Raw â†’ Processed â†’ UI** without a lineage/citation trail, itâ€™s incomplete.

A KFM-style path is typically:

**Raw âœ Work âœ Processed âœ Catalogs (STAC/DCAT/PROV) âœ Graph âœ API âœ UI âœ Story/Focus**

This `outputs/` folder is where the experimentâ€™s **final, shareable â€œProcessed âœ UI/Story/AIâ€ products** land â€” *with their metadata and proof*.

---

## ğŸ—‚ï¸ Recommended layout

```text
outputs/
â”œâ”€ README.md
â”œâ”€ meta/ ğŸ§¾
â”‚  â”œâ”€ run_manifest.json
â”‚  â”œâ”€ source.json
â”‚  â”œâ”€ checksums.sha256
â”‚  â”œâ”€ telemetry.ndjson
â”‚  â”œâ”€ evidence_manifest.json
â”‚  â”œâ”€ stac/ ğŸ›°ï¸
â”‚  â”‚  â”œâ”€ collection.json
â”‚  â”‚  â””â”€ items/
â”‚  â”œâ”€ dcat/ ğŸ·ï¸
â”‚  â”‚  â””â”€ dataset.json
â”‚  â”œâ”€ prov/ ğŸ§¬
â”‚  â”‚  â””â”€ lineage.json
â”‚  â””â”€ qa/ âœ…
â”‚     â”œâ”€ validation_report.md
â”‚     â”œâ”€ schema_checks.json
â”‚     â””â”€ policy_pack_results.json
â”œâ”€ datasets/ ğŸ—„ï¸
â”‚  â”œâ”€ geoparquet/
â”‚  â”œâ”€ raster_cogs/
â”‚  â””â”€ tables/
â”œâ”€ tiles/ ğŸ§±
â”‚  â”œâ”€ pmtiles/
â”‚  â””â”€ tiles3d/
â”œâ”€ graphs/ ğŸ•¸ï¸
â”‚  â”œâ”€ exports/
â”‚  â””â”€ queries/
â”œâ”€ ai/ ğŸ¤–
â”‚  â”œâ”€ focus_mode/
â”‚  â””â”€ audit_panels/
â”œâ”€ ui/ ğŸ§©
â”‚  â”œâ”€ story_nodes/
â”‚  â”œâ”€ screenshots/
â”‚  â””â”€ offline_packs/
â””â”€ packages/ ğŸ“¦
   â”œâ”€ oci/
   â””â”€ attestations/
```

> [!NOTE]
> You can simplify this for smaller experiments (e.g., only `meta/` + `datasets/`).  
> The key is: **outputs are discoverable, verifiable, and reproducible**.

---

## ğŸ§¾ Required â€œartifact contractâ€ (minimum per run)

| Artifact | Why it exists | Where |
|---|---|---|
| `run_manifest.json` | Reproducibility anchor: who/what/when/how | `meta/` |
| `checksums.sha256` | Integrity + tamper detection | `meta/` |
| `source.json` | Raw evidence references + retrieval notes | `meta/` |
| `telemetry.ndjson` | Append-only run log (events, counts, warnings) | `meta/` |
| `evidence_manifest.json` | â€œEvidence-firstâ€ map from claims âœ sources | `meta/` |
| STAC + DCAT + PROV | Findable + standardized metadata + lineage | `meta/stac`, `meta/dcat`, `meta/prov` |
| `validation_report.md` | Human-readable QA snapshot | `meta/qa` |

> [!IMPORTANT]
> If the run canâ€™t produce provenance (STAC/DCAT/PROV) and checksums, **it isnâ€™t a publishable output**.

---

## ğŸ·ï¸ Naming & versioning rules (recommended)

### ğŸ”‘ Identifiers
- `run_id`: unique run identifier (UUID, timestamped slug, or CI run number)
- `artifact_id`: stable logical ID for the output (e.g., `ks_river_gauge_daily_observations`)
- `version`: semver-ish or date-based (e.g., `v0.1.0` or `2026-01-22`)

### ğŸ“Œ Filename pattern
```
<artifact_id>__<run_id>__<timestamp>__<version>.<ext>
```

### âœ… Good examples
- `ks_county_drought_index__run_7c3b...__20260122T031500Z__v0.3.0.parquet`
- `ks_river_gauges__run_7c3b...__20260122T031500Z__v0.3.0.pmtiles`
- `focus_mode_answer__run_7c3b...__20260122T031500Z__v0.3.0.md`

---

## ğŸ§¬ Provenance & metadata (STAC + DCAT + PROV)

### The â€œcatalog tripletâ€ idea
Every publishable dataset output should be paired with:

- ğŸ›°ï¸ **STAC**: footprint + temporal extent + assets + geometry
- ğŸ·ï¸ **DCAT**: publication metadata, licensing, distribution info
- ğŸ§¬ **PROV**: lineage â€” inputs, transformations, agents, timestamps

### What â€œevidence-firstâ€ means in outputs
A run should produce a machine-readable mapping between:

- **claims/insights** (what the run concluded)
- **supporting data assets** (files in `datasets/`, `tiles/`, `graphs/`)
- **source evidence** (raw receipts, upstream datasets, citations)
- **transformations** (code/config versions)

> [!TIP]
> Think of `evidence_manifest.json` as the â€œproof ledgerâ€ that lets anyone say:  
> â€œShow me the chain from this map layer all the way back to original sources.â€

---

## ğŸ—ºï¸ Geospatial output formats (KFM-friendly)

### ğŸ§± Vector
- âœ… **GeoParquet** (preferred for analytics + modern pipelines)
- âœ… GeoPackage (portable, GIS-friendly)
- âœ… FlatGeobuf (fast streaming for some workflows)
- âš ï¸ GeoJSON (OK for small outputs; avoid for big datasets)

### ğŸŒ„ Raster
- âœ… **COG** (Cloud-Optimized GeoTIFF) for rasters that will be served or cached

### ğŸ—ºï¸ Tiles & web delivery
- âœ… **PMTiles** for vector tile packaging + offline packs
- âœ… Cesium/3D workflows: **3D Tiles** (+ glTF assets where applicable)

### ğŸ§­ CRS + spatial rules
- Record CRS on every output (even if you standardize to WGS84 for interchange).
- If you reproject, **it must be a declared transform** in provenance, not a silent step.

---

## ğŸ¤– AI outputs (Focus Mode / evidence-backed assistants)

If this experiment produces AI-generated narrative or Q&A artifacts, store them in `ai/` with:

- ğŸ§¾ the **question/prompt**
- ğŸ§  the **retrieved context** (graph nodes, datasets, documents)
- ğŸ§¬ the **citation list** (dataset IDs, STAC assets, document references)
- ğŸ§ª the **audit panel** (influences, governance flags, uncertainty)
- âœ… the **final answer** (human-readable)

Suggested structure:

```text
ai/focus_mode/
â”œâ”€ session_<run_id>/
â”‚  â”œâ”€ question.md
â”‚  â”œâ”€ answer.md
â”‚  â”œâ”€ citations.json
â”‚  â”œâ”€ retrieval_context.json
â”‚  â”œâ”€ audit_panel.json
â”‚  â””â”€ governance_flags.json
```

> [!IMPORTANT]
> If an AI output cannot be derived from available evidence, it should explicitly record uncertainty/refusal â€” never fabricate.

---

## ğŸ“– Narrative outputs (Story Nodes + playback-ready bundles)

Story/Narrative outputs make results **explainable and shareable**:

- ğŸ“ `story.md` (human narrative)
- âš™ï¸ `story.json` (configuration: chapters, map extents, time ranges, layers)
- ğŸ–¼ï¸ assets (figures, images, short clips, thumbnails)

Suggested structure:

```text
ui/story_nodes/
â”œâ”€ <story_slug>/
â”‚  â”œâ”€ story.md
â”‚  â”œâ”€ story.json
â”‚  â”œâ”€ assets/
â”‚  â””â”€ exports/
```

> [!TIP]
> Keep narratives â€œcitation-awareâ€: every major claim should point back to a dataset asset or source reference included in `meta/`.

---

## ğŸ§ª QA, governance, and sensitivity outputs

### âœ… QA / validation
Place structured QA artifacts in `meta/qa/`:

- schema validation results
- geospatial sanity checks (bounds, CRS, geometry validity)
- completeness checks (null rates, required columns)
- performance notes (tile generation time, indexing notes)

### ğŸ” Sensitivity-aware handling
If the run uses or produces sensitive data:

- include a `sensitivity_manifest.json` describing:
  - classification tier (public / restricted / admin)
  - allowed distributions
  - obfuscation methods (e.g., rounding, generalization)
  - audit trail for what was withheld or blurred

> [!IMPORTANT]
> For public-facing outputs, consider producing **two variants**:
> - `public/` (safe, obfuscated if needed)
> - `restricted/` (full fidelity, access-controlled)
>
> Both variants should be cataloged and prov-linked so the reason for differences is explicit.

---

## ğŸ“¦ Packaging & distribution (optional but powerful)

For â€œship it anywhereâ€ reproducibility, you can package outputs as **content-addressed artifacts**:

- store export bundles under `packages/oci/`
- store signatures/attestations under `packages/attestations/`
- ensure digests match `checksums.sha256`

> [!TIP]
> This mirrors â€œdata treated with the same rigor as codeâ€: versioned, reviewable, signed, rollbackable.

---

## ğŸ§° Reference & methodology packs (project libraries)

These project files are intentionally broad: they support experiments that span:
- geospatial WebGL + virtual worlds ğŸ—ºï¸ğŸŒ
- AI/LLMs + explainability ğŸ¤–ğŸ”
- data architecture + Bayesian methods ğŸ§ ğŸ“ˆ
- multi-language implementation notes ğŸ§‘â€ğŸ’»ğŸ§°

<details>
<summary><strong>ğŸ“š Resource bundles included in the project (high-level)</strong></summary>

- ğŸ§  **AI Concepts & more**: curated AI/ML references (PDF portfolio)
- ğŸ—„ï¸ **Data Management / Bayesian**: data architecture + statistical learning references (PDF portfolio)
- ğŸ§‘â€ğŸ’» **Programming languages & resources**: implementation resources across languages (PDF portfolio)
- ğŸ—ºï¸ **Maps / Google Maps / Virtual Worlds / WebGL / Archaeology**: mapping + rendering + virtual world references (PDF portfolio)

These packs inform how you design experiments and what kinds of outputs you may emit (tiles, scenes, notebooks, evaluation reports, etc.).
</details>

---

## ğŸ”— Related KFM design docs (alignment targets)

This README is designed to align experiment outputs with the broader KFM system:

- ğŸ§­ **KFM Architecture & Design** (modules, services, standards, growth strategy)
- ğŸ§¾ **KFM Data Intake Guide** (immutability, deterministic ETL, catalog triplet, evidence-first publishing)
- ğŸ§© **KFM UI System Overview** (2D/3D maps, timeline, Story Nodes, offline packs, AR)
- ğŸ¤– **KFM AI System Overview** (Focus Mode, citations, explainability/audit panels)
- âœ¨ **Latest Ideas & Future Proposals** (new domains, federation, governance maturity)
- ğŸ’¡ **Additional Project Ideas** (Pulse Threads, conceptual attention nodes, narrative pattern detection, OCI packaging)
- ğŸš€ **Innovative Concepts** (4D digital twins, AR storytelling, natural-language GIS co-pilots, cultural protocols)

---

## âœ… Reproducibility checklist (printable)

- [ ] Outputs are generated (not hand-edited)
- [ ] `meta/run_manifest.json` present
- [ ] `meta/checksums.sha256` present and matches files
- [ ] `meta/source.json` points to raw evidence / upstream inputs
- [ ] `meta/telemetry.ndjson` captured
- [ ] `meta/evidence_manifest.json` maps claims âœ assets âœ sources
- [ ] STAC + DCAT + PROV present and consistent
- [ ] QA artifacts present (at least a `validation_report.md`)
- [ ] Sensitive data handled (manifest + public/restricted split if needed)
- [ ] Optional: packaged + signed for distribution

---

## ğŸ§· Conventions for contributors

> [!NOTE]
> If youâ€™re adding a new kind of output, also add:
> - a short description in this README
> - a directory under `outputs/` with a clear name
> - a schema or example snippet under `meta/qa/` (so others can validate it)

Happy experimenting ğŸŒ¾ğŸ§ª
