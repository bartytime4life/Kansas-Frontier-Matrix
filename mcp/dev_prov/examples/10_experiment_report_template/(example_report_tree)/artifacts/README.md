# ğŸ§¾ Artifacts (Evidence Vault) â€” `example_report_tree/artifacts/` ğŸ”ğŸ§­

![Provenance First](https://img.shields.io/badge/Provenance-first-1f6feb)
![Evidence First](https://img.shields.io/badge/Evidence-first-2ea44f)
![Policy Gated](https://img.shields.io/badge/Policy-gated-ffb000)
![Reproducible](https://img.shields.io/badge/Reproducible-by%20design-8a2be2)
![FAIR+CARE](https://img.shields.io/badge/FAIR%2BCARE-aligned-0aa)

> **Rule of thumb:** if itâ€™s referenced in the experiment report, it should live here (or be referenced here with a stable, verifiable pointer). âœ…  
> **Second rule:** donâ€™t put â€œresultsâ€ in prose without the underlying evidence artifacts. â€œNo artifact, no claim.â€ ğŸ§ ğŸ§¾

---

## ğŸ¯ What belongs in `artifacts/`?

This folder holds the **auditable evidence** behind the experiment report:
- raw-ish inputs (or immutable references to them)
- configs + seeds + environment locks
- intermediate outputs
- final outputs (tables, maps, models, figures)
- provenance + catalogs + manifests
- QA/policy results + logs

Think of `report.md` as the **narrative** and `artifacts/` as the **court exhibits**. âš–ï¸

---

## ğŸ—‚ï¸ Suggested structure (template)

Use what you need; keep it tidy and predictable.

```text
artifacts/
â”œâ”€ ğŸ“„ README.md                         # ğŸ‘ˆ you are here ğŸ“Œ What this bundle is, how to navigate it, and how to verify it
â”œâ”€ ğŸ“¦ manifest/                         # ğŸ“¦ â€œWhat is here + whyâ€ (bundle index + reproducibility ledger)
â”‚  â”œâ”€ ğŸ§¾ artifact_index.yaml             # Inventory: paths â†’ roles â†’ descriptions â†’ primary/secondary designation
â”‚  â”œâ”€ ğŸ§¾ğŸ” run_manifest.json             # Deterministic run ledger: commands, params, tool versions, IO pointers, hashes
â”‚  â””â”€ ğŸ§± environment/                   # ğŸ§± Reproducible environment capture (pin deps / record build context)
â”‚     â”œâ”€ ğŸ“¦ requirements.txt             # Python deps (or use poetry.lock / uv.lock / etc.)
â”‚     â”œâ”€ ğŸ§Š conda-lock.yml               # Optional: locked conda env for reproducibility
â”‚     â””â”€ ğŸ³ docker_image.txt             # Container image tag/digest used (if applicable)
â”œâ”€ ğŸ§­ catalogs/                          # ğŸ§­ Evidence triplet metadata (publish/discovery + lineage), when applicable
â”‚  â”œâ”€ ğŸ›°ï¸ stac/                           # STAC Collection/Item(s) referencing produced assets
â”‚  â”œâ”€ ğŸ—‚ï¸ dcat/                           # DCAT Dataset/Distribution records (license, access, links)
â”‚  â””â”€ ğŸ§¬ prov/                           # PROV lineage (entities/activities/agents) tying inputs â†’ outputs
â”œâ”€ ğŸ“Š data/                              # ğŸ“Š Inputs/outputs (small-to-medium payloads; avoid huge binaries if possible)
â”‚  â”œâ”€ ğŸ“¥ inputs/                         # Raw inputs used by the run (or pointers/receipts if large)
â”‚  â”œâ”€ ğŸ§ª intermediates/                  # Intermediate artifacts (kept only if they aid debugging/repro)
â”‚  â””â”€ âœ… outputs/                         # Final outputs intended for review/promotion/publish
â”œâ”€ ğŸ—ºï¸ geospatial/                        # ğŸ—ºï¸ Map-heavy assets (optional; only if the run produces geo deliverables)
â”‚  â”œâ”€ ğŸ—ºï¸ geojson/                        # GeoJSON outputs or samples (keep small)
â”‚  â”œâ”€ ğŸ§± cog/                             # Cloud-Optimized GeoTIFFs (COGs) (or small samples/pointers)
â”‚  â”œâ”€ ğŸ§± pmtiles/                         # PMTiles archives for fast vector tile serving (or sample tiles)
â”‚  â””â”€ ğŸ‘€ tiles_preview/                   # Small preview tiles/snapshots (quicklook for review)
â”œâ”€ ğŸ“ˆ figures/                           # ğŸ“ˆ Figures used in reports (charts, screenshots, diagrams)
â”‚  â”œâ”€ ğŸ–¼ï¸ png/                             # Raster figures
â”‚  â”œâ”€ ğŸ§· svg/                             # Vector figures (preferred for diagrams)
â”‚  â””â”€ ğŸ§¾ pdf/                             # Print-ready figures (when needed)
â”œâ”€ ğŸ““ notebooks/                          # ğŸ““ Optional notebooks (keep runnable + reference locked env)
â”‚  â”œâ”€ ğŸ““ analysis.ipynb                   # Notebook capturing exploration/analysis (deterministic where possible)
â”‚  â””â”€ ğŸ“„ README.md                        # How to run notebooks + required env/data pointers
â”œâ”€ ğŸ§¾ logs/                               # ğŸ§¾ Runtime logs/telemetry/timings (sanitize secrets/PII)
â”‚  â”œâ”€ ğŸªµ pipeline.log                     # Main pipeline log (high-level)
â”‚  â”œâ”€ ğŸ“Š metrics.json                     # Machine-readable metrics (timings, counts, quality scores)
â”‚  â””â”€ ğŸªµ stdout_stderr.txt                # Captured console output (useful for debugging)
â”œâ”€ ğŸ›¡ï¸ governance/                         # ğŸ›¡ï¸ Policy checks, redaction notes, approvals (audit trail)
â”‚  â”œâ”€ ğŸš¦ğŸ§¾ policy_report.json              # Gate results: pass/fail, findings, severities, pointers
â”‚  â”œâ”€ ğŸ”’ğŸ“ redaction_notes.md              # What was redacted/withheld and why (sensitivity policy)
â”‚  â””â”€ âœ…ğŸ“ approvals.md                    # Review sign-offs (who/when/what) for this bundle
â”œâ”€ ğŸ”’ integrity/                          # ğŸ”’ Integrity + supply-chain proofs (checksums, SBOM, signatures)
â”‚  â”œâ”€ ğŸ”ğŸ“„ checksums.sha256                # sha256 digest list for bundle files (tamper detection)
â”‚  â”œâ”€ ğŸ§¾ğŸ” sbom.spdx.json                  # Optional SBOM for build/toolchain/artifacts
â”‚  â””â”€ ğŸ” signatures/                      # Optional cosign signatures/attestations references/exports
â””â”€ ğŸ“š narrative/                           # ğŸ“š Narrative artifacts (optional): Story/Pulse outputs + evidence
   â”œâ”€ ğŸ“ story_node.md                     # Story markdown narrative (citations inline)
   â”œâ”€ ğŸ§­ğŸ§¾ story_node.json                  # Story step/config JSON (map/time/layers/actions)
   â””â”€ ğŸ“ğŸ§¾ evidence_manifest.yaml           # Evidence manifest tying claims â†’ citations â†’ artifacts (plus checksums)
```

---

## âœ… Minimum required files (for most experiments)

### 1) `manifest/run_manifest.json` (required)
A structured description of **exactly what ran**:
- inputs (file paths or stable URIs)
- parameters + hyperparameters
- random seeds
- tool versions
- outputs produced
- runtime summary (counts, sizes, errors)

### 2) `integrity/checksums.sha256` (required)
Hashes for everything in `artifacts/` that is a *material dependency* for reproduction (and optionally everything, if small enough).

### 3) `manifest/artifact_index.yaml` (recommended, near-required)
A human-friendly index of **whatâ€™s here**, **why it exists**, and **where itâ€™s referenced** in the report.

---

## ğŸ§¾ Artifact index format (recommended)

Create a tiny â€œtable of contentsâ€ for machines *and* humans:

```yaml
# artifacts/manifest/artifact_index.yaml
run:
  run_id: EXP-YYYYMMDD-HHMM__short-slug
  report_ref: ../report.md#results
  owner: your-name-or-handle
  created_utc: "2026-01-22T00:00:00Z"

artifacts:
  - id: results_table
    kind: table
    path: ../data/outputs/results.csv
    described_in: ../report.md#results
    notes: "Primary quantitative outcome table."

  - id: model_weights
    kind: model
    path: ../models/model.onnx
    described_in: ../report.md#model
    notes: "Exported model used for evaluation."

  - id: map_layer_cog
    kind: geospatial-raster
    path: ../geospatial/cog/landcover_2020.tif
    described_in: ../report.md#maps
    notes: "Rendered in UI + used for stats."
```

---

## ğŸ§­ If your experiment produces publishable datasets: include the â€œEvidence Tripletâ€ ğŸ§¬

When the experiment outputs a dataset intended to be **discoverable + reusable**, add:

- **STAC** (`catalogs/stac/`) â€” spatiotemporal indexing + asset links  
- **DCAT** (`catalogs/dcat/`) â€” catalog/discovery metadata  
- **PROV** (`catalogs/prov/`) â€” lineage: inputs â†’ process â†’ outputs  

If you donâ€™t need full publishing, keep it lightweightâ€”**but still keep a run manifest + hashes**. ğŸ§ 

---

## ğŸ§  AI/LLM-related outputs (Focus Mode, copilots, summarizers) ğŸ¤–

If an artifact was produced by an AI system:
- label it clearly (e.g., `*_ai_draft.md`)
- include the retrieval set / evidence pointers (IDs, URIs, queries)
- include a provenance record of the generation (prompt template ID, model ID, policy outcome)

**No citations / no provenance = not shippable.** âœ…

---

## ğŸ“š Narrative artifacts (Story Nodes & Pulse Threads) ğŸ§µâœ¨

If your experiment includes **interactive narrative content** (like a story walkthrough, UI tour, or pulse update), store it here so itâ€™s versioned and reviewable:

- `narrative/story_node.md` â€” the narrative text
- `narrative/story_node.json` â€” the â€œscriptâ€ (map states, steps, timeline)
- `narrative/evidence_manifest.yaml` â€” references + raw evidence behind claims

This pattern makes narrative experiments testable: your report can point at exact story steps and their underlying evidence. ğŸ¬ğŸ—ºï¸

---

## ğŸ§± Large binary artifacts (PMTiles / GeoParquet / COG / big models)

If artifacts are too large for Git:
- store them in an artifact registry (OCI-style) or LFS
- **still keep the pointer + digest in `artifacts/`**

Recommended: keep a pointer file like:

```yaml
# artifacts/manifest/oci_distribution.yaml
oci:
  registry: ghcr.io
  repository: myorg/kfm/surficial_geology
  tag: "20260111"
  digest: "sha256:...immutable..."
  files:
    - name: surficial_geology.pmtiles
      mediaType: application/vnd.pmtiles
    - name: surficial_geology.parquet
      mediaType: application/vnd.geo+parquet
  provenance_ref: "oci://.../referrers"
```

---

## ğŸ•µï¸ Sensitive data & redactions (must be explicit)

If an experiment touches sensitive locations, protected sites, personal info, etc.:
- include a `governance/redaction_notes.md`
- document **what was generalized/removed** and why
- ensure derived assets donâ€™t leak raw coordinates (including in EXIF, GeoJSON properties, logs)

---

## ğŸ›¡ï¸ Quality gates checklist (copy into PR or report)

- [ ] `run_manifest.json` present + complete  
- [ ] checksums generated (and updated)  
- [ ] environment pinned (dependencies / container digest)  
- [ ] policy report included (if governance applies)  
- [ ] AI outputs labeled + evidence attached  
- [ ] sensitive data handled (generalized / access-controlled)  
- [ ] report links resolve to artifacts (no broken paths)  

---

## ğŸ”— Linking from `report.md` (recommended pattern)

In the report, link directly to artifacts using relative paths:

```markdown
See: [results.csv](./artifacts/data/outputs/results.csv)  
See: [run manifest](./artifacts/manifest/run_manifest.json)  
See: [policy report](./artifacts/governance/policy_report.json)
```

If you need citations in prose, use footnotes that point to artifact IDs or catalog entries (stable + reviewable). ğŸ§·

---

## ğŸ§¬ (Optional) Visual provenance map

```mermaid
flowchart LR
  A[Inputs<br/>data/config] --> B[Pipeline Run<br/>run_manifest.json]
  B --> C[Outputs<br/>tables/maps/models]
  C --> D[Integrity<br/>checksums/signatures]
  C --> E[Catalogs<br/>STAC/DCAT/PROV]
  D --> F[Experiment Report<br/>report.md]
  E --> F
```

---

## ğŸ“š â€œProject Libraryâ€ reference pack (optional, but handy)

If the experiment is based on a reading packet, include it in:
- `artifacts/references/` (small docs), or
- a pointer file in `manifest/` (for large PDFs)

Example pointer:

```text
artifacts/manifest/reference_pack.txt
- AI Concepts & more.pdf
- Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf
- Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf
- Various programming languages & resources 1.pdf
```

---

## ğŸ§¯ Common mistakes (avoid these)

- âŒ â€œfinal_v2_REAL_final.csvâ€ with no manifest, no seed, no code ref  
- âŒ screenshots with no underlying data  
- âŒ AI-generated narrative with no citations/evidence  
- âŒ overwriting files in-place instead of versioning  
- âŒ missing license/sensitivity fields for publishable datasets  

---

## ğŸ™Œ Good citizen norms

- Prefer **append-only** changes (new run directory, new run_id)  
- If you must revise, create a new `run_id` and note supersession  
- Keep artifacts boring, structured, and verifiable âœ¨
