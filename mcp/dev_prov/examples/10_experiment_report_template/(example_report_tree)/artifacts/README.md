# ğŸ§¾ Artifacts (Evidence Vault) â€” `example_report_tree/artifacts/` ğŸ”ğŸ§­

![Provenance First](https://img.shields.io/badge/Provenance-first-1f6feb)
![Evidence First](https://img.shields.io/badge/Evidence-first-2ea44f)
![Policy Gated](https://img.shields.io/badge/Policy-gated-ffb000)
![Reproducible](https://img.shields.io/badge/Reproducible-by%20design-8a2be2)
![FAIR+CARE](https://img.shields.io/badge/FAIR%2BCARE-aligned-0aa)

> **Rule of thumb:** if itâ€™s referenced in the experiment report, it should live here (or be referenced here with a stable, verifiable pointer). âœ…  
> **Second rule:** donâ€™t put â€œresultsâ€ in prose without the underlying evidence artifacts. â€œNo artifact, no claim.â€ ğŸ§ ğŸ§¾

---

## ğŸ¯ What belongs in `artifacts/`?

This folder holds the **auditable evidence** behind the experiment report:
- raw-ish inputs (or immutable references to them)
- configs + seeds + environment locks
- intermediate outputs
- final outputs (tables, maps, models, figures)
- provenance + catalogs + manifests
- QA/policy results + logs

Think of `report.md` as the **narrative** and `artifacts/` as the **court exhibits**. âš–ï¸

---

## ğŸ—‚ï¸ Suggested structure (template)

Use what you need; keep it tidy and predictable.

```text
artifacts/
â”œâ”€ README.md                        # ğŸ‘ˆ you are here
â”œâ”€ manifest/                         # ğŸ“¦ "what is here + why" (index + run manifest)
â”‚  â”œâ”€ artifact_index.yaml
â”‚  â”œâ”€ run_manifest.json
â”‚  â””â”€ environment/                   # ğŸ§± reproducible env
â”‚     â”œâ”€ requirements.txt            # or poetry.lock / uv.lock
â”‚     â”œâ”€ conda-lock.yml              # optional
â”‚     â””â”€ docker_image.txt            # image digest / tag (if used)
â”œâ”€ catalogs/                         # ğŸ§­ evidence triplet (when applicable)
â”‚  â”œâ”€ stac/                           # STAC Collection/Item(s)
â”‚  â”œâ”€ dcat/                           # DCAT dataset record(s)
â”‚  â””â”€ prov/                           # PROV JSON(-LD) activity/agent/entity lineage
â”œâ”€ data/                             # ğŸ“Š inputs/outputs (small-to-medium)
â”‚  â”œâ”€ inputs/
â”‚  â”œâ”€ intermediates/
â”‚  â””â”€ outputs/
â”œâ”€ geospatial/                        # ğŸ—ºï¸ map-heavy assets (optional)
â”‚  â”œâ”€ geojson/
â”‚  â”œâ”€ cog/                            # Cloud-Optimized GeoTIFFs
â”‚  â”œâ”€ pmtiles/                         # PMTiles archives
â”‚  â””â”€ tiles_preview/                   # small preview tiles or snapshots
â”œâ”€ figures/                           # ğŸ“ˆ charts, screenshots, diagrams
â”‚  â”œâ”€ png/
â”‚  â”œâ”€ svg/
â”‚  â””â”€ pdf/
â”œâ”€ notebooks/                         # ğŸ““ optional (keep them runnable!)
â”‚  â”œâ”€ analysis.ipynb
â”‚  â””â”€ README.md
â”œâ”€ logs/                              # ğŸ§¾ runtime logs, telemetry, timings
â”‚  â”œâ”€ pipeline.log
â”‚  â”œâ”€ metrics.json
â”‚  â””â”€ stdout_stderr.txt
â”œâ”€ governance/                        # ğŸ›¡ï¸ policy checks, redactions, approvals
â”‚  â”œâ”€ policy_report.json
â”‚  â”œâ”€ redaction_notes.md
â”‚  â””â”€ approvals.md
â”œâ”€ integrity/                         # ğŸ”’ checksums + signatures
â”‚  â”œâ”€ checksums.sha256
â”‚  â”œâ”€ sbom.spdx.json                  # optional
â”‚  â””â”€ signatures/                     # cosign / attestations (optional)
â””â”€ narrative/                         # ğŸ“š Story/Pulse style artifacts (optional)
   â”œâ”€ story_node.md
   â”œâ”€ story_node.json
   â””â”€ evidence_manifest.yaml
```

---

## âœ… Minimum required files (for most experiments)

### 1) `manifest/run_manifest.json` (required)
A structured description of **exactly what ran**:
- inputs (file paths or stable URIs)
- parameters + hyperparameters
- random seeds
- tool versions
- outputs produced
- runtime summary (counts, sizes, errors)

### 2) `integrity/checksums.sha256` (required)
Hashes for everything in `artifacts/` that is a *material dependency* for reproduction (and optionally everything, if small enough).

### 3) `manifest/artifact_index.yaml` (recommended, near-required)
A human-friendly index of **whatâ€™s here**, **why it exists**, and **where itâ€™s referenced** in the report.

---

## ğŸ§¾ Artifact index format (recommended)

Create a tiny â€œtable of contentsâ€ for machines *and* humans:

```yaml
# artifacts/manifest/artifact_index.yaml
run:
  run_id: EXP-YYYYMMDD-HHMM__short-slug
  report_ref: ../report.md#results
  owner: your-name-or-handle
  created_utc: "2026-01-22T00:00:00Z"

artifacts:
  - id: results_table
    kind: table
    path: ../data/outputs/results.csv
    described_in: ../report.md#results
    notes: "Primary quantitative outcome table."

  - id: model_weights
    kind: model
    path: ../models/model.onnx
    described_in: ../report.md#model
    notes: "Exported model used for evaluation."

  - id: map_layer_cog
    kind: geospatial-raster
    path: ../geospatial/cog/landcover_2020.tif
    described_in: ../report.md#maps
    notes: "Rendered in UI + used for stats."
```

---

## ğŸ§­ If your experiment produces publishable datasets: include the â€œEvidence Tripletâ€ ğŸ§¬

When the experiment outputs a dataset intended to be **discoverable + reusable**, add:

- **STAC** (`catalogs/stac/`) â€” spatiotemporal indexing + asset links  
- **DCAT** (`catalogs/dcat/`) â€” catalog/discovery metadata  
- **PROV** (`catalogs/prov/`) â€” lineage: inputs â†’ process â†’ outputs  

If you donâ€™t need full publishing, keep it lightweightâ€”**but still keep a run manifest + hashes**. ğŸ§ 

---

## ğŸ§  AI/LLM-related outputs (Focus Mode, copilots, summarizers) ğŸ¤–

If an artifact was produced by an AI system:
- label it clearly (e.g., `*_ai_draft.md`)
- include the retrieval set / evidence pointers (IDs, URIs, queries)
- include a provenance record of the generation (prompt template ID, model ID, policy outcome)

**No citations / no provenance = not shippable.** âœ…

---

## ğŸ“š Narrative artifacts (Story Nodes & Pulse Threads) ğŸ§µâœ¨

If your experiment includes **interactive narrative content** (like a story walkthrough, UI tour, or pulse update), store it here so itâ€™s versioned and reviewable:

- `narrative/story_node.md` â€” the narrative text
- `narrative/story_node.json` â€” the â€œscriptâ€ (map states, steps, timeline)
- `narrative/evidence_manifest.yaml` â€” references + raw evidence behind claims

This pattern makes narrative experiments testable: your report can point at exact story steps and their underlying evidence. ğŸ¬ğŸ—ºï¸

---

## ğŸ§± Large binary artifacts (PMTiles / GeoParquet / COG / big models)

If artifacts are too large for Git:
- store them in an artifact registry (OCI-style) or LFS
- **still keep the pointer + digest in `artifacts/`**

Recommended: keep a pointer file like:

```yaml
# artifacts/manifest/oci_distribution.yaml
oci:
  registry: ghcr.io
  repository: myorg/kfm/surficial_geology
  tag: "20260111"
  digest: "sha256:...immutable..."
  files:
    - name: surficial_geology.pmtiles
      mediaType: application/vnd.pmtiles
    - name: surficial_geology.parquet
      mediaType: application/vnd.geo+parquet
  provenance_ref: "oci://.../referrers"
```

---

## ğŸ•µï¸ Sensitive data & redactions (must be explicit)

If an experiment touches sensitive locations, protected sites, personal info, etc.:
- include a `governance/redaction_notes.md`
- document **what was generalized/removed** and why
- ensure derived assets donâ€™t leak raw coordinates (including in EXIF, GeoJSON properties, logs)

---

## ğŸ›¡ï¸ Quality gates checklist (copy into PR or report)

- [ ] `run_manifest.json` present + complete  
- [ ] checksums generated (and updated)  
- [ ] environment pinned (dependencies / container digest)  
- [ ] policy report included (if governance applies)  
- [ ] AI outputs labeled + evidence attached  
- [ ] sensitive data handled (generalized / access-controlled)  
- [ ] report links resolve to artifacts (no broken paths)  

---

## ğŸ”— Linking from `report.md` (recommended pattern)

In the report, link directly to artifacts using relative paths:

```markdown
See: [results.csv](./artifacts/data/outputs/results.csv)  
See: [run manifest](./artifacts/manifest/run_manifest.json)  
See: [policy report](./artifacts/governance/policy_report.json)
```

If you need citations in prose, use footnotes that point to artifact IDs or catalog entries (stable + reviewable). ğŸ§·

---

## ğŸ§¬ (Optional) Visual provenance map

```mermaid
flowchart LR
  A[Inputs<br/>data/config] --> B[Pipeline Run<br/>run_manifest.json]
  B --> C[Outputs<br/>tables/maps/models]
  C --> D[Integrity<br/>checksums/signatures]
  C --> E[Catalogs<br/>STAC/DCAT/PROV]
  D --> F[Experiment Report<br/>report.md]
  E --> F
```

---

## ğŸ“š â€œProject Libraryâ€ reference pack (optional, but handy)

If the experiment is based on a reading packet, include it in:
- `artifacts/references/` (small docs), or
- a pointer file in `manifest/` (for large PDFs)

Example pointer:

```text
artifacts/manifest/reference_pack.txt
- AI Concepts & more.pdf
- Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf
- Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf
- Various programming languages & resources 1.pdf
```

---

## ğŸ§¯ Common mistakes (avoid these)

- âŒ â€œfinal_v2_REAL_final.csvâ€ with no manifest, no seed, no code ref  
- âŒ screenshots with no underlying data  
- âŒ AI-generated narrative with no citations/evidence  
- âŒ overwriting files in-place instead of versioning  
- âŒ missing license/sensitivity fields for publishable datasets  

---

## ğŸ™Œ Good citizen norms

- Prefer **append-only** changes (new run directory, new run_id)  
- If you must revise, create a new `run_id` and note supersession  
- Keep artifacts boring, structured, and verifiable âœ¨
