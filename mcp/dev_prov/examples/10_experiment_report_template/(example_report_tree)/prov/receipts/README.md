# ğŸ§¾ Receipts â€” `prov/receipts/`

`ğŸ§¬ provenance-first` `ğŸ”’ tamper-evident` `ğŸ§ª reproducible` `ğŸ§­ audit-ready`

Welcome to **Receipts** â€” the place where we store *verifiable evidence artifacts* that back the provenance graph (`prov/`) and the human-readable experiment report.

> If itâ€™s not in `prov/receipts/`, it didnâ€™t happenâ€¦  
> (â€¦or at least: it isnâ€™t **provable** ğŸ˜‰)

---

## ğŸ¯ What belongs in `receipts/`

Receipts are **raw, machine-checkable evidence** captured during:
- ğŸŒ **fetching** inputs (HTTP headers, status codes, timestamps)
- ğŸ” **verifying integrity** (hash lists, digests)
- ğŸ§° **capturing environment** (tool versions, lockfiles, runtime fingerprints)
- ğŸ§­ **running policy gates** (validation outputs, policy decision logs)
- ğŸ§· **supply-chain verification** (signatures, attestations, SBOMs)
- ğŸ—ºï¸ **geospatial transforms** (CRS/reprojection logs, tile build configs)
- ğŸ¤– **AI-assisted steps** (redacted prompts, model + config IDs, evaluation specs)
- ğŸ§ª **experimental procedures** (seed logs, parameter snapshots, run manifests)

Receipts are designed so the system can answer questions like:
- â€œWhich exact inputs produced this output?â€  
- â€œWhat tool versions were used?â€  
- â€œCan I reproduce this run byte-for-byte?â€  
- â€œWhat policies were checkedâ€”and what did they decide?â€  

---

## ğŸš« What does *not* belong here

### âŒ Not allowed
- **Secrets** (tokens, keys, passwords), ever
- **Sensitive personal data** (unless explicitly permitted and redacted)
- â€œMystery blobsâ€ without hashes + context

### âŒ Not recommended
- **Huge artifacts** (store those in artifact storage; reference them by digest)
- Raw datasets (those live in `data/` or referenced externally by immutable ID)

> ğŸ§¯ Pro tip: Prefer **pointers + hashes** over copying large files.

---

## ğŸ§± Golden rules (non-negotiable)

âœ… **Deterministic names:** predictable file names, stable directory structure  
âœ… **Immutable mindset:** append new receipts; donâ€™t â€œrewrite historyâ€  
âœ… **Everything hashed:** receipts should be listed in a checksum file  
âœ… **Cross-linkable:** receipts must be referenceable from PROV + report text  
âœ… **Redact aggressively:** store *proof*, not private content

---

## ğŸ“¦ Recommended folder layout

Below is a suggested structure. Customize if your domain needs it, but keep the spirit: *evidence-first + navigable + machine-friendly*.

```text
prov/receipts/
â”œâ”€ README.md
â”œâ”€ receipts.index.json                 # ğŸ” machine index of all receipt artifacts
â”‚
â”œâ”€ integrity/                          # ğŸ” tamper evidence
â”‚  â”œâ”€ checksums.sha256
â”‚  â””â”€ checksums.multihash.json         # optional
â”‚
â”œâ”€ fetch/                              # ğŸŒ network + acquisition receipts
â”‚  â”œâ”€ <source_id>/
â”‚  â”‚  â”œâ”€ request.headers.txt
â”‚  â”‚  â”œâ”€ response.headers.txt
â”‚  â”‚  â”œâ”€ response.status.json
â”‚  â”‚  â”œâ”€ etag.txt                      # if present
â”‚  â”‚  â””â”€ fetch.meta.json               # timestamps, byte counts, etc.
â”‚  â””â”€ ...
â”‚
â”œâ”€ env/                                # ğŸ§° reproducible runtime evidence
â”‚  â”œâ”€ git_commit.txt
â”‚  â”œâ”€ git_status.patch                 # optional (dirty diff)
â”‚  â”œâ”€ python_version.txt
â”‚  â”œâ”€ pip_freeze.txt
â”‚  â”œâ”€ node_version.txt
â”‚  â”œâ”€ package_lock.json                # optional copy
â”‚  â”œâ”€ rustc_version.txt                # optional
â”‚  â””â”€ docker_image_digests.json         # optional
â”‚
â”œâ”€ run/                                # ğŸƒ run-level evidence
â”‚  â”œâ”€ run_manifest.json
â”‚  â”œâ”€ telemetry.ndjson
â”‚  â””â”€ timings.json
â”‚
â”œâ”€ policy/                             # ğŸ§­ governance + validation
â”‚  â”œâ”€ conftest.results.json
â”‚  â”œâ”€ schema_validation.json
â”‚  â””â”€ gates.summary.md                 # small human-readable summary
â”‚
â”œâ”€ supply-chain/                       # ğŸ§· signatures + attestations
â”‚  â”œâ”€ artifact_digests.json
â”‚  â”œâ”€ signatures/                      # e.g., cosign outputs
â”‚  â”œâ”€ attestations/                    # e.g., in-toto provenance
â”‚  â””â”€ sbom/                            # SPDX/CycloneDX, etc.
â”‚
â”œâ”€ geospatial/                         # ğŸ—ºï¸ geo processing evidence
â”‚  â”œâ”€ reprojection.log
â”‚  â”œâ”€ crs.normalization.json
â”‚  â”œâ”€ tile_build_config.json
â”‚  â””â”€ tile_build.log
â”‚
â””â”€ ai/                                 # ğŸ¤– AI-related receipts (redacted!)
   â”œâ”€ model_id.txt
   â”œâ”€ prompt.hashes.json               # store hashes, not raw prompts (default)
   â”œâ”€ inference_config.json
   â”œâ”€ evaluation/
   â”‚  â”œâ”€ metricspec_id.txt
   â”‚  â””â”€ metrics.json
   â””â”€ ...
```

---

## ğŸ”— How receipts connect to provenance

Receipts are **supporting evidence** for the formal provenance graph:
- **PROV Entities** â†’ files, datasets, artifacts, manifests
- **PROV Activities** â†’ fetch, transform, evaluate, publish
- **PROV Agents** â†’ humans, CI bots, services, model identities

### ğŸ§© Linking strategy
1. Every receipt file gets a **hash** (and goes into `integrity/checksums.sha256`)
2. `receipts.index.json` becomes the **single lookup table** for tools and humans
3. PROV records reference receipts via:
   - receipt `id`
   - receipt `path`
   - receipt `sha256` (or multihash)
4. The experiment report references the same receipt IDs (no divergence)

---

## ğŸ—‚ï¸ `receipts.index.json` (minimal schema)

Keep this file small, stable, and machine-readable.

```json
{
  "schema_version": "receipts/v1",
  "run_id": "RUN-YYYYMMDD-HHMMSSZ-XXXX",
  "generated_at": "YYYY-MM-DDTHH:MM:SSZ",
  "items": [
    {
      "id": "fetch:source_usgs_nwis:stations",
      "kind": "http",
      "path": "fetch/source_usgs_nwis/response.headers.txt",
      "sha256": "â€¦",
      "relates_to": {
        "prov_activity": "prov.jsonld#activity-fetch-1",
        "prov_entity": "prov.jsonld#entity-input-1"
      },
      "notes": "Headers captured for reproducible retrieval."
    }
  ]
}
```

> ğŸ›ï¸ Design goal: tools can validate a run without â€œreading the whole reportâ€.

---

## ğŸ§ª Minimum receipts checklist

Use this as a baseline for any experiment run:

- [ ] ğŸ” `integrity/checksums.sha256` includes *every* receipt artifact
- [ ] ğŸŒ Fetch receipts exist for every external download (headers + status)
- [ ] ğŸ§° Environment receipts include tool versions + code commit ID
- [ ] ğŸƒ `run/run_manifest.json` exists and is hashable
- [ ] ğŸ§­ Policy receipts show what gates were checked (and outcomes)
- [ ] ğŸ§· Supply-chain receipts exist for any produced artifact (if applicable)
- [ ] ğŸ—ºï¸ Geo receipts exist for CRS changes / tile builds (if applicable)
- [ ] ğŸ¤– AI receipts are **redacted** by default (hashes > raw content)

---

## ğŸ› ï¸ Quick capture recipes (examples)

> These are examples; use equivalent commands for your OS/tooling.

### ğŸ” Checksums
```bash
# From the report root
find prov/receipts -type f -print0 | sort -z | xargs -0 sha256sum > prov/receipts/integrity/checksums.sha256
```

### ğŸ§° Environment snapshot
```bash
git rev-parse HEAD > prov/receipts/env/git_commit.txt
python -V > prov/receipts/env/python_version.txt
pip freeze > prov/receipts/env/pip_freeze.txt
node -v > prov/receipts/env/node_version.txt
```

### ğŸŒ HTTP fetch receipts (pattern)
```bash
# Replace <URL> and output filenames as needed
curl -sS -D prov/receipts/fetch/<source_id>/response.headers.txt -o /tmp/payload.bin "<URL>"
```

---

## ğŸ“š Project context (why this folder is so strict)

This repoâ€™s documentation emphasizes:
- **provenance-first** ingestion, processing, publishing, and AI outputs
- **contract-first** data acceptance (no â€œmystery layersâ€)
- **policy gates** that fail closed
- **UI + AI transparency** powered by inspectable sources

Receipts are the â€œground truth glueâ€ that keeps those promises enforceable.

<details>
<summary>ğŸ“¦ Included project reference docs that informed this receipts design</summary>

### ğŸ§­ Core KFM / provenance docs
- ğŸ“„ *Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation*
- ğŸ“„ *Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design*
- ğŸ“„ *Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–*
- ğŸ“„ *Kansas Frontier Matrix â€“ Comprehensive UI System Overview*
- ğŸ“„ *ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide*
- ğŸ“„ *ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals*
- ğŸ“„ *Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM)*
- ğŸ“„ *Additional Project Ideas*

### ğŸ§  Knowledge libraries (packaged as PDF portfolios)
- ğŸ“š *AI Concepts & more* (PDF Portfolio)
- ğŸ—ºï¸ *Mapsâ€“GoogleMapsâ€“VirtualWorldsâ€“Archaeologicalâ€“Computer Graphicsâ€“Geospatialâ€“webgl* (PDF Portfolio)
- ğŸ§® *Data Managmentâ€“Theoriesâ€“Archituresâ€“Data Scienceâ€“Baysian Methodsâ€“Some Programming Ideas* (PDF Portfolio)
- ğŸ§° *Various programming langurages & resources 1* (PDF Portfolio)

</details>

---

## âœ… Done right, receipts unlockâ€¦

- ğŸ§¾ **Evidence you can audit**
- ğŸ” **Runs you can reproduce**
- ğŸ§¬ **Provenance graphs you can query**
- ğŸ§  **AI answers you can trust**
- ğŸ—ºï¸ **Maps you can defend in peer review**

Keep it tight. Keep it verifiable. Keep the chain unbroken. ğŸ”—âœ¨
