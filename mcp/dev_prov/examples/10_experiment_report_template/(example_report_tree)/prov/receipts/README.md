# ğŸ§¾ Receipts â€” `prov/receipts/`

`ğŸ§¬ provenance-first` `ğŸ”’ tamper-evident` `ğŸ§ª reproducible` `ğŸ§­ audit-ready`

Welcome to **Receipts** â€” the place where we store *verifiable evidence artifacts* that back the provenance graph (`prov/`) and the human-readable experiment report.

> If itâ€™s not in `prov/receipts/`, it didnâ€™t happenâ€¦  
> (â€¦or at least: it isnâ€™t **provable** ğŸ˜‰)

---

## ğŸ¯ What belongs in `receipts/`

Receipts are **raw, machine-checkable evidence** captured during:
- ğŸŒ **fetching** inputs (HTTP headers, status codes, timestamps)
- ğŸ” **verifying integrity** (hash lists, digests)
- ğŸ§° **capturing environment** (tool versions, lockfiles, runtime fingerprints)
- ğŸ§­ **running policy gates** (validation outputs, policy decision logs)
- ğŸ§· **supply-chain verification** (signatures, attestations, SBOMs)
- ğŸ—ºï¸ **geospatial transforms** (CRS/reprojection logs, tile build configs)
- ğŸ¤– **AI-assisted steps** (redacted prompts, model + config IDs, evaluation specs)
- ğŸ§ª **experimental procedures** (seed logs, parameter snapshots, run manifests)

Receipts are designed so the system can answer questions like:
- â€œWhich exact inputs produced this output?â€  
- â€œWhat tool versions were used?â€  
- â€œCan I reproduce this run byte-for-byte?â€  
- â€œWhat policies were checkedâ€”and what did they decide?â€  

---

## ğŸš« What does *not* belong here

### âŒ Not allowed
- **Secrets** (tokens, keys, passwords), ever
- **Sensitive personal data** (unless explicitly permitted and redacted)
- â€œMystery blobsâ€ without hashes + context

### âŒ Not recommended
- **Huge artifacts** (store those in artifact storage; reference them by digest)
- Raw datasets (those live in `data/` or referenced externally by immutable ID)

> ğŸ§¯ Pro tip: Prefer **pointers + hashes** over copying large files.

---

## ğŸ§± Golden rules (non-negotiable)

âœ… **Deterministic names:** predictable file names, stable directory structure  
âœ… **Immutable mindset:** append new receipts; donâ€™t â€œrewrite historyâ€  
âœ… **Everything hashed:** receipts should be listed in a checksum file  
âœ… **Cross-linkable:** receipts must be referenceable from PROV + report text  
âœ… **Redact aggressively:** store *proof*, not private content

---

## ğŸ“¦ Recommended folder layout

Below is a suggested structure. Customize if your domain needs it, but keep the spirit: *evidence-first + navigable + machine-friendly*.

```text
prov/receipts/
â”œâ”€ ğŸ“„ README.md                        # ğŸ“˜ How receipts are organized, retention rules, and how to verify bundles
â”œâ”€ ğŸ”ğŸ§¾ receipts.index.json             # ğŸ” Machine index of all receipt artifacts (paths, types, timestamps, digests)
â”‚
â”œâ”€ ğŸ” integrity/                       # ğŸ” Tamper evidence for the receipts directory itself
â”‚  â”œâ”€ ğŸ”ğŸ“„ checksums.sha256             # sha256 sums for files in receipts/ (or referenced subset)
â”‚  â””â”€ ğŸ”ğŸ§¾ checksums.multihash.json      # Optional multihash map (algorithm agility / cross-tool compatibility)
â”‚
â”œâ”€ ğŸŒ fetch/                           # ğŸŒ Network/acquisition receipts (what was requested + what was returned)
â”‚  â”œâ”€ ğŸ†” <source_id>/                   # One folder per upstream source endpoint/file
â”‚  â”‚  â”œâ”€ ğŸ“„ request.headers.txt         # Captured request headers (sanitize auth tokens; no secrets)
â”‚  â”‚  â”œâ”€ ğŸ“„ response.headers.txt        # Captured response headers (cache hints, content-type, etc.)
â”‚  â”‚  â”œâ”€ ğŸ§¾ response.status.json        # Status + timing + error info (if any)
â”‚  â”‚  â”œâ”€ ğŸ·ï¸ etag.txt                    # Entity tag (if present) used for caching/change detection
â”‚  â”‚  â””â”€ ğŸ§¾ fetch.meta.json             # Timestamps, byte counts, retry counts, and fetch tool/version
â”‚  â””â”€ â• â€¦                              # Additional sources
â”‚
â”œâ”€ ğŸ§° env/                              # ğŸ§° Repro runtime evidence (what code + deps ran)
â”‚  â”œâ”€ ğŸ§¾ git_commit.txt                 # Exact commit SHA used for the run
â”‚  â”œâ”€ ğŸ§¾ git_status.patch               # Optional â€œdirty diffâ€ patch (only if uncommitted changes existed)
â”‚  â”œâ”€ ğŸğŸ§¾ python_version.txt           # Python version used
â”‚  â”œâ”€ ğŸğŸ§¾ pip_freeze.txt               # Frozen Python deps (pip freeze)
â”‚  â”œâ”€ ğŸŸ©ğŸ§¾ node_version.txt             # Node.js version used
â”‚  â”œâ”€ ğŸ§¾ package_lock.json              # Optional lockfile copy (npm/yarn/pnpm) for reproducibility
â”‚  â”œâ”€ ğŸ¦€ğŸ§¾ rustc_version.txt            # Optional Rust compiler version (if used)
â”‚  â””â”€ ğŸ³ğŸ§¾ docker_image_digests.json     # Optional container digests (images used, pinned by sha256)
â”‚
â”œâ”€ ğŸƒ run/                              # ğŸƒ Run-level evidence (what happened during execution)
â”‚  â”œâ”€ ğŸ§¾ğŸ” run_manifest.json             # Run receipt: commands, params, inputs/outputs, tools, digests, pointers
â”‚  â”œâ”€ ğŸ“¡ğŸ§¾ telemetry.ndjson              # Event stream (newline-delimited JSON) for tracing/debugging (redacted)
â”‚  â””â”€ â±ï¸ğŸ§¾ timings.json                  # Timing breakdowns (step durations, IO time, CPU/GPU utilization if captured)
â”‚
â”œâ”€ ğŸ§­ policy/                           # ğŸ§­ Governance + validation proofs (what gates ran, what they concluded)
â”‚  â”œâ”€ ğŸ§ªğŸ§¾ conftest.results.json         # OPA/Conftest evaluation output (pass/fail + findings + policy ids)
â”‚  â”œâ”€ ğŸ“ğŸ§¾ schema_validation.json        # Schema validation results (which schemas, which files, errors/warnings)
â”‚  â””â”€ ğŸ“ğŸ§¾ gates.summary.md              # Small human summary (top findings, waivers used, links to full reports)
â”‚
â”œâ”€ ğŸ§· supply-chain/                     # ğŸ§· Supply-chain proofs for produced artifacts
â”‚  â”œâ”€ ğŸ”ğŸ§¾ artifact_digests.json         # Digest list for released artifacts (subject â†’ sha256/size/mediaType)
â”‚  â”œâ”€ ğŸ” signatures/                    # Signatures (e.g., cosign bundles/refs) for verification
â”‚  â”œâ”€ ğŸ§¾ attestations/                  # Attestations (e.g., in-toto/SLSA provenance) tied to artifact digests
â”‚  â””â”€ ğŸ“¦ sbom/                          # SBOM outputs (SPDX/CycloneDX) for toolchain/runtime or shipped artifacts
â”‚
â”œâ”€ ğŸ—ºï¸ geospatial/                       # ğŸ—ºï¸ Geo processing receipts (CRS, tiling, transformation decisions)
â”‚  â”œâ”€ ğŸªµ reprojection.log               # Reprojection operations log (inputs, outputs, warnings)
â”‚  â”œâ”€ ğŸ§¾ crs.normalization.json         # CRS normalization decisions (source CRS â†’ normalized CRS; authority refs)
â”‚  â”œâ”€ ğŸ›ï¸ğŸ§¾ tile_build_config.json        # Tile build configuration (zoom range, buffer, simplification, compression)
â”‚  â””â”€ ğŸªµ tile_build.log                 # Tile build log (commands, warnings, counts, performance)
â”‚
â””â”€ ğŸ¤– ai/                               # ğŸ¤– AI-related receipts (redacted by default; hashes over raw prompts)
   â”œâ”€ ğŸ¤–ğŸ§¾ model_id.txt                  # Model identifier used (and provider/version if applicable)
   â”œâ”€ ğŸ”ğŸ§¾ prompt.hashes.json            # Hashes of prompts/instructions (default) to avoid storing sensitive text
   â”œâ”€ ğŸ›ï¸ğŸ§¾ inference_config.json         # Inference params (temperature, max tokens, tools enabled, policy pack version)
   â”œâ”€ ğŸ“ evaluation/                     # Evaluation artifacts (metrics + metric spec linkage)
   â”‚  â”œâ”€ ğŸ§¾ metricspec_id.txt            # Metrics spec identifier used (ties to review metrics catalog)
   â”‚  â””â”€ ğŸ“ŠğŸ§¾ metrics.json               # Computed evaluation metrics (citation coverage, refusal rate, etc.)
   â””â”€ â• â€¦                                # Additional AI receipts as needed (always redact/sanitize)
```

---

## ğŸ”— How receipts connect to provenance

Receipts are **supporting evidence** for the formal provenance graph:
- **PROV Entities** â†’ files, datasets, artifacts, manifests
- **PROV Activities** â†’ fetch, transform, evaluate, publish
- **PROV Agents** â†’ humans, CI bots, services, model identities

### ğŸ§© Linking strategy
1. Every receipt file gets a **hash** (and goes into `integrity/checksums.sha256`)
2. `receipts.index.json` becomes the **single lookup table** for tools and humans
3. PROV records reference receipts via:
   - receipt `id`
   - receipt `path`
   - receipt `sha256` (or multihash)
4. The experiment report references the same receipt IDs (no divergence)

---

## ğŸ—‚ï¸ `receipts.index.json` (minimal schema)

Keep this file small, stable, and machine-readable.

```json
{
  "schema_version": "receipts/v1",
  "run_id": "RUN-YYYYMMDD-HHMMSSZ-XXXX",
  "generated_at": "YYYY-MM-DDTHH:MM:SSZ",
  "items": [
    {
      "id": "fetch:source_usgs_nwis:stations",
      "kind": "http",
      "path": "fetch/source_usgs_nwis/response.headers.txt",
      "sha256": "â€¦",
      "relates_to": {
        "prov_activity": "prov.jsonld#activity-fetch-1",
        "prov_entity": "prov.jsonld#entity-input-1"
      },
      "notes": "Headers captured for reproducible retrieval."
    }
  ]
}
```

> ğŸ›ï¸ Design goal: tools can validate a run without â€œreading the whole reportâ€.

---

## ğŸ§ª Minimum receipts checklist

Use this as a baseline for any experiment run:

- [ ] ğŸ” `integrity/checksums.sha256` includes *every* receipt artifact
- [ ] ğŸŒ Fetch receipts exist for every external download (headers + status)
- [ ] ğŸ§° Environment receipts include tool versions + code commit ID
- [ ] ğŸƒ `run/run_manifest.json` exists and is hashable
- [ ] ğŸ§­ Policy receipts show what gates were checked (and outcomes)
- [ ] ğŸ§· Supply-chain receipts exist for any produced artifact (if applicable)
- [ ] ğŸ—ºï¸ Geo receipts exist for CRS changes / tile builds (if applicable)
- [ ] ğŸ¤– AI receipts are **redacted** by default (hashes > raw content)

---

## ğŸ› ï¸ Quick capture recipes (examples)

> These are examples; use equivalent commands for your OS/tooling.

### ğŸ” Checksums
```bash
# From the report root
find prov/receipts -type f -print0 | sort -z | xargs -0 sha256sum > prov/receipts/integrity/checksums.sha256
```

### ğŸ§° Environment snapshot
```bash
git rev-parse HEAD > prov/receipts/env/git_commit.txt
python -V > prov/receipts/env/python_version.txt
pip freeze > prov/receipts/env/pip_freeze.txt
node -v > prov/receipts/env/node_version.txt
```

### ğŸŒ HTTP fetch receipts (pattern)
```bash
# Replace <URL> and output filenames as needed
curl -sS -D prov/receipts/fetch/<source_id>/response.headers.txt -o /tmp/payload.bin "<URL>"
```

---

## ğŸ“š Project context (why this folder is so strict)

This repoâ€™s documentation emphasizes:
- **provenance-first** ingestion, processing, publishing, and AI outputs
- **contract-first** data acceptance (no â€œmystery layersâ€)
- **policy gates** that fail closed
- **UI + AI transparency** powered by inspectable sources

Receipts are the â€œground truth glueâ€ that keeps those promises enforceable.

<details>
<summary>ğŸ“¦ Included project reference docs that informed this receipts design</summary>

### ğŸ§­ Core KFM / provenance docs
- ğŸ“„ *Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation*
- ğŸ“„ *Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design*
- ğŸ“„ *Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–*
- ğŸ“„ *Kansas Frontier Matrix â€“ Comprehensive UI System Overview*
- ğŸ“„ *ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide*
- ğŸ“„ *ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals*
- ğŸ“„ *Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM)*
- ğŸ“„ *Additional Project Ideas*

### ğŸ§  Knowledge libraries (packaged as PDF portfolios)
- ğŸ“š *AI Concepts & more* (PDF Portfolio)
- ğŸ—ºï¸ *Mapsâ€“GoogleMapsâ€“VirtualWorldsâ€“Archaeologicalâ€“Computer Graphicsâ€“Geospatialâ€“webgl* (PDF Portfolio)
- ğŸ§® *Data Managmentâ€“Theoriesâ€“Archituresâ€“Data Scienceâ€“Baysian Methodsâ€“Some Programming Ideas* (PDF Portfolio)
- ğŸ§° *Various programming langurages & resources 1* (PDF Portfolio)

</details>

---

## âœ… Done right, receipts unlockâ€¦

- ğŸ§¾ **Evidence you can audit**
- ğŸ” **Runs you can reproduce**
- ğŸ§¬ **Provenance graphs you can query**
- ğŸ§  **AI answers you can trust**
- ğŸ—ºï¸ **Maps you can defend in peer review**

Keep it tight. Keep it verifiable. Keep the chain unbroken. ğŸ”—âœ¨
