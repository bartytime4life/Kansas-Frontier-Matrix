# ğŸ›¡ï¸ Provenance Policy Pack (ğŸ—‚ï¸ `prov/policy/`)

![Policy-as-Code](https://img.shields.io/badge/Policy--as--Code-OPA%20%2B%20Rego-blue)
![Conftest](https://img.shields.io/badge/CI-Gated%20with%20Conftest-informational)
![PROV-O](https://img.shields.io/badge/Provenance-W3C%20PROV--O-success)
![FAIR+CARE](https://img.shields.io/badge/Governance-FAIR%20%2B%20CARE-6f42c1)
![Fail-Closed](https://img.shields.io/badge/Default-Fail--Closed-critical)
![Supply%20Chain](https://img.shields.io/badge/Supply%20Chain-OCI%20%2B%20Cosign-orange)

> âœ… This folder exists so every experiment run is **publishable by proof**, not by vibes.  
> It contains the **policy-as-code bundle** (snapshot) and the **policy evaluation results** that validate provenance, governance, security, and reproducibility.

---

## ğŸ§­ Where this fits in the experiment report tree

This `prov/policy/` directory is part of the **experiment report artifact**. A typical report tree looks like:

```text
(example_report_tree)/
â”œâ”€ ğŸ“„ report.md (or README.md)
â””â”€ ğŸ§¬ prov/
   â”œâ”€ ğŸ§¾ manifest.json                  # run + environment metadata (canonicalized + hashed)
   â”œâ”€ ğŸ—ºï¸ stac/                          # STAC collections/items
   â”œâ”€ ğŸ§± dcat/                          # DCAT dataset/distributions (JSON-LD)
   â”œâ”€ ğŸ§¾ prov/                          # W3C PROV-O bundles (JSON-LD)
   â””â”€ ğŸ›¡ï¸ policy/
      â”œâ”€ ğŸ“„ README.md                   # (this file)
      â”œâ”€ ğŸ“¦ bundle/                     # snapshot of policy pack used for this run (OPA bundle)
      â”œâ”€ ğŸ“¥ input/                      # compiled â€œfactsâ€ used by the policy engine
      â”œâ”€ ğŸ“¤ results/                    # machine + human-friendly outputs
      â””â”€ ğŸ§¾ waivers/                    # (optional) signed/approved exceptions
```

> âœï¸ Template rule: **policy evaluation is reproducible** only if the report includes *both*:
> - the **inputs** (facts), and  
> - the **policy bundle digest/version** used to evaluate them.

---

## ğŸ¯ What â€œpolicyâ€ means here

KFM treats governance as a **first-class, testable interface**:

- **Policy-as-code** ğŸ§© â€” rules are written in OPA/Rego and run via Conftest (CI) and/or runtime gates.  
- **Evidence-first** ğŸ§¾ â€” policies evaluate against explicit artifacts (STAC/DCAT/PROV, run manifests, SBOMs, signaturesâ€¦).  
- **Fail-closed by default** ğŸš¦ â€” if evidence is missing or invalid, the gate blocks publication/use until fixed or waived.  
- **No mystery layers** ğŸ§± â€” nothing reaches UI/AI without a data contract + provenance trail.

---

## ğŸš¦ Policy gates (when enforcement happens)

KFMâ€™s governance model uses **checkpoints** (a.k.a. â€œpolicy gatesâ€) throughout the lifecycle:

```mermaid
flowchart LR
  A[ğŸ“¥ Ingestion] --> B[ğŸ§ª Validation]
  B --> C{ğŸ›¡ï¸ Policy Gate}
  C -->|PASS âœ…| D[ğŸ—ƒï¸ Catalog: STAC/DCAT/PROV]
  C -->|FAIL âŒ| X[â›” Block + Emit Findings]
  D --> E[ğŸ§  Graph + Index]
  E --> F[ğŸ›°ï¸ API]
  F --> G[ğŸ—ºï¸ UI + Exports]
  F --> H[ğŸ¤– Focus Mode / AI Inference]
  H --> C
  G --> C
```

**Minimum gate intent** (baseline for v13+):
- Schema validity âœ…
- STAC/DCAT/PROV completeness ğŸ§¾
- License presence ğŸ“œ
- Sensitivity labeling + handling ğŸ·ï¸
- Provenance completeness ğŸ”—
- AI answers require citations ğŸ“Œ

---

## ğŸ§¾ Policy inputs (facts) evaluated by this pack

The policy engine reads from a **compiled input set** (â€œfactsâ€) built from this reportâ€™s provenance artifacts. At minimum, expect:

| Evidence artifact ğŸ§¾ | Why it exists ğŸ§  | Typical location ğŸ“ |
|---|---|---|
| Run Manifest (`run_id`, tool versions, inputs/outputs, counts, errors) | Reproducibility + audit trail | `prov/manifest.json` or `prov/audits/<run_id>/run_manifest.json` |
| Canonical digest + idempotency key | Guarantees stable identity of the run | inside manifest (`canonical_digest`, `idempotency_key`) |
| STAC collections/items | Spatial/temporal extents + discoverability | `prov/stac/` |
| DCAT dataset/distributions (JSON-LD) | Publishing + licensing + distribution refs | `prov/dcat/` |
| PROV-O bundles (JSON-LD) | Machine-queryable lineage graph | `prov/prov/` |
| Data contracts / metadata contracts | â€œNo mystery layersâ€ guarantee | referenced from STAC/DCAT/manifest |
| Artifact references (OCI digests, PMTiles/COGs/GeoParquet) | Immutable retrieval + verification | referenced from DCAT distributions |
| Supply chain evidence (SBOM / signatures) | Trust + tamper resistance | `prov/policy/input/` or referrers in OCI |
| AI transcripts + citations (if AI was used) | Accountability + source traceability | `prov/ai/` (recommended) |

---

## ğŸ“¤ Policy outputs (what you should look at first)

Inside `prov/policy/results/`, you should find at least one of:

- `summary.md` âœ… human-friendly â€œPASS/FAIL + findingsâ€
- `results.json` / `results.ndjson` ğŸ§¾ machine-readable findings (best for CI + dashboards)
- `junit.xml` ğŸ§ª test-style output (best for CI UIs)
- `policy_bundle.lock` ğŸ”’ bundle digest/version pin

> ğŸ” If youâ€™re reviewing a report: start with `results/summary.md`, then inspect the underlying `results.json` for control IDs and evidence pointers.

---

## ğŸ§± Control catalog (baseline)

Below is a suggested **control inventory** for this template. Your repository may implement more or fewer controls; keep the IDs stable.

| Control ID | Gatepoint | What it enforces | Severity | Evidence |
|---|---|---|---|---|
| **KFM-POL-SCHEMA-001** | Ingest | Data + metadata schemas validate (no malformed STAC/DCAT/PROV) | âŒ Deny | STAC/DCAT/PROV files |
| **KFM-POL-PROV-001** | Catalog | Every published entity has PROV lineage (inputs + activities) | âŒ Deny | PROV bundle |
| **KFM-POL-CAT-001** | Catalog | STAC/DCAT/PROV completeness for every dataset | âŒ Deny | STAC + DCAT + PROV |
| **KFM-POL-LIC-001** | Publish | License present + approved SPDX/known value | âŒ Deny | DCAT license + data contract |
| **KFM-POL-SENS-001** | Publish | Sensitivity classification present; if sensitive, proper handling | âŒ Deny | sensitivity fields + policy config |
| **KFM-POL-CARE-001** | Publish | CARE governance flags for community/indigenous data where applicable | âš ï¸ Warn/âŒ Deny | governance fields |
| **KFM-POL-GEO-OBF-001** | UI/Export | Sensitive locations are generalized/obfuscated per policy | âŒ Deny | geometry + obfuscation proof |
| **KFM-POL-RUN-001** | Ingest | Run manifest exists (inputs/outputs/versions/counts/errors) | âŒ Deny | run manifest |
| **KFM-POL-RUN-002** | Ingest | Manifest canonical digest + idempotency key present | âŒ Deny | manifest fields |
| **KFM-POL-SUPPLY-001** | Publish | Artifacts referenced by immutable digest; signed where required | âŒ Deny | OCI digest + signature |
| **KFM-POL-SECRETS-001** | CI | No obvious secrets/API keys committed | âŒ Deny | repo scan findings |
| **KFM-POL-AI-CITE-001** | AI | Focus Mode outputs must include citations; otherwise refuse | âŒ Deny | AI transcript + citations |
| **KFM-POL-DEVPROV-001** | CI/Publish | Dev provenance links run â†’ commit/PR/reviewer chain | âš ï¸ Warn | PR/commit PROV JSON-LD |
| **KFM-POL-EXP-001** | Report | Experiment protocol completeness (question â†’ method â†’ results) | âš ï¸ Warn | protocol section in report |

---

## ğŸ§ª Re-running policy checks (local)

> This template supports **two equivalent modes**: Conftest (recommended for CI) and raw OPA evaluation.

### Option A â€” Conftest âœ…
```bash
# From the report root:
conftest test \
  --policy ./prov/policy/bundle \
  --input  ./prov/policy/input/input.json \
  ./prov
```

### Option B â€” OPA eval ğŸ§ 
```bash
# Example: evaluate deny rules
opa eval \
  -b ./prov/policy/bundle \
  -i ./prov/policy/input/input.json \
  "data.kfm.deny"
```

> ğŸ§© Tip: keep the compiled policy input stable. If you regenerate `input.json`, pin and record the generator + version in the run manifest.

---

## ğŸ§¾ Waivers (exceptions) â€” how to do them safely

Sometimes you need an exception. Waivers must be **explicit**, **time-bounded**, and **auditable**.

âœ… Recommended structure (`prov/policy/waivers/waivers.yaml`):

```yaml
waivers:
  - waiver_id: "WVR-2026-001"
    control_id: "KFM-POL-LIC-001"
    scope:
      dataset_ids: ["kfm.dataset.example"]
    justification: "License under review; dataset restricted to internal use only."
    mitigations:
      - "Do not publish publicly"
      - "Access restricted to role:admin"
    expires_on: "2026-03-01"
    approved_by:
      - name: "Maintainer Name"
        role: "Data Governance"
    evidence:
      - "prov/policy/results/finding-KFM-POL-LIC-001.json"
```

ğŸš« Anti-patterns:
- â€œTemporaryâ€ waivers with no expiration
- Waivers with no scope (too broad)
- Waivers with no mitigations

---

## ğŸ”’ Security + privacy notes (why policy cares)

Policy isnâ€™t just â€œlint for metadata.â€ Itâ€™s how we prevent harm:

- **Sensitive data controls** ğŸ·ï¸: classification + access restrictions + UI warnings  
- **Location protection** ğŸ—ºï¸: generalization/obfuscation for protected sites  
- **Query auditing** ğŸ”: prevent inference attacks from aggregate outputs  
- **Supply chain verification** ğŸ“¦: signed artifacts + immutable digests  
- **Prompt / output governance** ğŸ¤–: AI answers must cite sources; unsafe outputs are blocked

---

## ğŸ—ºï¸ UI + export behavior (provenance is visible)

KFMâ€™s UI philosophy is â€œğŸ—ºï¸ the map behind the mapâ€:

- Every visible layer should expose **source, license, provenance summary**  
- Exports should include **credits/attribution** automatically  
- â€œStoryâ€ experiences should carry an **evidence manifest** that points to the exact supporting sources

If you donâ€™t see provenance surfaced in the UI, treat it like a **policy failure** (even if the map â€œworksâ€).

---

## âœ… Reproducibility checklist (report reviewer edition)

Use this quick checklist when reviewing a run:

- [ ] The run has a **stable `run_id`** and **canonical digest**  
- [ ] The report includes **inputs + outputs** (or immutable references to them)  
- [ ] Tool versions are recorded (libraries, containers, pipelines)  
- [ ] STAC/DCAT/PROV artifacts exist and cross-link correctly  
- [ ] Licensing is explicit and compatible with intended publication  
- [ ] Sensitivity policies are honored (especially geospatial points)  
- [ ] Any AI-generated content has citations (or is blocked)  
- [ ] If exceptions exist, waivers are **scoped + expiring + justified**  
- [ ] (Optional) Dev provenance ties outputs back to commits/PR reviews

---

## ğŸ“š Project reference pack (design inputs)

This template is grounded in the projectâ€™s architecture, ingestion, UI, AI, and governance documentation:

- ğŸ“˜ **KFM â€“ Comprehensive Technical Documentation**
- ğŸ—ï¸ **KFM â€“ Comprehensive Architecture, Features, and Design**
- ğŸ¤– **KFM â€“ AI System Overview**
- ğŸ–¥ï¸ **KFM â€“ Comprehensive UI System Overview**
- ğŸ“¥ **KFM Data Intake â€“ Technical & Design Guide**
- ğŸ’¡ **Innovative Concepts to Evolve KFM**
- ğŸŒŸ **Latest Ideas & Future Proposals**
- ğŸ§  **Additional Project Ideas**
- ğŸ“¦ **AI Concepts & more** (portfolio)
- ğŸ§° **Various programming languages & resources** (portfolio)
- ğŸ—ºï¸ **Maps / Virtual Worlds / Geospatial WebGL** (portfolio)
- ğŸ—ƒï¸ **Data Management / Architectures / Bayesian / Data Science** (portfolio)

> ğŸ§· Keep this README in sync with policy pack versions.  
> When policies evolve, update: control catalog, evidence requirements, waiver rules, and rerun outputs.

---
