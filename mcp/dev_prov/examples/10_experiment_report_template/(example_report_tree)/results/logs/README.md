# ğŸ§¾ Experiment Logs (`results/logs/`)

![PROV](https://img.shields.io/badge/PROV-provenance--first-success)
![Format](https://img.shields.io/badge/format-NDJSON%20%7C%20JSON--LD-informational)
![Audit](https://img.shields.io/badge/audit-traceable%20runs-blue)
![Policy](https://img.shields.io/badge/policy-fail--closed-critical)

> ğŸ§  **Goal:** make every experiment run *reproducible, auditable, and explainable* â€” â€œreceipts included.â€  
> KFM treats *all data* and *all derived outputs* as untrusted until validated + cataloged, and logging is part of that contract.  [oai_citation:0â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)

---

## ğŸ§­ Where this fits in the KFM pipeline

KFM enforces a strict â€œno skipping stagesâ€ pipeline: **ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode**. Logs in this folder should help you prove you followed the ordering and didnâ€™t bypass trust boundaries.  [oai_citation:1â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## âœ… What belongs in `results/logs/`

Store **run-time evidence** here â€” the stuff youâ€™d need to debug, reproduce, audit, or defend the result later:

### ğŸ“Œ Core run trace (recommended minimum)
- **`telemetry.ndjson`** â€” structured event stream (append-only JSON Lines / NDJSON)
- **`stdout.log` / `stderr.log`** â€” raw process output (captured once; donâ€™t edit)
- **`run_manifest.json`** â€” the â€œledgerâ€ of the run (who/what/when/inputs/outputs/tools) with integrity hash
- **`policy/`** â€” governance gates + policy decision logs (OPA/Conftest output)
- **`prov/`** â€” provenance bundle export (PROV JSON-LD or equivalent)
- **`checksums.sha256`** â€” hashes for log artifacts (and optionally all result artifacts)

KFM explicitly calls for **append-only telemetry logging** during ingest/pipeline runs (e.g., â€œfetched X bytes from URL Y â€¦ outcome=successâ€), stored as NDJSON.  [oai_citation:2â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)

### ğŸ§© Optional (but powerful) add-ons
- **`ui/`** â€” UI interaction + performance traces (especially if youâ€™re testing map layers, provenance UI, etc.)
- **`ai/`** â€” AI-related run telemetry (drift checks, evaluation summaries, redacted prompt traces)
- **`perf/`** â€” profiler outputs (CPU, memory, GPU), FPS traces for WebGL map scenes
- **`dev_prov/`** â€” developer provenance events (CI, PR checks, review steps) as a structured feed

Observability is a first-class system concern (correlation/request IDs, metrics, traces, and â€œFocus telemetryâ€), so logs should carry those identifiers when relevant. 

---

## ğŸš« What does *not* belong here

- âŒ Final figures, tables, dashboards (those go in other `results/` folders)
- âŒ Raw datasets (those belong in the governed data lifecycle, not ad-hoc logs)
- âŒ Secrets, tokens, API keys, or unredacted PII  
  - KFM governance can include **policy-as-code** checks that block secrets from being committed and â€œfail closedâ€ in CI.  [oai_citation:3â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
- âŒ â€œMystery logsâ€ with no `experiment_id` / `run_id` / timestamps

> [!IMPORTANT]
> If youâ€™re doing anything user-facing (UI tests, Focus Mode tests, query logs), treat logs as potentially sensitive. Privacy- and access-aware audit trails are part of responsible data practice.  [oai_citation:4â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)

---

## ğŸ—‚ï¸ Recommended folder layout (per-run isolation)

Use a **run-per-folder** layout so that logs are self-contained and easy to diff.

```text
ğŸ“ results/
  ğŸ“ logs/
    ğŸ“„ README.md
    ğŸ“ runs/
      ğŸ“ 2026-01-22T013045Z__EXP-010__run-7f3a1c/
        ğŸ“„ run_manifest.json
        ğŸ“„ telemetry.ndjson
        ğŸ“„ stdout.log
        ğŸ“„ stderr.log
        ğŸ“„ checksums.sha256
        ğŸ“ policy/
          ğŸ“„ opa_decisions.ndjson
          ğŸ“„ conftest_report.json
        ğŸ“ prov/
          ğŸ“„ prov_bundle.jsonld
        ğŸ“ ui/
          ğŸ“„ ui_events.ndjson
          ğŸ“„ webgl_perf.json
        ğŸ“ ai/
          ğŸ“„ drift_eval.json
          ğŸ“„ focus_telemetry.ndjson  # redacted
```

**Naming convention suggestion:**

`<ISO8601>__<experiment_id>__<run_id>/`

This makes logs sortable and easy to locate. Your `run_id` should match whatever the pipeline uses as the unique identifier.

---

## ğŸ§¾ Run manifest contract (what â€œgoodâ€ looks like)

A Run Manifest is a structured JSON record of the run â€” including:
- `run_id`, `run_time`
- `idempotency_key`
- `canonical_digest` (hash of canonicalized manifest)
- `source_urls`, `tool_versions`, summary counts, errors, etc.

KFMâ€™s design notes describe canonicalizing the manifest (RFC 8785) and hashing with SHA-256 to produce a stable digest used as an idempotency key and immutable run identifier.  [oai_citation:5â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)

> [!TIP]
> Treat `run_manifest.json` as the *index* into everything else. Your report should link to it first.

---

## ğŸ“¦ Log formats we expect

### 1) NDJSON telemetry (`*.ndjson`)
- One JSON object per line
- Append-only (donâ€™t â€œrewrite historyâ€ â€” append corrections as new events)
- Easy to stream and grep
- Matches KFMâ€™s ingest telemetry pattern  [oai_citation:6â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)

**Suggested event fields (template):**
- `ts` (ISO8601)
- `level` (`debug|info|warn|error`)
- `experiment_id`
- `run_id`
- `component` (`etl|catalog|graph|api|ui|focus|policy|ci`)
- `event` (stable name: `etl.extract.start`, `policy.opa.decision`, etc.)
- `message` (human hint)
- `metrics` (numbers)
- `artifacts` (paths/digests)
- `prov` (optional: activity/entity IDs)
- `git` (commit, branch)
- `correlation_id` / `request_id` (if applicable) 

**Example telemetry line:**
```json
{"ts":"2026-01-22T01:30:45Z","level":"info","experiment_id":"EXP-010","run_id":"run-7f3a1c","component":"etl","event":"etl.extract.fetch","source_url":"https://example.org/data.csv","bytes":184233,"sha256":"...","outcome":"success","prov":{"activity":"kfm:prov:activity/run-7f3a1c#extract"}}
```

### 2) Provenance bundles (`prov/*.jsonld`)
KFM relies on PROV-O lineage bundles as boundary artifacts for trust and traceability.  [oai_citation:7â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

### 3) Policy outputs (`policy/*`)
KFM governance is designed to be enforced through automated policy gates (OPA/Conftest), including secret scanning and metadata requirements. Logs should capture **inputs â†’ decision â†’ reason**.  [oai_citation:8â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)  

---

## ğŸ§ª AI + Focus Mode logs (special handling)

KFMâ€™s AI system includes **drift monitoring** and **prompt security controls**; those outputs belong here (as summaries), but raw prompts/contexts must be handled carefully. 

**Recommended pattern:**
- âœ… Store **evaluation summaries** (metrics, pass/fail, dataset IDs)
- âœ… Store **redacted prompt traces** (hashes, token counts, citation IDs)
- âŒ Donâ€™t store raw user text unless explicitly approved & classified

---

## ğŸ—ºï¸ UI & map experiments: provenance + performance logs

The UI design includes **Layer Info** and a **Provenance Panel** (including â€œexport attributions + provenanceâ€). UI experiments should log:
- layer toggles / filters / time slider changes
- provenance panel opens + export events
- FPS + tile load timing (esp. WebGL scenes)

These UI provenance features are explicitly described as a first-class UI affordance. 

---

## ğŸ§  Dev provenance (`dev_prov`) for experiment runs

This is an **experiment report template** inside `mcp/dev_prov/â€¦`, so we treat development actions as provenance too:

- PR/CI events can be represented as structured provenance (JSON-LD) and integrated into the graph.
- Capturing â€œwho reviewed what, which checks ran, which artifacts were producedâ€ makes experiments defensible.

KFMâ€™s proposals explicitly describe **GitHub PR â†’ PROV Graph Integration**, ingesting PR events as structured provenance so changes and reviews become traceable graph facts.  [oai_citation:9â€¡Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf](file-service://file-G71zNoWKxsoSW44iwZaaCC)

**Suggested files:**
- `dev_prov/events.ndjson` (CI + PR + review events)
- `dev_prov/prov_bundle.jsonld` (optional PROV view)
- `dev_prov/checks/` (test reports, lint outputs)

---

## ğŸ” Redaction + governance checklist (before committing logs)

- [ ] No secrets (keys/tokens) â€” policy should catch common patterns, but donâ€™t rely on it alone.  [oai_citation:10â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
- [ ] No unapproved PII / sensitive content (or itâ€™s properly classified + stored privately)  [oai_citation:11â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
- [ ] Every log file includes `experiment_id` and `run_id`
- [ ] `run_manifest.json` exists and links to inputs/outputs
- [ ] `checksums.sha256` updated
- [ ] Provenance bundle exists for any derived dataset/model that matters (PROV is not optional in an evidence-first system)  [oai_citation:12â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

> [!NOTE]
> For large artifacts/logs, prefer â€œpointer + receipt + checksumâ€ patterns (donâ€™t bloat the repo). The KFM intake guide explicitly supports pointer/receipt approaches for large external files.  [oai_citation:13â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)

---

## ğŸ§° Practical tips (debugging & parsing)

### Quick CLI patterns
```bash
# Find errors quickly
rg '"level":"error"' results/logs/runs/**/telemetry.ndjson

# Inspect last 50 events
tail -n 50 results/logs/runs/**/telemetry.ndjson | jq

# Compare two runs (manifest first)
diff -u runs/<runA>/run_manifest.json runs/<runB>/run_manifest.json
```

### Python pipeline logging
Structured logging is encouraged â€” even â€œdebug statements / loggingâ€ are called out as a practical necessity in geospatial automation workflows.  [oai_citation:14â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)

---

## ğŸ” How logs connect back to the experiment report

Your report should be able to answer:
- What question did we test?
- What changed between runs?
- What data/code/config produced these outputs?
- Can someone reproduce it?

The MCP/Scientific Method guidance explicitly requires a **data logging process**, traceability via IDs/timestamps, and linking results back to the exact procedure and inputs.  [oai_citation:15â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)

If you maintain an experiment-level traceability matrix (highly recommended), you can link:
`Experiment ID â†’ hypothesis/feature â†’ code version â†’ data version â†’ result reference`.  [oai_citation:16â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)

---

## ğŸŒŒ â€œUse all project filesâ€ â€” how these logs support KFMâ€™s broader scope

KFM experiments arenâ€™t only ETL. This logs template supports work across:
- ğŸ—ºï¸ Geospatial pipelines + WebGL map UIs
- ğŸ¤– AI & Focus Mode experiments (drift/evals)
- ğŸ§± Governance + policy gates
- ğŸ§¬ â€œScientific methodâ€ style investigations with reproducible receipts
- ğŸ•°ï¸ 4D digital twins + AR overlays (prototype experiments need performance + provenance logs)

KFMâ€™s future concepts include â€œ4D digital twins,â€ â€œinteractive 3D Kansas,â€ and AR overlays â€” all of which benefit from robust logging of performance + provenance and simulation inputs/outputs.  [oai_citation:17â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)

---

## ğŸ“š Project source pack (documents informing this template)

These are the KFM docs/resources this README is aligned to:

- **KFM data contracts & audit emphasis**: â€œdonâ€™t trust the dataâ€¦ data contractâ€¦ logging for auditâ€  [oai_citation:18â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
- **Data intake telemetry + NDJSON pattern**  [oai_citation:19â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
- **Observability / correlation IDs / Focus telemetry** 
- **Policy-as-code governance gates (OPA/Conftest)**  [oai_citation:20â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
- **Run manifest + canonical digest hashing**  [oai_citation:21â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
- **UI provenance panel + export attributions** 
- **AI drift monitoring + prompt security** 
- **Dev provenance / PRâ†’PROV integration**  [oai_citation:22â€¡Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf](file-service://file-G71zNoWKxsoSW44iwZaaCC)
- **Scientific Method + experiment log rigor**  [oai_citation:23â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)
- **Privacy + auditing considerations**  [oai_citation:24â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
- **Geospatial workflow logging reminders**  [oai_citation:25â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)

### ğŸ“¦ Resource bundles (PDF portfolios)
Some provided resources are packaged as PDF portfolios (open in Acrobat for the embedded docs):
- AI Concepts & more (portfolio)  [oai_citation:26â€¡Various programming langurages & resources 1.pdf](file-service://file-4wp3wSSZs7gk5qHWaJVudi)
- Maps / Google Maps / Virtual Worlds / WebGL (portfolio)  [oai_citation:27â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)
- Various programming languages & resources (portfolio)  [oai_citation:28â€¡Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf](file-service://file-G71zNoWKxsoSW44iwZaaCC)
- Data management / data science / Bayesian methods (portfolio) 

---

## ğŸ“ Direct file links (workspace)
(Convenience links to the project PDFs referenced across this template.)
-  [oai_citation:29â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt)  
-  [oai_citation:30â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)  
-  [oai_citation:31â€¡Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf](file-service://file-G71zNoWKxsoSW44iwZaaCC)  
-  [oai_citation:32â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)  

---
