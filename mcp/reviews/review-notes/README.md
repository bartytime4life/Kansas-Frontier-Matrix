# ğŸ§¾ MCP Review Notes (KFM / Kansas-Matrix-System)

![MCP](https://img.shields.io/badge/MCP-Review%20Notes-0A66C2?logo=github)
![Evidence](https://img.shields.io/badge/Evidence--First-Required-brightgreen)
![FAIR+CARE](https://img.shields.io/badge/FAIR%20%2B%20CARE-Enforced-orange)
![Policy](https://img.shields.io/badge/Policy--as--Code-OPA%20%2B%20Conftest-purple)
![PROV](https://img.shields.io/badge/Provenance-W3C%20PROV-blue)
![Graph](https://img.shields.io/badge/Knowledge%20Graph-Neo4j-4581C3?logo=neo4j&logoColor=white)

> **What lives here:** human-readable, evidence-backed review records for major changes (data, AI, UI, architecture, governance).  
> **Why:** KFM is *provenance-first* and *contract-first* â€” review notes make decisions auditable, searchable, and reproducible.

---

## ğŸ§  What â€œMCPâ€ means here

In this repo, **MCP** is the umbrella for **Methods, Controls & Processes** (a.k.a. â€œMaster Coder Protocolâ€ discipline):  
- ğŸ§ª scientific-method style rigor (hypothesis â†’ method â†’ validation â†’ replication)  
- ğŸ§° engineering rigor (tests, CI, code review, policy gates)  
- ğŸ§¾ governance rigor (FAIR+CARE, licensing, sensitivity, provenance)

This folder is the **review** layer that complements automated checks (CI + policy gates). âœ…ğŸ¤

---

## ğŸ—‚ï¸ Folder layout

```text
mcp/
  reviews/
    review-notes/
      README.md                     ğŸ‘ˆ you are here
      templates/
        review-note.template.md     ğŸ§© (recommended)
      index/
        INDEX.md                    ğŸ§­ (recommended: running table of review notes)
      2026/
        2026-01-20__example__RN-0001.md
      assets/
        RN-0001/                    ğŸ“¦ optional supporting screenshots/exports (keep small)
```

> [!TIP]
> If artifacts are â€œbigâ€ (tiles, rasters, parquet), store them via the projectâ€™s artifact strategy (e.g., OCI registry / signed artifacts) and **only reference immutable IDs/digests here**.

---

## ğŸ¯ When to write a review note

Create a review note when a change is any of the following:

- ğŸ§± **Architecture / schema** changes (graph model, API contracts, metadata schema, STAC/DCAT/PROV profiles)
- ğŸ§º **New dataset intake** or substantial dataset refresh (new source, new license, new sensitivity class, new pipeline)
- ğŸ¤– **AI / Focus Mode** updates (models, retrieval strategy, policy pack changes, evaluation changes)
- ğŸ—ºï¸ **UI map system** changes (layer state format, story node rendering, timeline behaviors, accessibility)
- ğŸ” **Security / governance** changes (policy gates, secrets, permissions, sensitivity rules)
- ğŸ§ª **Experimental features** moving from sandbox â†’ promoted (Detect â†’ Validate â†’ Promote)
- ğŸŒ **Federation / integration** changes (external APIs, cross-region queries, new storage backends)
- ğŸ§­ **Narrative systems** changes (Story Nodes, Pulse Threads, evidence manifests, citation behavior)

If youâ€™re unsureâ€¦ write one anyway. ğŸ“âœ¨

---

## ğŸ§© Review note types

| Type | Use whenâ€¦ | Must includeâ€¦ |
|---|---|---|
| ğŸ§º **Data Intake Review** | new dataset or refresh | license + sensitivity + STAC/DCAT/PROV + checksums + validation results |
| ğŸ§± **Architecture Review** | schemas/contracts/major components | compatibility plan + migration plan + observability + rollback |
| ğŸ¤– **AI / Focus Mode Review** | model/retrieval/prompt/policies | eval results + citation rules + safety checks + drift plan |
| ğŸ—ºï¸ **UI/UX Review** | map UX, layer state, story UI | accessibility + performance budgets + interaction specs |
| ğŸ•¸ï¸ **Knowledge Graph Review** | ontology/Neo4j changes | constraint/index impacts + integrity checks + lineage patterns |
| ğŸ” **Governance/Security Review** | policy gates, permissions | threat model notes + policy diffs + sensitive data handling |
| ğŸš€ **Release / Promotion Review** | promoting sandbox â†’ main | gate results + run manifest + rollback plan + sign-off |

---

## âœ… Minimum requirements (Definition of Done)

A review note is â€œdoneâ€ when it has:

- **Clear scope** (what is being reviewed; what is not)
- **Evidence references** (datasets, STAC/DCAT records, PROV activities, commits/PRs, artifacts by digest)
- **Gate results** (what CI/policy gates were run and what passed/failed)
- **Decision** (approved / approved with changes / rejected / deferred)
- **Action items** (owner + due date + tracking links)
- **Sign-off** (who reviewed)

> [!IMPORTANT]
> KFMâ€™s ethos: **no mystery layers**. If a review note asserts a claim, it must point to verifiable evidence (data + metadata + provenance). ğŸ§¾ğŸ”

---

## ğŸ·ï¸ Naming conventions

Use one of these (choose one and stay consistent):

### Option A â€” Friendly + sortable (recommended)
`YYYY-MM-DD__topic-slug__RN-####.md`

Example:
- `2026-01-20__pmtiles-oci-distribution__RN-0007.md`

### Option B â€” Strict ID first
`RN-####__YYYY-MM-DD__topic-slug.md`

---

## ğŸ§¾ Review Note Template (copy/paste)

```md
---
id: RN-0000
date: 2026-01-20
type: data-intake | ai | ui | architecture | governance | graph | release
status: draft | in-review | approved | approved-with-changes | rejected | deferred
owners:
  - "@owner1"
reviewers:
  - "@reviewer1"
related:
  prs: []
  issues: []
  datasets: []          # dataset IDs / slugs
  stac: []              # STAC collection/item refs
  dcat: []              # DCAT dataset/distribution refs
  prov: []              # PROV activity/entity refs
artifacts:
  - kind: oci
    ref: "ghcr.io/org/repo:tag"
    digest: "sha256:..."
    contents:
      - "application/vnd.pmtiles"
      - "application/vnd.geo+parquet"
risk:
  severity: low | medium | high
  notes: ""
---

# RN-0000 â€” <Title>

## ğŸ¯ Scope
- **In scope:** â€¦
- **Out of scope:** â€¦

## ğŸ§© Background / Context
- Why now?
- What problem are we solving?
- What user / system impact?

## ğŸ”„ What changed
- Summary of changes
- Links to PR(s) / commits / design docs

## ğŸ§¾ Evidence & Provenance Snapshot
- **Data contracts:** (link)
- **Checksums / digests:** (link)
- **STAC/DCAT:** (link)
- **PROV:** (link)
- **Repro instructions:** (how to re-run)

## âœ… Automated Gates (CI / Policy-as-Code)
- [ ] Unit/integration tests
- [ ] Schema validation (metadata + data)
- [ ] STAC/DCAT/PROV completeness
- [ ] License present + compatible
- [ ] Sensitivity classification + rules
- [ ] Citation / evidence rules (AI + narratives)
- [ ] Security checks (secrets, dependencies, SBOM if applicable)

> Paste failing gate output snippets here (short) and link to full logs/artifacts.

## ğŸ” Human Review Checklist (pick what applies)
### ğŸ§º Data
- [ ] Source is trustworthy + documented
- [ ] Transform steps are deterministic / idempotent
- [ ] QA metrics reviewed (ranges, CRS, nulls, duplicates, drift)
- [ ] FAIR+CARE considerations recorded

### ğŸ¤– AI / Focus Mode
- [ ] Answers require citations + provide them
- [ ] Prompt / tool injection considerations reviewed
- [ ] Evaluation covers key query families
- [ ] Drift/monitoring plan noted

### ğŸ—ºï¸ UI
- [ ] Map layer state behavior verified
- [ ] Performance budget met (tiles, rendering, interactions)
- [ ] Accessibility checks (keyboard, contrast, screen reader)
- [ ] Mobile/responsive considerations

### ğŸ•¸ï¸ Knowledge Graph
- [ ] Constraints/indexes still valid
- [ ] No orphaned nodes/edges introduced
- [ ] Lineage links present + queryable
- [ ] Health check results attached

## ğŸ§  Findings
- What went well
- What failed / concerns
- Unknowns / follow-ups

## âœ… Decision
**Decision:** Approved / Approved with changes / Rejected / Deferred  
**Rationale:** â€¦

## ğŸ§· Action Items
- [ ] (Owner) Task â€” due YYYY-MM-DD â€” link

## ğŸ”™ Rollback Plan
- What to revert
- What artifacts to pin by digest
- How to confirm rollback success

## âœï¸ Sign-off
- Reviewer(s): â€¦
- Date: â€¦
```

---

## ğŸ§· Evidence rules (KFM-standard)

### 1) Everything should be **reproducible**
Whenever possible, record:
- the **run manifest** / run ID
- pinned inputs (URLs + checksums or digests)
- environment details (tool versions, containers)
- parameters + random seeds (if applicable)

### 2) Prefer **immutable references**
- âœ… `sha256:...` digests for stored artifacts  
- âœ… stable dataset IDs for catalogs/graph  
- âœ… commit SHAs / PR links for code changes

### 3) Narratives must be evidence-backed (Story Nodes / Pulse Threads)
If the reviewed change touches narratives:
- include a **human-readable citations block**
- include a **machine-readable evidence manifest** (YAML/JSON)
- include (or reference) a **PROV JSON-LD** snippet that ties the narrative to its evidence and authorship

> [!NOTE]
> Treat narrative authoring like writing a research paper: citations arenâ€™t decoration â€” theyâ€™re part of the product. ğŸ“šğŸ§¾

---

## ğŸ”„ Lifecycle (how review notes flow)

```mermaid
flowchart TD
  A[Change Proposed] --> B[Create Review Note]
  B --> C[Run CI + Policy Gates]
  C -->|Pass| D[Human Review]
  C -->|Fail| E[Fix + Re-run Gates]
  E --> C
  D -->|Approved| F[Merge / Promote]
  D -->|Approved w/ Changes| E
  D -->|Rejected| G[Close / Archive Note]
  F --> H[Index + Link Evidence]
  H --> I[Optional: Post-merge QA / Health Checks]
```

---

## ğŸ§° How this connects to CI + Policy Gates

KFMâ€™s automation style is **Detect â†’ Validate â†’ Promote**:
- Detect changes (data/code/config)
- Validate via tests + schema checks + policy-as-code (OPA + Conftest)
- Promote only when gates pass and humans sign off

Review notes are the **human complement** to those gates:
- record why a decision was made
- document exceptions and mitigations
- keep governance transparent and repeatable

---

## ğŸ•µï¸ Common pitfalls (avoid these ğŸš«)

- ğŸš« â€œLooks goodâ€ with no evidence links  
- ğŸš« Accepting a dataset without license/sensitivity classification  
- ğŸš« UI/AI changes without explaining how provenance/citations are preserved  
- ğŸš« Big artifacts committed without a clear artifact strategy + immutable refs  
- ğŸš« Changes that break reproducibility (unpinned inputs, undocumented steps)

---

## ğŸ” Sensitive content reminders

If a review touches sensitive data:
- confirm coordinate generalization / access control behavior
- confirm policy gates enforce restrictions
- document who is allowed to view/ship the data and why

> [!IMPORTANT]
> If thereâ€™s any chance a dataset reveals sensitive locations or personal data, treat it as **high-risk** until proven otherwise. ğŸ›¡ï¸

---

## ğŸ“š Project doc map (what to consult per review)

Use these docs to ground the review note (and to make sure weâ€™re consistent across the system):

- ğŸ§± **Architecture & features**: core platform structure, roadmap, governance, future directions  
- ğŸ§­ **AI System Overview**: Focus Mode, policy pack, W-P-E agents, provenance in DevOps, safety  
- ğŸ—ºï¸ **UI System Overview**: map interaction patterns, layer state conventions, story-driven UX  
- ğŸ§º **Data Intake Guide**: ingestion gates, PROV-first requirements, reproducibility, promotion workflow  
- ğŸ§  **Innovative Concepts / Future Proposals**: forward-looking features (AR, offline packs, federation, etc.)  
- ğŸ§¾ **Technical Documentation**: governance SOPs, sensitivity handling, interoperability, scalability  
- ğŸ§ª **Scientific Method + Master Coder Protocol**: peer review expectations, reproducibility discipline  
- ğŸ§° **Supplemental libraries** (AI concepts, geospatial/webgl, programming resources, data management, data mining): deeper background for specialized reviews

> [!TIP]
> If your review note is drifting into â€œwe need to decide X,â€ consider also adding/using an ADR system â€” but keep this folder focused on **review outcomes**.

---

## ğŸ“– Glossary (quick)

- **STAC**: SpatioTemporal Asset Catalog (data catalog patterns for geospatial assets) ğŸ—ºï¸  
- **DCAT**: Data Catalog Vocabulary (metadata standard) ğŸ§¾  
- **PROV**: W3C provenance model (entities, activities, agents) ğŸ§¬  
- **FAIR+CARE**: findable/accessible/interoperable/reusable + collective benefit/authority/responsibility/ethics ğŸ¤  
- **Focus Mode**: KFMâ€™s AI assistant view, expected to be citation-backed ğŸ¤–  
- **W-P-E**: Watcher â†’ Planner â†’ Executor agent workflow (PR-first automation) ğŸ‘€ğŸ§ ğŸ› ï¸  
- **Policy-as-Code**: enforce governance rules via OPA/Conftest (gates fail closed) ğŸš¦  
- **OCI/ORAS/Cosign**: artifact distribution + signing for integrity and reproducibility ğŸ“¦ğŸ”  

---

## âœ… Final note

> [!IMPORTANT]
> **Review notes are not bureaucracy â€” they are the userâ€™s trust surface.**  
> Theyâ€™re how we prove KFM is *auditable*, *reproducible*, and *community-safe* over time. ğŸŒ¾ğŸ§ ğŸ—ºï¸
