# ğŸ§  Model Cards (MCP)

![MCP](https://img.shields.io/badge/MCP-Model%20Cards-blue)
![Reproducible](https://img.shields.io/badge/Reproducibility-First-success)
![Governance](https://img.shields.io/badge/Governance-Required-orange)
![Provenance](https://img.shields.io/badge/Provenance-Never%20Optional-purple)

Welcome to `mcp/model_cards/` ğŸ“ â€” the **single source of truth** for every AI/ML model used anywhere in this repo (pipelines, experiments, Focus Mode, embeddings, NER, OCR helpers, rerankers, etc.).

A **model card** is a short, standardized, version-controlled document that explains:

- âœ… **What** the model is (family/version/weights/runtime)
- âœ… **How** we run it (Ollama/local runtime, configs, parameters)
- âœ… **Where** it came from (license, provenance, training/fine-tuning notes)
- âœ… **What itâ€™s allowed to do** in KFM/Kansas-Matrix-System (tools, access boundaries)
- âœ… **How well it performs** (evaluation + known failure modes)
- âœ… **How to interpret outputs safely** (limits, risks, redaction expectations)

---

## ğŸ¯ Nonâ€‘Negotiables

> [!IMPORTANT]
> If a model is used by **code** or influences **user-facing output**, it **must** have a model card.

**Minimum bar (required):**
- **Intended Use** + **Out-of-Scope Use**
- **Model Details** (identity + runtime + version/variant)
- **Data / Provenance** (whatâ€™s known + whatâ€™s unknown)
- **Evaluation** (even if â€œinformal baselineâ€ at first)
- **Limitations & Risks** (hallucination modes, bias, edge cases)
- **KFM Integration Contract** (tools/APIs, redaction, citation behavior)

---

## ğŸ—‚ï¸ Recommended Folder Layout

You can keep it flat or grouped. Grouped is preferred as the library grows:

```text
ğŸ“ mcp/
â””â”€ ğŸ“ model_cards/                           ğŸ§¾ model documentation (capabilities, evals, safety, provenance)
   â”œâ”€ ğŸ“„ README.md                            ğŸ“˜ how model cards are organized + required fields
   â”œâ”€ ğŸ“ templates/                           ğŸ§© â€œcopy-meâ€ templates for consistency
   â”‚  â”œâ”€ ğŸ“„ MODEL_CARD_TEMPLATE.md             ğŸªª standard model card template
   â”‚  â””â”€ ğŸ“„ EVAL_REPORT_TEMPLATE.md            ğŸ“Š evaluation report template
   â”œâ”€ ğŸ“ llm/                                 ğŸ¤– large language models (chat, agents, Focus Mode)
   â”‚  â”œâ”€ ğŸ“„ focus_mode__<model_id>.md          ğŸ§  Focus Mode deployment card (policy + citations + tools)
   â”‚  â””â”€ ğŸ“„ agents__<model_id>.md              ğŸ§© agent runtime card (roles, permissions, guardrails)
   â”œâ”€ ğŸ“ embeddings/                          ğŸ§² embedding models (vectorization + retrieval)
   â”‚  â””â”€ ğŸ“„ <model_id>.md                      ğŸ“˜ embedding model card (dims, distance, evals)
   â”œâ”€ ğŸ“ nlp/                                 ğŸ§  classic NLP models (task-specific)
   â”‚  â”œâ”€ ğŸ“„ ner__<model_id>.md                 ğŸ“ NER model card (labels, coverage, evals)
   â”‚  â””â”€ ğŸ“„ ocr_post__<model_id>.md            ğŸ§¾ OCR post-processing card (rules, evals, failure modes)
   â””â”€ ğŸ“ vision/                              ğŸ‘ï¸ vision models (detection, segmentation, VQA)
      â””â”€ ğŸ“„ <model_id>.md                      ğŸ“˜ vision model card (inputs, limits, evals, safety)
```

**Naming convention (recommended):**
- `category__purpose__model_id.md` (best for searching)
- Use `__` to keep filenames grep-friendly
- Keep `model_id` stable across upgrades; track upgrades in **Changelog**

Examples:
- `llm/focus_mode__gpt-oss__q4_k_m.md`
- `embeddings/nomic-embed-text-v1.5.md`
- `nlp/ner__spacy_en_core_web_trf.md`

---

## ğŸ§¾ Model Card Format

We use **Markdown** with optional **YAML front-matter** (recommended) for machine parsing.

### âœ… YAML Front-Matter (Recommended)

```yaml
---
id: llm.focus_mode.gpt-oss.q4_k_m
display_name: "GPT-OSS (Focus Mode)"
category: llm
purpose: focus_mode
runtime: ollama
source: "ollama://gpt-oss:latest"   # or huggingface/model@sha, local path, etc.
weights_version: "unknown-or-link"
quantization: "Q4_K_M"
context_window: 8192
license: "UNKNOWN (must fill)"
owners:
  - "@maintainer_handle"
last_reviewed: "YYYY-MM-DD"
risk_tier: "LOW | MEDIUM | HIGH"
---
```

> [!TIP]
> If you donâ€™t know something (license details, training data specifics), **say so explicitly** and add a TODO. Unknown is better than guessed.

---

## ğŸ§© Required Sections

Copy/paste this outline into each model card:

1. **Summary**
2. **Intended Use**
3. **Out-of-Scope / Prohibited Use**
4. **Model Details**
   - family / variant / version
   - runtime (Ollama/local/etc.)
   - parameters (temperature defaults, max tokens, system prompt policy)
5. **Training / Fine-Tuning Data**
   - whatâ€™s known (and what isnâ€™t)
   - data licensing notes
6. **Evaluation**
   - datasets/tasks
   - metrics (or qualitative rubric)
   - â€œknown goodâ€ and â€œknown badâ€ examples
7. **Limitations**
   - common error patterns
   - domain weaknesses (dates, OCR noise, historical spelling, etc.)
8. **Risks & Mitigations**
   - hallucination controls
   - privacy/redaction expectations
   - bias / representational harms
9. **KFM / Kansas-Matrix Integration Contract**
   - allowed tools/APIs
   - citation requirements
   - â€œfail-closedâ€ behavior expectations
   - logging / audit hooks (PROV + experiment logs)
10. **Reproducibility**
   - exact run commands
   - pinned versions / hashes
   - hardware notes (VRAM/RAM, CPU expectations)
11. **Changelog**
12. **References**
   - papers/docs
   - internal experiment reports (link into `mcp/experiments/`)

---

## ğŸ”Œ KFM Integration Contract (What Every Card Must Declare)

Every model card must explicitly answer:

### 1) What data can this model see?
- âœ… Only **approved** tool outputs and governed API responses
- âœ… No direct reads of restricted files or raw secrets
- âœ… State whether prompts include **retrieved context** (RAG) and from where

### 2) What tools can it call (if any)?
If the model is used agentically (tool calling), list:
- tool name
- inputs/outputs schema
- rate limits / cost notes
- safety boundaries (redaction, allowlist queries)

### 3) What must the UI/user see?
For user-facing models:
- citation expectations
- how uncertainty is communicated
- what â€œrefusalâ€ looks like

> [!NOTE]
> If the model canâ€™t reliably cite or is prone to confident errors, the card must document the mitigation (stronger retrieval, stricter prompting, output validators, policy checks, etc.).

---

## ğŸ§ª Evaluation: Minimum Viable Standard

At minimum, include:
- A **small benchmark set** (even 20â€“50 prompts)
- A **scoring rubric** (Correct / Partially Correct / Incorrect / Unsupported)
- A **failure log** (what broke and why)
- A link to the corresponding experiment record:
  - `mcp/experiments/<date>__<experiment_name>/README.md`

**For Focus Mode models**, also test:
- citation fidelity (does it cite the right artifact?)
- tool calling correctness (no invented tool outputs)
- refusal behavior (sensitive data, policy-prohibited asks)
- geospatial reasoning sanity checks (coords, distances, projections)

---

## âœ… Add / Update Workflow

### Adding a new model
1. Create a model card in the right category folder
2. Add or link:
   - eval report (or baseline rubric + examples)
   - experiment log under `mcp/experiments/`
3. Update configuration that selects the model (wherever it lives)
4. If the model is agentic:
   - update tool allowlists / policies
   - ensure logging + provenance hooks exist

### Updating an existing model
Update the card when you change **anything** that affects behavior:
- weights/version/quantization
- prompts/system policies
- tool schema
- retrieval strategy
- redaction rules
- evaluation results

Add a changelog entry with:
- what changed
- why
- expected impact
- links to experiment/eval artifacts

---

## ğŸ§° Templates

You should maintain these in `mcp/model_cards/templates/`:

- `MODEL_CARD_TEMPLATE.md`
- `EVAL_REPORT_TEMPLATE.md`

Quick starter (drop-in):

<details>
<summary><strong>ğŸ“„ Minimal Model Card Skeleton</strong> (click to expand)</summary>

```markdown
---
id: <fill>
display_name: "<fill>"
category: <llm|embeddings|nlp|vision|other>
runtime: <ollama|python|other>
license: "<fill>"
owners: ["@<fill>"]
last_reviewed: "YYYY-MM-DD"
risk_tier: "LOW|MEDIUM|HIGH"
---

# Summary
# Intended Use
# Out-of-Scope Use
# Model Details
# Training / Data Notes
# Evaluation
# Limitations
# Risks & Mitigations
# KFM Integration Contract
# Reproducibility
# Changelog
# References
```
</details>

---

## ğŸ” Quick Index Tips

- Keep `id:` stable and grep-friendly
- Prefer **one model = one card**
- Link cards from:
  - `mcp/README.md` (high-level)
  - relevant SOPs (e.g., model update process)
  - experiment folders

---

## ğŸ“ Where This Fits in the Bigger System

Model cards connect the dots between:
- ğŸ§ª **experiments** (`mcp/experiments/`)
- ğŸ§­ **SOPs** (`mcp/sops/`)
- ğŸ§¾ **governance + policies** (policy-as-code, redaction rules)
- ğŸ§¬ **provenance** (PROV logs + dataset lineage)
- ğŸ—ºï¸ **Focus Mode behavior** (tool boundaries + citations)

If itâ€™s not documented here, itâ€™s not â€œrealâ€ yet ğŸš«âœ¨
