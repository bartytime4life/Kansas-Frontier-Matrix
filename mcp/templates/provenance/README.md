# ğŸ§¾ Provenance Template Pack (MCP)

![Provenance-First](https://img.shields.io/badge/provenance-first-2ea44f)
![STAC](https://img.shields.io/badge/STAC-cataloged-6f42c1)
![DCAT](https://img.shields.io/badge/DCAT-cataloged-f39c12)
![W3C PROV](https://img.shields.io/badge/W3C-PROV--O-1f77b4)
![FAIR+CARE](https://img.shields.io/badge/FAIR%2BCARE-governed-0b7285)
![Policy%20as%20Code](https://img.shields.io/badge/OPA%2FRego-policy%20gates-555)

**Path:** `mcp/templates/provenance/`

> [!IMPORTANT]
> **No mystery layers. No unsourced outputs.**  
> If something is visible in the UI, queryable via the API, or exportable as an artifact (dataset, layer, Story Node, Pulse Thread, Focus Mode answer), it must have **machineâ€‘readable provenance**.

---

## ğŸ“Œ What this folder is

This folder defines **canonical provenance templates** used across the Kansas Matrix / Kansas Frontier Matrix ecosystem to ensure:

- âœ… **Reproducibility** (same inputs + same config â‡’ same outputs)
- ğŸ” **Traceability** (every claim/layer/output can be walked back to evidence)
- ğŸ§­ **Governance** (FAIR + CARE compliance via policy gates)
- ğŸ§‘â€âš–ï¸ **Human-in-the-loop** review for anything that impacts public understanding or sensitive domains
- ğŸ—ºï¸ **User-visible provenance** (the UI can explain â€œwhat am I looking at?â€ at any time)

These templates turn provenance into a **first-class product artifact**, not an afterthought.

---

## ğŸ§  The core pattern: â€œEvidence Tripletâ€ (plus supply-chain extras)

KFMâ€™s baseline publishing contract is the **triplet**:

1. ğŸ›°ï¸ **STAC** â€“ spatial/temporal footprint + assets (tiles, rasters, vectors, docs)
2. ğŸ—‚ï¸ **DCAT** â€“ dataset publication metadata (title, license, publisher, access)
3. ğŸ”— **PROV** â€“ lineage graph (inputs â†’ activities â†’ outputs, with agents)

Optional but strongly recommended for large binaries & distribution:

4. ğŸ“¦ **OCI distribution** â€“ store artifacts (PMTiles, GeoParquet, COGs) in an OCI registry
5. ğŸ” **Signatures / attestations** â€“ Cosign signatures, SBOMs, and provenance attachments

---

## ğŸ§± Where rendered outputs should land

> [!NOTE]
> Exact folder names may differ slightly per repo, but the *boundary artifacts* land in canonical locations.

```text
ğŸ“¦ data/
â”œâ”€ ğŸ§¾ raw/                # immutable â€œas receivedâ€ evidence
â”œâ”€ ğŸ› ï¸ work/               # intermediate transforms (reproducible, throwaway)
â”œâ”€ âœ… processed/           # publishable outputs (COGs, PMTiles, GeoParquet, etc.)
â”œâ”€ ğŸ›°ï¸ stac/               # STAC Items/Collections (asset + spatial/temporal)
â”œâ”€ ğŸ—‚ï¸ catalog/
â”‚  â””â”€ dcat/               # DCAT dataset records (license/publisher/access)
â”œâ”€ ğŸ”— prov/               # PROV JSON-LD bundles (lineage)
â””â”€ ğŸ§ª audits/             # run manifests, logs, idempotency keys, digests
```

---

## ğŸ§¬ Provenance primitives (how to think)

| Primitive | Meaning | Examples |
|---|---|---|
| **Entity** ğŸ“„ | A thing (input/output) | raw download, processed PMTiles, GeoParquet, OCR corpus, generated report |
| **Activity** âš™ï¸ | A transformation/event | ETL run, reprojection, georeference, join, model inference, PR merge |
| **Agent** ğŸ§‘â€ğŸ’»ğŸ¤– | Who/what acted | maintainer, CI runner, automation bot, model runtime |

> [!TIP]
> If you canâ€™t name the **Entity**, **Activity**, and **Agent**, you donâ€™t have enough provenance yet.

---

## ğŸ§© Template catalog (recommended)

This README is the contract; the templates are the implementation. A typical pack looks like:

```text
mcp/templates/provenance/
â”œâ”€ ğŸ“„ README.md                           # ğŸ“˜ How to use provenance templates + required inputs/outputs + validation steps
â”œâ”€ ğŸ§¬ prov/                               # ğŸ§¬ PROV template files (Jinja) for generating JSON-LD provenance bundles
â”‚  â”œâ”€ ğŸ§¬ğŸ§¾ dataset.prov.jsonld.jinja       # Dataset lineage template (sources â†’ transforms â†’ published artifacts)
â”‚  â”œâ”€ ğŸ§¬ğŸ§¾ pipeline_run.prov.jsonld.jinja  # Pipeline run template (activities/agents/entities + params + timestamps)
â”‚  â”œâ”€ ğŸ§¬ğŸ§¾ focus_answer.prov.jsonld.jinja  # Focus Mode answer provenance (retrieval â†’ reasoning steps â†’ cited outputs)
â”‚  â””â”€ ğŸ§¬ğŸ§¾ github_pr.prov.jsonld.jinja     # PRâ†’PROV template (commits/reviews â†’ artifacts/receipts/approvals)
â”œâ”€ ğŸ§¾ manifests/                          # ğŸ§¾ Non-PROV manifest templates (receipts + evidence indices)
â”‚  â”œâ”€ ğŸ§¾ğŸ” run_manifest.json.jinja         # Run manifest template (commands, env, inputs/outputs, digests, tool versions)
â”‚  â””â”€ ğŸ“ğŸ§¾ story_evidence.yml.jinja        # Story evidence manifest template (claimsâ†’citationsâ†’artifacts + checksums)
â”œâ”€ ğŸ§  contexts/                           # ğŸ§  JSON-LD contexts used by the generated PROV bundles
â”‚  â””â”€ ğŸ§ ğŸ§¬ kfm.context.jsonld              # KFM @context (namespaces, term mappings, prefixes; used by templates)
â””â”€ âœ… policy/                             # âœ… Policy pack enforcing template outputs (schema/profile invariants)
   â”œâ”€ âš–ï¸ğŸ“„ provenance.rego                 # OPA/Rego rules for provenance artifacts (required links, ids, ordering, etc.)
   â””â”€ âš™ï¸ğŸ“„ conftest.toml                   # Conftest configuration for running provenance.rego against generated outputs
```

> [!NOTE]
> Use whatever renderer your repo standardizes on (Jinja/Cookiecutter/etc.). The important part is that the output conforms to the profiles + gates.

---

## ğŸ› ï¸ How to use these templates

### 1) Add or update a dataset (batch / â€œstaticâ€)

âœ… **Goal:** produce publishable data **and** the evidence triplet.

**Workflow:**
1. ğŸ§¾ Put source bytes in `data/raw/<domain>/...` (**immutable**)
2. ğŸ› ï¸ Run ETL into `data/processed/<domain>/...`
3. ğŸ›°ï¸ Generate STAC (Collection + Item(s)) for assets
4. ğŸ—‚ï¸ Generate DCAT dataset record (license/publisher/access)
5. ğŸ”— Generate PROV bundle capturing:
   - input entities (raw bytes, upstream datasets)
   - activity (pipeline run; config; tool versions)
   - output entities (processed artifacts + digests)
6. ğŸ§ª Emit a **Run Manifest** (audit trail) and store it under `data/audits/<run_id>/...`
7. âœ… Pass policy gates (schema + OPA/Conftest) â†’ open PR â†’ review â†’ merge

---

### 2) Record a pipeline run (Run Manifest + PROV)

A pipeline run must be independently audit-able.

**Run Manifest should capture (minimum):**
- `run_id`, `run_time`
- `idempotency_key` (so reruns can be recognized)
- `canonical_digest` (hash of canonicalized manifest JSON)
- `source_urls` / `dataset_ids` used
- `tool_versions` (GDAL, Python, PostGIS, etc.)
- `summary_counts` and error summaries

> [!IMPORTANT]
> Treat the Run Manifest as â€œthe electronic lab notebook entryâ€ for the run. It should be usable for reproduction *even years later*.

---

### 3) Distribute large artifacts (OCI + ORAS + Cosign)

When artifacts are too large for Git, store them in an OCI registry:

- ğŸ“¦ Use **ORAS** to push arbitrary data files (PMTiles, GeoParquet, COGs) with custom media types.
- ğŸ” Use **Cosign** to sign the artifact manifest (keyless/OIDC is ideal for CI).
- ğŸ”— Attach provenance / SBOM as **OCI referrers** (linked to the digest).

#### Template snippet: `distribution.oci` (YAML-ish)

```yaml
distribution:
  oci:
    registry: ghcr.io
    repository: myorg/kfm/surficial_geology
    tag: "20260111"
    digest: "sha256:PUT_REAL_DIGEST_HERE"
    artifacts:
      - name: surficial_geology.pmtiles
        mediaType: application/vnd.pmtiles
      - name: surficial_geology.parquet
        mediaType: application/vnd.geo+parquet
    provenance_ref:
      type: oci-referrer
      selector: "sha256:PUT_REAL_DIGEST_HERE"
    verification:
      signatures:
        tool: cosign
        mode: keyless
        issuer: oidc
```

> [!TIP]
> Catalog records (STAC/DCAT) should reference OCI artifacts by **digest**, not only â€œlatestâ€ tags.

---

### 4) Author a Story Node / Pulse Thread (Evidence Manifest + lineage)

Narrative content is only trusted if itâ€™s **evidence-backed**.

**Required:**
- ğŸ§¾ `story_evidence.yml` listing sources (dataset IDs, URLs, snapshots)
- ğŸ”— (recommended) a PROV bundle connecting the Story/Pulse to the evidence entities and authoring activity

#### Example: evidence manifest (shape)

```yaml
story_id: kfm:story:example:001
title: "Example Narrative"
created_at: "2026-01-21T00:00:00Z"
claims:
  - id: claim-001
    text: "A specific claim that must be verifiable."
    evidence:
      - kind: dataset
        dataset_id: kfm:dataset:hydro:usgs_nwis:v1
        locator: "station_id=06891000&timestamp=2026-01-21T20:00:00Z"
      - kind: document
        source_url: "https://example.org/report.pdf"
        checksum: "sha256:..."
```

> [!WARNING]
> **CI should fail** if a citation in a Story/Pulse cannot be resolved to an evidence manifest entry.

---

### 5) Log Focus Mode / AI outputs (answer provenance)

Focus Mode answers must be **explainable** and **traceable**:

- Every answer should cite what it used (datasets, queries, docs).
- AI outputs and key decisions should be recorded in an **append-only governance ledger**.
- For dynamic queries (real-time), provenance must include the **timestamped reading** used as an input entity.

âœ… Template should capture (minimum):
- question + answer ID
- timestamp
- model/runtime ID and version
- source dataset IDs + citations
- query parameters (when applicable)
- policy gate outcomes (passed/blocked/warn)

---

### 6) Treat DevOps as provenance (GitHub PR â†’ PROV)

Provenance doesnâ€™t stop at data. PRs and releases are **Activities** too.

A PR-to-PROV template should represent:
- **Entities:** commit(s), files changed, generated artifacts
- **Activity:** â€œPR mergedâ€, â€œpipeline publishâ€
- **Agents:** author(s), reviewer(s), CI bot

This makes â€œhow did this dataset get here?â€ answerable directly from the graph.

---

## âœ… Validation & policy gates (fail-closed by default)

This system assumes **policy-as-code**:

- JSON Schema validation (STAC/DCAT/PROV + domain contracts)
- OPA/Rego rules via Conftest
- Secrets scanning & restricted fields
- Required license/provider fields
- Sensitivity classification and redaction rules
- Citation completeness (stories + AI)

> [!IMPORTANT]
> Gates must be **fail-closed**: missing metadata, missing provenance, or invalid schema blocks merges.

---

## ğŸ—ºï¸ UI + API expectations (why provenance is user-facing)

Provenance isnâ€™t just for maintainersâ€”KFMâ€™s UI is designed to surface it:

- ğŸ§¾ **Layer provenance panel**: active layers + sources + processing summary
- ğŸ§  **Focus Mode citations**: â€œevery insight has a footnoteâ€
- ğŸ“¤ **Exports carry credits**: attributions bundled into downloadable artifacts
- ğŸ”’ **Classification enforcement**: API filters or labels sensitive features

---

## ğŸ”¢ Versioning rules & identifiers

To keep lineage stable:

- Use stable dataset IDs and versioning (semver or date tags)
- Prefer **content digests** (sha256) for immutable identity of files
- Record tool versions and environment snapshots (requirements/containers)
- Never overwrite raw data; any change must be a new entity + activity

> [!TIP]
> If you canâ€™t reproduce the output from recorded inputs + config, the provenance is incomplete.

---

## ğŸ§ª Minimal PROV JSONâ€‘LD example (illustrative)

<details>
  <summary>Click to expand</summary>

```json
{
  "@context": [
    "https://www.w3.org/ns/prov.jsonld",
    "./contexts/kfm.context.jsonld"
  ],
  "id": "kfm:prov:bundle:run:2026-01-21T20:00:00Z",
  "type": "prov:Bundle",
  "entity": {
    "kfm:entity:raw:usgs_nwis_snapshot_2026-01-21.json": {
      "prov:label": "USGS NWIS snapshot",
      "kfm:checksum": "sha256:..."
    },
    "kfm:entity:processed:river_gauges.parquet": {
      "prov:label": "River gauges (normalized)",
      "kfm:checksum": "sha256:..."
    }
  },
  "activity": {
    "kfm:activity:pipeline:hydro_ingest:run:RUN_ID": {
      "prov:used": ["kfm:entity:raw:usgs_nwis_snapshot_2026-01-21.json"],
      "prov:generated": ["kfm:entity:processed:river_gauges.parquet"],
      "kfm:code_commit": "GIT_SHA",
      "kfm:tool_versions": {
        "python": "3.x",
        "gdal": "x.y",
        "postgis": "x.y"
      }
    }
  },
  "agent": {
    "kfm:agent:ci:github_actions": {
      "prov:type": "prov:SoftwareAgent",
      "prov:label": "GitHub Actions"
    }
  }
}
```

</details>

---

## âœ… Definition of Done (DoD) checklist

Use this when adding any dataset, derived artifact, story, or AI output:

- [ ] ğŸ§¾ Raw evidence stored immutably (or referenced immutably)
- [ ] ğŸ› ï¸ Processing is deterministic (config/code; no manual edits)
- [ ] ğŸ›°ï¸ STAC records exist and validate
- [ ] ğŸ—‚ï¸ DCAT record exists and validates (license + publisher present)
- [ ] ğŸ”— PROV lineage exists and validates (entities/activities/agents linked)
- [ ] ğŸ§ª Run Manifest emitted with canonical digest
- [ ] ğŸ“¦ (If OCI) distribution references include digest + media types
- [ ] ğŸ” (If OCI) artifact signatures/attestations are present
- [ ] ğŸ§  (If AI/story) citations resolve to evidence manifest entries
- [ ] âœ… All policy gates pass (fail-closed)

---

## ğŸ¤ Contributing

If you add a new provenance pattern:

1. Copy the closest existing template (donâ€™t invent one-off formats)
2. Extend profiles intentionally (avoid ad-hoc fields)
3. Add/adjust policy gates so the pattern stays enforceable
4. Add an example fixture for CI validation (recommended)

> [!NOTE]
> Provenance isnâ€™t bureaucracyâ€”itâ€™s the trust engine that keeps KFM credible.
