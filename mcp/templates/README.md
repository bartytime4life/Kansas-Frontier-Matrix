# ğŸ§ª MCP Templates

![MCP](https://img.shields.io/badge/MCP-Methods%20%26%20Computational%20Experiments-blue)
![Reproducible](https://img.shields.io/badge/Reproducible-Yes-success)
![Provenance--First](https://img.shields.io/badge/Provenance--First-Yes-success)
![FAIR%20%2B%20CARE](https://img.shields.io/badge/FAIR%20%2B%20CARE-By%20Design-informational)

> **Purpose:** This folder contains the standardized, copyâ€‘paste templates used by the projectâ€™s **MCP layer** (`mcp/`) to keep experiments **transparent**, **repeatable**, and **auditable**.  
> Think: *lab notebook meets engineering runbook* ğŸ§¾âš™ï¸

---

## ğŸ§­ Jump To

- [What belongs in `mcp/templates/`?](#-what-belongs-in-mcptemplates)
- [Quickstart](#-quickstart)
- [Template Catalog](#-template-catalog)
- [Conventions](#-conventions)
- [Evidence & Provenance Hooks](#-evidence--provenance-hooks)
- [Quality Gates](#-quality-gates)
- [Add / Update a Template](#-add--update-a-template)
- [FAQ](#-faq)

---

## ğŸ“¦ What belongs in `mcp/templates/`?

`mcp/templates/` is where we keep **reusable scaffolds** for MCP artifacts, including:

- ğŸ§ª **Experiment reports** (design â†’ execution â†’ results â†’ interpretation)
- ğŸƒ **Run logs** (a single execution record: params, inputs, outputs, environment)
- ğŸ§  **Model cards** (capabilities, limits, intended use, risks)
- ğŸ“„ **SOPs / runbooks** (repeatable operational procedures)
- âœ… **Checklists** (reproducibility, review, governance, release readiness)

If itâ€™s something you **copy**, fill out, and commit to preserve **how** and **why** work was done â€” itâ€™s a template âœ…

---

## ğŸš€ Quickstart

1. **Pick the right template** from this folder.
2. **Copy** it into its destination folder (examples below).
3. **Rename** it using the naming rules in [Conventions](#-conventions).
4. **Fill in every required field** (look for âœ… Required markers).
5. **Link everything**: data inputs, code commit, config files, artifacts, and any provenance/metadata entries.
6. **Commit** with a message that explains the â€œwhyâ€, not just the â€œwhatâ€.

> Tip: If youâ€™re doing this more than twice, you probably need a better template or a checklist update ğŸ› ï¸

---

## ğŸ—‚ï¸ Template Catalog

> File names below are the **recommended standard** for this repo.  
> If a template doesnâ€™t exist yet, create it here with the same naming pattern.

| Template | Use it whenâ€¦ | Typical destination after copy |
|---|---|---|
| `TEMPLATE__EXPERIMENT_REPORT.md` ğŸ§ª | Youâ€™re testing a method, model, extraction approach, or evaluation | `mcp/experiments/EXP-*/` |
| `TEMPLATE__RUN_LOG.md` ğŸƒ | You ran a pipeline/script/notebook and need an execution record | `mcp/runs/` (or under an experiment folder) |
| `TEMPLATE__MODEL_CARD.md` ğŸ§  | A model is trained/selected and might be reused, shipped, or cited | `mcp/model_cards/` |
| `TEMPLATE__DATASET_DATASHEET.md` ğŸ—ƒï¸ | You created/ingested a dataset (or derived artifact) worth reusing | `data/**/` + `docs/` reference |
| `TEMPLATE__SOP.md` ğŸ“„ | Thereâ€™s an operational procedure others must repeat exactly | `docs/runbooks/` or `mcp/sops/` |
| `TEMPLATE__REVIEW_CHECKLIST.md` âœ… | You want a consistent review gate before merge/release | `docs/checklists/` |

---

## ğŸ§± Conventions

### ğŸ·ï¸ Naming & IDs

Use consistent IDs so we can trace history quickly:

- **Experiments:** `EXP-YYYYMMDD-<short-slug>/`
  - Example: `EXP-20260129-ner-place-extraction/`
- **Experiment report file:** `REPORT__EXP-YYYYMMDD-<slug>.md`
- **Run logs:** `RUN-YYYYMMDD-HHMM__<short-slug>.md`
- **Model cards:** `MODEL_CARD__<model-name>__vX.Y.md`
- **SOPs:** `SOP__<domain>__<task>__vX.Y.md`

> The goal is *human scanning + machine parsing* ğŸ‘€ğŸ¤–

---

### ğŸ§¾ Recommended Front Matter (YAML)

Templates should start with YAML front matter to enable indexing and automation:

```yaml
---
id: EXP-YYYYMMDD-<slug>              # âœ… Required (or RUN-/MODEL_CARD-/SOP-)
title: "<human title>"               # âœ… Required
status: draft | in_review | approved
owners:
  - "<name-or-handle>"
created: YYYY-MM-DD
updated: YYYY-MM-DD

tags: ["mcp", "experiment", "etl", "ocr", "nlp"]

inputs:
  datasets:
    - id: "<dataset-id>"
      path: "data/raw/<...>"
      version: "<git-tag-or-hash>"
      checksum: "<optional>"
  code:
    repo_path: "<relative path>"
    commit: "<git sha>"
  config:
    - "configs/<...>.yml"

outputs:
  artifacts:
    - "data/processed/<...>"
    - "mcp/runs/<...>"
  metadata:
    - "data/catalog/<...>.json"
    - "data/provenance/<...>.json"

governance:
  access: public | restricted
  sensitivity: none | pii | cultural_sensitive | embargoed
---
```

---

## ğŸ§¬ Evidence & Provenance Hooks

### ğŸ” â€œPipeline Orderâ€ (donâ€™t bypass)

KFM work is intentionally structured so data and results are **vetted** before they become user-facing.  
When your experiment creates a new artifact (dataset, layer, metric, narrative, model), donâ€™t â€œshipâ€ it straight to the UI.

```mermaid
flowchart LR
  A[Raw] --> B[Processed]
  B --> C[Catalog / Provenance]
  C --> D[Database]
  D --> E[API]
  E --> F[UI]
  subgraph MCP["MCP: Methods & Computational Experiments"]
    G[Runs / Experiments / Model Cards]
  end
  B --> G
  G --> C
```

### ğŸ§¾ What to link in every MCP artifact

At minimum, your filled template should link to:

- ğŸ§· **Inputs:** dataset IDs/paths, source references, and versions
- ğŸ§· **Code:** commit hash + entrypoint command (or notebook path)
- ğŸ§· **Config:** parameter files, seeds, feature flags
- ğŸ§· **Outputs:** artifacts + where they live in the repo
- ğŸ§· **Provenance:** which provenance/metadata records were created/updated
- ğŸ§· **Interpretation:** what changed, what you learned, what to do next

> If someone canâ€™t rerun it from your template + repo state, itâ€™s not â€œdoneâ€ yet âœ…

---

## âœ… Quality Gates

Before merging MCP outputs, use these gates:

### ğŸ”¬ Reproducibility Gate
- [ ] Environment is specified (e.g., container, `requirements.txt`, versions)
- [ ] Inputs are versioned and traceable (hash/ID)
- [ ] Randomness is controlled (seeds documented if relevant)
- [ ] Command(s) to reproduce are written and tested

### ğŸ‘¥ Review Gate
- [ ] Another contributor can follow your report without asking you questions
- [ ] Claims are backed by linked artifacts (tables, charts, logs, metrics)
- [ ] Deviations from plan are documented (what changed and why)

### ğŸ›¡ï¸ Governance Gate
- [ ] License/rights for inputs are documented
- [ ] Sensitive content is flagged and access level is set
- [ ] Any restricted data is not exposed in public artifacts

---

## ğŸ§© Add / Update a Template

When you notice repetition, paper cuts, or missing fields:

1. Add or revise the template in `mcp/templates/`
2. Include a short changelog section at the bottom of the template:
   - What changed
   - Why it changed
   - What old docs may need to update
3. If automation relies on parsing, keep YAML keys stable

> Templates are *interfaces*. Breaking changes should be treated like API changes ğŸ§¯

---

## â“ FAQ

### â€œShould this be in `docs/templates/` instead?â€
- Use **`mcp/templates/`** for experiment/run/model/process documentation.
- Use **`docs/templates/`** for narrative docs, architecture specs, story node patterns, or governance documentation.

### â€œDo I need both an Experiment Report and a Run Log?â€
Usually:
- âœ… **Experiment Report** = *the narrative + interpretation*
- âœ… **Run Log** = *the execution record(s)*  
Large experiments often have **1 report** and **many run logs**.

### â€œWhat if the experiment fails?â€
Perfect â€” document it. Failure logs prevent repeated mistakes and preserve negative results ğŸ§ 

---

## ğŸ§° Related Paths (mental map)

```text
ğŸ“¦ repo/
â”œâ”€ ğŸ§ª mcp/
â”‚  â”œâ”€ ğŸ§© templates/        ğŸ‘ˆ you are here
â”‚  â”œâ”€ ğŸ§ª experiments/
â”‚  â”œâ”€ ğŸƒ runs/
â”‚  â”œâ”€ ğŸ§  model_cards/
â”‚  â””â”€ ğŸ““ notebooks/
â”œâ”€ ğŸ—ƒï¸ data/
â”‚  â”œâ”€ raw/
â”‚  â”œâ”€ processed/
â”‚  â”œâ”€ catalog/
â”‚  â””â”€ provenance/
â””â”€ ğŸ“š docs/
   â”œâ”€ templates/
   â”œâ”€ runbooks/
   â””â”€ checklists/
```

---

## ğŸ Final note

MCP templates are here to ensure the project stays:

- **Evidence-backed** ğŸ“Œ
- **Transparent & auditable** ğŸ”
- **Collaborative & teachable** ğŸ¤
- **Ethically grounded** ğŸ›¡ï¸

If a template makes your work *slower* in the long run, improve the template â€” donâ€™t skip the rigor.
