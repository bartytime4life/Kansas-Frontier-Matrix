---
title: "ğŸ¤– MCP Experiment â€” CrewAI Harmonization & Metadata Autogeneration Trial (AI-EXP-004)"
path: "mcp/experiments/2025-11-12_AI-EXP-004.md"
version: "v11.0.0"
last_updated: "2025-11-12"
experiment_id: "AI-EXP-004"
experiment_date: "2025-11-12"
domain: "AI Â· Data Harmonization Â· Metadata Autogeneration Â· CREWAI v2.5â†’v3"
review_cycle: "Quarterly Â· MCP Board Â· FAIR+CARE Council Â· AI Governance Committee"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../releases/v11.0.0/sbom.spdx.json"
manifest_ref: "../../releases/v11.0.0/manifest.zip"
telemetry_ref: "../../releases/v11.0.0/mcp-experiments-telemetry.json"
telemetry_schema: "../../schemas/telemetry/mcp-experiments-v11.json"
data_contract: "KFM-PDC v11 â€” harmonization.json"
governance_ref: "../../docs/standards/governance/ROOT-GOVERNANCE.md"
ethics_ref: "../../docs/standards/faircare/FAIRCARE-GUIDE.md"
sovereignty_policy: "../../docs/standards/sovereignty/INDIGENOUS-DATA-PROTECTION.md"
license: "CC-BY 4.0"
mcp_version: "MCP-DL v6.3"
markdown_protocol_version: "KFM-MDP v11.0.0"
ontology_protocol_version: "KFM-OP v11.0"
status: "Completed"
doc_kind: "Experiment"
intent: "ai-harmonization-test"
semantic_document_id: "kfm-exp-ai-004"
doc_uuid: "urn:kfm:mcp:experiment:ai:004:v11.0.0"
machine_extractable: true
classification: "Scientific Experiment"
sensitivity: "Mixed"
fair_category: "F1-A1-I2-R2"
care_label: "Collective Benefit Â· Responsibility Â· Ethics"
immutability_status: "version-pinned"
accessibility_compliance: "WCAG 2.1 AA+"
jurisdiction: "Kansas / United States"
---

<div align="center">

# ğŸ¤– **AI-EXP-004 â€” CrewAI Harmonization & Metadata Autogeneration Trial (v11 LTS)**  
`mcp/experiments/2025-11-12_AI-EXP-004.md`

**Purpose:**  
Evaluate CrewAI v2.5â€“v3 harmonization workers for **automated metadata generation**, **unit normalization**, **CRS validation**, and **semantic uplift** of climate, hydrology, and GIS assets into KFM-STAC v11 / KFM-DCAT v11 formats.

</div>

---

# ğŸ“˜ 1. Objective / Hypothesis

### Objective  
Assess whether CrewAI workers can autonomously:

- Harmonize heterogeneous datasets  
- Generate compliant STAC/DCAT metadata  
- Apply KFM-PDC v11 data contract rules  
- Validate CRS/units  
- Annotate provenance  
- Propagate FAIR+CARE metadata  
- Prepare datasets for pipeline ingestion  

### Hypothesis  
CrewAI v3 workers will achieve **â‰¥92% metadata accuracy**, **â‰¥95% contract compliance**, and reduce manual harmonization time by **â‰¥45%**.

---

# ğŸ“š 2. Background

KFM v11 integrates highly heterogeneous data sources:

- Hydrology (USGS, USACE)  
- Climate (PRISM, ERA5, Mesonet)  
- GIS (DEM, landcover, soils, hazard layers)  
- Cultural & historical datasets  
- Archives (public domain)  

These datasets differ in:

- Coordinate reference systems  
- Units  
- Naming conventions  
- Extents  
- Temporal resolutions  
- Metadata completeness  

CrewAI harmonization workers aim to automate:

- Validation  
- Normalization  
- Metadata creation  
- Error-detection  
- Contract enforcement  

AI-EXP-004 tests the new v3 pipeline.

---

# ğŸ“¥ 3. Inputs

### Datasets
All datasets passed through this test:

| Dataset | ID | Notes |
|---------|----|-------|
| Mesonet Precip | `stac:climate/mesonet` | Daily precip |
| ERA5 Reanalysis | `stac:climate/era5` | Multiband climate |
| USGS Daily Flow | `stac:hydrology/usgs_daily` | Hydrochronologies |
| DEM 10m | `stac:terrain/dem10` | Raster |
| Landcover | `stac:ecology/landcover` | Categorical data |

### Scripts & Configs
```
src/pipelines/harmonization/crewai_config.yaml
src/pipelines/harmonization/contracts/*.json
```

### Environment
- CrewAI v3  
- LangGraph v11 deterministic executor  
- Python 3.12  
- Torch 2.2 (for AI inference models)  

Seed: **777194**

---

# ğŸ› ï¸ 4. Methods (Deterministic)

## 4.1 Step 1 â€” Load Assets & Validate Contracts
CrewAI validates:

- CRS (must match contract rules)  
- Units  
- Variable names  
- Spatial/temporal extents  
- Missing metadata fields  

Files failing contract compliance are sent to remediation.

---

## 4.2 Step 2 â€” Unit Normalization
- Temperature â†’ Â°C  
- Precip â†’ mm/day  
- Streamflow â†’ cfs  
- Raster values normalized per domain contract  

CrewAI uses:

- Contract lookups  
- Unit registry  
- Dimension inference  

---

## 4.3 Step 3 â€” CRS Validation & Correction
- Convert to EPSG:4326 unless contract specifies otherwise  
- Detect missing CRS tags  
- Resolve ambiguous coordinate systems via transformer classifier  
- Validate geometry consistency  

---

## 4.4 Step 4 â€” STAC/DCAT Autogeneration
For each dataset:

- STAC Item or Collection created  
- DCAT Metadata generated with:
  - keywords  
  - spatial/temporal coverage  
  - lineage references  
  - license/rights metadata  
  - CARE fields  
  - Sovereignty fields  

All STAC assets validated via `.github/workflows/stac_validate.yml`.

---

## 4.5 Step 5 â€” Provenance & Lineage
CrewAI writes:

- **PROV-O block**  
- **OpenLineage event**  
- Contract compliance report  
- Normalization log  

Saved to:
```
data/provenance/harmonization/<timestamp>.json
```

---

## 4.6 Step 6 â€” Error & Drift Detection
CrewAI detects:

- CRS mislabeled rasters  
- Anomalous out-of-range values  
- Missing timestamps  
- Corrupted spatial grids  
- Unit drift  

Outputs suggestions to human operator.

---

# ğŸ“Š 5. Results

### Metrics
| Metric | Score |
|--------|-------|
| Metadata Accuracy | 0.94 |
| Contract Compliance | 0.96 |
| CRS Correction Accuracy | 0.98 |
| Provenance Completeness | 1.00 |
| FAIR+CARE Annotation Accuracy | 0.92 |

### Observed Improvements
- Manual metadata writing reduced by **~48%**  
- CRS correction automated for all rasters  
- Contract compliance check caught 31 errors  
- Sovereignty masking auto-applied where needed  

### Output Location
```
data/processed/harmonized/v11/*
```

---

# ğŸ›¡ï¸ 6. CARE, Sovereignty & Ethics

- No sensitive cultural data processed directly  
- All datasets validated for sovereignty classification  
- No coordinate leakage occurred  
- Masking applied to restricted rasters automatically  
- Strict separation of public vs sovereign data maintained  

CARE Classification: **Tier B (Lowâ€“Moderate Risk)**  
Governance: **PASS**

---

# ğŸ”— 7. Provenance (PROV-O Block)

```
{
  "prov:entity": "harmonized_dataset_bundle_v11",
  "prov:wasGeneratedBy": "AI-EXP-004",
  "prov:used": [
    "stac:climate/mesonet",
    "stac:climate/era5",
    "stac:hydrology/usgs_daily",
    "stac:terrain/dem10",
    "stac:ecology/landcover"
  ],
  "prov:wasAssociatedWith": "crewAI-harmonizer-v3"
}
```

OpenLineage logs stored:

```
data/provenance/experiments/harmonization/2025-11-12/
```

---

# ğŸ“ˆ 8. Telemetry

- Energy: **4.2 kWh**  
- Carbon: **208 gCOâ‚‚e**  
- Compute: 2.1 GPU-hours  
- I/O: ~12 GB  

Stored in `mcp-experiments-telemetry.json`.

---

# ğŸ§¯ 9. Failure Modes & Recovery

### Failures Detected
- Landcover CRS mismatch  
- ERA5 missing variable metadata  
- USGS inconsistent date formatting  
- DEM with malformed GEOTIFF tags  

### Recovery Steps
- Auto-CRS correction  
- Contract-based repair  
- Temporal normalization  
- Raster metadata rebuild  

---

# ğŸ•° 10. Version History

| Version | Date | Summary |
|--------:|------|---------|
| v11.0.0 | 2025-11-12 | Initial CrewAI harmonization experiment for KFM v11. |

---

<div align="center">

Â© 2025 Kansas Frontier Matrix â€” MCP-DL v6.3  
FAIR+CARE Â· Governance-by-Design Â· Automation-Aware  
Diamondâ¹ Î© / CrownâˆÎ© Certified  

</div>
