# ğŸ§© `api/services/` â€” Service (Useâ€‘Case) Layer

![Python](https://img.shields.io/badge/Python-3.11%2B-informational?logo=python&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-Backend-009688?logo=fastapi&logoColor=white)
![Clean Architecture](https://img.shields.io/badge/Architecture-Clean%20%26%20Layered-blueviolet)
![Governance](https://img.shields.io/badge/Governance-Policy%20Enforced-critical)
![Provenance](https://img.shields.io/badge/Provenance-First-success)
![LLM](https://img.shields.io/badge/LLM-Ollama%20(Local)-orange)

> ğŸ§  **What this folder is:** the **business logic + orchestration layer** for the KFM backend.  
> ğŸ”’ **What it is *not*:** FastAPI route handlers, database code, or framework glue.

---

## ğŸ“Œ Why `services/` exists

KFM follows a layered approach where the **UI never talks to databases directly**â€”everything is mediated by the backend API, which performs validation + governance checks. The service layer is where we implement **use-cases**: workflows, analysis routines, and â€œdo the thingâ€ logic.

âœ… Services should:
- Orchestrate **domain entities/models**
- Call **repository/adapters** via interfaces (not direct DB calls)
- Apply **decision rules**, algorithms, and governance rules
- Be **easy to test** (mock repositories)
- Return **domain objects / DTOs**, not web-framework responses

---

## ğŸ§­ Mental Model (Request Flow)

```mermaid
flowchart LR
  UI[ğŸ–¥ï¸ Web UI] --> R[ğŸ§° FastAPI Routes / GraphQL Resolvers]
  R --> S[ğŸ§© Services (Useâ€‘Cases)]
  S -->|interfaces| A[ğŸ”Œ Adapters / Repositories]
  A --> P[(ğŸ—ºï¸ PostGIS)]
  A --> N[(ğŸ•¸ï¸ Neo4j)]
  A --> E[(ğŸ” Search Index)]
  A --> X[(ğŸŒ External APIs)]
  S --> G[ğŸ›¡ï¸ Policy / Governance Checks]
  S --> V[ğŸ§¾ Provenance + Audit Logs]
```

---

## ğŸ—‚ï¸ Suggested Layout

> Your exact files may vary â€” this is the **recommended convention**.

```text
ğŸ“ api/
  ğŸ“ routes/                # Thin controllers (HTTP)
  ğŸ“ graphql/               # Optional resolvers/schema
  ğŸ“ models/ or domain/     # Pydantic/domain entities (lingua franca)
  ğŸ“ repositories/          # Interfaces + implementations (or adapters/)
  ğŸ“ db/                    # Database clients (PostGIS, Neo4j, etc.)
  ğŸ“ services/              # âœ… You are here
    ğŸ“„ analysis_service.py
    ğŸ“„ story_service.py
    ğŸ“„ search_service.py
    ğŸ“ ai/
      ğŸ“„ ai_query_service.py
    ğŸ“„ __init__.py
```

---

## âœ… Service Design Rules (The â€œCommandmentsâ€)

### 1) Keep services frameworkâ€‘agnostic ğŸ§¼
- âœ… OK: pure Python + domain models
- âŒ Avoid: importing `fastapi.Request`, `Depends`, router objects, response classes

### 2) No direct DB calls from services ğŸš«ğŸ—„ï¸
Services should never know whether data came from:
- PostGIS
- Neo4j
- CSV / file pipeline output
- External API

Instead, they call **interfaces** (repositories/adapters) and operate on **domain objects**.

### 3) Prefer dependency injection (constructor or explicit params) ğŸ§©
Pass repositories/adapters into services:
- Constructor injection for longâ€‘lived services
- Function arguments for simpler use-cases

### 4) Split â€œQueriesâ€ vs â€œCommandsâ€ âš–ï¸
- **Query**: read/aggregate/search â†’ returns data
- **Command**: create/update/delete â†’ returns result + writes provenance/audit trails

### 5) Provenance isnâ€™t optional ğŸ§¾
If a service produces:
- an analysis output,
- an AI answer,
- a generated artifact,

â€¦it should also produce/trigger whatever logging is required for provenance & auditability.

### 6) Fail closed by default ğŸ›‘
When policy checks fail:
- return a safe refusal / sanitized result
- donâ€™t â€œbest effortâ€ leak restricted content

---

## ğŸ§ª Testing Expectations

Services are intended to be highly testable.

### Unit tests (fast + pure) âœ…
- Mock repository interfaces
- Provide synthetic domain objects
- Validate:
  - correct calculations
  - decision rules
  - policy outcomes (allow/deny/mask)

### Integration tests (endpoints) ğŸ”—
- Use FastAPI test client at the route layer
- Optionally spin up ephemeral DB(s) for realistic queries

---

## ğŸ§° Common Service Patterns

### Pattern A â€” Thin service function (simple use-case)
```python
def get_story_node(story_repo, story_id: str):
    node = story_repo.get_story_node(story_id)
    if not node:
        raise ValueError("Story node not found")
    return node
```

### Pattern B â€” Service class (stateful dependencies + workflows)
```python
class StoryService:
    def __init__(self, story_repo, graph_repo, policy):
        self.story_repo = story_repo
        self.graph_repo = graph_repo
        self.policy = policy

    def get_story_with_related(self, user, story_id: str):
        self.policy.check_access(user=user, resource_id=story_id)
        story = self.story_repo.get_story_node(story_id)
        related = self.graph_repo.get_related_events(story_id)
        return {"story": story, "related": related}
```

---

## ğŸŒ¾ Example Useâ€‘Case: `DroughtAnalysisService`

This is the archetype for analytic services:
- Pull domain records via repositories (rainfall, yield, etc.)
- Compute a result (drought impact summary)
- Return a clean model/summary

```python
class DroughtAnalysisService:
    def __init__(self, rainfall_repo, yield_repo):
        self.rainfall_repo = rainfall_repo
        self.yield_repo = yield_repo

    def drought_report(self, year_range: tuple[int, int]):
        rainfall = self.rainfall_repo.get_records(year_range)
        yields = self.yield_repo.get_records(year_range)

        # ğŸ”¬ Domain logic here (compute drought index, correlate yield drop, etc.)
        report = compute_drought_impact(rainfall, yields)

        return report
```

---

## ğŸ¤– AI Services: Focus Mode + Local LLM (Ollama)

KFMâ€™s **Focus Mode** is designed to run a **local LLM via Ollama**, with governance:
- AI only uses **approved tools/APIs**
- AI must provide **citations** for factual claims
- Output is run through a **policy engine** before returning
- Typical backend endpoint shape: `POST /ai/query`

### Recommended service split
- `AiQueryService`: orchestration + policy + provenance
- `RetrievalService`: semantic search / â€œsearch databaseâ€ tooling
- `CitationService`: normalizes and attaches citations
- `PolicyService`: allow/deny/sanitize decisions

```python
class AiQueryService:
    def __init__(self, llm_client, retrieval, policy, provenance, citation):
        self.llm = llm_client
        self.retrieval = retrieval
        self.policy = policy
        self.provenance = provenance
        self.citation = citation

    def answer(self, user, question: str):
        # 1) Pre-check question (fail closed)
        self.policy.precheck_ai_question(user=user, question=question)

        # 2) Retrieve grounded context (safe tools only)
        snippets = self.retrieval.fetch_context(question)

        # 3) Ask local LLM (Ollama) for answer + citations
        raw = self.llm.generate(question=question, context=snippets)

        # 4) Attach/normalize citations + enforce policy on final answer
        answered = self.citation.attach(raw, snippets)
        self.policy.postcheck_ai_answer(user=user, answer=answered)

        # 5) Record provenance / audit trail
        self.provenance.record_ai_interaction(user=user, question=question, answer=answered)

        return answered
```

> âœ¨ Design goal: AI isnâ€™t an oracle â€” it â€œshows its workâ€ by retrieving data and citing it.

---

## ğŸ§© How Routes Should Use Services

Routes/controllers should be *thin*:
- parse & validate inputs
- call service
- serialize outputs

### REST
- Swagger UI typically lives at: `/docs`

### GraphQL (optional)
Resolvers should call the **same services** as REST to avoid duplicating business logic.

---

## ğŸ§± Adding a New Service (Checklist)

1. **Name it by use-case**: `parcel_service.py`, `analysis_service.py`, `ai_query_service.py` ğŸ·ï¸  
2. Define/confirm the **domain model** youâ€™ll return (`api/models` or `api/domain`) ğŸ§¬  
3. Add or reuse **repository interfaces** (no direct DB calls) ğŸ”Œ  
4. Implement service logic (pure, deterministic where possible) ğŸ§   
5. Add policy hooks (pre/post checks) ğŸ›¡ï¸  
6. Add provenance hooks if outputs must be traceable ğŸ§¾  
7. Write unit tests with mocked repos âœ…  
8. Wire it into routes/resolvers with DI ğŸ§°  

---

## ğŸ§¨ Common Pitfalls (Avoid These)

- âŒ Service imports FastAPI objects (`Request`, `Depends`, `HTTPException`)
- âŒ SQL/Cypher query strings embedded in service methods
- âŒ Returning raw DB rows or ORM models instead of domain models
- âŒ Skipping policy checks because â€œitâ€™s just internalâ€
- âŒ Generating AI answers without citations / provenance

---

## ğŸ”— Handy Navigation

- ğŸ“ `api/routes/` â€” HTTP endpoints (thin controllers)
- ğŸ“ `api/repositories/` / `api/adapters/` â€” external integration surface
- ğŸ“ `api/db/` â€” PostGIS/Neo4j clients and sessions
- ğŸ“ `policy/` â€” policy-as-code (OPA/Rego), governance rules

---

## ğŸ§­ Service Quality Bar (Quick Scorecard)

| Requirement | Must? | Notes |
|---|:---:|---|
| Pure business logic (no framework) | âœ… | Keep route handlers thin |
| Uses repository interfaces | âœ… | No direct DB access |
| Easy to unit test | âœ… | Mock repos |
| Policy enforcement | âœ… | Fail closed |
| Provenance hooks where needed | âœ… | Especially for AI + derived artifacts |
| Returns domain models / DTOs | âœ… | Stable contracts |

---

<details>
  <summary>ğŸ“¦ â€œWhat belongs in services vs repositories vs routes?â€</summary>

- **Routes**: request/response boundary (HTTP), validation, status codes  
- **Services**: orchestration + business rules + workflows  
- **Repositories/Adapters**: â€œhow to fetch/store dataâ€ (PostGIS/Neo4j/external APIs)  
- **Domain Models**: shared language across all layers  

</details>