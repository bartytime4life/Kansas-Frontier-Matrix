# ðŸ§© `api/services/` â€” Service Layer (Use-Cases)

![Layer](https://img.shields.io/badge/layer-service%20%2F%20use--cases-blue)
![API](https://img.shields.io/badge/api-REST%20%2B%20GraphQL-informational)
![Data](https://img.shields.io/badge/data-PostGIS%20%7C%20Neo4j%20%7C%20Search%20%7C%20Object%20Store-orange)
![Governance](https://img.shields.io/badge/governance-OPA%20policy%20gates-success)
![AI](https://img.shields.io/badge/ai-Focus%20Mode%20%28RAG%29%20%2B%20Ollama-purple)

> **Purpose:** `api/services/` holds KFMâ€™s *application services / use-cases* â€” the orchestration layer that turns domain intent into governed, traceable outcomes.  
> Services sit **between** API routers/controllers and **adapters** (DBs, search, LLM, storage), enforcing the â€œtruth pathâ€ and KFMâ€™s evidence-first rules.

---

## ðŸ“Œ What belongs here?

âœ… **DO put in `api/services/`:**
- Use-case orchestration (`CatalogService.search()`, `TilesService.get_tile()`, `FocusModeService.query()`)
- Business rules and workflow sequencing
- Evidence bundling and citation mapping (the â€œmap behind the mapâ€ mindset)
- Governance hooks: policy checks, provenance logging, allowlists/guardrails

âŒ **DO NOT put in `api/services/`:**
- FastAPI routers/controllers (HTTP parsing/response formatting)
- Raw SQL, Cypher, or vendor SDK calls (those belong in adapters/repos)
- Framework globals (request objects, app state, etc.)
- â€œJust a helperâ€ utilities with no business meaning (put in `api/utils/`)

---

## ðŸ§± Architectural role (Clean Architecture fit)

KFM follows a layered architecture where services implement the **Service / Use-Case Layer**:
- **Domain layer** = core entities/models (framework-agnostic)
- **Service layer (this folder)** = workflows + decision rules + orchestration
- **Integration/Adapter layer** = PostGIS/Neo4j/search/object-store/LLM clients and repositories
- **Infrastructure** = FastAPI app wiring, DI, routers, startup config

**Rule of thumb:**  
> **Services depend on interfaces (ports), not implementations.**  
> This keeps use-cases testable and prevents DB/LLM details from leaking into business logic.

---

## ðŸ—‚ï¸ Suggested folder map

> (Actual filenames may vary; keep the *intent* consistent.)

```text
api/
  services/ ðŸ§©
    README.md  â† you are here ðŸ“

    catalog_service.py        # DCAT/STAC dataset discovery & retrieval
    query_service.py          # constrained ad-hoc query interface (allowlisted)
    tiles_service.py          # vector/raster tile orchestration
    graph_service.py          # graph/relationship use-cases (GraphQL resolvers call here)
    focus_mode_service.py     # RAG pipeline orchestration (Prompt Gate â†’ Retrieval â†’ LLM â†’ Policy)
    provenance_service.py     # provenance ledger logging + citation maps
    policy_service.py         # OPA wrapper (authorization + content/policy checks)

  adapters/ ðŸ”Œ                # PostGIS/Neo4j/Search/Ollama/Object-store implementations
  domain/ ðŸ§¬                  # Pydantic/dataclass domain models (no I/O)
  routers/ ðŸŒ                 # FastAPI routers/controllers
```

---

## ðŸ§  Service design principles

### 1) Evidence-first by default ðŸ§¾
Services should make it *easy* to do the right thing:
- Prefer return types that include **data + evidence metadata**
- Keep â€œcitation mappingâ€ close to the logic that selects evidence
- If evidence is missing, fail safely (or return â€œinsufficient evidenceâ€)

### 2) Governed access (policy gates) ðŸ›¡ï¸
Every service that exposes data should:
- Validate inputs (bbox, time range, query params)
- Enforce allowlists (tables, layers, fields, datasets)
- Run authorization/policy checks (OPA or policy module)

### 3) Traceability (provenance logging) ðŸ§·
Services that produce user-visible outputs should log:
- Request context (user/role, map context, time filters)
- The exact datasets/documents used
- The transformation steps (if any)
- Output IDs + citations map

### 4) Keep services stateless â™»ï¸
- No hidden caches unless explicit and documented
- Prefer pure functions + injected dependencies
- Make operations idempotent where possible

---

## ðŸ“š â€œService catalogâ€ (what we expect to find here)

| Service | What it owns ðŸ§© | Typical callers ðŸŒ | Notes |
|---|---|---|---|
| `CatalogService` | Dataset metadata, discovery, dataset asset links | `/api/v1/datasets/*`, `/api/v1/catalog/search` | Returns DCAT/STAC summaries + links |
| `QueryService` | Constrained â€œpower userâ€ querying | `/api/v1/query` | Must be allowlisted + logged |
| `TilesService` | Tile orchestration + layer gating | `/tiles/{layer}/{z}/{x}/{y}.*` | Keeps map clients on the same tile â€œwellâ€ |
| `GraphService` | Relationship-driven use-cases | `/graphql` resolvers | Often joins Neo4j + PostGIS |
| `FocusModeService` | RAG orchestration for Focus Mode | `/focus-mode/query` | Prompt Gate â†’ retrieval â†’ LLM â†’ policy â†’ citations |
| `PolicyService` | OPA integration + content rules | called by all services | Centralize policy logic here |
| `ProvenanceService` | Immutable audit + citation maps | called by key services | â€œNo provenance, no publishâ€ |

---

## ðŸ” Focus Mode (RAG) service workflow

This is the *canonical* AI-related service orchestration pattern.

```mermaid
flowchart LR
  A[User question ðŸ—¨ï¸] --> B[Prompt Gate ðŸ§¼]
  B --> C[Hybrid Retrieval ðŸ”Ž\nNeo4j + PostGIS + Full-text + Vector]
  C --> D[Evidence Bundle ðŸ“¦\nnumbered sources + IDs]
  D --> E[LLM Generate ðŸ¤–\n(Ollama)]
  E --> F[Policy Check ðŸ›¡ï¸\n(OPA rules)]
  F --> G[Response + Citation Map ðŸ§¾]
  G --> H[Provenance Log ðŸ§·\n(question, sources, model, prompt ver)]
```

### Implementation notes (service-level)
- Keep retrieval *compact and high-signal* (snippets, not whole documents).
- Ensure output contains required citation markers (e.g., `[1]`, `[2]`) before returning.
- If policy fails (missing citations, sensitive content, role mismatch), return a governed fallback.

---

## ðŸ§ª Testing expectations

### âœ… Unit tests (fast)
- Services tested with **fake repositories/adapters**
- Assert:
  - policy hooks are called
  - allowlists enforce correctly
  - provenance is emitted on successful flows
  - â€œinsufficient evidenceâ€ behavior is consistent

### ðŸ”§ Integration tests (real deps)
- Adapter-level tests against PostGIS/Neo4j/search/ollama containers (compose profile)
- Golden tests for:
  - tile generation contract (headers/content-type)
  - query constraints (blocked tables/columns)
  - GraphQL resolver consistency

### ðŸ“œ Contract tests
- Ensure service return shapes remain stable for routers/controllers.

---

## ðŸ§¯ Error handling contract

Keep a consistent pattern so controllers can map to HTTP cleanly.

**Recommended:**
- Define service exceptions with:
  - `code` (stable string)
  - `message` (safe for users)
  - optional `details` (internal)
- Avoid leaking raw DB/LLM errors upward.

Example patterns:
- `NotFoundError("dataset_not_found")`
- `PolicyDeniedError("not_authorized")`
- `ValidationError("invalid_bbox")`
- `EvidenceError("no_source_no_answer")`

---

## ðŸ§° Example service skeleton (Python)

```python
from dataclasses import dataclass
from typing import Protocol

class DatasetRepo(Protocol):
    async def get_dataset(self, dataset_id: str) -> dict: ...
    async def search(self, *, q: str | None, bbox=None, time=None) -> list[dict]: ...

class Policy(Protocol):
    async def assert_allowed(self, *, actor, action: str, resource: dict) -> None: ...

class Provenance(Protocol):
    async def log(self, *, actor, action: str, inputs: dict, outputs: dict) -> None: ...

@dataclass
class CatalogService:
    repo: DatasetRepo
    policy: Policy
    prov: Provenance

    async def get_dataset(self, *, actor, dataset_id: str) -> dict:
        ds = await self.repo.get_dataset(dataset_id)
        await self.policy.assert_allowed(actor=actor, action="datasets:read", resource=ds)
        await self.prov.log(
            actor=actor,
            action="datasets:read",
            inputs={"dataset_id": dataset_id},
            outputs={"dataset_id": dataset_id},
        )
        return ds
```

---

## âž• Adding a new service (checklist)

1. **Name the use-case** ðŸŽ¯  
   Example: `WaterWellsAnalysisService` vs `utils_wells.py`

2. **Define the inputs/outputs** ðŸ§¬  
   Prefer domain models or small typed DTOs.

3. **Create ports (interfaces)** ðŸ”Œ  
   Repositories/clients your service needs (PostGIS, Neo4j, search, object store).

4. **Write the service logic** ðŸ§©  
   Keep DB/SDK details out.

5. **Wire dependencies** ðŸ§·  
   Add DI bindings so routers can construct the service.

6. **Enforce governance** ðŸ›¡ï¸  
   Policy checks + allowlists + provenance logging.

7. **Add tests** âœ…  
   Unit tests first, then integration tests if needed.

8. **Document** ðŸ“  
   Update this README and any domain README that applies.

---

## ðŸ§­ Operational notes (dev + prod)

### Local dev via containers ðŸ³
The broader KFM stack is designed to run with Docker Compose (API + PostGIS + Neo4j + web + optional OPA/Ollama).  
Services should assume dependencies are reachable via container DNS names (e.g., `db`, `graph`, `ollama`) when running in compose.

### Scalability ðŸ“ˆ
- Keep services stateless so the API layer can scale horizontally.
- Expensive operations should be cached *only if governed* (cache keys must include policy context).

---

## ðŸ”— Related docs (repo pointers)

> These are the docs that define system-level expectations for the service layer:
- `docs/architecture/system_overview.md` (truth path + API role)
- `docs/architecture/ai/AI_SYSTEM_OVERVIEW.md` (AI boundaries)
- `docs/architecture/ai/OLLAMA_INTEGRATION.md` (Focus Mode RAG pipeline)
- `pipelines/README.md` (data lifecycle + provenance artifacts)

---

## ðŸ§¼ Philosophy recap

- **One truth path:** Raw â†’ Processed â†’ Catalog â†’ Databases â†’ API â†’ UI/AI  
- **No backdoors:** UIs donâ€™t query DBs directly; services are the controlled gateway.  
- **No source, no answer:** If we canâ€™t cite it, we shouldnâ€™t claim it.

âœ¨ If you keep services clean, everything else becomes easier: testing, governance, scaling, and trust.