# ðŸ›¡ï¸ KFM API Policy Pack (OPA) â€” `api/policies/`

**Policy-as-Code** ðŸ§© â€¢ **Fail Closed** ðŸ”’ â€¢ **Least Privilege** ðŸ§  â€¢ **Evidence-First (â€œNo Source, No Answerâ€)** ðŸ“Ž â€¢ **FAIR + CARE** ðŸŒ¾

Welcome to the policy â€œbrainâ€ for the Kansas Frontier Matrix (KFM) API layer.  
This directory defines **how requests are allowed, denied, or sanitized**â€”consistentlyâ€”across REST, GraphQL, tile services, and AI endpoints.

---

## ðŸ“Œ Why this exists

KFM is designed as an evidence-first geospatial knowledge system where:

- **All access flows through the API** (no UI â†’ DB shortcuts) ðŸ§±
- **Every request is governed** by *explicit*, versioned policy checks âœ…
- The platform **fails closed**: if required metadata or governance conditions arenâ€™t satisfied, the system blocks the operation ðŸ”’
- AI outputs are treated as first-class artifacts and must stay **traceable + auditable** ðŸ§¾

This policy pack helps enforce those guarantees at:
- âœ… **CI time** (prevent non-compliant changes from merging)
- âœ… **Runtime** (authorize + sanitize every request and response)

---

## ðŸ§­ Contents

- [ðŸ§  Policy philosophy](#-policy-philosophy)
- [ðŸ§± Where policies run](#-where-policies-run)
- [ðŸ“ Suggested folder layout](#-suggested-folder-layout)
- [ðŸŽ›ï¸ Decision contract](#ï¸-decision-contract)
- [ðŸ—‚ï¸ Policy domains](#ï¸-policy-domains)
- [ðŸ§ª Testing locally](#-testing-locally)
- [ðŸ§© Adding a new policy](#-adding-a-new-policy)
- [ðŸ“Ž Examples](#-examples)
- [ðŸ§¾ Auditing & provenance](#-auditing--provenance)
- [â“ FAQ](#-faq)

---

## ðŸ§  Policy philosophy

### 1) ðŸ”’ Fail closed by default
If anything is missing or ambiguous (license absent, sensitivity unset, provenance missing, unknown role), **deny**.

### 2) ðŸ§  Least privilege (RBAC + ABAC)
Access is determined by:
- **User role(s)** (RBAC)
- **Resource sensitivity + classification tags** (ABAC)
- **Context** (endpoint type, query shape, org/group membership, environment)

### 3) ðŸŒ¾ FAIR + CARE governance is â€œrealâ€
We aim for open exploration **without** exposing sensitive locations, private records, or culturally protected data.

### 4) ðŸ“Ž Evidence-first AI
AI responses must be grounded and verifiable:
- â€œNo Source, No Answerâ€ means the system should **refuse** or **de-escalate** rather than hallucinate.
- Policies should be able to enforce **citations**, **topic limits**, and **sensitive-data protections** for AI.

---

## ðŸ§± Where policies run

```mermaid
flowchart LR
  A[ðŸ‘¤ Client: UI / External App] --> B[ðŸŒ KFM API (REST/GraphQL/Tiles/AI)]
  B --> C{ðŸ›¡ï¸ Policy Decision}
  C -->|allow âœ…| D[ðŸ“¦ Data / Tiles / AI Answer]
  C -->|deny â›”| E[403 / 401 / safe refusal]
  C -->|sanitize ðŸ§½| F[âœ… Return filtered/rounded/aggregated output]

  subgraph CI[ðŸ¤– CI Policy Gate]
    G[PR change] --> H[ðŸ§ª Conftest / Rego checks]
    H -->|pass âœ…| I[merge]
    H -->|fail â›”| J[block + report violations]
  end
```

---

## ðŸ“ Suggested folder layout

> Your repo may vary. This layout keeps things predictable and testable.

```text
ðŸ“¦ api/
  â””â”€â”€ ðŸ›¡ï¸ policies/
      â”œâ”€â”€ README.md
      â”œâ”€â”€ ðŸ“œ rego/
      â”‚   â”œâ”€â”€ security.rego          # RBAC/ABAC allow/deny + endpoint rules
      â”‚   â”œâ”€â”€ data_policies.rego      # dataset license/sensitivity/provenance gating
      â”‚   â”œâ”€â”€ ai_policies.rego        # citation + AI safety + sensitive output checks
      â”‚   â”œâ”€â”€ compliance.rego         # governance checks (e.g., publish rules)
      â”‚   â””â”€â”€ lib/
      â”‚       â”œâ”€â”€ strings.rego
      â”‚       â”œâ”€â”€ sanitize.rego
      â”‚       â””â”€â”€ time.rego
      â”œâ”€â”€ ðŸ§ª tests/
      â”‚   â”œâ”€â”€ security_test.rego
      â”‚   â”œâ”€â”€ data_policies_test.rego
      â”‚   â””â”€â”€ ai_policies_test.rego
      â”œâ”€â”€ ðŸ—‚ï¸ data/
      â”‚   â”œâ”€â”€ roles.json              # optional: role definitions / capability maps
      â”‚   â”œâ”€â”€ sensitivities.json      # optional: standard sensitivity taxonomy
      â”‚   â””â”€â”€ denylist.json           # optional: banned prompt patterns, etc.
      â””â”€â”€ ðŸ“¦ bundle/
          â””â”€â”€ (optional OPA bundle outputs)
```

---

## ðŸŽ›ï¸ Decision contract

To keep the API integration simple, every policy â€œentrypointâ€ should return a **single decision object** with a stable shape.

âœ… Recommended output:

```json
{
  "allow": false,
  "reasons": ["default deny"],
  "sanitize": {
    "mask_coordinates": true,
    "rounding_meters": 5000,
    "suppress_fields": ["owner_name", "exact_geometry"]
  },
  "obligations": {
    "audit": true,
    "log_level": "info",
    "policy_version_required": true
  }
}
```

### Key idea ðŸ§ 
- `allow=false` can still return `sanitize` instructions if you prefer **safe partial disclosure**
- `obligations` tell the API what it **must** do if it proceeds (audit logging, provenance stamping, etc.)

---

## ðŸ—‚ï¸ Policy domains

### ðŸ” 1) `security.rego` â€” RBAC + endpoint protection
Typical rules include:
- Only Admin can hit ingestion/pipeline-trigger endpoints
- Contributor can draft/submit, but not publish
- Public Viewer can read **only** public-approved datasets/stories

### ðŸ§¾ 2) `data_policies.rego` â€” dataset governance (license, sensitivity, provenance)
Typical rules include:
- A dataset **must** have a license before itâ€™s publishable
- A dataset **must** declare a sensitivity classification
- A dataset **must** have provenance (PROV) before it can enter â€œpublic catalogâ€ flows

### ðŸŒ¾ 3) `compliance.rego` â€” governance council rules
This is where â€œhuman governanceâ€ becomes enforceable guardrails, e.g.:
- withdrawn datasets are not accessible
- culturally protected datasets are access-controlled by owner group
- release processes require approvals (modeled as metadata assertions)

### ðŸ¤– 4) `ai_policies.rego` â€” evidence + safety for Focus Mode
Typical rules include:
- require citations in answers (format is project-specific)
- block answers that reference restricted datasets for unauthorized users
- prevent disclosure of private information about living individuals
- refuse disallowed intents (e.g., exploitative requests)

---

## ðŸ§ª Testing locally

> The goal: contributors can catch governance failures **before** opening a PR.

### âœ… OPA unit tests
Run Rego tests (example):
```bash
opa test api/policies -v
```

### âœ… Conftest checks (CI parity)
Run policy checks against repo content (example):
```bash
conftest test . -p api/policies/rego
```

> If your CI checks for missing license fields, missing sensitivity tags, or missing provenance records, keep local runs aligned with CI.

---

## ðŸ§© Adding a new policy

### âœ… Checklist
- [ ] Decide the **policy domain** (security / data / AI / compliance)
- [ ] Add rule(s) under `rego/` with **default deny**
- [ ] Add test coverage under `tests/`
- [ ] If needed, add policy data under `data/`
- [ ] Update [Decision contract](#ï¸-decision-contract) usage if introducing new obligations/sanitize outputs
- [ ] Document the **intent** (what risk is mitigated) + **examples** (what should pass/fail)

### âœï¸ Style conventions
- Keep packages stable (avoid renaming `package kfm.*` once published)
- Prefer clear â€œentrypointâ€ rules:
  - `kfm.security.decision`
  - `kfm.data.decision`
  - `kfm.ai.decision`
- Avoid deeply nested logicâ€”extract to `rego/lib/*`
- Return **structured** reasons (machine readable), not just strings

---

## ðŸ“Ž Examples

### 1) ðŸ“Ž AI citations requirement (evidence-first)

> Enforce: answers must include at least one citation marker (example pattern: `[12]`)

```rego
package kfm.ai

default allow_answer = false

allow_answer {
  re_match("\\[\\d+\\]", input.answer)
}
```

âœ… Recommended upgrade: return a decision object:

```rego
package kfm.ai

default decision = {
  "allow": false,
  "reasons": ["missing_citations"],
  "sanitize": {},
  "obligations": {"audit": true}
}

decision := {
  "allow": true,
  "reasons": [],
  "sanitize": {},
  "obligations": {"audit": true}
} {
  re_match("\\[\\d+\\]", input.answer)
}
```

---

### 2) ðŸ—ºï¸ Sensitive location handling (mask / round / aggregate)

Common patterns:
- round coordinates to reduce precision
- return county-level aggregates instead of exact points
- suppress fields that could deanonymize

```rego
package kfm.data

default decision = {"allow": false, "reasons": ["default_deny"], "sanitize": {}, "obligations": {"audit": true}}

decision := out {
  # allow reading public datasets
  input.resource.sensitivity == "public"
  out := {"allow": true, "reasons": [], "sanitize": {}, "obligations": {"audit": true}}
}

decision := out {
  # allow restricted dataset only for authorized roles
  input.resource.sensitivity == "restricted"
  "admin" in input.user.roles
  out := {"allow": true, "reasons": [], "sanitize": {}, "obligations": {"audit": true}}
}

decision := out {
  # for non-admins, sanitize instead of deny (optional pattern)
  input.resource.sensitivity == "restricted"
  not ("admin" in input.user.roles)
  out := {
    "allow": true,
    "reasons": ["sanitized_restricted_dataset"],
    "sanitize": {"mask_coordinates": true, "rounding_meters": 5000},
    "obligations": {"audit": true}
  }
}
```

---

### 3) ðŸ” Endpoint protection (pipeline triggers)

```rego
package kfm.security

default allow = false

# Only Admin can run ingestion / pipeline actions
allow {
  input.request.path == "/api/v1/ingest/runPipeline"
  input.request.method == "POST"
  "admin" in input.user.roles
}
```

---

## ðŸ§¾ Auditing & provenance

Policies should be **auditable** and **replayable**.

Recommended logging fields (API responsibility, policy-defined requirement):
- `request_id`
- `user_id` (or pseudonymous id if required)
- `decision.allow`
- `decision.reasons`
- `decision.sanitize`
- `policy_version` (commit SHA or bundle hash)
- `resource_id` (dataset/story/tile layer id)
- `timestamp`

âœ… Why this matters:
- If a decision is challenged later, we can identify **which exact policy** produced the decision.
- AI answers should include policy decision context as part of their provenance record.

---

## â“ FAQ

### â€œShould policies deny, or sanitize?â€
Both are valid. Prefer:
- **deny** when risk is unacceptable or requirements are missing (fail closed)
- **sanitize** when the use-case is legitimate but precision is harmful (e.g., sensitive sites)

### â€œDo we enforce policies only at runtime?â€
Noâ€”CI policy gates prevent non-compliant assets and metadata from ever shipping.

### â€œWhere does token validation happen?â€
Typically **outside** OPA (API middleware verifies token), then passes claims to OPA:
- roles
- groups
- org affiliation
- scopes

OPA decides authorization + obligations; the API executes them.

---

## ðŸ“š References (project library)
- Kansas Frontier Matrix â€” architecture, governance model, and policy-gated â€œtruth pathâ€
- KFM Technical Blueprint â€” policy-as-code approach (OPA/Rego), CI enforcement, audit/versioning patterns
- Privacy techniques â€” query auditing, inference controls, and differential privacy patterns (where needed)

> Keep this README aligned with the **real policy entrypoints** and **actual API integration points** as implementation evolves. ðŸŒ±