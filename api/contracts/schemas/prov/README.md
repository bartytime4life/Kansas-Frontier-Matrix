<!-- üìÑ File: api/contracts/schemas/prov/README.md -->

# üßæ PROV Schemas ‚Äî Provenance Contracts (KFM)

![Status](https://img.shields.io/badge/status-draft-orange)
![Contracts](https://img.shields.io/badge/contracts-first-1f6feb)
![Lineage](https://img.shields.io/badge/lineage-PROV%E2%80%91O%20(JSON%E2%80%91LD)-2ea44f)

> [!NOTE]
> **Context (docs uploaded 2026-01-12):** KFM runs a strict pipeline (**ETL ‚Üí STAC/DCAT/PROV ‚Üí Graph ‚Üí API ‚Üí UI ‚Üí Story Nodes ‚Üí Focus Mode**) where **PROV lineage is a required boundary artifact**.  
> This folder is the contract layer that makes provenance machine-checkable. ‚úÖ

---

## üéØ What this folder is

**`api/contracts/schemas/prov/`** contains the **JSON Schema contracts** for KFM‚Äôs provenance payloads ‚Äî primarily **W3C PROV-O expressed as JSON-LD**, plus **KFM profile rules** needed for:

- üß™ **Reproducible ETL + modeling runs** (determinism, seeds, parameters, run IDs)
- üßæ **Dataset publishing** (every published dataset has STAC + DCAT + PROV)
- üß† **Focus Mode + Story Nodes** (no unsourced claims; everything traceable)
- üîç **Auditing & governance** (FAIR/CARE, redaction, policy gates, CI proofs)
- üß∞ *(optional but planned)* **DevOps lineage** (GitHub PRs / CI jobs mapped to PROV) and **OpenLineage** event bridging

If it crosses a boundary (pipeline ‚Üí catalog, catalog ‚Üí graph, graph ‚Üí API), it must be **contracted** here.

---

## üß¨ What PROV means in KFM (the 3 building blocks)

KFM uses PROV‚Äôs core model:

- **üß± Entity** ‚Äî ‚Äúa thing‚Äù: dataset, raster, vector layer, table, document, model artifact, commit, config
- **‚öôÔ∏è Activity** ‚Äî ‚Äúa process‚Äù: ETL run, transformation step, model training, validation pass, merge, publish
- **üßë‚Äçü§ù‚Äçüßë Agent** ‚Äî ‚Äúan actor‚Äù: person, org, service account, pipeline runner, CI bot

‚Ä¶and connects them with relations like:

- `prov:used` (activity used an entity)
- `prov:wasGeneratedBy` (entity generated by activity)
- `prov:wasDerivedFrom` (entity derived from entity)
- `prov:wasAssociatedWith` (activity associated with agent)
- `prov:wasAttributedTo` (entity attributed to agent)

> [!IMPORTANT]
> **Non‚Äënegotiable invariant:** every ‚Äúofficial‚Äù artifact (data product, analysis output, UI-visible evidence) must have **explicit lineage** and must pass validation **before** it can power UI or narrative.

---

## üó∫Ô∏è Pipeline map (why PROV is a ‚Äúboundary artifact‚Äù)

```mermaid
flowchart LR
  A[üì• Raw Sources] --> B[üß™ ETL + Normalization]
  B --> C[üóÇÔ∏è STAC Items & Collections]
  C --> D[üìö DCAT Dataset Views]
  C --> E[üßæ PROV Lineage Bundles]
  C --> G[üß† Neo4j Graph (references catalogs)]
  G --> H[üîå API Layer (contracts + redaction)]
  H --> I[üó∫Ô∏è Map UI (React + MapLibre + optional Cesium)]
  I --> J[üìù Story Nodes (governed narratives)]
  J --> K[üîé Focus Mode (provenance-linked context)]
```

---

## üì¶ Where provenance files live vs where schemas live

- **Schemas (this folder):** `api/contracts/schemas/prov/‚Ä¶` ‚úÖ  
- **Produced lineage artifacts (data outputs):**
  - **v13 canonical:** `data/prov/‚Ä¶`
  - **legacy wording seen in earlier docs:** `data/provenance/‚Ä¶`

> [!TIP]
> If both `data/prov/` and `data/provenance/` exist during migration, choose **one canonical home** and treat the other as deprecated to avoid split-brain provenance.

---

## üóÇÔ∏è Expected layout (recommended)

> This README is the source of truth for *how this folder should evolve*.
> If some files don‚Äôt exist yet, treat them as the backlog for ‚Äúcontract-first‚Äù completion.

```text
üìÅ api/contracts/schemas/prov/
‚îú‚îÄ üìÑ README.md
‚îú‚îÄ üìÅ v1/                       # ‚úÖ stable, backwards-compatible
‚îÇ  ‚îú‚îÄ üìÑ bundle.schema.json      # PROV bundle (top-level JSON-LD document)
‚îÇ  ‚îú‚îÄ üìÑ node.entity.schema.json # Entity node rules
‚îÇ  ‚îú‚îÄ üìÑ node.activity.schema.json
‚îÇ  ‚îú‚îÄ üìÑ node.agent.schema.json
‚îÇ  ‚îú‚îÄ üìÑ relations.schema.json   # PROV relation field constraints
‚îÇ  ‚îú‚îÄ üìÑ identifiers.schema.json # ID + version rules (URN/IRI, UUID, hashes)
‚îÇ  ‚îú‚îÄ üìÑ security.schema.json    # sensitivity labels + redaction markers
‚îÇ  ‚îî‚îÄ üìÑ kfm.profile.schema.json # KFM-required fields (pointers to STAC/DCAT/etc.)
‚îî‚îÄ üìÅ vNext/                    # üöß staging for breaking changes
```

---

## ‚úÖ Contract goals (what the schema MUST guarantee)

### 1) Minimal structural validity
- JSON must be well-formed
- required top-level keys exist (e.g., `@context`, `@graph` for JSON-LD bundles)
- node types are constrained to known PROV/KFM types

### 2) KFM ‚Äúprofile‚Äù validity (KFM-specific requirements)
- every published dataset lineage bundle must:
  - point to its **STAC Item/Collection identity**
  - point to its **DCAT dataset identity**
  - include run metadata (at least a stable run ID)
  - include **inputs** and **outputs** as entities
  - include an agent attribution (human or service)

### 3) Operational integrity
- safe to ingest into Neo4j (IDs stable, links resolvable)
- safe to expose via API (redaction-ready; no sensitive leakage by default)
- deterministic/replayable runs can be proven (seed + environment captured where relevant)

---

## üè∑Ô∏è ID & versioning rules (KFM profile)

> [!IMPORTANT]
> If IDs are unstable, provenance collapses. **Stable identifiers are part of the contract.**

### Recommended identifier shapes

| Thing | Recommended ID shape | Why |
|---|---|---|
| Bundle | `urn:kfm:prov:bundle:<uuid>` | stable, shareable, unique |
| Entity | `urn:kfm:prov:entity:<uuid>` | stable node identity |
| Activity | `urn:kfm:prov:activity:<uuid>` | stable run identity |
| Agent | `urn:kfm:prov:agent:<uuid>` | stable actor identity |
| Artifact checksum | `sha256:<hex>` | immutability anchor |

> [!TIP]
> Use **content hashes** for immutable artifacts and **time-sortable UUIDs** for run IDs where event ordering matters.

### Versioning expectations

- Schemas are versioned by folder: `v1/`, `v2/`, ‚Ä¶
- **Breaking changes** ‚Üí new major folder (`v2/`)
- **Non-breaking changes** allowed in-place (e.g., add optional fields, expand enums)

> [!CAUTION]
> Renaming a required field or changing meaning of an ID field is **breaking**, even if JSON still validates.

---

## üßæ JSON-LD bundle shape (recommended)

A KFM PROV bundle is a JSON-LD document (minimal pattern):

```json
{
  "@context": {
    "prov": "http://www.w3.org/ns/prov#",
    "kfm": "https://kansasfrontiermatrix.org/ns#",
    "xsd": "http://www.w3.org/2001/XMLSchema#"
  },
  "@id": "urn:kfm:prov:bundle:01HZZZZZZZZZZZZZZZZZZZZZZZ",
  "@type": "prov:Bundle",
  "@graph": [
    {
      "@id": "urn:kfm:prov:entity:01HZZ...A",
      "@type": ["prov:Entity", "kfm:Dataset"],
      "prov:label": "Example processed dataset",
      "kfm:stacItem": "urn:kfm:stac:item:example",
      "kfm:dcatDataset": "urn:kfm:dcat:dataset:example",
      "kfm:checksum": "sha256:abc123...",
      "prov:wasGeneratedBy": { "@id": "urn:kfm:prov:activity:01HZZ...B" },
      "prov:wasAttributedTo": { "@id": "urn:kfm:prov:agent:01HZZ...C" }
    },
    {
      "@id": "urn:kfm:prov:activity:01HZZ...B",
      "@type": ["prov:Activity", "kfm:PipelineRun"],
      "prov:startedAtTime": "2025-11-01T12:00:00Z",
      "prov:endedAtTime": "2025-11-01T12:10:00Z",
      "prov:used": [
        { "@id": "urn:kfm:prov:entity:01HZZ...IN1" },
        { "@id": "urn:kfm:prov:entity:01HZZ...IN2" }
      ],
      "prov:wasAssociatedWith": { "@id": "urn:kfm:prov:agent:01HZZ...C" },
      "kfm:runId": "run_2025_11_01_0001",
      "kfm:gitCommit": "abcdef1234567890",
      "kfm:deterministic": true,
      "kfm:randomSeed": 1337
    },
    {
      "@id": "urn:kfm:prov:agent:01HZZ...C",
      "@type": ["prov:Agent", "kfm:ServiceAccount"],
      "prov:label": "kfm-pipeline-bot"
    }
  ]
}
```

### KFM-required fields (profile-level)
At minimum, KFM expects:

- `@context` and `@graph`
- at least one `prov:Entity` output with `prov:wasGeneratedBy`
- at least one `prov:Activity` run with `prov:used`
- at least one `prov:Agent` associated with the activity
- KFM linkage fields on outputs:
  - `kfm:stacItem`
  - `kfm:dcatDataset`
  - *(recommended)* `kfm:checksum`, `kfm:runId`, `kfm:gitCommit`

---

## üß™ Validation workflow (local + CI)

### Local (developer) validation checklist ‚úÖ

1. **Schema validation** (structure)
2. **JSON-LD sanity** (context + graph structure)
3. **Policy validation** (FAIR/CARE, redaction rules, licensing invariants)
4. **Graph ingest smoke test** (optional but recommended)

### Example commands (pick one stack)

**Node / AJV**
```bash
# Example (adjust paths to your repo tooling)
npx ajv-cli validate \
  -s api/contracts/schemas/prov/v1/bundle.schema.json \
  -d data/prov/**/*.jsonld
```

**Python / jsonschema**
```bash
python -m pip install jsonschema
python -m jsonschema \
  -i data/prov/example.bundle.jsonld \
  api/contracts/schemas/prov/v1/bundle.schema.json
```

> [!IMPORTANT]
> CI should fail if a dataset is published/modified **without** a valid PROV bundle.

---

## üîê Security & governance hooks (built into the contracts)

KFM‚Äôs contracts must support governance gates:

- üß∑ **Sensitivity labels** on nodes/relations (e.g., ‚Äúrestricted‚Äù, ‚Äúinternal‚Äù, ‚Äúpublic‚Äù)
- ‚úÇÔ∏è **Redaction-ready provenance** (API can downscope fields based on role/policy)
- üßæ **Auditability** (who changed what, when, with what checks)

> [!NOTE]
> A policy pack approach (OPA/Rego + Conftest) is compatible with these schemas: JSON schema handles structure; policies handle ethics, licensing, and redaction constraints.

---

## üîå API boundary expectations (how these schemas are used)

These schemas are intended to be referenced by the API contract layer:

- REST endpoints returning provenance should return **objects that validate** against the bundle schema
- GraphQL resolvers should map graph provenance to this shape (or a projection of it)
- OpenAPI should reference the schema artifacts as `$ref` targets (contract-first)

**Typical endpoint patterns (illustrative):**
- `GET /v1/datasets/{datasetId}/prov` ‚Üí PROV bundle
- `GET /v1/runs/{runId}/prov` ‚Üí run bundle
- `GET /v1/story-nodes/{id}/context` ‚Üí provenance-linked context bundle

---

## üß∞ Optional extensions (planned / supported)

### 1) CI / OpenLineage ‚Üí PROV bridge
- Treat each CI job execution as an `prov:Activity`
- Treat CI inputs (code, manifests, raw URLs) and outputs (artifacts) as `prov:Entity`
- Treat runner identity (GitHub Actions, bot) as `prov:Agent`

### 2) GitHub PR ‚Üí PROV graph integration
Map PR lifecycle events into PROV so KFM can answer:

- ‚ÄúWhich code version produced this dataset?‚Äù
- ‚ÄúWhich PR reviewed/approved the pipeline change that generated this layer?‚Äù

---

## üß© Common mistakes (and how to avoid them)

- ‚ùå **Ephemeral IDs** (random IDs regenerated on each run)  
  ‚úÖ Use stable URNs/IRIs and record hashes.

- ‚ùå **Missing inputs** (output exists, but no `prov:used`)  
  ‚úÖ Every activity must list the entities it used.

- ‚ùå **Provenance without attribution**  
  ‚úÖ Always include an agent and link it (`prov:wasAssociatedWith`, `prov:wasAttributedTo`).

- ‚ùå **Leaking sensitive details via provenance**  
  ‚úÖ Classify and redact at the contract boundary; never ‚Äúship raw‚Äù.

---

## ü§ù Contributing (schema changes)

**Before you change anything:**
- [ ] Decide if change is breaking ‚Üí create `vNext/` or `v2/`
- [ ] Add/adjust schema + update examples
- [ ] Add contract tests (fixtures that must pass/fail)
- [ ] Update any policy rules that depend on the fields
- [ ] Ensure API & pipeline validators are updated together

> [!TIP]
> Contract artifacts are ‚Äúpublic APIs‚Äù inside the repo. Treat changes like product releases.

---

## üìö Project sources & library (what informs these contracts)

### Core KFM docs (authoritative)
- Kansas Frontier Matrix (KFM) ‚Äì Comprehensive Technical Documentation  [oai_citation:0‚Ä°Kansas Frontier Matrix (KFM) ‚Äì Comprehensive Technical Documentation.docx](file-service://file-PaBDqECcJe7NbC8hvXNGDS)  
- Kansas Frontier Matrix ‚Äî Master Guide v13 (Draft)  [oai_citation:1‚Ä°MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- Audit of the Kansas Frontier Matrix (KFM) Repository  [oai_citation:2‚Ä°Audit of the Kansas Frontier Matrix (KFM) Repository.pdf](file-service://file-1RwSrWXaDb5fnJ5gZX5kS3)  
- üåü Kansas Frontier Matrix ‚Äì Latest Ideas & Future Proposals  [oai_citation:3‚Ä°üåü Kansas Frontier Matrix ‚Äì Latest Ideas & Future Proposals.docx](file-service://file-QrXwct2pX9kFpqgjtBiijR)  

### Engineering + methodology shelf (supporting)
> These docs inform *how* we capture reproducibility, modeling runs, data formats, performance, and security ‚Äî all of which should be reflected in provenance fields.

- Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf
- Understanding Statistics & Experimental Design.pdf
- think-bayes-bayesian-statistics-in-python.pdf
- regression-analysis-with-python.pdf
- Regression analysis using Python - slides-linear-regression.pdf
- graphical-data-analysis-with-r.pdf
- python-geospatial-analysis-cookbook.pdf  [oai_citation:4‚Ä°python-geospatial-analysis-cookbook.pdf](file-service://file-HT14njz1MhrTZCE7Pwm5Cu)  
- Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf
- making-maps-a-visual-guide-to-map-design-for-gis.pdf
- Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf
- webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf
- responsive-web-design-with-html5-and-css3.pdf
- PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf
- Scalable Data Management for Future Hardware.pdf  [oai_citation:5‚Ä°Scalable Data Management for Future Hardware.pdf](file-service://file-GZ8gMsQ8hxu7GWEVd3csNE)  
- concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf
- ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf
- Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf
- compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf
- Data Spaces.pdf
- Introduction to Digital Humanism.pdf
- On the path to AI Law‚Äôs prophecies and the conceptual foundations of the machine learning age.pdf
- Spectral Geometry of Graphs.pdf
- Generalized Topology Optimization for Structural Design.pdf
- A programming Books.pdf
- B-C programming Books.pdf  [oai_citation:6‚Ä°B-C programming Books.pdf](file-service://file-7V9zHZSJakZZrJAw9ASCMJ)  
- D-E programming Books.pdf
- F-H programming Books.pdf  [oai_citation:7‚Ä°F-H programming Books.pdf](file-service://file-QofzooQDG9grJwh9nFN9SY)  
- I-L programming Books.pdf  [oai_citation:8‚Ä°I-L programming Books.pdf](file-service://file-T9sYu87k1GPNNKMLddx41a)  
- M-N programming Books.pdf
- O-R programming Books.pdf  [oai_citation:9‚Ä°O-R programming Books.pdf](file-service://file-M6zCNBGmJbot7A2aaUUy9M)  
- S-T programming Books.pdf  [oai_citation:10‚Ä°S-T programming Books.pdf](file-service://file-NT32tqqzGW9RvfcNZmMH1K)  
- U-X programming Books.pdf

---

## üß≠ Next actions (if you‚Äôre implementing the schemas)

1. Create `v1/` schema files listed above (start with `bundle.schema.json`)
2. Add a small set of **fixtures**:
   - ‚úÖ minimal valid dataset bundle
   - ‚úÖ valid modeling run bundle (seed + params)
   - ‚ùå missing attribution (should fail)
   - ‚ùå missing `prov:used` (should fail)
3. Wire validation into CI so:
   - new dataset changes fail without PROV
   - policy checks fail on sensitive leaks or missing licensing pointers

üß© Once this is in place, provenance becomes a *real* API contract ‚Äî not an aspirational promise.
