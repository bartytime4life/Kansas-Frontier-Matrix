# DCAT Outbound Catalog Adapter ğŸ—‚ï¸â¡ï¸ğŸŒ  
`api/src/adapters/outbound/catalogs/dcat/`

![adapter](https://img.shields.io/badge/adapter-outbound-blue)
![spec](https://img.shields.io/badge/spec-DCAT%20(JSON--LD)-informational)
![evidence](https://img.shields.io/badge/evidence-STAC%20%2B%20DCAT%20%2B%20PROV-purple)
![governance](https://img.shields.io/badge/policy-OPA%20%2F%20Rego-brightgreen)
![gates](https://img.shields.io/badge/gates-fail--closed-critical)
![principles](https://img.shields.io/badge/principles-FAIR%20%2B%20CARE-orange)

> [!IMPORTANT]
> **KFM is catalogâ€‘driven + evidenceâ€‘first** âœ…  
> This adapter exists to ensure every published dataset has a **DCAT Dataset entry** (discovery metadata) that stays linked to **STAC** (asset metadata) and **PROV** (lineage). ğŸ§¾ğŸ§­

---

## ğŸ“Œ What this adapter is
This outbound adapter is the **DCAT publisher** for KFM. It takes **domain dataset metadata** (contracts/entities) and produces a **DCAT-compliant JSONâ€‘LD** representation:

- ğŸ“š **DCAT Dataset entries** (per dataset, version-aware)
- ğŸ—ƒï¸ An optional **DCAT Catalog** view (aggregated feed for harvesting)
- ğŸ”— **Distribution links** pointing to STAC, API endpoints, and/or downloadable artifacts
- ğŸ§¯ Output that is **policy-gated** (failâ€‘closed) and **deterministic** (stable diffs)

---

## ğŸ§  Why DCAT in KFM?
DCAT is KFMâ€™s **high-level discovery layer**:
- Itâ€™s what external portals/harvesters can index to know â€œwhat datasets exist.â€ ğŸŒ
- Itâ€™s what KFMâ€™s own UI and Focus Mode can cite for **source, license, publisher, coverage**, etc. ğŸ§¾
- It ties into the **evidence triplet**: **STAC + DCAT + PROV**. ğŸ§¬

---

## ğŸ§­ Where it sits in the pipeline
```mermaid
flowchart LR
  subgraph Data_Lifecycle["ğŸ“¦ Data lifecycle"]
    RAW["data/raw/ ğŸ“¥"] --> WORK["data/work/ ğŸ§ª"] --> PROC["data/processed/ ğŸ—„ï¸"]
  end

  PROC --> STAC["data/stac/ ğŸ›°ï¸ (Items + Collections)"]
  PROC --> DCAT["data/catalog/dcat/ ğŸ—‚ï¸ (Dataset entries + feed)"]
  PROC --> PROV["data/prov/ ğŸ§¾ (Lineage bundles)"]

  STAC --> GRAPH["Neo4j graph ğŸ•¸ï¸ (references catalogs)"]
  DCAT --> GRAPH
  PROV --> GRAPH

  GRAPH --> API["API layer ğŸ§· (auth + redaction + contracts)"]
  API --> UI["Web UI ğŸ—ºï¸ (Map + timeline)"]
  API --> FOCUS["Focus Mode ğŸ” (evidence-linked)"]
```

> [!NOTE]
> Some docs reference legacy catalog folders like `data/catalog/` + `data/provenance/`.  
> **This adapter should treat the output paths as configuration**, with sensible defaults aligned to the current repo conventions. âœ…

---

## âœ… Responsibilities
This adapter **must**:

### 1) ğŸ§¾ Produce KFM-profiled DCAT JSONâ€‘LD
- Generate a **DCAT Dataset** record for each published dataset.
- Ensure records include **required discovery fields** and **distribution links** (see below).

### 2) ğŸ”— Maintain crossâ€‘layer linkage (DCAT â†” STAC â†” PROV)
- DCAT records should point to:
  - STAC Collection / Item(s) (geospatial asset detail)
  - PROV lineage bundle (how it was produced)
  - API endpoints / download URLs (how to access)

### 3) ğŸ§± Enforce determinism + auditability
- Stable ordering of keys and arrays where practical
- Stable identifiers + version linkage
- Atomic writes (no partial files)
- Clear diffs for PR review ğŸ§‘â€âš–ï¸

### 4) ğŸ›¡ï¸ Respect governance + sensitivity rules
- Never publish metadata that violates classification / sovereignty / ethics constraints
- Fail closed under policy gates (OPA/Rego via Conftest) ğŸš«âœ…

---

## ğŸš« Nonâ€‘goals
This adapter is **not** responsible for:

- âŒ Crawling/harvesting inbound datasets (thatâ€™s intake/ETL)
- âŒ Building Neo4j graph nodes/edges (thatâ€™s graph ingestion)
- âŒ Authentication/authorization (thatâ€™s API boundary enforcement)
- âŒ UI rendering (thatâ€™s `web/`)

---

## ğŸ“¦ Output conventions
### Canonical outputs (recommended)
```text
data/
â”œâ”€â”€ ğŸ›°ï¸ stac/                           # STAC metadata layer (Collections + Items that point to assets/artifacts)
â”‚   â”œâ”€â”€ ğŸ—‚ï¸ collections/                # Dataset-level STAC Collections (extent/license/providers/links)
â”‚   â””â”€â”€ ğŸ§· items/                      # Snapshot STAC Items (time/run slices; assets + roles + hrefs)
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ catalog/                        # Discovery layer (DCAT + optional rollups for fast lookup)
â”‚   â””â”€â”€ ğŸ—‚ï¸ dcat/
â”‚       â”œâ”€â”€ ğŸ§¾ğŸ“š catalog.jsonld         # (optional, recommended) Aggregated DCAT feed/index across datasets
â”‚       â””â”€â”€ ğŸ“š datasets/               # Per-dataset (or per-version) DCAT records (preferred canonical units)
â”‚           â”œâ”€â”€ ğŸ§¾ <dataset_id>.jsonld  # One-per dataset/version: license, access, distributions, provenance pointers
â”‚           â””â”€â”€ â• â€¦                    # Additional dataset records
â”‚
â””â”€â”€ ğŸ§¬ prov/                           # Lineage bundles (PROV-O JSON-LD) linking rawâ†’workâ†’processedâ†’catalog
    â”œâ”€â”€ ğŸ§¬ğŸ§¾ <dataset_id>.prov.jsonld   # Dataset-level provenance (or run-bundled lineage) for reproducibility/audit
    â””â”€â”€ â• â€¦                            # Additional PROV bundles (per-run, per-release, per-activity as needed)
```

> [!TIP]
> Prefer **one file per dataset version** under `datasets/` + a small `catalog.jsonld` index.  
> This keeps diffs readable and makes deprecations/revisions explicit. ğŸ§©

---

## ğŸ§¾ Required fields (KFM DCAT profile baseline)
At minimum, each DCAT Dataset entry should include:

| Concern | DCAT / DCTerms field (typical) | Why it matters ğŸ§  |
|---|---|---|
| Identifier | `dct:identifier` / `@id` | Stable IDs for graph + citations |
| Title | `dct:title` | UI display + search |
| Description | `dct:description` | Discovery + context |
| Publisher | `dct:publisher` | Accountability + credit |
| Contact | `dcat:contactPoint` | Stewardship + support |
| License | `dct:license` | Legal compliance + reuse |
| Keywords/Themes | `dcat:keyword`, `dcat:theme` | Findability + concept linking |
| Temporal coverage | `dct:temporal` | Timeline filtering |
| Spatial coverage | `dct:spatial` | Map filtering |
| Distributions | `dcat:distribution` | â€œHow do I access it?â€ |
| Provenance link | `dct:provenance` and/or `prov:*` link | Traceability + reproducibility |
| Versioning | `dct:hasVersion` / `dct:isVersionOf` / `prov:wasRevisionOf` | Dataset evolution |

### ğŸ§© KFM extensions (typical)
KFM commonly extends base standards with project-specific fields. Examples (names may vary by profile):
- `kfm:dataset_id` (canonical dataset ID)
- `kfm:classification` (public/internal/restricted)
- `kfm:sovereignty` / `kfm:sensitivity` (Indigenous data governance, sensitive areas, etc.)
- `kfm:uncertainty` / `kfm:quality` indicators

> [!IMPORTANT]
> **Do not invent ad-hoc fields.**  
> If a domain needs new metadata, extend **KFM_DCAT_PROFILE.md** (and update validators) via PR. ğŸ§‘â€âš–ï¸

---

## ğŸ”— Distribution linking rules (DCAT â†’ STAC / Data / API)
A DCAT Dataset should include one or more `dcat:distribution` entries. Typical distributions:

- ğŸ›°ï¸ **STAC Collection URL** (preferred for geospatial datasets)
- ğŸ§¾ **PROV bundle URL** (lineage)
- ğŸ§· **API query endpoint** (e.g., a parameterized dataset query)
- ğŸ“¥ **Direct download URL** (GeoJSON, Parquet, COG, etc.)
- ğŸ“¦ **OCI artifact reference** (future/optional supply-chain hardened distribution)

Each `dcat:Distribution` should include as applicable:
- `dcat:accessURL` (landing/query)
- `dcat:downloadURL` (direct file)
- `dct:format` / `dcat:mediaType`
- optional: byte size, checksum, compression, etc.

---

## ğŸ›¡ï¸ Governance & policy gates
KFM uses **policy-as-code** and runs checks in CI. This adapter must be compatible with:

- âœ… **Fail-closed** validation (missing required fields => CI fails)
- âœ… License allowlists (SPDX strings, approved licenses)
- âœ… Classification propagation: **outputs must not be less restricted than inputs**
- âœ… â€œNo bypassing catalogsâ€: nothing should be used by graph/UI without boundary artifacts
- âœ… â€œNo secrets in gitâ€: ensure catalogs never embed credentials/tokens/keys

> [!CAUTION]
> **Redaction belongs at the API boundary**, but **metadata can still leak** (names, exact coordinates, locations).  
> For restricted datasets, publish only what is allowed (e.g., generalized spatial extent; distribution links requiring auth). ğŸ”’

---

## âš™ï¸ Configuration
Recommended configuration surface (names are suggestions â€” align with your repo conventions):

| Variable | Example | Purpose |
|---|---|---|
| `KFM_PUBLIC_BASE_URL` | `https://kfm.example.org` | Base for public IRIs/URLs |
| `KFM_DCAT_OUTPUT_DIR` | `data/catalog/dcat` | Where JSONâ€‘LD is written |
| `KFM_DCAT_DATASETS_DIR` | `data/catalog/dcat/datasets` | Per-dataset outputs |
| `KFM_DCAT_CATALOG_FILE` | `data/catalog/dcat/catalog.jsonld` | Aggregated feed |
| `KFM_DCAT_CONTEXT_FILE` | `docs/standards/dcat/context.json` | JSONâ€‘LD context |
| `KFM_PROFILE_DCAT` | `docs/standards/KFM_DCAT_PROFILE.md` | Profile reference |
| `KFM_POLICY_PACK_DIR` | `tools/validation/policy` | OPA/Rego policies |

---

## ğŸ§± Implementation sketch (suggested structure)
> This is a **suggested** layout â€” match what actually exists in the repo.

```text
ğŸ“¦ api/src/adapters/outbound/catalogs/dcat/
  â”œâ”€â”€ ğŸ“„ README.md
  â”œâ”€â”€ ğŸ§© mapper.py              # domain â†’ DCAT model mapping
  â”œâ”€â”€ ğŸ§¾ models.py              # typed DCAT DTOs (pydantic/dataclasses)
  â”œâ”€â”€ ğŸ§° serializer.py          # JSON-LD serialization + deterministic ordering
  â”œâ”€â”€ âœ… validator.py           # profile/schema hooks (optional)
  â”œâ”€â”€ ğŸ’¾ storage.py             # filesystem (atomic) writes
  â””â”€â”€ ğŸ”Œ adapter.py             # implements the outbound port
```

### ğŸ§· Suggested outbound port
Your application layer typically defines a port such as:

```python
from typing import Protocol
from pathlib import Path

class DcatCatalogPort(Protocol):
    def upsert_dataset(self, dataset_id: str, metadata: dict) -> Path: ...
    def remove_dataset(self, dataset_id: str) -> None: ...
    def rebuild_catalog_index(self) -> Path: ...
```

---

## ğŸ§ª Testing strategy
### Unit tests (fast)
- âœ… Mapping tests: domain metadata â†’ expected DCAT fields
- âœ… Determinism tests: same input â†’ byte-for-byte stable output
- âœ… Version linkage tests: v2 includes revision/isVersionOf links to v1

### Golden file tests (high value)
- ğŸ“¸ Snapshot known dataset outputs and diff on PRs
- ğŸ” Validate JSONâ€‘LD compaction/expansion as needed (optional)

### CI validation (required)
- âœ… Schema validation (JSON Schema / SHACL) on DCAT outputs
- âœ… Policy pack (OPA/Rego via Conftest) over catalog files

---

## ğŸ§¾ Example output (minimal DCAT Dataset JSONâ€‘LD)
<details>
<summary>ğŸ‘€ Click to expand (example)</summary>

```json
{
  "@context": {
    "dcat": "http://www.w3.org/ns/dcat#",
    "dct": "http://purl.org/dc/terms/",
    "prov": "http://www.w3.org/ns/prov#",
    "skos": "http://www.w3.org/2004/02/skos/core#",
    "xsd": "http://www.w3.org/2001/XMLSchema#",
    "kfm": "https://kfm.example.org/ns#"
  },
  "@id": "https://kfm.example.org/dataset/kfm.ks.hydrology.usgs_nwis.v1",
  "@type": "dcat:Dataset",
  "dct:identifier": "kfm.ks.hydrology.usgs_nwis.v1",
  "dct:title": "USGS NWIS Real-time Water Data (Kansas)",
  "dct:description": "Real-time river gauge measurements for Kansas stations sourced from USGS NWIS.",
  "dct:license": "https://spdx.org/licenses/CC-BY-4.0.html",
  "dcat:keyword": ["hydrology", "river gauge", "real-time"],
  "dct:publisher": {
    "@type": "foaf:Organization",
    "foaf:name": "USGS"
  },
  "dcat:distribution": [
    {
      "@type": "dcat:Distribution",
      "dcat:accessURL": "https://kfm.example.org/api/v1/query?table=river_gauge_latest",
      "dct:format": "application/json"
    },
    {
      "@type": "dcat:Distribution",
      "dcat:accessURL": "https://kfm.example.org/data/stac/collections/usgs_nwis.json",
      "dct:format": "application/json"
    },
    {
      "@type": "dcat:Distribution",
      "dcat:accessURL": "https://kfm.example.org/data/prov/kfm.ks.hydrology.usgs_nwis.v1.prov.jsonld",
      "dct:format": "application/ld+json"
    }
  ],
  "kfm:classification": "public",
  "prov:wasRevisionOf": "https://kfm.example.org/dataset/kfm.ks.hydrology.usgs_nwis.v0"
}
```
</details>

---

## ğŸ§¯ Troubleshooting
- **CI fails: â€œmissing licenseâ€** ğŸ§¾  
  Add `dct:license` and ensure it matches approved license policy.
- **Catalog diffs are noisy** ğŸ§¹  
  Ensure deterministic ordering of arrays (keywords, distributions) and stable serialization.
- **A dataset is restricted but metadata is public** ğŸ”’  
  Confirm classification rules: redact or generalize sensitive fields and require auth on distributions.
- **Graph shows â€œmystery datasetâ€** ğŸ‘»  
  Ensure DCAT entry exists *and* is linked to STAC/PROV; graph ingestion should reference catalog IDs only.

---

## ğŸ›£ï¸ Roadmap ideas (optional but aligned with KFM direction)
- ğŸ“¦ **OCI-backed distributions** (signed + attestations) for supply-chain hardened dataset artifacts
- ğŸ›°ï¸ **DCAT federation** (cross-state â€œFrontier Matricesâ€ catalog aggregation)
- ğŸ§Š **3D / AR distributions** (e.g., 3D Tiles / digital twins) for immersive layers
- ğŸ“ **DOI/ARK integration** for persistent citation of dataset versions
- ğŸŒ **DCAT-AP / DCAT-US compatibility mode** for easier harvesting by national portals

---

## ğŸ”— Related components
- ğŸ›°ï¸ `api/src/adapters/outbound/catalogs/stac/` (STAC publisher)
- ğŸ§¾ `api/src/adapters/outbound/catalogs/prov/` (PROV publisher)
- ğŸ•¸ï¸ Graph ingestion tools (catalogs â†’ Neo4j)
- ğŸ§· API contracts (dataset search, catalog endpoints)
- ğŸ—ºï¸ UI dataset panel + Focus Mode citations (consumers of DCAT metadata)

---

## âœ… Definition of done (for changes here)
- [ ] Output matches **KFM_DCAT_PROFILE** (required fields present)
- [ ] DCAT entries include **distribution links** to STAC and PROV where applicable
- [ ] Policy pack passes (fail-closed) âœ…
- [ ] Output is deterministic (stable diffs) ğŸ§Š
- [ ] No sensitive leakage (classification respected) ğŸ”

