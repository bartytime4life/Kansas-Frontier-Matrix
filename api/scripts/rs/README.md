# ğŸ›°ï¸ Remote Sensing Scripts (`api/scripts/rs`)

![KFM](https://img.shields.io/badge/KFM-Kansas%20Frontier%20Matrix-2b6cb0)
![Remote Sensing](https://img.shields.io/badge/Domain-Remote%20Sensing%20%26%20EO-0ea5e9)
![STAC](https://img.shields.io/badge/Metadata-STAC-22c55e)
![DCAT](https://img.shields.io/badge/Metadata-DCAT-16a34a)
![PROV](https://img.shields.io/badge/Lineage-W3C%20PROV-8b5cf6)
![COG](https://img.shields.io/badge/Rasters-COG%20ready-f59e0b)
![Parquet](https://img.shields.io/badge/Tables-Parquet-64748b)

> **What this folder is:** API-adjacent scripts for **Remote Sensing / Earth Observation (RS/EO)** workflows in the Kansas Frontier Matrix (KFM).  
> **What â€œdoneâ€ means:** a dataset is only â€œpublishedâ€ when the **data artifact + STAC + DCAT + PROV** boundary artifacts exist, pass validation, and are promoted atomically âœ…

---

## ğŸ§­ Quick Jump

- [ğŸ¯ Responsibilities](#-responsibilities)
- [ğŸ“¦ The KFM â€œboundary artifactsâ€ contract](#-the-kfm-boundary-artifacts-contract)
- [ğŸš€ Running scripts](#-running-scripts)
- [ğŸ§¾ Provenance-first outputs](#-provenance-first-outputs)
- [ğŸ§ª Validation checklist](#-validation-checklist)
- [ğŸ” Security, ethics, governance](#-security-ethics-governance)
- [ğŸ§© Add a new RS script](#-add-a-new-rs-script)
- [ğŸ“š Project Library (all project files)](#-project-library-all-project-files)

---

## ğŸ¯ Responsibilities

These scripts exist to turn raw RS/EO sources into **KFM-grade** products:

- ğŸ›°ï¸ **Compute derived layers** (e.g., NDVI/NDWI/NDBI, composites, classifications, change/anomaly products)
- ğŸ§± **Export in scalable formats** (COGs for rasters, Parquet/GeoParquet for tables, GeoJSON for small vectors)
- ğŸ§¾ **Emit catalogs + lineage**  
  - **STAC** item/collection
  - **DCAT** dataset JSON-LD
  - **PROV** lineage bundle (machine-readable provenance)
- ğŸ§  **Make results â€œAPI-readyâ€** (clean contracts, stable identifiers, safe defaults, optional redaction)

---

## ğŸ“¦ The KFM â€œboundary artifactsâ€ contract

KFM treats metadata + provenance as *first-class outputs*.

### âœ… Nonâ€‘negotiables (for every RS script)

- [ ] **Declared Inputs/Outputs** (no hidden side effects; outputs are discoverable & repeatable)
- [ ] **Deterministic & reproducible** (same inputs + same code commit â‡’ same results)
- [ ] **Schema & bounds validation** (Kansas bounds where appropriate; sane ranges; correct CRS)
- [ ] **License + attribution captured** (source, author, terms, citations)
- [ ] **Provenance emitted** (W3C PROV with run parameters + code version + inputs used)
- [ ] **Atomic publish** (stage â†’ validate â†’ publish; no half-published datasets)
- [ ] **Idempotency** (support `--run-id` / `--idempotency-key` patterns so replays are safe)

---

## ğŸ—‚ï¸ Suggested folder map ğŸ§©

> Your actual contents may vary â€” this is the recommended structure to keep scripts composable and testable.

```text
ğŸ“¦ api/
 â””â”€ ğŸ§ª scripts/
    â””â”€ ğŸ›°ï¸ rs/
       â”œâ”€ ğŸ“„ README.md                 ğŸ‘ˆ you are here
       â”œâ”€ ğŸ§  _lib/                     (shared helpers)
       â”‚  â”œâ”€ gee.py                    (Earth Engine helpers, optional)
       â”‚  â”œâ”€ raster.py                 (COG/warp/QA helpers)
       â”‚  â”œâ”€ stac.py                   (STAC emit/validate helpers)
       â”‚  â”œâ”€ dcat.py                   (DCAT JSON-LD emit helpers)
       â”‚  â””â”€ prov.py                   (PROV bundle emit helpers)
       â”œâ”€ ğŸ§¾ pipelines/                (script entrypoints)
       â”‚  â”œâ”€ ndvi_county.py
       â”‚  â”œâ”€ ndwi_water.py
       â”‚  â”œâ”€ landcover_dynamic_world.py
       â”‚  â””â”€ change_detection.py
       â””â”€ ğŸ§ª tests/                    (fast checks; schema + smoke)
```

---

## ğŸš€ Running scripts

### 1) Discover whatâ€™s available

```bash
ls api/scripts/rs
# or
find api/scripts/rs -maxdepth 2 -type f -name "*.py"
```

### 2) Run a script (two common patterns)

```bash
# pattern A: direct file execution
python api/scripts/rs/pipelines/<script>.py --help

# pattern B: module execution (preferred if packaged)
python -m api.scripts.rs.pipelines.<script> --help
```

### 3) A realistic example (NDVI by county)

```bash
python api/scripts/rs/pipelines/ndvi_county.py \
  --aoi data/processed/boundaries/kansas_counties.geojson \
  --start 2022-07-01 \
  --end 2022-07-31 \
  --sensor landsat \
  --out data/work/rs/ndvi_county__2022-07.parquet \
  --publish
```

> ğŸ’¡ Tip: **Default to â€œdry-runâ€** behavior unless `--publish` is explicitly set.

---

## âš™ï¸ Configuration (env vars) ğŸ§°

| Variable | Purpose | Example |
|---|---|---|
| `KFM_ENV` | runtime environment | `dev` / `prod` |
| `KFM_DATA_DIR` | base data directory | `data` |
| `KFM_RAW_DIR` | raw inputs root | `data/raw` |
| `KFM_WORK_DIR` | staging/work outputs | `data/work` |
| `KFM_PROCESSED_DIR` | published outputs | `data/processed` |
| `KFM_STAC_DIR` | STAC output root | `data/stac` |
| `KFM_DCAT_DIR` | DCAT output root | `data/catalog/dcat` |
| `KFM_PROV_DIR` | provenance output root | `data/prov` |
| `KFM_RUN_ID` | stable run UUID (optional) | `2026-01-12T...` |
| `KFM_IDEMPOTENCY_KEY` | safe replay key (optional) | `rs-ndvi-ks-2022-07` |
| `KFM_POSTGIS_URL` | PostGIS connection (optional) | `postgresql://...` |
| `KFM_NEO4J_URL` | Graph connection (optional) | `neo4j://...` |
| `KFM_GEE_PROJECT` | Earth Engine project (optional) | `my-gee-project` |
| `KFM_GEE_CREDENTIALS` | EE creds path (optional) | `/secrets/gee.json` |

---

## ğŸ§¾ Provenance-first outputs

KFM wants outputs that are **traceable years later**.

### ğŸ“Œ Expected outputs per published dataset

```text
ğŸ“¦ data/processed/rs/<dataset_id>/        âœ… final â€œuser-facingâ€ artifacts
 â”œâ”€ ğŸ—ºï¸ <dataset_id>.tif                   (COG raster)  OR
 â”œâ”€ ğŸ§® <dataset_id>.parquet               (table)       OR
 â””â”€ ğŸ§© <dataset_id>.geojson               (small vector)

ğŸ“¦ data/stac/items/rs/<dataset_id>.json   âœ… STAC Item
ğŸ“¦ data/catalog/dcat/<dataset_id>.jsonld  âœ… DCAT Dataset
ğŸ“¦ data/prov/<dataset_id>.jsonld          âœ… PROV lineage bundle
```

### ğŸ§¬ Minimal PROV fields we expect

- **Entities:** inputs (source collections, AOIs), outputs (COG/Parquet), intermediate work artifacts (optional)
- **Activities:** â€œcompute NDVIâ€, â€œmask cloudsâ€, â€œreduce time seriesâ€, â€œexportâ€, â€œvalidateâ€, â€œpublishâ€
- **Agents:** script name + git SHA, user or CI bot, optional external service (Earth Engine)

<details>
  <summary>ğŸ§¾ Example: â€œscript contract headerâ€ (copy/paste template)</summary>

```yaml
# --- kfm:script ---
id: rs__ndvi_county__monthly
title: "NDVI by county (monthly)"
description: >
  Computes per-county NDVI summary statistics for Kansas using a chosen sensor
  and date range, then publishes a Parquet table + STAC/DCAT/PROV.
inputs:
  - aoi: "data/processed/boundaries/kansas_counties.geojson"
  - sensor: "landsat|sentinel2"
  - date_range: ["YYYY-MM-DD", "YYYY-MM-DD"]
  - compute_backend: "local|gee"
outputs:
  - data: "data/processed/rs/<dataset_id>/<dataset_id>.parquet"
  - stac_item: "data/stac/items/rs/<dataset_id>.json"
  - dcat: "data/catalog/dcat/<dataset_id>.jsonld"
  - prov: "data/prov/<dataset_id>.jsonld"
validation:
  - "schema: parquet columns/types"
  - "bounds: Kansas"
  - "license: required"
determinism:
  - "run_id + git_sha + params â†’ stable dataset_id"
publish:
  - "atomic promote from data/work â†’ data/processed"
# --- /kfm:script ---
```

</details>

---

## ğŸ§ª Validation checklist

### ğŸ” Fast-fail checks (before heavy compute)

- âœ… parameters parse + defaults
- âœ… AOI loads + valid geometry
- âœ… date range sane (start < end)
- âœ… backend creds present if required (e.g., GEE)
- âœ… output location writable

### ğŸ§  RS-specific QA (after compute, before publish)

- âœ… nodata ratio under threshold (configurable)
- âœ… expected band names / column names
- âœ… value ranges plausible (e.g., NDVI âˆˆ [-1, 1])
- âœ… spatial bounds not outside Kansas (unless explicitly allowed)
- âœ… CRS recorded correctly in outputs + STAC

### ğŸ“¦ Publish gate

- âœ… data artifact exists (COG/Parquet/etc.)
- âœ… STAC Item exists + references assets
- âœ… DCAT exists + matches dataset id + license
- âœ… PROV exists + references run + inputs + script version
- âœ… publish is atomic (no partial datasets)

---

## ğŸ›°ï¸ Earth Engine patterns (optional backend)

> If you use GEE here, keep the pipeline **server-side**, avoid pulling huge data to the client, and treat exports as **jobs**.

**Recommended patterns:**
- âœ… process small AOIs first (debug quickly)
- âœ… avoid `.getInfo()` loops on large collections
- âœ… record dataset IDs, date ranges, and parameters in metadata
- âœ… export results + bring back only the product (COG/table) + metadata

---

## ğŸ§Š Raster performance notes (COGs + tiles)

Remote sensing rasters get big fast. Preferred output strategies:

- ğŸ§± **COGs** for random access (HTTP range requests)
- ğŸ§© **pre-generated tiles** for common baselayers / heavy rasters
- ğŸ—ƒï¸ keep **raw** vs **processed** separate (and donâ€™t accidentally â€œpublishâ€ raw)
- âš¡ parallelize by scene, year, or tile (within backend limits)

---

## ğŸ” Security, ethics, governance

### ğŸ›¡ï¸ Security basics (donâ€™t skip)
- ğŸ”‘ secrets only via env vars / secret mounts (never commit credentials)
- ğŸ§¼ sanitize all user-controlled inputs (paths, dataset IDs, SQL parameters)
- ğŸ§¾ log with a **trace id** (and keep logs clean of secrets)

### ğŸ¤ Ethical data handling (FAIR/CARE vibes)
- ğŸ§­ be explicit about license, attribution, and reuse conditions
- ğŸ§¯ protect sensitive locations / PII: aggregate, redact, or restrict outputs when needed
- ğŸ” keep provenance transparent: *who/what/when/how produced the dataset*

### ğŸ§¬ Supply chain & automation (CI-friendly)
- âœ… prefer workflows that open PRs for changes (human review)
- âœ… attach SBOM/provenance attestations where supported
- âœ… keep a â€œkill switchâ€ config for automated executors

---

## ğŸ§© Add a new RS script

### âœ… Checklist (copy/paste)

- [ ] Create entrypoint in `api/scripts/rs/pipelines/<name>.py`
- [ ] Add a **contract header** (inputs/outputs/validation/determinism)
- [ ] Implement `--dry-run` and `--publish`
- [ ] Write to `data/work/rs/...` first
- [ ] Validate (schema/bounds/ranges/license)
- [ ] Emit STAC/DCAT/PROV to canonical folders
- [ ] Promote atomically to `data/processed/rs/...`
- [ ] Add a smoke test in `api/scripts/rs/tests/`
- [ ] Document the dataset ID scheme + examples in this README or a sibling doc

---

## ğŸ“š Project Library (all project files)

> These are the â€œreference shelfâ€ documents available in this project. RS scripts should borrow patterns from them (performance, metadata rigor, modeling discipline, security hygiene, and human-centered governance).

<details>
  <summary>ğŸ›°ï¸ Remote Sensing, EO, Geospatial</summary>

- **Cloud-Based Remote Sensing with Google Earth Engine â€“ Fundamentals and Applications** ğŸ“˜  
- **python-geospatial-analysis-cookbook** ğŸğŸ—ºï¸  
- **making-maps-a-visual-guide-to-map-design-for-gis** ğŸ¨ğŸ—ºï¸  
- **Mobile Mapping: Space, Cartography and the Digital** ğŸ“±ğŸ§­  

</details>

<details>
  <summary>ğŸ—ƒï¸ Data, Databases, Scale, Systems</summary>

- **PostgreSQL Notes for Professionals** ğŸ˜  
- **Scalable Data Management for Future Hardware** âš¡ğŸ§   
- **Data Spaces** ğŸŒğŸ“¦  

</details>

<details>
  <summary>ğŸ“Š Statistics, ML, Analytics</summary>

- **Understanding Statistics & Experimental Design** ğŸ§ªğŸ“ˆ  
- **regression-analysis-with-python** ğŸğŸ“‰  
- **Regression analysis using Python (slides)** ğŸï¸ğŸ“‰  
- **think-bayes-bayesian-statistics-in-python** ğŸ§ ğŸ²  
- **graphical-data-analysis-with-r** ğŸ“ŠğŸ§¾  

</details>

<details>
  <summary>ğŸ§ª Modeling, Simulation, Optimization, Graphs</summary>

- **Scientific Modeling and Simulation: A Comprehensive NASA-Grade Guide** ğŸš€ğŸ§ª  
- **Generalized Topology Optimization for Structural Design** ğŸ—ï¸ğŸ§©  
- **Spectral Geometry of Graphs** ğŸ•¸ï¸ğŸ“  

</details>

<details>
  <summary>ğŸ§‘â€âš–ï¸ Ethics, Humanism, Policy</summary>

- **Introduction to Digital Humanism** ğŸ¤ğŸŒ  
- **Principles of Biological Autonomy** ğŸ§¬ğŸ§   
- **On the path to AI Lawâ€™s prophecies... (conceptual foundations of the ML age)** âš–ï¸ğŸ¤–  

</details>

<details>
  <summary>ğŸ›¡ï¸ Security & Hardening</summary>

- **ethical-hacking-and-countermeasures-secure-network-infrastructures** ğŸ›¡ï¸ğŸ•µï¸  
- **Gray Hat Python (2009)** ğŸğŸ§¨  
- **compressed-image-file-formats-jpeg-png-gif-xbm-bmp** ğŸ–¼ï¸ğŸ—œï¸  

</details>

<details>
  <summary>ğŸŒ UI / Web / Visualization</summary>

- **responsive-web-design-with-html5-and-css3** ğŸ“±ğŸ’»  
- **webgl-programming-guide-interactive-3d-graphics-programming-with-webgl** ğŸ§ŠğŸ–¥ï¸  

</details>

<details>
  <summary>ğŸ“š Programming Compendiums (Aâ€“X)</summary>

- **A programming Books** ğŸ“š A  
- **B-C programming Books** ğŸ“š Bâ€“C  
- **D-E programming Books** ğŸ“š Dâ€“E  
- **F-H programming Books** ğŸ“š Fâ€“H  
- **I-L programming Books** ğŸ“š Iâ€“L  
- **M-N programming Books** ğŸ“š Mâ€“N  
- **O-R programming Books** ğŸ“š Oâ€“R  
- **S-T programming Books** ğŸ“š Sâ€“T  
- **U-X programming Books** ğŸ“š Uâ€“X  

</details>

<details>
  <summary>ğŸ“œ Core KFM docs</summary>

- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation** ğŸ§­ğŸ“˜  
- **ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals** ğŸ’¡ğŸ§¬  

</details>

---

## ğŸ§· Glossary (tiny but useful)

- **RS/EO**: Remote Sensing / Earth Observation  
- **COG**: Cloud-Optimized GeoTIFF (efficient partial reads)  
- **STAC**: SpatioTemporal Asset Catalog (geospatial metadata standard)  
- **DCAT**: Data Catalog Vocabulary (catalog/discovery standard)  
- **PROV**: W3C Provenance model (lineage/audit trails)  
- **AOI**: Area of Interest  
- **Zonal stats**: aggregations over polygons (counties, watersheds, etc.)

---

## âœ… Done meansâ€¦

A script is â€œKFM-completeâ€ when it can be run by anyone (with the same inputs), produces the same outputs, passes validation, and publishes data + STAC + DCAT + PROV as a cohesive, auditable dataset. ğŸ§¾âœ¨

