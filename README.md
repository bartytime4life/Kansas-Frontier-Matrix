# Kansas Frontier Matrix System (KFM) ğŸ§­ğŸ—ºï¸  
> A **provenance-first, evidence-backed** â€œliving atlasâ€ of Kansas â€” where **data, maps, narratives, and AI** stay traceable to sources.

![Status](https://img.shields.io/badge/status-alpha-orange)
![Scope](https://img.shields.io/badge/focus-geospatial%20%2B%20historical%20knowledge-informational)
![Core%20Principle](https://img.shields.io/badge/non--negotiable-provenance--first-success)
![Build](https://img.shields.io/badge/CI-quality%20gates%20%2B%20security%20scans-blue)
![UI](https://img.shields.io/badge/UI-React%20%7C%20MapLibre%20%7C%20Cesium%20(optional)-informational)
![API](https://img.shields.io/badge/API-FastAPI%20(OpenAPI)%20%2B%20GraphQL-informational)
![Graph](https://img.shields.io/badge/Graph-Neo4j%20(semantic%20layer)-informational)

---

## ğŸ“Œ Table of Contents
- [What this is](#-what-this-is)
- [The Trust Contract](#-the-trust-contract)
- [What you can do with KFM](#-what-you-can-do-with-kfm)
- [Architecture at a glance](#-architecture-at-a-glance)
- [Repository layout](#-repository-layout)
- [Quickstart](#-quickstart)
- [Data lifecycle](#-data-lifecycle)
- [Story Nodes + Focus Mode](#-story-nodes--focus-mode)
- [APIs](#-apis)
- [Governance, ethics, and safety](#-governance-ethics-and-safety)
- [Tooling](#-tooling)
- [Roadmap](#-roadmap)
- [Contributing](#-contributing)
- [Project library](#-project-library)
- [Citation & reuse](#-citation--reuse)

---

## ğŸŒ¾ What this is
**Kansas Frontier Matrix (KFM)** is an open-source **geospatial + historical knowledge system** (a â€œliving atlasâ€ of Kansas). It:

- ingests **heterogeneous sources** (rasters, vectors, documents, time series, etc.)
- publishes governed metadata catalogs:
  - **STAC** for spatial assets
  - **DCAT** for dataset discovery
  - **PROV** for lineage (how outputs were produced)
- builds a semantically-structured **Neo4j knowledge graph** (people â‡„ places â‡„ events â‡„ documents â‡„ datasets)
- serves evidence through **contracted APIs** into a combined **map + narrative UI**
- supports governed storytelling via **Story Nodes**, and evidence-backed Q&A via **Focus Mode**

> ğŸ§  KFM is designed so **every narrative claim can be traced to versioned evidence**, and **every derived data product has explicit lineage**.

---

## ğŸ”’ The Trust Contract
These are the projectâ€™s â€œguardrailsâ€ â€” if we violate them, weâ€™re not building KFM anymore.

### âœ… Nonâ€‘negotiables
- **Pipeline ordering is absolute**  
  **ETL â†’ STAC/DCAT/PROV catalogs â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**
- **API boundary rule**  
  The **frontend must never query Neo4j directly** â€” access is only through the governed API layer (contracts + redaction).
- **Provenance-first**  
  If it shows up in the UI (or in an AI answer), it must be traceable back to cataloged sources and provable processing â€” no â€œmystery layers.â€
- **Deterministic, idempotent ETL**  
  Pipelines are config-driven, reproducible, and safe to re-run.
- **Evidence-first narrative**  
  No unsourced content in Story Nodes or Focus Mode. AI-generated text must be clearly labeled and accompanied by provenance/confidence metadata.
- **Governance & sovereignty are explicit**  
  FAIR/CARE principles, licensing clarity, sensitivity flags, and review gates are part of the definition of done.

---

## âœ¨ What you can do with KFM
### ğŸ—ºï¸ Map + Timeline exploration
- Toggle datasets like layers in a GIS (vector + raster + tiles)
- Navigate time with a **timeline slider**
- Click features for details, charts, and provenance
- 2D via **MapLibre**, optional 3D via **Cesium** (including **3D Tiles** streaming)

### ğŸ” Evidence discovery (not just keyword search)
- Use the graph to discover related datasets, events, people, places, and documents
- Run relationship-aware queries (e.g., â€œevents involving X near Y during Zâ€)

### ğŸ“– Story Nodes (governed, machine-ingestible storytelling)
- Narratives authored in **Markdown**, synchronized to map state via **JSON step configs**
- Stories can hyperlink entities (people/places/events) into graph-backed panels
- Designed for educators, historians, researchers, and public storytelling

### ğŸ§  Focus Mode (AI assistant with receipts)
- Ask questions about the current map view, place, time window, or dataset
- Answers are **graph-grounded** and **citation-backed**
- The system can fetch dataset provenance to cite sources rather than guessing

---

## ğŸ—ï¸ Architecture at a glance
```mermaid
flowchart LR
  subgraph Data
    A["Raw Sources"] --> B["ETL + Normalization"]
    B --> C["STAC Items + Collections"]
    C --> D["DCAT Dataset Views"]
    C --> E["PROV Lineage Bundles"]
  end

  C --> G["Neo4j Graph (references back to catalogs)"]
  G --> H["API Layer (contracts + redaction)"]
  H --> I["Map UI â€” React Â· MapLibre Â· (optional) Cesium"]
  I --> J["Story Nodes (governed narratives)"]
  J --> K["Focus Mode (provenance-linked context bundle)"]
```

> ğŸ§© Every stage consumes the outputs of the previous stage â€” so you can trace a public-facing story sentence back to the exact input sources and transformations.

---

## ğŸ—‚ï¸ Repository layout
This repo follows a **contract-first + evidence-first** structure (v13 blueprint). The key idea: every subsystem has **one canonical home** (no duplicate â€œmysteryâ€ folders).

```text
ğŸ“ .github/
  â””â”€ ğŸ“ workflows/                         # CI, security scans, validation gates

ğŸ“ data/
  â”œâ”€ ğŸ“ stac/
  â”‚  â”œâ”€ ğŸ“ collections/                    # STAC Collections
  â”‚  â””â”€ ğŸ“ items/                          # STAC Items
  â”œâ”€ ğŸ“ catalog/
  â”‚  â””â”€ ğŸ“ dcat/                           # DCAT outputs (JSON-LD)
  â”œâ”€ ğŸ“ prov/                               # PROV bundles (per run / per dataset)
  â”œâ”€ ğŸ“ graph/
  â”‚  â”œâ”€ ğŸ“ csv/                             # Graph import CSV exports
  â”‚  â””â”€ ğŸ“ cypher/                          # Optional post-import scripts
  â”œâ”€ ğŸ“ <domain>/                           # hydrology/, air-quality/, historical/, etc.
  â”‚  â”œâ”€ ğŸ“ raw/                             # Raw source data (read-only)
  â”‚  â”œâ”€ ğŸ“ work/                            # Intermediate outputs
  â”‚  â”œâ”€ ğŸ“ processed/                       # Final processed outputs
  â”‚  â”œâ”€ ğŸ“ mappings/                        # Datasetâ†’STAC/DCAT/PROV mapping notes (optional)
  â”‚  â””â”€ ğŸ“„ README.md                        # Domain runbook
  â””â”€ ğŸ“„ README.md                           # General data catalog README

ğŸ“ docs/
  â”œâ”€ ğŸ“„ MASTER_GUIDE_v13.md                 # Canonical pipeline & structure reference
  â”œâ”€ ğŸ“„ glossary.md
  â”œâ”€ ğŸ“ architecture/                       # Blueprints, ADRs, diagrams
  â”œâ”€ ğŸ“ standards/                          # STAC/DCAT/PROV profiles, repo standards
  â”œâ”€ ğŸ“ templates/                          # Story Node + API contract templates
  â”œâ”€ ğŸ“ governance/                         # ethics, sovereignty, review gates
  â””â”€ ğŸ“ reports/
     â””â”€ ğŸ“ story_nodes/
        â”œâ”€ ğŸ“ draft/
        â””â”€ ğŸ“ published/
           â””â”€ ğŸ“ <story_slug>/
              â”œâ”€ ğŸ“„ story.md
              â””â”€ ğŸ“ assets/

ğŸ“ schemas/                                  # JSON Schemas for STAC/DCAT/PROV/story/ui/telemetry
  â”œâ”€ ğŸ“ stac/
  â”œâ”€ ğŸ“ dcat/
  â”œâ”€ ğŸ“ prov/
  â”œâ”€ ğŸ“ storynodes/
  â”œâ”€ ğŸ“ ui/
  â””â”€ ğŸ“ telemetry/

ğŸ“ src/
  â”œâ”€ ğŸ“ pipelines/                          # ETL jobs, transforms (domain pipelines)
  â”œâ”€ ğŸ“ graph/                              # Graph build code (ontology bindings, ingest, constraints)
  â””â”€ ğŸ“ server/                             # API boundary + contracts + redaction

ğŸ“ web/                                      # Frontend app (React + MapLibre + optional Cesium)
ğŸ“ tools/                                    # Validators, utilities, devops helpers
  â””â”€ ğŸ“ rs/                                  # Rust tooling (fast validators/tilers/etc.)

ğŸ“ mcp/                                      # Methods & Computational Experiments (runs, notebooks, model cards)
ğŸ“ tests/                                    # Unit/integration tests
ğŸ“ releases/                                 # Versioned release bundles, manifests, SBOMs

ğŸ“„ README.md                                 # You are here ğŸ™‚
ğŸ“„ LICENSE
ğŸ“„ CITATION.cff
ğŸ“„ CONTRIBUTING.md
ğŸ“„ SECURITY.md
ğŸ“„ CHANGELOG.md
ğŸ“„ docker-compose.yml
ğŸ“„ .env.example
```

---

## âš¡ Quickstart
> ğŸ§° KFM is intentionally modular. The fastest path is Docker for dependencies + local dev for API/UI.

### 1) Prerequisites
- **Docker + Docker Compose** (recommended)
- **Python 3.11+** (API + pipelines)
- **Node.js 18+** (web UI)
- **Rust stable** (optional, for `tools/rs`)
- Optional but common in geospatial stacks: **GDAL**, **PostgreSQL/PostGIS** tooling

### 2) Bring up core services (recommended)
```bash
cp .env.example .env
docker compose up -d
```

### 3) Run the API (example)
```bash
cd src/server
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
uvicorn kfm_server.main:app --reload
```

### 4) Run the web app (example)
```bash
cd web
npm install
npm run dev
```

### 5) Verify
- API docs (OpenAPI/Swagger): `http://localhost:8000/docs` *(or your configured port)*
- UI: `http://localhost:5173` *(or your configured port)*

> ğŸ§­ For the canonical workflows and directory rules, start with **docs/MASTER_GUIDE_v13.md**.

---

## ğŸ“¦ Data lifecycle
KFM treats data like code: **it must compile** (validate) before it can ship.

### Required staging (always)
- `data/<domain>/raw/` â†’ **ingest only** (read-only sources)
- `data/<domain>/work/` â†’ intermediate transforms
- `data/<domain>/processed/` â†’ published outputs

### Required boundary artifacts (before â€œpublishedâ€)
Every published dataset must generate:
- **STAC** records  
  `data/stac/collections/` and `data/stac/items/`
- **DCAT** dataset entry (JSON-LD)  
  `data/catalog/dcat/`
- **PROV** lineage bundle  
  `data/prov/`

### â€œNo mystery layersâ€
If it can be toggled in the UI, it must have:
- a data contract (source, license, spatial/temporal extent, processing steps, etc.)
- validators passing in CI
- provenance that the API/Focus Mode can cite

---

## ğŸ“– Story Nodes + Focus Mode
### Story Nodes = governed narrative as data
A Story Node is typically:
- `story.md` (Markdown narrative, citations, annotations)
- `story.json` (step-by-step map/timeline instructions)
- `/assets/` (images, figures, supporting media)

**Story Node rules (high level):**
- Every factual claim has a citation to cataloged sources
- Key entities (people/places/events/documents) reference stable graph IDs
- Facts vs interpretation are clearly separated

### Focus Mode = AI answers with evidence
Focus Mode:
- relies on the graph as the contextual knowledge base
- surfaces references and provenance for datasets, events, and documents
- is guarded by â€œhard gateâ€ rules to prevent unsourced claims from entering the system

---

## ğŸ”Œ APIs
### REST (FastAPI)
- Contracted endpoints with **OpenAPI/Swagger** schemas
- Intended for both UI consumption and external integrations

### GraphQL
- Best for relationship-heavy queries (people â‡„ events â‡„ places)
- The resolver layer should guard expensive queries (depth limits, pagination, etc.)

> ğŸ§± API boundary rule reminder: UI uses APIs; APIs talk to PostGIS + Neo4j + storage.

---

## ğŸ›¡ï¸ Governance, ethics, and safety
KFM is built to be **adoptable by institutions** (schools, libraries, agencies) without compromising trust:

- **FAIR**: findable, accessible, interoperable, reusable metadata
- **CARE / sovereignty**: explicitly consider sensitive data and community impact
- **Licensing clarity**: dataset licenses are first-class metadata (no ambiguity)
- **Review gates**: contributions are validated (schemas, provenance completeness, link integrity, security scans)
- **Security posture**: secrets scanning, dependency scanning, responsible disclosure

---

## ğŸ§° Tooling
### `tools/` (validators + helpers)
Typical responsibilities:
- validate dataset contracts (STAC/DCAT/PROV + KFM extensions)
- run link checks, schema checks, policy checks
- generate graph import artifacts
- produce release manifests + SBOMs

### `tools/rs/` (Rust tooling ğŸš€)
Rust is ideal for:
- fast validation on large catalogs
- tiling / packaging utilities
- batch transforms that benefit from speed and memory safety

> ğŸ”§ See `tools/rs/README.md` for Rust-specific workflows and crates.

### `mcp/` (Methods & Computational Experiments)
A governed space for:
- reproducible notebooks
- model cards
- experiment runs and outputs that must also be cataloged + provenanced if promoted to â€œpublishedâ€ datasets

---

## ğŸ§­ Roadmap
A few directionally consistent goals (summarized from project planning):

### Near-term
- âœ… **Dataset schema + validator** (treat metadata â€œlike codeâ€)
- âœ… **CI catalog QA gates** (prevent broken provenance, missing licenses, invalid geometries/CRS)
- ğŸ›°ï¸ **Remote sensing pipeline templates** (including Earth Engine-backed workflows)
- ğŸ—ºï¸ **Map + timeline MVP hardening** (performance, layer ergonomics, accessibility)

### Medium-term
- ğŸ§± Story Builder GUI (make Story Nodes accessible to non-devs)
- ğŸ“¦ Offline â€œeducation packsâ€ / PWA mode
- ğŸ§© Richer evidence panels (uncertainty/completeness surfaced in UI)

### Long-term
- ğŸŒ Federation (â€œFrontier Matrixâ€ blueprint for other regions, interoperable hubs)
- ğŸ“š DOI-backed releases for data snapshots + research workflows (Binder/Colab integrations)

---

## ğŸ¤ Contributing
KFM welcomes contributions from **developers and domain experts** (historians, educators, scientists, cartographers).

### Contribution types (how to think about changes)
- **(A) New data / domain**: add raw sources + pipeline + publish STAC/DCAT/PROV
- **(C) Graph enrichment**: new entity types, ontology bindings, new relationships
- **(D) API endpoint/service**: contract-first (schemas first), then implementation + tests
- **(E) UI layer/feature**: register layers; ensure provenance is visible in UI

### Definition of done (practical)
A contribution is â€œdoneâ€ when:
- schemas/contracts validate
- provenance is complete (STAC/DCAT/PROV)
- tests pass
- governance requirements are addressed (FAIR/CARE, licensing, sensitivity)
- CI is green âœ…

---

## ğŸ“š Project library
This repo is deliberately â€œresearch-backed.â€ The PDFs below inform architecture, modeling, geospatial pipelines, UI, governance, and security posture.

<details>
  <summary><b>ğŸ“¦ Library index (click to expand)</b></summary>

### ğŸ§ª Scientific modeling, statistics, and inference
- *Scientific Modeling and Simulation â€” A Comprehensive NASAâ€‘Grade Guide*  
- *Regression Analysis with Python* (book)
- *Regression analysis using Python* (slides: linear regression)
- *Understanding Statistics & Experimental Design*
- *Think Bayes: Bayesian Statistics in Python*
- *Graphical Data Analysis with R*

### ğŸ›°ï¸ GIS, mapping, remote sensing, and 3D geospatial
- *Cloudâ€‘Based Remote Sensing with Google Earth Engine â€” Fundamentals and Applications*
- *Python Geospatial Analysis Cookbook*
- *Making Maps â€” A Visual Guide to Map Design for GIS*
- *Mobile Mapping: Space, Cartography and the Digital*
- *Archaeological 3D GIS*
- *WebGL Programming Guide â€” Interactive 3D Graphics with WebGL*

### ğŸ—„ï¸ Databases, performance, and scalable data systems
- *PostgreSQL Notes for Professionals*
- *Database Performance at Scale*
- *Scalable Data Management for Future Hardware*
- *Data Spaces* (FAIR governance + architecture framing)

### ğŸ§  Graph theory + structure discovery
- *Spectral Geometry of Graphs* (useful for clustering/centrality thinking in knowledge graphs)

### ğŸ§© Design, systems thinking, and humanistic framing
- *Introduction to Digital Humanism*
- *Principles of Biological Autonomy*

### âš–ï¸ Law, evidence integrity, and ML governance
- *On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age*

### ğŸ›¡ï¸ Security & secure engineering references
- *Ethical Hacking and Countermeasures â€” Secure Network Infrastructures* (defense-oriented)
- *Gray Hat Python* (security awareness / defensive understanding)

### ğŸ–¼ï¸ Media formats and compression
- *Compressed Image File Formats (JPEG/PNG/GIF/XBM/BMP)*

### ğŸ“š Programming mega-packs (multi-book compilations)
- *A programming Books*
- *Bâ€‘C programming Books*
- *Dâ€‘E programming Books*
- *Fâ€‘H programming Books*
- *Iâ€‘L programming Books*
- *Mâ€‘N programming Books*
- *Oâ€‘R programming Books*
- *Sâ€‘T programming Books*
- *Uâ€‘X programming Books*

### ğŸ—ï¸ Specialized modeling references
- *Generalized Topology Optimization for Structural Design*
</details>

---

## ğŸ§¾ Citation & reuse
- For software citation, use **CITATION.cff** (and consider publishing a DOI for releases).
- For data reuse, always consult:
  - dataset **license** fields in metadata
  - **PROV** lineage bundles for processing steps
  - source attribution requirements (no â€œunknown provenanceâ€ data is accepted)

> ğŸ“Œ If youâ€™re building research outputs on top of KFM, prefer citing a **versioned data release** (snapshot) so results remain reproducible.

---

### ğŸ§­ Final note
KFMâ€™s goal is bigger than â€œa map.â€ Itâ€™s a **community knowledge system**: open, evidence-driven, and built to scale across time, disciplines, and data typesâ€”without losing trust.