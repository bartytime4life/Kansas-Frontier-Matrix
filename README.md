# ğŸŒ¾ğŸ—ºï¸ Kansas Matrix System (KFM) â€” *Provenanceâ€‘First Living Atlas*

![Status](https://img.shields.io/badge/status-alpha-orange)
![Provenance](https://img.shields.io/badge/provenance-first-6f42c1)
![Docker](https://img.shields.io/badge/docker-compose-blue)
![Python](https://img.shields.io/badge/python-3.11%2B-informational)
![Node](https://img.shields.io/badge/node-18%2B-informational)
![GIS](https://img.shields.io/badge/gis-PostGIS%20%7C%20Neo4j-success)
![AI](https://img.shields.io/badge/AI-Ollama%20(Local%20LLM)-brightgreen)

**KFM is a geospatial knowledge + modeling platform** that fuses **maps**, **datasets**, **historical narratives**, and **AI-assisted analysis** into a single governed system â€” where every output has a traceable â€œ**map behind the map**.â€ âœ…

> [!IMPORTANT]
> **KFM is not a black-box GIS.** Nothing â€œmagically appearsâ€ in the UI without passing through deterministic pipelines, catalogs, governance checks, and contracted APIs.

---

## âœ¨ What you get

- ğŸ§± **Pipeline â†’ Catalog â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode** (strict ordering)
- ğŸ§¾ **Evidence metadata**: STAC / DCAT / PROV boundary artifacts
- ğŸ§­ **Interactive web atlas**: Map + timeline + narrative reading
- ğŸ§  **Focus Mode AI** (local LLM via Ollama) with **citations** + policy enforcement
- ğŸ›¡ï¸ **Policy-as-code** (OPA/Rego) for access control, redaction, publication gates, and AI rules

---

## âš¡ Quick Start (Docker Compose)

> [!TIP]
> This is the recommended path for a consistent dev environment (DBs, API, UI, and optional AI services).

### 1) Prereqs âœ…
- Docker Desktop (or Docker Engine) + Docker Compose plugin  
- Git  
- (Optional) Ollama installed locally if you want **local** Focus Mode AI

### 2) Boot the stack ğŸš€
```bash
# from repo root
cp .env.example .env   # if present
docker compose up --build
# (older installs: docker-compose up --build)
```

### 3) Open the services ğŸŒ
- ğŸ§ª API docs (Swagger): `http://localhost:8000/docs`
- ğŸ—ºï¸ Web UI: `http://localhost:3000`
- ğŸ•¸ï¸ Neo4j Browser: `http://localhost:7474`
- ğŸ˜ PostGIS: `localhost:5432`

> [!WARNING]
> If you have port conflicts, the usual suspects are: **5432**, **7474**, **7687**, **8000**, **3000**.  
> Update your `.env` and/or `docker-compose.yml` accordingly.

---

## ğŸ§© Architecture at a glance

```mermaid
flowchart LR
  subgraph Data["ğŸ“¦ Data lifecycle"]
    A["ğŸ§± Raw Sources"] --> B["ğŸ§ª ETL + Normalization"]
    B --> C["ğŸ—‚ï¸ STAC Items + Collections"]
    C --> D["ğŸ“œ DCAT Dataset Views"]
    C --> E["ğŸ”— PROV Lineage Bundles"]
  end

  C --> G["ğŸ•¸ï¸ Neo4j Graph (links back to catalogs)"]
  G --> H["ğŸŒ API Layer (contracts + redaction)"]
  H --> I["ğŸ—ºï¸ Map UI â€” React Â· MapLibre Â· (optional) Cesium"]
  I --> J["ğŸ“ Story Nodes (governed narratives)"]
  J --> K["ğŸ§  Focus Mode (provenance-linked context bundle)"]
```

---

## ğŸ§­ Nonâ€‘negotiable invariants (donâ€™t fight these)

> [!CAUTION]
> These are **hard rules**. If you break them, KFM becomes un-auditable.

1. **Pipeline ordering is absolute**  
   **ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**
2. **API boundary rule**  
   The UI **must never** query PostGIS/Neo4j directly â€” only through the governed API.
3. **Provenance First**  
   No dataset, narrative claim, or AI answer is â€œvalidâ€ without traceable sources.

---

## ğŸ—‚ï¸ Repo layout (v13+ canonical homes)

```text
ğŸ“ .
â”œâ”€â”€ ğŸ“¦ data/
â”‚   â”œâ”€â”€ ğŸ§ª raw/<domain>/                 # immutable-ish source snapshots
â”‚   â”œâ”€â”€ ğŸ§° work/<domain>/                # intermediate pipeline outputs
â”‚   â”œâ”€â”€ âœ… processed/<domain>/           # final published outputs (evidence artifacts)
â”‚   â”œâ”€â”€ ğŸ—‚ï¸ stac/
â”‚   â”‚   â”œâ”€â”€ collections/                 # STAC collections
â”‚   â”‚   â””â”€â”€ items/                       # STAC items
â”‚   â”œâ”€â”€ ğŸ§¾ catalog/
â”‚   â”‚   â””â”€â”€ dcat/                        # DCAT JSON-LD catalog entries
â”‚   â””â”€â”€ ğŸ”— prov/                         # PROV lineage bundles
â”œâ”€â”€ ğŸ§  src/
â”‚   â”œâ”€â”€ ğŸ§ª pipelines/                    # deterministic ETL jobs (domain pipelines)
â”‚   â”œâ”€â”€ ğŸ•¸ï¸ graph/                        # graph build/migrations/sync tooling
â”‚   â””â”€â”€ ğŸŒ server/
â”‚       â”œâ”€â”€ contracts/                   # OpenAPI / GraphQL SDL / schema contracts
â”‚       â””â”€â”€ ...                          # API implementation (REST/GraphQL)
â”œâ”€â”€ ğŸ—ºï¸ web/                              # React UI (MapLibre configs, layers, components)
â”œâ”€â”€ ğŸ›¡ï¸ policy/                           # OPA/Rego policy-as-code (data + AI + access)
â”œâ”€â”€ ğŸ§¬ schemas/                          # JSON Schemas (STAC/DCAT/PROV/story nodes/etc.)
â”œâ”€â”€ ğŸ“š docs/
â”‚   â”œâ”€â”€ ğŸ›ï¸ architecture/                 # system design docs, ADRs, blueprints
â”‚   â”œâ”€â”€ ğŸ§· standards/                    # governed standards + profiles
â”‚   â”œâ”€â”€ ğŸ§© templates/                    # doc/story/api templates
â”‚   â”œâ”€â”€ ğŸ“’ data/<domain>/                # domain runbooks + notes
â”‚   â””â”€â”€ ğŸ“ reports/story_nodes/
â”‚       â”œâ”€â”€ ğŸ§ª draft/                    # WIP narratives
â”‚       â””â”€â”€ âœ… published/                 # released narratives (folder-per-story)
â”œâ”€â”€ ğŸ§ª tests/                             # unit + integration tests
â”œâ”€â”€ ğŸ§° tools/                             # validation + helper utilities (if present)
â””â”€â”€ ğŸ§« mcp/                               # methods & computational experiments (optional)
```

> [!NOTE]
> If you see legacy folders (e.g., `api/`, `pipelines/`, `src/api/`), treat them as **migration targets** into the canonical homes above.

---

## ğŸ§± Core subsystems (how the pieces fit)

### ğŸ“¦ Data & Pipelines (`src/pipelines/`)
- Deterministic ETL transforms **raw** â†’ **processed** outputs
- Pipelines must be **idempotent** (re-running shouldnâ€™t create duplicate â€œtruthâ€)
- Outputs must generate boundary artifacts before â€œpublicationâ€:
  - ğŸ—‚ï¸ STAC records
  - ğŸ§¾ DCAT dataset entries
  - ğŸ”— PROV lineage bundles

### ğŸ•¸ï¸ Knowledge Graph (`src/graph/`)
- Neo4j stores **relationships** across people, places, events, documents, datasets
- Graph nodes should always reference back to catalog + provenance IDs

### ğŸŒ API Boundary (`src/server/`)
- FastAPI-style service boundary (REST and/or GraphQL)
- **Contract-first** development:
  - define/extend schemas & contracts first (`src/server/contracts/`)
  - implement resolvers/controllers second
  - add tests + (if needed) redaction rules

### ğŸ—ºï¸ Web UI (`web/`)
- React UI is a **pure client**
- It renders what the API returns, and surfaces provenance in legends/popovers/tooltips
- Map layers must cite their underlying evidence sources

### ğŸ“ Story Nodes (`docs/reports/story_nodes/`)
Story Nodes are â€œ**machine-ingestible storytelling**â€:
- Every claim must be backed by citations/provenance
- Entities should link to stable graph IDs
- Facts vs interpretation must be distinguishable (especially with AI assistance)

### ğŸ§  Focus Mode (AI)
- AI must operate **through approved tools/APIs** (never direct DB access)
- AI must return **answers with citations**
- AI outputs are subject to governance policy checks (redaction, disallowed content, sensitive topics)

---

## ğŸ§ª Common developer tasks

### Run tests âœ…
```bash
docker compose exec api pytest
```

### Run a pipeline (example) ğŸ§ª
```bash
docker compose exec api python src/pipelines/<domain>/run.py
```

### Seed sample data (if included) ğŸŒ±
```bash
docker compose exec api python scripts/init_sample_data.py
```

### Explore APIs ğŸ”
- Swagger: `http://localhost:8000/docs`
- If enabled, GraphQL: `http://localhost:8000/graphql`

---

## ğŸ›¡ï¸ Governance & policy (OPA/Rego)

KFM encodes governance rules as **versioned policy-as-code** in `policy/`:
- âœ… publication gates (metadata required, licenses required, provenance required)
- ğŸ” access control + redaction (e.g., sensitive datasets)
- ğŸ§  AI behavior constraints (citations required, refusal paths, sensitive info blocking)

> [!TIP]
> Treat governance like code: propose changes by PR, review them, test them, version them.

---

## ğŸ¤ Contributing

We welcome contributions â€” **as long as they preserve provenance**. ğŸ™Œ

### âœ… Contribution checklist
- [ ] Deterministic pipeline (or doc-only change) with repeatable steps
- [ ] STAC/DCAT/PROV artifacts produced/updated where applicable
- [ ] Graph + API + UI changes follow the canonical ordering
- [ ] Policies updated if you introduce new sensitivity or access rules
- [ ] Tests added/updated (unit + integration where relevant)
- [ ] Documentation updated (domain runbooks, templates, or architecture notes)

> [!IMPORTANT]
> If youâ€™re adding a new dataset/domain: start at `data/raw/<domain>/` and add a runbook at `docs/data/<domain>/README.md`.

---

## ğŸ“š Key docs (start here)

- ğŸ“˜ `docs/MASTER_GUIDE_v13.md` â€” canonical structure + rules of the road  
- ğŸ›ï¸ `docs/architecture/` â€” blueprints, diagrams, ADRs  
- ğŸ§· `docs/standards/` â€” STAC/DCAT/PROV profiles + governance standards  
- ğŸ§© `docs/templates/` â€” governed templates (Story Nodes, API changes, etc.)

---

## ğŸ—ºï¸ Roadmap (high level)

<details>
  <summary>Click to expand ğŸ”®</summary>

- ğŸ§  More robust Focus Mode tool-use + provenance bundles
- ğŸ§­ Stronger redaction + sensitivity tiers (policy-driven)
- ğŸ›°ï¸ More domains (remote sensing, surveys, archival corpora, simulation outputs)
- ğŸ§± Better contract validation + schema versioning automation
- ğŸŒ Public â€œevidence explorerâ€ experience (downloadable + citable artifacts)

</details>

---

## ğŸ“„ License

ğŸ“Œ **TBD** â€” add a `LICENSE` file and update this section once selected.

---

## ğŸ†˜ Troubleshooting (fast fixes)

- ğŸ§± **DB not ready** â†’ re-run `docker compose up` and check logs  
- ğŸ” **Hot reload not working** â†’ verify volume mounts for `web/src` and server code  
- ğŸš« **Ports busy** â†’ stop the conflicting service or remap ports in `.env` / compose  
- ğŸ§  **Ollama not reachable** â†’ ensure `ollama serve` is running and the API can reach `11434`  