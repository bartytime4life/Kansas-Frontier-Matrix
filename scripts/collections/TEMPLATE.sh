#!/usr/bin/env bash
#
# TEMPLATE — Collection builder for Kansas-Frontier-Matrix
# -----------------------------------------------------------------------------
# Copy this file to scripts/collections/<your_collection>.sh and customize
# the TODO sections. This template enforces a consistent, reproducible
# fetch → transform → load (STAC) → validate → render workflow.
#
# Usage:
#   ./scripts/collections/<your_collection>.sh build
#   ./scripts/collections/<your_collection>.sh fetch|transform|load|validate|render|clean
#
# Notes:
# - Keep outputs deterministic; log every step; fail fast on errors.
# - Prefer open formats: COG for rasters, GeoJSON/PMTiles for vectors.
# - Include provenance: source URLs, license, time/bbox/CRS in STAC.
# - Wire into Makefile and CI (stac-validate) once stable.

set -euo pipefail

# ----------------------------- CONFIG (EDIT) ---------------------------------

# Collection identifiers (STAC)
COLLECTION_ID="${COLLECTION_ID:-TEMPLATE}"        # TODO: set e.g., "hazards_drought"
COLLECTION_TITLE="${COLLECTION_TITLE:-Template Collection}"  # Human title
COLLECTION_DESC="${COLLECTION_DESC:-Template collection generated by TEMPLATE.sh}"

# Data domains (choose one or both)
IS_RASTER="${IS_RASTER:-false}"    # "true" or "false"
IS_VECTOR="${IS_VECTOR:-true}"     # "true" or "false"

# Source endpoints (one or more). You can also point to local files in data/raw/
SOURCE_URLS=(
  # TODO: add one or more URLs (HTTP, S3, ArcGIS REST export URL, etc.)
  # "https://example.org/path/to/data.geojson"
  # "https://example.org/path/to/raster.tif"
)

# Temporal coverage (ISO8601). If per-item varies, you can override later.
START_DATETIME="${START_DATETIME:-1900-01-01T00:00:00Z}"   # TODO
END_DATETIME="${END_DATETIME:-1900-12-31T23:59:59Z}"       # TODO

# Spatial metadata
CRS_OUT="${CRS_OUT:-EPSG:4326}"            # Standardize to WGS84
BBOX_OUT="${BBOX_OUT:--102.051,36.993,-94.588,40.003}"  # KS default, override if needed

# Licensing/provenance
LICENSE="${LICENSE:-Public Domain}"         # TODO: specify exact license if required
PROVIDER="${PROVIDER:-Unknown Source}"      # e.g., "NOAA NCEI", "KGS", etc.

# Paths (keep consistent with repo layout)
ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
RAW_DIR="${RAW_DIR:-$ROOT_DIR/data/raw/$COLLECTION_ID}"
PROC_DIR="${PROC_DIR:-$ROOT_DIR/data/processed/$COLLECTION_ID}"
COG_DIR="${COG_DIR:-$ROOT_DIR/data/cogs/$COLLECTION_ID}"
PMTILES_DIR="${PMTILES_DIR:-$ROOT_DIR/data/tiles/$COLLECTION_ID}"
STAC_ITEMS_DIR="${STAC_ITEMS_DIR:-$ROOT_DIR/stac/items/$COLLECTION_ID}"
STAC_COLLECTIONS_DIR="${STAC_COLLECTIONS_DIR:-$ROOT_DIR/stac/collections}"
STAC_COLLECTION_FILE="${STAC_COLLECTION_FILE:-$STAC_COLLECTIONS_DIR/${COLLECTION_ID}.json}"

# Tools (override via env if you use specific versions)
JQ_BIN="${JQ_BIN:-jq}"
CURL_BIN="${CURL_BIN:-curl -L --fail}"
OGR2OGR_BIN="${OGR2OGR_BIN:-ogr2ogr}"
GDALINFO_BIN="${GDALINFO_BIN:-gdalinfo}"
GDALWARP_BIN="${GDALWARP_BIN:-gdalwarp}"
RIO_BIN="${RIO_BIN:-rio}"  # rasterio / rio-cogeo
TIPPECANOE_BIN="${TIPPECANOE_BIN:-tippecanoe}"
PMTILES_BIN="${PMTILES_BIN:-pmtiles}"   # e.g., "pmtiles convert" if using PMTiles CLI
STAC_VALIDATE_BIN="${STAC_VALIDATE_BIN:-stac-validator}"

# --------------------------- LOGGING / UTILITIES ------------------------------

RED=$'\033[1;31m'; GREEN=$'\033[1;32m'; YELLOW=$'\033[1;33m'; BLUE=$'\033[1;34m'; NC=$'\033[0m'

log()   { echo -e "${BLUE}[$COLLECTION_ID]${NC} $*"; }
ok()    { echo -e "${GREEN}[$COLLECTION_ID✔]${NC} $*"; }
warn()  { echo -e "${YELLOW}[$COLLECTION_ID!]${NC} $*"; }
fail()  { echo -e "${RED}[$COLLECTION_ID✖]${NC} $*"; exit 1; }

require_cmd() { command -v "$1" >/dev/null 2>&1 || fail "Missing dependency: $1"; }

trap 'fail "Aborted (line $LINENO)"' INT TERM
set -o errtrace
trap 'fail "Error on line $LINENO"' ERR

# ------------------------------ PREREQUISITES --------------------------------

check_deps() {
  require_cmd bash
  require_cmd $JQ_BIN
  require_cmd $CURL_BIN
  $IS_VECTOR && require_cmd $OGR2OGR_BIN || true
  $IS_RASTER && { require_cmd $GDALINFO_BIN; require_cmd $GDALWARP_BIN; require_cmd $RIO_BIN; } || true
  # Optional:
  command -v $TIPPECANOE_BIN >/dev/null 2>&1 || warn "tippecanoe not found (vector tiling optional)"
  command -v $PMTILES_BIN >/dev/null 2>&1 || warn "pmtiles not found (PMTiles optional)"
  require_cmd $STAC_VALIDATE_BIN
}

ensure_dirs() {
  mkdir -p "$RAW_DIR" "$PROC_DIR" "$COG_DIR" "$PMTILES_DIR" "$STAC_ITEMS_DIR" "$STAC_COLLECTIONS_DIR"
}

# ------------------------------ FETCH (RAW) ----------------------------------

fetch() {
  check_deps
  ensure_dirs
  if [ ${#SOURCE_URLS[@]} -eq 0 ]; then
    warn "No SOURCE_URLS defined; assuming local raw files present in $RAW_DIR"
    return 0
  fi

  for url in "${SOURCE_URLS[@]}"; do
    local fn="$RAW_DIR/$(basename "${url%%\?*}")"
    log "Downloading: $url → $fn"
    $CURL_BIN "$url" -o "$fn"
    ok "Fetched $(basename "$fn")"
  done
}

# ------------------------------ TRANSFORM ------------------------------------

# RASTER → COG example (edit as needed)
transform_raster_to_cog() {
  local in_raster="$1"
  local out_cog="$2"

  log "Raster → COG: $(basename "$in_raster") → $(basename "$out_cog")"
  # 1) Reproject to CRS_OUT
  local reproj="$PROC_DIR/$(basename "${in_raster%.*}")_${CRS_OUT//:/_}.tif"
  $GDALWARP_BIN -t_srs "$CRS_OUT" -r bilinear -of GTiff "$in_raster" "$reproj"

  # 2) Create COG with overviews
  $RIO_BIN cogeo create "$reproj" "$out_cog" --overview-level 5 --web-optimized
  ok "COG created: $(basename "$out_cog")"
}

# VECTOR → GeoJSON example (edit as needed)
transform_vector_to_geojson() {
  local in_vector="$1"
  local out_json="$2"

  log "Vector → GeoJSON: $(basename "$in_vector") → $(basename "$out_json")"
  $OGR2OGR_BIN -f GeoJSON -t_srs "$CRS_OUT" "$out_json" "$in_vector"
  ok "GeoJSON created: $(basename "$out_json")"
}

# VECTOR → PMTiles (optional)
tile_vector_to_pmtiles() {
  local in_json="$1"
  local out_pmt="$2"
  local layer="${3:-layer}"

  if ! command -v $TIPPECANOE_BIN >/dev/null 2>&1; then
    warn "tippecanoe not available; skipping tiles"
    return 0
  fi
  if ! command -v $PMTILES_BIN >/dev/null 2>&1; then
    warn "pmtiles not available; skipping PMTiles"
    return 0
  fi

  log "Vector → PMTiles: $(basename "$in_json") → $(basename "$out_pmt")"
  local mbtiles="$PROC_DIR/${layer}.mbtiles"
  $TIPPECANOE_BIN -o "$mbtiles" -l "$layer" --drop-densest-as-needed "$in_json"
  $PMTILES_BIN convert "$mbtiles" "$out_pmt"
  ok "PMTiles created: $(basename "$out_pmt")"
}

transform() {
  check_deps
  ensure_dirs

  # TODO: enumerate your inputs found in $RAW_DIR and route by extension.
  shopt -s nullglob
  for f in "$RAW_DIR"/*; do
    case "${f,,}" in
      *.tif|*.tiff|*.sid)
        $IS_RASTER || { warn "Found raster but IS_RASTER=false: $f"; continue; }
        transform_raster_to_cog "$f" "$COG_DIR/$(basename "${f%.*}").tif"
        ;;
      *.shp|*.gpkg|*.kml|*.gdb|*.csv)
        $IS_VECTOR || { warn "Found vector but IS_VECTOR=false: $f"; continue; }
        transform_vector_to_geojson "$f" "$PROC_DIR/$(basename "${f%.*}").geojson"
        ;;
      *.geojson|*.json)
        $IS_VECTOR || { warn "Found vector but IS_VECTOR=false: $f"; continue; }
        # Optionally normalize CRS even if already GeoJSON
        transform_vector_to_geojson "$f" "$PROC_DIR/$(basename "${f%.*}")_wgs84.geojson"
        ;;
      *)
        warn "Skipping unrecognized input: $f"
        ;;
    esac
  done
}

# ------------------------------ STAC (LOAD) ----------------------------------

write_collection_json() {
  # Creates/overwrites the STAC Collection JSON for this dataset family.
  # If you maintain collections manually, you can skip this or adjust to append.
  log "Writing STAC Collection: $STAC_COLLECTION_FILE"
  cat > "$STAC_COLLECTION_FILE" <<EOF
{
  "type": "Collection",
  "stac_version": "1.0.0",
  "id": "${COLLECTION_ID}",
  "description": "${COLLECTION_DESC}",
  "license": "${LICENSE}",
  "title": "${COLLECTION_TITLE}",
  "extent": {
    "spatial": { "bbox": [[${BBOX_OUT}]] },
    "temporal": { "interval": [["${START_DATETIME}", "${END_DATETIME}"]] }
  },
  "links": []
}
EOF
  ok "Collection JSON written"
}

# Create a STAC Item for a single asset
write_item_json() {
  local item_id="$1"        # e.g., file stem
  local asset_href="$2"     # relative path from repo root
  local asset_type="$3"     # e.g., "application/geo+json" or "image/tiff; application=geotiff; profile=cloud-optimized"

  local out_item="$STAC_ITEMS_DIR/${item_id}.json"
  log "Writing STAC Item: ${out_item#$ROOT_DIR/}"

  mkdir -p "$STAC_ITEMS_DIR"
  cat > "$out_item" <<EOF
{
  "type": "Feature",
  "stac_version": "1.0.0",
  "id": "${item_id}",
  "collection": "${COLLECTION_ID}",
  "properties": {
    "start_datetime": "${START_DATETIME}",
    "end_datetime": "${END_DATETIME}",
    "providers": [{"name": "${PROVIDER}"}]
  },
  "bbox": [${BBOX_OUT}],
  "geometry": null,
  "assets": {
    "data": {
      "href": "${asset_href}",
      "type": "${asset_type}",
      "roles": ["data"]
    }
  },
  "links": [
    { "rel": "collection", "href": "../../collections/${COLLECTION_ID}.json", "type": "application/json" }
  ]
}
EOF
  ok "Item JSON written: ${item_id}.json"
}

load_stac() {
  check_deps
  ensure_dirs
  write_collection_json

  # Register transformed outputs as STAC Items.
  # Rasters (COGs)
  if $IS_RASTER; then
    shopt -s nullglob
    for cog in "$COG_DIR"/*.tif; do
      local name="$(basename "${cog%.*}")"
      # HREF relative to repo root for portability
      local href="data/cogs/${COLLECTION_ID}/${name}.tif"
      write_item_json "$name" "$href" "image/tiff; application=geotiff; profile=cloud-optimized"
    done
  fi

  # Vectors (GeoJSON) + optional PMTiles
  if $IS_VECTOR; then
    shopt -s nullglob
    for gj in "$PROC_DIR"/*.geojson; do
      local name="$(basename "${gj%.*}")"
      local href="data/processed/${COLLECTION_ID}/${name}.geojson"
      write_item_json "$name" "$href" "application/geo+json"

      # Optional: build PMTiles for web perf
      if command -v $TIPPECANOE_BIN >/dev/null 2>&1 && command -v $PMTILES_BIN >/dev/null 2>&1; then
        local pmt="$PMTILES_DIR/${name}.pmtiles"
        tile_vector_to_pmtiles "$gj" "$pmt" "${COLLECTION_ID}"
        # Optionally add a second asset to the same item (left simple here)
      fi
    done
  fi
}

# ------------------------------ VALIDATE -------------------------------------

validate() {
  check_deps
  local ok_count=0
  local err_count=0

  # Validate collection
  log "Validating STAC Collection: ${STAC_COLLECTION_FILE#$ROOT_DIR/}"
  if $STAC_VALIDATE_BIN "$STAC_COLLECTION_FILE"; then ok_count=$((ok_count+1)); else err_count=$((err_count+1)); fi

  # Validate items
  shopt -s nullglob
  for item in "$STAC_ITEMS_DIR"/*.json; do
    log "Validating STAC Item: ${item#$ROOT_DIR/}"
    if $STAC_VALIDATE_BIN "$item"; then ok_count=$((ok_count+1)); else err_count=$((err_count+1)); fi
  done

  if [ "$err_count" -gt 0 ]; then
    fail "Validation failed for $err_count document(s). Passed: $ok_count."
  fi
  ok "Validation passed for $ok_count document(s)"
}

# ------------------------------ RENDER CONFIG --------------------------------

render() {
  # Regenerate the MapLibre config from STAC items (requires project CLI if available).
  # Replace with your actual command (e.g., `kgt render-config ...`), or call Make target.
  if command -v kgt >/dev/null 2>&1; then
    log "Rendering web/app.config.json from STAC"
    kgt render-config --stac "$ROOT_DIR/stac/items" --output "$ROOT_DIR/web/app.config.json" --pretty
    ok "Rendered web/app.config.json"
  else
    warn "kgt not found; skipping render. Use: make site-config"
  fi
}

# ------------------------------ CLEAN ----------------------------------------

clean() {
  log "Cleaning outputs for $COLLECTION_ID"
  rm -rf "$PROC_DIR" "$COG_DIR" "$PMTILES_DIR" "$STAC_ITEMS_DIR"
  ok "Clean complete"
}

# ------------------------------ DISPATCH -------------------------------------

usage() {
  cat <<EOF
Usage: $(basename "$0") <command>

Commands:
  fetch        Download raw inputs to $RAW_DIR
  transform    Convert raw → standardized outputs (COG/GeoJSON/PMTiles)
  load         Write STAC items + collection JSON
  validate     Run stac-validator on collection + items
  render       Update web/app.config.json from STAC (if kgt available)
  build        fetch → transform → load → validate → render
  clean        Remove generated outputs for this collection

Environment overrides:
  COLLECTION_ID, COLLECTION_TITLE, COLLECTION_DESC
  IS_RASTER=true|false, IS_VECTOR=true|false
  CRS_OUT, BBOX_OUT, START_DATETIME, END_DATETIME
  RAW_DIR, PROC_DIR, COG_DIR, PMTILES_DIR, STAC_ITEMS_DIR, STAC_COLLECTIONS_DIR

EOF
}

cmd="${1:-}"
case "$cmd" in
  fetch)      fetch ;;
  transform)  transform ;;
  load)       load_stac ;;
  validate)   validate ;;
  render)     render ;;
  build)
    fetch
    transform
    load_stac
    validate
    render
    ;;
  clean)      clean ;;
  ""|help|-h|--help) usage ;;
  *) fail "Unknown command: $cmd" ;;
esac

