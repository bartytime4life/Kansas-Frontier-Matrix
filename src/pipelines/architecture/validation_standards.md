---
title: "ğŸ§ª Kansas Frontier Matrix â€” Pipeline Validation Standards (Diamondâ¹ Î© / CrownâˆÎ© Ultimate Certified)"
path: "src/pipelines/architecture/validation_standards.md"
version: "v10.3.1"
last_updated: "2025-11-13"
review_cycle: "Quarterly / FAIR+CARE Council"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../../../releases/v10.3.0/sbom.spdx.json"
manifest_ref: "../../../../releases/v10.3.0/manifest.zip"
telemetry_ref: "../../../../releases/v10.3.0/focus-telemetry.json"
telemetry_schema: "../../../../schemas/telemetry/pipelines-validation-standards-v1.json"
governance_ref: "../../../../docs/standards/governance/ROOT-GOVERNANCE.md"
license: "CC-BY 4.0"
mcp_version: "MCP-DL v6.3"
---

<div align="center">

# ğŸ§ª **Kansas Frontier Matrix â€” Pipeline Validation Standards**  
`src/pipelines/architecture/validation_standards.md`

**Purpose:**  
Define the **FAIR+CARE-aligned, MCP-governed validation requirements** for all pipelines in the Kansas Frontier Matrix (KFM).  
These standards ensure **correctness, ethical compliance, reproducibility, provenance integrity, and schema coherence** across all ingestion, ETL, AI, geospatial, metadata, and publishing pipelines.

</div>

---

## ğŸ“˜ Overview

Every KFM pipeline must pass a rigorous sequence of **validation gates**, ensuring:

- Data integrity  
- Schema compliance  
- Provenance correctness  
- FAIR+CARE ethical safeguards  
- Geospatial validity  
- AI explainability checks  
- Sustainability logging  
- Reproducibility across versions  

Validation is **non-optional**. Any failure blocks further processing and prevents publication to:

- STAC/DCAT  
- Neo4j knowledge graph  
- Processed datasets  
- Focus Mode AI layer  
- Public-facing APIs & UI

---

## ğŸ—‚ï¸ Directory Context

~~~~~text
src/pipelines/architecture/
â”œâ”€â”€ reliable-pipelines.md
â”œâ”€â”€ validation_standards.md      # This document
â”œâ”€â”€ pipeline_patterns.md
â”œâ”€â”€ metadata_lineage.md
â”œâ”€â”€ governance_contracts.md
â””â”€â”€ telemetry_spec.md
~~~~~

---

## ğŸ§© Validation Architecture (Indented Mermaid)

~~~~~mermaid
flowchart TD
  A["Pipeline Execution<br/>extract Â· transform Â· load"] --> B["Validation Layer"]
  B --> C["Schema Validation<br/>JSONSchema Â· Pydantic Â· Avro"]
  B --> D["FAIR+CARE Checks<br/>consent Â· sovereignty Â· sensitivity"]
  B --> E["Geospatial Validation<br/>GDAL Â· GeoJSON Â· STAC geometry"]
  B --> F["AI Validation<br/>explainability Â· drift Â· bias"]
  B --> G["Metadata Validation<br/>STAC/DCAT Â· PROV-O Â· CIDOC"]
  G --> H["Integrity Validation<br/>checksums Â· hashes"]
  H --> I["Governance Ledger Update<br/>immutable record"]
~~~~~

---

## ğŸ§¬ 1. Schema Validation Standards

All pipeline outputs **must** validate against declared schema definitions.

### Allowed Schema Engines

| Engine | Use Case |
|--------|----------|
| **JSON Schema Draft 2020-12** | STAC Items, DCAT Datasets, metadata contracts |
| **Pydantic v2** | Python ETL model validation |
| **Avro / Parquet Schema** | Tabular, GeoParquet, long-term archiving |
| **PROV-O & CIDOC CRM Mappings** | Provenance, historical/archival datasets |

### Mandatory Checks

- Required fields present  
- Correct type enforcement  
- Allowed enumerations respected  
- GeoJSON geometry validity  
- Temporal coverage standards  
- Multi-asset STAC item consistency  
- No silent coercion (strict mode only)

**Failure â†’ Pipeline Halted.**

---

## ğŸ§  2. FAIR+CARE Validation Standards

All datasets must satisfy FAIR+CARE ethical requirements:

### FAIR Checks

| Requirement | Rule |
|------------|------|
| **Findable** | STAC/DCAT metadata must be complete; identifiers stable |
| **Accessible** | Formats must be open (CSV, GeoJSON, GeoParquet, COG, NetCDF) |
| **Interoperable** | CRS, timestamps, media types must follow standards |
| **Reusable** | License + provenance must be explicit |

### CARE Checks

| Category | Rule |
|----------|------|
| **Collective Benefit** | Data contributes to shared community value |
| **Authority to Control** | Indigenous or sensitive data must include governance review |
| **Responsibility** | Clear attribution, no decontextualized use |
| **Ethics** | Masking of sensitive coordinates; sovereign restrictions applied |

CARE flags required:

```
care_label âˆˆ ["public", "sensitive", "restricted"]
```

---

## ğŸŒ 3. Geospatial Validation Standards

All geospatial data must pass:

### Raster Validation

- COG compliance  
- Internal tiling verified  
- GDAL `info` error-free  
- Correct nodata definitions  
- CRS metadata present & valid  

### Vector Validation

- Valid GeoJSON geometries (OGR checks)  
- No self-intersections  
- Bounding box correctness  
- MultiPolygon winding-order normalization  

### STAC Spatial Validation

- BBOX matches asset geometry  
- Geometry validity = TRUE  
- Temporal/spatial extents consistent  

---

## ğŸ¤– 4. AI Validation Standards (Focus Mode v2.4)

Required for pipelines generating:

- Summaries  
- Embeddings  
- Story Nodes  
- Explainability metadata  
- Predictive layers  

### Mandatory Checks

| Check | Description |
|--------|-------------|
| **Explainability** | SHAP or LIME scores must be generated |
| **Bias Scan** | Subgroup bias checks (Î”F1, Î”Recall) |
| **Drift Detection** | Compare embedding distributions vs past releases |
| **Provenance** | Model + dataset versions must be logged |

Outputs must link to:

```
docs/models/<model_name>_card.md
```

---

## ğŸ“¦ 5. Metadata Validation Standards (STAC/DCAT/PROV-O)

All published datasets must include:

- STAC **Item** (raster/vector) OR  
- STAC **Collection** (multi-asset)  
- DCAT **Dataset** descriptor  
- PROV-O lineage chain  
- SPDX software license mapping  

### Required STAC Fields

| Field | Required |
|-------|----------|
| `id` | âœ” |
| `type` | âœ” |
| `bbox` | âœ” |
| `geometry` | âœ” |
| `assets` | âœ” |
| `properties.datetime` | âœ” |
| `kfm:provenance` | âœ” |
| `kfm:care_label` | âœ” |

---

## ğŸ” 6. Integrity Validation (Checksums & Hashes)

All artifacts must include:

- **sha256** checksums  
- Optional **blake3** for large rasters  
- Hash verification on both input and output  

Checksum manifest example:

~~~~~json
{
  "artifact": "hydrology_flow_1895.tif",
  "sha256": "39abfe00b4...",
  "size_bytes": 148392049
}
~~~~~

Checksum chain stored in:

```
data/checksums/<dataset_id>.json
```

---

## ğŸ“¡ 7. Telemetry Validation Standards

Every pipeline must emit:

- Runtime (sec)  
- Bytes processed  
- Memory usage  
- Validation failures  
- CARE flag conflicts  
- Energy (Wh)  
- COâ‚‚e estimate  
- Model token counts (AI pipelines)  

Telemetry stored in:

```
../../../../releases/v10.3.0/focus-telemetry.json
```

---

## ğŸ§¾ 8. Validation Failure Handling

If ANY validation step fails:

- Pipeline halts  
- Outbox events suppressed  
- No STAC/DCAT publication occurs  
- Error details logged in:
  - `reports/audit/pipeline_errors/`
  - `governance-ledger.json`

Downstream systems (UI, Focus Mode) never see invalid data.

---

## ğŸ“˜ Example Validation Summary (v10.3.1)

~~~~~json
{
  "pipeline_id": "etl_climate_normals_v10.3.1",
  "schema_passed": true,
  "faircare_passed": true,
  "geospatial_passed": true,
  "ai_valid_passed": false,
  "integrity_passed": true,
  "telemetry": {
    "runtime_sec": 43.1,
    "energy_wh": 11.8
  },
  "errors": [
    "AI drift threshold exceeded (Î” = 0.13)"
  ]
}
~~~~~

---

## ğŸ•°ï¸ Version History

| Version | Date | Author | Summary |
|---------|--------|---------|---------|
| v10.3.1 | 2025-11-13 | FAIR+CARE Council | Updated for v10.3 telemetry, new CARE flags, and AI validation gates. |
| v10.2.2 | 2025-11-12 | Pipeline Architecture Team | Initial comprehensive validation rule set. |

---

<div align="center">

**Kansas Frontier Matrix â€” Pipeline Validation Standards**  
Accuracy Ã— Ethics Ã— Provenance Ã— Reproducibility  
Â© 2025 Kansas Frontier Matrix â€” CC-BY 4.0  

[Back to Pipeline Architecture](./README.md)

</div>