Hereâ€™s a dropâ€‘in, GitHubâ€‘ready Markdown that sets up a STAC polling + validation + publish loop tailored to your KFM stack, using ETags, Great Expectations, and GitHub Actions on a cron. It follows your Markdown Output Protocol (YAML frontâ€‘matter, centered title, required sections, Mermaid, directory layout, badges, governance, version history) and stays within one box for copy/paste.

---
title: "ğŸ›°ï¸ Kansas Frontier Matrix â€” STAC Monitor â†’ Validate â†’ Publish Orchestrator (Diamondâ¹ Î© / CrownâˆÎ© Ultimate Certified)"
path: "src/pipelines/stac/monitor-validate-publish/README.md"
version: "v10.3.0"
last_updated: "2025-11-14"
review_cycle: "Quarterly / FAIR+CARE Council"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../../../releases/v10.3.0/sbom.spdx.json"
manifest_ref: "../../../../releases/v10.3.0/manifest.zip"
telemetry_ref: "../../../../releases/v10.3.0/focus-telemetry.json"
telemetry_schema: "../../../../schemas/telemetry/pipelines-stac-orchestrator-v1.json"
governance_ref: "../../../../docs/standards/governance/ROOT-GOVERNANCE.md"
license: "CC-BY 4.0"
mcp_version: "MCP-DL v6.3"
---

<div align="center">

# ğŸ›°ï¸ **Kansas Frontier Matrix â€” STAC Monitor â†’ Validate â†’ Publish Orchestrator**  
`src/pipelines/stac/monitor-validate-publish/README.md`

**Purpose:** Turn **STAC API Item Search** results in the Kansas AOI into reliable, validated items and collections, then **upsert** them to KFM storage/graph on a schedule. Uses **HTTP conditional requests (ETag / If-None-Match)** for efficient polling, **Great Expectations** for schema/range/uniqueness checks, and **GitHub Actions** for cron orchestration and attestable CI.

**Scope:** KFM-wide ingestion of remote sensing & environmental feeds (NOAA/USGS/NASA vendors) within Kansas bounding geometries, producing ready-to-serve STAC assets, provenance, and Neo4j graph links.

</div>

---

## âœ… Goals & Nonâ€‘Goals

- **Goals**
  - Poll STAC Item Search for **new/changed** Items in the **Kansas AOI**.
  - Cache and reuse **ETags** so unchanged queries return **304 Not Modified**.
  - Run **Great Expectations Checkpoints** as the **gate** for downstream publish.
  - **Upsert** STAC Items/Collections, refresh **graph edges** (Scenesâ†’Datasetsâ†’Themes).
  - Orchestrate on **cron** with **GitHub Actions**, produce artifacts & SLSA/SBOM links.

- **Nonâ€‘Goals**
  - Full data science analysis; this is an ingestion/validation/publish loop.
  - Longâ€‘term warehousing strategy (covered in `src/ARCHITECTURE.md`).

---

## ğŸ§­ Kansas AOI

- Authoritative AOI lives at `data/geometry/kansas_aoi.geojson` (CRS: EPSG:4326).
- Derived tiling (H3/quadbin) may be generated to shard polling windows.

---

## ğŸ§© Flow Overview

### Orchestrator Diagram

```mermaid
flowchart LR
  A[Schedule GitHub Actions] --> B[Poll STAC API with If-None-Match]
  B -->|304 Not Modified| Z[No-Op & Telemetry]
  B -->|200 OK with Items| C[Stage Raw JSONL in data/stac/incoming]
  C --> D[Great Expectations Checkpoint]
  D -->|PASS| E[Transform & Normalize STAC]
  D -->|FAIL| F[Quarantine + Open Issue]
  E --> G[Upsert Items/Collections to data/stac/published]
  G --> H[Update Neo4j Graph Links]
  H --> I[Emit Telemetry + Artifacts]


â¸»

ğŸ“¦ Repo Layout (Excerpt)

src/pipelines/stac/monitor-validate-publish/
â”œâ”€ monitor.py
â”œâ”€ publish.py
â”œâ”€ transform.py
â”œâ”€ etag_cache.json
â”œâ”€ expectations/
â”‚  â”œâ”€ great_expectations.yml
â”‚  â”œâ”€ checkpoints/stac_items.yml
â”‚  â””â”€ expectations/stac_item_schema.json
data/stac/
â”œâ”€ incoming/               # raw polled JSONL
â”œâ”€ quarantine/             # failed validation
â””â”€ published/              # validated Items/Collections
data/geometry/
â””â”€ kansas_aoi.geojson
.github/workflows/
â””â”€ stac-orchestrator.yml


â¸»

ğŸŒ Polling STAC API Efficiently (ETag / Ifâ€‘Noneâ€‘Match)

Why: Save bandwidth and API quotas. If nothing changed, server returns 304.

Item Search Query (example):
	â€¢	Endpoint: <PROVIDER_STAC_API>/search
	â€¢	Filters: intersects=<Kansas AOI>, datetime=2020-01-01T00:00:00Z/.., limit=200, collections=[...]

cURL sketch:

ETAG_FILE="src/pipelines/stac/monitor-validate-publish/etag_cache.json"
ETAG=$(jq -r '.search_etag // empty' "$ETAG_FILE" 2>/dev/null)

curl -sS -X POST "${STAC_API}/search" \
  -H "Content-Type: application/json" \
  -H "If-None-Match: ${ETAG}" \
  -d @- <<'JSON' | tee /tmp/stac_response.json
{
  "collections": ["landsat-c2-l2","sentinel-2-l2a"],
  "intersects": { /* load data/geometry/kansas_aoi.geojson */ },
  "datetime": "2020-01-01T00:00:00Z/..",
  "limit": 200
}
JSON

# Capture ETag for next run (if provided on 200)
RESP_CODE=$(jq -r '."http_code" // empty' <<<"{}") # replace with runner-provided status if needed
NEW_ETAG=$(jq -r '."etag" // empty' <<<"{}")       # replace via response headers capture

Python (requests) snippet to persist ETag:

import json, requests
from pathlib import Path

cache = Path("src/pipelines/stac/monitor-validate-publish/etag_cache.json")
etag_cache = json.loads(cache.read_text()) if cache.exists() else {}

headers = {"Content-Type": "application/json"}
if etag_cache.get("search_etag"):
    headers["If-None-Match"] = etag_cache["search_etag"]

payload = {
    "collections": ["landsat-c2-l2","sentinel-2-l2a"],
    "intersects": json.loads(Path("data/geometry/kansas_aoi.geojson").read_text()),
    "datetime": "2020-01-01T00:00:00Z/..",
    "limit": 200
}
resp = requests.post(f"{STAC_API}/search", json=payload, headers=headers)

if resp.status_code == 304:
    print("No changes (304).")
else:
    resp.raise_for_status()
    Path("data/stac/incoming/items.jsonl").write_text(
        "\n".join(json.dumps(f) for f in resp.json().get("features", []))
    )
    if "ETag" in resp.headers:
        etag_cache["search_etag"] = resp.headers["ETag"]
        cache.write_text(json.dumps(etag_cache, indent=2))


â¸»

ğŸ” Validation Gate (Great Expectations)
	â€¢	Checkpoint: expectations/checkpoints/stac_items.yml
	â€¢	Covers: JSON schema conformity, numeric ranges (e.g., cloud cover 0..100), field presence, ID uniqueness, link integrity.
	â€¢	Outcome:
	â€¢	PASS â†’ proceed to transform/publish
	â€¢	FAIL â†’ move batch to data/stac/quarantine/ and open a GitHub Issue with findings

Minimal GE CLI pattern:

cd src/pipelines/stac/monitor-validate-publish/expectations
great_expectations checkpoint run stac_items \
  --config "great_expectations.yml" \
  --suite "stac_item_suite"


â¸»

ğŸ§ª Transform â†’ Normalize
	â€¢	Normalize Item properties, ensure proj:* & eo:* fields present when applicable.
	â€¢	Recompute/verify assets (media types, roles), fix relative hrefs, embed created/updated.
	â€¢	Add KFM provenance blocks (source, license, ingest signature hash).

# transform.py (excerpt)
def normalize_item(item: dict) -> dict:
    item["properties"].setdefault("kfm:ingest_version", "v10.3.0")
    # ensure datetime, gsd, cloud_cover normalization, media types, etc.
    return item


â¸»

â¬†ï¸ Publish (Upsert Items & Collections)
	â€¢	Write validated outputs to data/stac/published/collections/<id>.json and .../items/<collection>/<id>.json.
	â€¢	Graph links: call Neo4j to (create or) merge nodes and relationships:
(:Scene {stac_id})-[:BELONGS_TO]->(:Dataset {collection_id})-[:THEMATIC]->(:Theme {name}).

# publish.py (excerpt)
from neo4j import GraphDatabase

def upsert_graph(item):
    with GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS)) as d:
        q = """
        MERGE (s:Scene {stac_id: $id})
        SET s.updated = timestamp(), s.datetime = $dt
        MERGE (dset:Dataset {id: $collection})
        MERGE (s)-[:BELONGS_TO]->(dset)
        """
        d.session().run(q, id=item["id"], dt=item["properties"]["datetime"], collection=item["collection"])


â¸»

â±ï¸ GitHub Actions (Cron + Artifacts)

File: .github/workflows/stac-orchestrator.yml

name: STAC Orchestrator

on:
  schedule:
    - cron: "5 * * * *"   # every hour at :05
  workflow_dispatch: {}

jobs:
  run:
    runs-on: ubuntu-latest
    permissions:
      contents: write
      issues: write
    steps:
      - uses: actions/checkout@v4

      - uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          pip install -r requirements.txt
          pip install great_expectations neo4j

      - name: Poll STAC with ETag
        env:
          STAC_API: ${{ secrets.STAC_API }}
        run: |
          python src/pipelines/stac/monitor-validate-publish/monitor.py

      - name: Validate (Great Expectations)
        run: |
          great_expectations checkpoint run stac_items \
            --config src/pipelines/stac/monitor-validate-publish/expectations/great_expectations.yml \
            --suite stac_item_suite

      - name: Publish + Graph
        env:
          NEO4J_URI: ${{ secrets.NEO4J_URI }}
          NEO4J_USER: ${{ secrets.NEO4J_USER }}
          NEO4J_PASS: ${{ secrets.NEO4J_PASS }}
        run: |
          python src/pipelines/stac/monitor-validate-publish/publish.py

      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: stac-run-${{ github.run_id }}
          path: |
            data/stac/incoming/**/*.jsonl
            data/stac/published/**/*.json
            src/pipelines/stac/monitor-validate-publish/expectations/uncommitted/data_docs

      - name: Open issue on validation failure
        if: failure()
        uses: peter-evans/create-issue-from-file@v5
        with:
          title: "STAC validation failure in run ${{ github.run_id }}"
          content-file: data/stac/quarantine/last_failure_summary.md
          labels: pipeline, stac, validation


â¸»

ğŸ” Secrets & Configuration
	â€¢	STAC_API: Provider base URL.
	â€¢	NEO4J_URI, NEO4J_USER, NEO4J_PASS: Graph store.
	â€¢	Optional: HTTP_TIMEOUT, RETRY_COUNT, BATCH_LIMIT.

â¸»

ğŸ“ˆ Telemetry & Provenance
	â€¢	Emit counters: polled_count, new_items, updated_items, quarantined_items, publish_latency_ms.
	â€¢	Attach run metadata to telemetry_ref and store JSONL in data/stac/telemetry/.
	â€¢	Include ingest hash over normalized Item for immutability audit.

â¸»

ğŸ§° Requirements (excerpt)

Add to requirements.txt:

requests>=2.32
great-expectations>=1.0
neo4j>=5.25
jsonschema
shapely
h3


â¸»

ğŸ§ª Great Expectations: Minimal Check Examples
	â€¢	Schema presence: id, geometry, properties.datetime, assets
	â€¢	Ranges: properties.eo:cloud_cover in [0,100]
	â€¢	Uniqueness: id unique per collection
	â€¢	Links: links[?rel=="self"], links[?rel=="collection"] must exist

â¸»

ğŸ§¯ Failure Handling
	â€¢	On GE failure: move batch to data/stac/quarantine/TS/, write last_failure_summary.md, autoâ€‘open Issue with artifact link.
	â€¢	On publish failure: retry with backoff; if repeated, open Issue + mark as blocked.

â¸»

ğŸ§ª Local Dryâ€‘Run

export STAC_API="https://example-stac.com"
python src/pipelines/stac/monitor-validate-publish/monitor.py
great_expectations checkpoint run stac_items \
  --config src/pipelines/stac/monitor-validate-publish/expectations/great_expectations.yml \
  --suite stac_item_suite
python src/pipelines/stac/monitor-validate-publish/publish.py


â¸»

ğŸ§­ Governance & Compliance
	â€¢	FAIR+CARE: metadata completeness, licensing, community impacts logged in provenance.
	â€¢	Security: leastâ€‘privilege secrets; attest CI runs; record SBOM/manifest hashes.
	â€¢	Accessibility: data docs exported with altâ€‘text & WCAGâ€‘aware HTML.

â¸»

ğŸ“œ Badges
	â€¢	âœ… GE Checkpoint Gate â€¢ ğŸ§ª CI Enforced â€¢ ğŸ”’ Secrets Scanned â€¢ ğŸ§­ FAIR+CARE Logged â€¢ ğŸ§¾ SBOM Linked

â¸»

ğŸ“š References
	â€¢	STAC API â€” Item Search 1.0.x (query, paging, intersects)
	â€¢	HTTP ETag / Ifâ€‘Noneâ€‘Match (conditional requests)
	â€¢	Great Expectations â€” Checkpoints & Validation Stores
	â€¢	GitHub Actions â€” on.schedule cron, artifacts, issues

â¸»

ğŸ—“ï¸ Version History
	â€¢	v10.3.0 (2025â€‘11â€‘14): Initial orchestrator spec (ETag polling, GE gate, upsert, GHA cron).

