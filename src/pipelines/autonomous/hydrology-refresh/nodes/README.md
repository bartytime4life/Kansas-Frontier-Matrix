---
title: "ğŸ§© KFM v11 â€” Hydrology Refresh Nodes Module (Diamondâ¹ Î© / CrownâˆÎ© Ultimate Certified)"
path: "src/pipelines/autonomous/hydrology-refresh/nodes/README.md"
version: "v11.0.0"
last_updated: "2025-11-22"
review_cycle: "Daily Â· Autonomous"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../../../../releases/v11.0.0/sbom.spdx.json"
manifest_ref: "../../../../../releases/v11.0.0/manifest.zip"
telemetry_ref: "../../../../../releases/v11.0.0/telemetry/autonomous-hydrology-refresh.json"
telemetry_schema: "../../../../../schemas/telemetry/autonomous-hydrology-refresh-v1.json"
governance_ref: "../../../../../docs/standards/governance/ROOT-GOVERNANCE.md"
data_contract_ref: "../../../../../docs/contracts/data-contract-v3.json"
license: "MIT"
mcp_version: "MCP-DL v6.3"
markdown_protocol_version: "KFM-MDP v11.0.0"
status: "Active / Enforced"
doc_kind: "Module"
semantic_document_id: "kfm-autonomous-hydro-nodes-v11"
doc_uuid: "urn:kfm:pipelines:autonomous:hydrology-refresh:nodes:v11"
machine_extractable: true
accessibility_compliance: "WCAG 2.1 AA+"
fair_category: "F1-A1-I1-R1"
care_label: "Public / Medium-Risk"
immutability_status: "version-pinned"
---

<div align="center">

# ğŸ§© **Hydrology Refresh Nodes Module (v11)**  
`src/pipelines/autonomous/hydrology-refresh/nodes/README.md`

**Purpose:**  
Document each **node component** that composes the **Autonomous Hydrology Refresh pipeline**.  
These nodes deliver deterministic ingestion, normalization, STAC generation, checksum validation,  
and Neo4j graph synchronization for hydrology datasets under KFM v11.

</div>

---

# ğŸ“˜ Overview

The nodes in this module form the *atomic ETL/AI building blocks* of the Autonomous Hydrology Refresh DAG:

- Every node exposes a **single** `run(...)` function  
- I/O is passed via LangGraph context dictionaries  
- Nodes MUST be:
  - Idempotent  
  - Deterministic  
  - Side-effect minimal  
  - Scope-minimal  
  - JSON/YAML schema-safe  
  - STAC v11 + Hydrology v11 compliant  
- All nodes follow **MCP-DL v6.3** documentation-first engineering rules

The full DAG behavior is defined at:  
`src/pipelines/autonomous/hydrology-refresh/README.md`.

---

# ğŸ—‚ Directory Layout (v11)

```text
src/pipelines/autonomous/hydrology-refresh/nodes/
â”‚
â”œâ”€â”€ README.md                   # This file (v11 MDP)
â”‚
â”œâ”€â”€ detect_stale.py             # Identify stale hydrology data (etag / Last-Modified)
â”œâ”€â”€ fetch_sources.py            # Download sources from USGS, NOAA, KDHE, etc.
â”œâ”€â”€ normalize_tabular.py        # Harmonize tabular station/flow/precip datasets
â”œâ”€â”€ build_stac_items.py         # Generate STAC Items for hydrology datasets
â”œâ”€â”€ validate_checksums.py       # Verify SHA-256 asset integrity
â”œâ”€â”€ stac_validate.py            # Validate STAC Items against STAC v11 + Hydro schemas
â”œâ”€â”€ neo4j_sync.py               # Write hydrology entities to Neo4j graph
â””â”€â”€ post_hooks.py               # Telemetry, lineage completion, notifications
```

---

# ğŸ§  Node Responsibilities

## ğŸ” detect_stale.py
**Role:** Determine which water/hydrology datasets must be refreshed.

**Inputs:**
- `context["providers_cfg"]`  
- `context["checksum_manifest"]`  

**Outputs:**
- `stale_targets: list[str]`

**Actions:**
- Compare provider etags + Last-Modified timestamps  
- Evaluate checksum age & upstream drift  
- Emit OpenLineage start/end events

---

## ğŸŒ fetch_sources.py
**Role:** Download hydrology datasets (e.g., USGS flow CSV, NOAA precip, KDHE water-quality).

**Inputs:**  
`stale_targets`, `context["workdir"]`, `providers_cfg`

**Outputs:**  
`raw_files: list[str]`

**Actions:**
- Fetch remote feeds with retry/backoff  
- Preserve provider timestamps for STAC lineage  
- Save raw files under `workdir/raw/`

---

## ğŸ“Š normalize_tabular.py
**Role:** Normalize hydrology tabular data (streamflow, groundwater, precip, etc.)

**Inputs:**  
`raw_files`, `context["schema"]`

**Outputs:**  
`norm_files: list[str]`

**Actions:**
- Standardize column names: `SITE_ID`, `DATETIME`, `FLOW_CFS`, `STAGE_M`, etc.  
- Enforce units (m, mÂ³/s) per **Hydrology Standard v11**  
- Handle timezone â†’ UTC normalization  
- Validate against hydrology schema  
- Output Parquet/CSV under `workdir/norm/`

---

## ğŸ›° build_stac_items.py
**Role:** Build **STAC Items** for each processed hydrology dataset.

**Inputs:**  
`norm_files`, `context["stac_out"]`, `context["providers_cfg"]`

**Outputs:**  
`stac_items: list[str]`

**Actions:**
- Generates Items with:
  - `hydro:type` (streamflow/bathymetry/water_surface/etc.)  
  - `datetime` or interval  
  - `geometry`, `bbox` (EPSG:4326)  
  - Vertical-axis metadata (NAVD88, GEOID18)  
  - CF-positive rules (`up` or `down`)  
  - Hydrology rasters tagged as COGs  
  - Full PROV-O lineage  

---

## ğŸ” validate_checksums.py
**Role:** Check SHA-256 hashes for all STAC assets.

**Inputs:**  
`stac_items`, `checksum_manifest`

**Outputs:**  
`validated_items: list[str]`

**Actions:**
- Compute SHA-256 per asset  
- Compare to `manifest.json`  
- Fail/alert on mismatch  
- Update manifest only under governance-approved mode  

---

## ğŸ§ª stac_validate.py
**Role:** Run comprehensive STAC validation.

**Inputs:**  
`validated_items`

**Outputs:**  
`ready_items: list[str]`

**Actions:**
- Validate against:
  - STAC 1.0  
  - KFM STAC Geo Spec v11  
  - Hydrology STAC extension  
  - CRS v11  
  - Vertical Axis v11  
- Emit structured error logs for CI  

---

## ğŸ§  neo4j_sync.py
**Role:** Convert hydrology STAC Items into Neo4j graph entities.

**Inputs:**  
`ready_items`

**Outputs:**  
`graph_report: dict`

**Actions:**
- Create/merge:
  - `HydrologyObservation`  
  - `StreamflowSeries`  
  - `ReservoirLevel`  
  - `BathymetryGrid`  
- Map geometry to GeoSPARQL WKT  
- Map datetime to OWL-Time  
- Refresh spatial & temporal indexes  
- Log statistics for telemetry

---

## ğŸ“¬ post_hooks.py
**Role:** Post-run housekeeping and telemetry emission.

**Inputs:**  
`graph_report`

**Outputs:**  
`run_summary: dict`

**Actions:**
- Emit pipeline run telemetry  
- Close OpenLineage run event  
- Handle notifications (email/Slack if configured)  
- Rotate logs, update DAG health metrics  

---

# ğŸ§ª Testing Requirements

All nodes MUST:

- Provide a top-level `run()` function  
- Be covered by at least one test (direct test or DAG smoke test)  
- Use only `context` for configuration (no hardcoded paths)  
- Produce deterministic outputs  
- Pass schema validation & STAC validation in CI  
- Provide error messages in machine-readable form  

A minimal smoke test is required at:  
`src/pipelines/autonomous/hydrology-refresh/tests/test_dag_smoke.py`

---

# ğŸ§­ Node Signature (Recommended)

```python
def run(*, context, **kwargs) -> dict:
    """
    Parameters
    ----------
    context : dict
        Pipeline context: paths, schemas, configuration.
    **kwargs :
        Node-specific inputs (e.g., raw_files, stale_targets).

    Returns
    -------
    dict
        Keys match DAG `outputs` declarations.
    """
```

---

# ğŸ•° Version History

- **v11.0.0 (2025-11-22)** â€” Initial Hydrology Refresh nodes module for KFM v11.

---

<div align="center">

**Kansas Frontier Matrix â€” Hydrology Refresh Nodes (v11)**  
*Clear Contracts Â· Deterministic Behavior Â· Water-Safe ETL*

</div>

---

### ğŸ”— Footer  
[â¬… Back to Hydrology Pipeline](../README.md) Â· [ğŸ§° Autonomous Utils](../../utils/README.md) Â· [ğŸ› Governance](../../../../../docs/standards/governance/ROOT-GOVERNANCE.md)

