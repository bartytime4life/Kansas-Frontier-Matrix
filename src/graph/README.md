# ğŸ•¸ï¸ KFM Graph Subsystem (`src/graph/`)

![Neo4j](https://img.shields.io/badge/graph-Neo4j-1f6feb?logo=neo4j&logoColor=white)
![Contract](https://img.shields.io/badge/contract-canonical%20pipeline%20enforced-0a0a0a)
![Policy](https://img.shields.io/badge/governance-fail--closed%20by%20default-8b0000)

> **Purpose:** build and maintain KFMâ€™s **semantically structured Neo4j graph** as a *derived* (reproducible) index that powers context-linking and evidence retrieval for APIs/UI. :contentReference[oaicite:0]{index=0}

---

## ğŸ§­ Where `src/graph/` fits in the KFM pipeline

KFM is **contract-first**: every stage consumes outputs from the previous stage (no leapfrogging). :contentReference[oaicite:1]{index=1}

```mermaid
flowchart LR
  subgraph Data
    A["Raw Sources"] --> B["ETL + Normalization"]
    B --> C["STAC Items + Collections"]
    C --> D["DCAT Dataset Views"]
    C --> E["PROV Lineage Bundles"]
  end

  C --> G["Neo4j Graph (references back to catalogs)"]
  G --> H["API Layer (contracts + redaction)"]
  H --> I["Map UI â€” React Â· MapLibre Â· (optional) Cesium"]
  I --> J["Story Nodes (governed narratives)"]
  J --> K["Focus Mode (provenance-linked context bundle)"]
```

The **Neo4j graph must reference back to catalogs** so users (and downstream services) can trace every claim to governed metadata and lineage. :contentReference[oaicite:2]{index=2}

---

## âœ… Scope (what belongs here)

`src/graph/` is the **canonical home** for graph build code: **ontology bindings, ingest scripts, constraints**, and graph initialization/sync utilities. :contentReference[oaicite:3]{index=3}

More concretely, `src/graph/` should contain:
- ğŸ§  **Ontology application** (labels/types, controlled vocab, mapping rules)
- ğŸ§± **Cypher migrations** (schema evolution, constraints, indexes)
- ğŸ“¦ **CSV generation / export** for import workflows
- ğŸ” **Sync/update** routines (incremental rebuilds, idempotent upserts)
  
> â€œGraph buildâ€ lives here; **static import files** (like generated CSVs) belong under `data/graph/` for consistency. :contentReference[oaicite:4]{index=4}

---

## ğŸš« Anti-scope (what does *not* belong here)

To protect provenance + governance contracts, avoid:
- âŒ UI data fetch logic (that belongs in `src/server/` + `web/`):contentReference[oaicite:5]{index=5}
- âŒ â€œMysteryâ€ graph definitions elsewhere (single canonical home):contentReference[oaicite:6]{index=6}
- âŒ Manual edits in Neo4j as â€œsource of truthâ€ (graph is a **derived index**, not evidence storage)

---

## ğŸ§© Inputs & Outputs (contracts)

### Inputs (must exist before graph build)
Graph build consumes **published boundary artifacts**:
- `data/stac/` âœ… STAC Items/Collections
- `data/catalog/dcat/` âœ… DCAT dataset entries
- `data/prov/` âœ… PROV lineage bundles

These â€œboundary artifactsâ€ are required before data is considered published and are the interface to downstream stages (including graph). :contentReference[oaicite:7]{index=7}

### Outputs (graph build artifacts)
Graph import/sync outputs should land in:
- `data/graph/csv/` ğŸ“„ (import-ready node/edge tables)
- `data/graph/cypher/` ğŸ§¾ (optional post-import scripts / migrations)

This layout is part of the expected repository structure. :contentReference[oaicite:8]{index=8}

---

## ğŸ—‚ï¸ Suggested folder layout (inside `src/graph/`)

> This is a **recommended** structure that matches the v13 intent (ontology + migrations + CSV generation). :contentReference[oaicite:9]{index=9}

```text
ğŸ“ src/graph/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ§  ontology/                 # types, vocab, mapping rules (contract-first)
â”œâ”€â”€ ğŸ§± migrations/               # Cypher migrations (constraints/indexes/schema changes)
â”œâ”€â”€ ğŸ”Œ loaders/                  # loaders that read STAC/DCAT/PROV + processed data
â”œâ”€â”€ ğŸ“¦ exporters/                # CSV generation to data/graph/csv/
â”œâ”€â”€ âœ… validation/               # â€œfail-closedâ€ checks (schemas present, ids stable, etc.)
â”œâ”€â”€ ğŸ§° utils/                    # shared helpers (ids, hashing, normalization)
â””â”€â”€ ğŸšª cli.py                    # optional: CLI entrypoint (build/sync/validate)
```

---

## ğŸ§¬ Provenance & traceability rules

KFM treats lineage as first-class: provenance records describe **entities, activities, agents**, and how outputs were derived. :contentReference[oaicite:10]{index=10}

### Graph-level expectations
At minimum, each â€œknowledgeâ€ node/edge created here should be able to answer:
- ğŸ” **What evidence (dataset/artifact) supports this?**
- ğŸ§¾ **Which PROV activity produced it?**
- ğŸ§­ **Which STAC/DCAT records describe it?**

### AI/analysis evidence artifacts
If an AI/analysis pipeline generates new entities/relationships, they must be loaded **with explicit provenance** pointing back to the artifact and sourcesâ€”e.g., an OCR pipeline producing text nodes linked to the scanned document via a PROV activity node. :contentReference[oaicite:11]{index=11}

---

## ğŸ§± Neo4j model notes (practical conventions)

Neo4j uses the **property graph model** (nodes/edges/properties) and is queried via **Cypher**. :contentReference[oaicite:12]{index=12}

Recommended conventions for KFM graph builds:
- ğŸ†” **Stable IDs:** every node/relationship should have a deterministic `id` (or composite key) so rebuilds are idempotent.
- ğŸ·ï¸ **Labels reflect ontology:** prefer fewer, consistent labels (e.g., `Place`, `Event`, `Dataset`, `Person`, `Org`, `EvidenceArtifact`, `ProvActivity`).
- ğŸ”— **Relationships are typed verbs:** keep them readable and consistent (e.g., `:LOCATED_IN`, `:MENTIONS`, `:DERIVED_FROM`, `:SUPPORTED_BY`, `:HAS_PROV_ACTIVITY`).
- ğŸ§¾ **Always link back to evidence:** do not create â€œfloatingâ€ narrative facts without dataset/PROV anchors.

### Optional: modeling time (for historical / â€œtime travelâ€)
For long-range Kansas history, consider adding **time intervals** as properties on nodes and relationships (valid-time and/or transaction-time patterns), enabling temporal queries over evolving graph states. :contentReference[oaicite:13]{index=13}

---

## ğŸ” Build & Sync Workflow (recommended)

> The graph is downstream of catalogs, so the **first step is always**: ETL â†’ STAC/DCAT/PROV publication. :contentReference[oaicite:14]{index=14}

### 1) Validate inputs (fail-closed)
- Confirm all required catalog + PROV records exist for the target domain(s). :contentReference[oaicite:15]{index=15}
- Confirm IDs are stable and mappings are declared (no ad-hoc fields).

### 2) Generate import artifacts (deterministic)
- Export nodes/edges to `data/graph/csv/` and any post-load scripts to `data/graph/cypher/`. :contentReference[oaicite:16]{index=16}

### 3) Apply migrations / constraints
- Run Cypher migrations to enforce constraints and indexes (schema evolution lives here). :contentReference[oaicite:17]{index=17}

### 4) Load / sync Neo4j
- Bulk import for fresh loads, then incremental sync for updates (implementation-defined).

---

## ğŸ”Œ How the API should talk to the graph

The server layer should access Neo4j through a dedicated adapter (e.g., `Neo4jAdapter`) and run Cypher queries like â€œget related events for a place.â€ :contentReference[oaicite:18]{index=18}

> ğŸ” Important: governance checks should happen at the API boundary (contracts + redaction), not in the UI. :contentReference[oaicite:19]{index=19}

---

## ğŸ§ª Local development quick check

If you run the full stack locally, Neo4j is commonly exposed at `http://localhost:7474` via Docker Compose (Neo4j Browser UI). :contentReference[oaicite:20]{index=20}

### Common dev pitfalls
- ğŸ”Œ **Port conflicts**: `7474` (Neo4j), `5432` (PostGIS), `8000/3000` (API/UI) may already be in use. :contentReference[oaicite:21]{index=21}
- ğŸ§  **Memory limits**: large imports can OOM containersâ€”allocate more Docker memory when needed. :contentReference[oaicite:22]{index=22}

---

## ğŸ§© Contribution checklist (graph changes)

When adding or changing graph behavior, aim for small, reviewable diffs:
- [ ] ğŸ§  Update ontology bindings / mapping rules (and keep them documented)
- [ ] ğŸ§± Add a Cypher migration (donâ€™t â€œhot editâ€ DB state)
- [ ] ğŸ“¦ Ensure CSV exports remain deterministic (stable IDs)
- [ ] ğŸ§¾ Ensure new entities/relations link to STAC/DCAT + PROV
- [ ] âœ… Add validations + tests for regressions (missing provenance should fail)
- [ ] ğŸ§· Update docs where the new entity types are introduced (domain README)

---

## ğŸ“š Sources used for this module README

- `MARKDOWN_GUIDE_v13.md.gdoc` (pipeline + canonical homes + graph build scope) :contentReference[oaicite:23]{index=23}:contentReference[oaicite:24]{index=24} :contentReference[oaicite:25]{index=25}  
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf` (PROV expectations, APIâ†”Neo4j adapter patterns, local dev notes) :contentReference[oaicite:26]{index=26}:contentReference[oaicite:27]{index=27}:contentReference[oaicite:28]{index=28} :contentReference[oaicite:29]{index=29}  
- `Data Spaces.pdf` (Neo4j property graph + Cypher context) :contentReference[oaicite:30]{index=30} :contentReference[oaicite:31]{index=31}  
- `Scalable Data Management for Future Hardware.pdf` (optional temporal graph modeling reference) :contentReference[oaicite:32]{index=32} :contentReference[oaicite:33]{index=33}  
