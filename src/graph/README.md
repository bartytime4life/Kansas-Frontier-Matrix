# ğŸ•¸ï¸ KFM Graph Subsystem (Neo4j) â€” `src/graph`

![Neo4j](https://img.shields.io/badge/Neo4j-knowledge%20graph-008CC1?logo=neo4j&logoColor=white)
![PostGIS](https://img.shields.io/badge/PostGIS-spatial%20DB-4169E1?logo=postgresql&logoColor=white)
![Elasticsearch](https://img.shields.io/badge/Search-Elasticsearch-005571?logo=elasticsearch&logoColor=white)
![STAC](https://img.shields.io/badge/STAC-catalogs-informational)
![DCAT](https://img.shields.io/badge/DCAT-metadata-informational)
![PROV](https://img.shields.io/badge/PROV-lineage-informational)
![GraphQL](https://img.shields.io/badge/GraphQL-semantic%20traversals-E10098?logo=graphql&logoColor=white)
![FastAPI](https://img.shields.io/badge/FastAPI-governed%20API-009688?logo=fastapi&logoColor=white)
![OPA](https://img.shields.io/badge/OPA-policy%20gates-7D3C98?logo=openpolicyagent&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-local%20stack-2496ED?logo=docker&logoColor=white)
![Ollama](https://img.shields.io/badge/Ollama-local%20LLM%20RAG-000000)

> **What this folder is:** the **semantic backbone** of Kansas Frontier Matrix (KFM).  
> It builds and maintains the **Neo4j knowledge graph** that connects **datasets â†” places â†” events â†” people â†” organizations â†” documents â†” story nodes**, powers **Focus Mode** multi-hop reasoning, and upholds **provenance-first** guarantees. ğŸ§­ğŸ¤–

---

## âœ… Nonâ€‘Negotiables (KFM Invariants)

These are the â€œwonâ€™t regressâ€ rules this subsystem must enforce:

- ğŸ”Œ **UI never talks to Neo4j directly** (no browser Cypher).  
  âœ… All graph access is **via the API layer** (REST/GraphQL) so governance can be enforced.
- ğŸ§¾ **No Mystery Nodes:** every node/edge must trace to **STAC/DCAT/PROV** artifacts *or* curated Story content with citations.
- ğŸ§¬ **Graph is a derived store** (rebuildable from export contracts), **except** explicitly curated â€œcontentâ€ nodes (e.g., Story Nodes / editorial notes) which must still be versioned + provenance-linked.
- ğŸ›¡ï¸ **Safeâ€‘byâ€‘default:** sensitivity & classification tags must be queryable and enforceable at the API layer (redaction/generalization).
- ğŸ§  **Focus Mode** requires citations: **â€œNo Source, No Answer.â€** If retrieval fails, answers must fail safely (no guessing).

---

## ğŸ§  Why a Graph?

KFM uses a **hybrid storage trio** (and a vector extension) because no single datastore is â€œbestâ€ at everything:

- ğŸ—ºï¸ **PostGIS** â†’ heavy geospatial compute (bbox filters, joins, tiling, geometry ops).
- ğŸ•¸ï¸ **Neo4j** â†’ semantic relationships, provenance chains, narrative linking, multi-hop exploration.
- ğŸ” **Search Index (e.g., Elasticsearch)** â†’ full-text search over documents, story text, OCR corpora.
- ğŸ§² **Vector store (optional)** â†’ embedding-based retrieval for semantic similarity (RAG).

The graph exists so KFM can answer questions like:

- â€œWhat datasets are related to **Event X** in **Place Y**?â€
- â€œWhat happened **here** during **the 1930s**?â€
- â€œShow **Story Nodes** that reference these layers and this county.â€
- â€œWhy did Focus Mode cite **these** sources?â€ (explainable traversals)

---

## ğŸ”— Quick Links (Repo)

> Paths shown here are **canonical intents**; exact filenames may vary by repo version.

- `../../data/graph/csv/README.md` ğŸ“„ â€” import-ready CSV contracts
- `../../docs/MASTER_GUIDE_v13.md` ğŸ§± â€” pipeline ordering + invariants (v13+)
- `../../docs/architecture/` ğŸ›ï¸ â€” system architecture blueprints
- `../../docs/governance/` âš–ï¸ â€” ethics / sovereignty / policy triggers
- `../../api/` ğŸ”Œ â€” governed REST/GraphQL gateway (Cypher/SQL lives here)

---

## ğŸ§­ What `src/graph` Owns

âœ… This module owns:

- ğŸ§¬ **Ontology bindings & mapping rules** (CIDOCâ€‘CRM / PROVâ€‘O / OWLâ€‘Time / GeoSPARQL alignment)
- ğŸ§± **Graph schema contract** (labels, rel types, required properties, invariants)
- ğŸ§° **Ingest tooling** (CSV bulk load + deterministic rebuilds; incremental sync if supported)
- ğŸ§· **Constraints & indexes** (uniqueness, required fields, full-text indexes)
- ğŸ©º **Graph Health Checks** (integrity, drift detection, orphan detection, cross-store checks)
- ğŸ” **Curated query templates** used by API + Focus Mode (no â€œfree-form Cypherâ€ for UI)

ğŸš« This module does **not** own:

- Heavy geometry calculations â†’ **PostGIS**
- UI state / Story playback controls â†’ **web client**
- Raw data fetching / scraping â†’ **pipeline intake**
- Authorization decisions â†’ **API policy pack** (OPA or internal policy engine)

---

## ğŸ“¦ Folder Map (Recommended Layout)

> Treat `src/graph` like a mini product: **schema â†’ ingest â†’ constraints â†’ health â†’ queries â†’ governance hooks**.

```text
ğŸ“ src/graph/
â”œâ”€ ğŸ“„ README.md                         # you are here
â”œâ”€ ğŸ“ ontology/                         # ğŸ§¬ ontology bindings (CIDOC / PROV / OWL-Time / GeoSPARQLâ€¦)
â”‚  â”œâ”€ ğŸ“„ cidoc_crm.(yaml|json|ttl)
â”‚  â”œâ”€ ğŸ“„ prov_o.(yaml|json|ttl)
â”‚  â”œâ”€ ğŸ“„ owl_time.(yaml|json|ttl)
â”‚  â”œâ”€ ğŸ“„ geosparql.(yaml|json|ttl)
â”‚  â””â”€ ğŸ“„ mapping_rules.md               # â€œhow KFM maps standards â†’ labels/propsâ€
â”œâ”€ ğŸ“ schema/                           # ğŸ§± labels + rels + required keys + schema versioning
â”‚  â”œâ”€ ğŸ“„ labels.md
â”‚  â”œâ”€ ğŸ“„ relationships.md
â”‚  â”œâ”€ ğŸ“„ property_keys.md
â”‚  â””â”€ ğŸ“„ schema_versioning.md
â”œâ”€ ğŸ“ constraints/                      # ğŸ§· Neo4j constraints + indexes (Cypher migrations)
â”‚  â”œâ”€ ğŸ“„ 001_constraints.cypher
â”‚  â”œâ”€ ğŸ“„ 002_indexes.cypher
â”‚  â””â”€ ğŸ“„ 003_fulltext_indexes.cypher
â”œâ”€ ğŸ“ ingest/                           # ğŸ§° CSV â†’ Neo4j (bulk import / upsert strategies)
â”‚  â”œâ”€ ğŸ“„ ingest_csv.(py|ts)
â”‚  â”œâ”€ ğŸ“„ id_strategy.md
â”‚  â”œâ”€ ğŸ“„ upsert_strategies.md
â”‚  â””â”€ ğŸ“„ import_manifest.md             # contract for build_id/git_sha/timestamps
â”œâ”€ ğŸ“ queries/                          # ğŸ” curated Cypher templates (used by API only)
â”‚  â”œâ”€ ğŸ“„ search_entities.cypher
â”‚  â”œâ”€ ğŸ“„ expand_neighbors.cypher
â”‚  â”œâ”€ ğŸ“„ provenance_chain.cypher
â”‚  â”œâ”€ ğŸ“„ storynode_context.cypher
â”‚  â””â”€ ğŸ“„ governance_filtered_view.cypher
â”œâ”€ ğŸ“ health/                           # ğŸ©º integrity + drift detection + smoke checks
â”‚  â”œâ”€ ğŸ“„ graph_health_check.(py|ts)
â”‚  â”œâ”€ ğŸ“„ drift_checks.cypher
â”‚  â”œâ”€ ğŸ“„ referential_checks.cypher       # PostGIS/catalog ID sanity checks
â”‚  â””â”€ ğŸ“„ health_report_schema.json
â””â”€ ğŸ“ tests/                            # ğŸ§ª contract + integration tests (Neo4j container)
   â”œâ”€ ğŸ“„ test_csv_contracts.py
   â”œâ”€ ğŸ“„ test_ingest_smoke.py
   â”œâ”€ ğŸ“„ test_health_checks.py
   â””â”€ ğŸ“ fixtures/
```

---

## ğŸ” Data Flow & Ordering Invariants (KFM-wide)

KFMâ€™s pipeline ordering exists to enforce **reproducibility** and **chain-of-custody**:

1. ğŸ§± `data/raw/` â€” source data (immutable inputs)
2. ğŸ§ª `data/processed/` â€” derived products (versioned artifacts)
3. ğŸ—‚ï¸ `data/stac/`, `data/catalogs/`, `data/prov/` â€” STAC/DCAT/PROV metadata
4. ğŸ•¸ï¸ `data/graph/csv/` â€” graph import exports (derived semantic layer)
5. ğŸ§  (optional) `data/embeddings/` â€” vector index inputs (also provenance-tracked)

### Mermaid: end-to-end flow

```mermaid
flowchart LR
  raw[ğŸ§± data/raw] --> processed[ğŸ§ª data/processed]
  processed --> catalogs[ğŸ—‚ï¸ STAC/DCAT/PROV]
  catalogs --> csv[ğŸ“„ data/graph/csv]
  csv --> neo4j[(ğŸ•¸ï¸ Neo4j)]
  processed --> postgis[(ğŸ—ºï¸ PostGIS)]
  catalogs --> search[(ğŸ” Search Index)]
  processed --> search
  search --> ai[ğŸ§  Focus Mode AI]
  neo4j --> api[ğŸ”Œ API (FastAPI + GraphQL)]
  postgis --> api
  ai --> api
  api --> ui[ğŸ–¥ï¸ Web UI]
  api --> notebooks[ğŸ““ Notebooks / External Clients]
```

---

## ğŸš€ Quickstart (Local Dev)

> Commands are **examples**. Adjust to the repoâ€™s actual CLI/module names.

### 1) Start Neo4j (Docker-first)

```bash
docker compose up -d neo4j
```

**Common dev URLs**
- Neo4j Browser: `http://localhost:7474`
- Bolt: `bolt://localhost:7687`

### 2) Configure environment variables

```bash
export NEO4J_URI="bolt://localhost:7687"
export NEO4J_USER="neo4j"
export NEO4J_PASSWORD="password"
# export NEO4J_DATABASE="neo4j"   # optional (Neo4j multi-db)
```

### 3) Generate graph CSV exports

The authoritative import contract is: `data/graph/csv/`

```bash
# Example (pipeline step):
python -m src.pipelines.build_graph_csv --out data/graph/csv
```

### 4) Apply constraints + indexes (migrations)

```bash
python -m src.graph.constraints.apply
```

### 5) Ingest into Neo4j

```bash
python -m src.graph.ingest.ingest_csv --csv-dir data/graph/csv
```

### 6) Run health checks (required)

```bash
python -m src.graph.health.graph_health_check --format markdown
```

âœ… **Rebuild-friendly:** Neo4j is a **derived store**.  
If you hit a bad state, itâ€™s usually correct to **drop + reimport** (as long as CSV exports are correct).

---

## ğŸ§¬ Modeling Rules (Schema Contract)

KFMâ€™s graph is **ontology-aware** and built to serve **explainable retrieval**.

### ğŸ·ï¸ Canonical labels (examples)

- `Dataset` â€” ties to DCAT + STAC IDs (do not store payloads)
- `StacCollection`, `StacItem`, `Asset` â€” catalog structure
- `Place` â€” gazetteer-backed locations (counties, towns, riversâ€¦)
- `Event` â€” historical events, observations, incidents
- `Person`, `Organization` â€” people/institutions
- `Document` â€” text sources (newspapers, reports, treaties; often indexed in search)
- `StoryNode` â€” narrative objects referencing datasets + places + docs
- `Concept` â€” topics/themes for browsing + clustering
- `Activity`, `Agent`, `Entity` â€” provenance (PROV-style backbone)
- `AIAnswer` (optional) â€” stored responses with explicit provenance + citations

### ğŸ”— Relationship naming

Use **UPPER_SNAKE_CASE**:

- Spatial-ish: `LOCATED_IN`, `CONTAINS`, `HAPPENED_AT`
- Text-ish: `MENTIONS`, `CITES`, `DESCRIBES`
- Data-ish: `REFERENCES_DATASET`, `HAS_ITEM`, `HAS_ASSET`
- Provenance-ish: `USED`, `WAS_GENERATED_BY`, `WAS_DERIVED_FROM`, `WAS_ASSOCIATED_WITH`
- Governance-ish: `HAS_POLICY_TAG`, `REDACTS_TO` (optional)

### ğŸ†” Identity, Keys & Versioning (required)

Every â€œrealâ€ node should have:

- `id` â€” stable unique ID (prefer **ULID** or deterministic composite keys)
- `kind` or `type` â€” stable category if label multiplexing exists
- `source_id` â€” the canonical external reference (STAC Item ID, DCAT identifier, DOI, archive IDâ€¦)
- `prov_id` â€” pointer to PROV record (or prov bundle ID)
- `created_at`, `updated_at` (or equivalent)
- `valid_time_start`, `valid_time_end` when temporal validity matters
- `classification` / `sensitivity` â€” required where governance applies (e.g., protected sites)

> ğŸ§  Tip: store **references**, not bulky artifacts. Neo4j should not hold rasters, full PDFs, or large geometries.

---

## ğŸ§¬ Ontology Alignment (How We Stay â€œMeaningfulâ€)

KFM aligns the graph with established standards:

- ğŸº **CIDOCâ€‘CRM** for cultural heritage entities (events, actors, places, documents)
- â›“ **PROVâ€‘O** for lineage chains (entities, activities, agents)
- ğŸ•° **OWLâ€‘Time** for time instants/intervals (timeline-friendly modeling)
- ğŸŒ **GeoSPARQL** concepts for spatial semantics (even if heavy geometry stays in PostGIS)

ğŸ“Œ **Rule:** if you create a new node type that maps cleanly to an ontology class/property, add it to:
- `ontology/â€¦` (bindings)
- `schema/â€¦` (labels/rels/props)
- `mapping_rules.md` (how metadata maps into the graph)

---

## ğŸ§° Ingestion Strategy (CSV â†’ Neo4j)

### âœ… Principle: â€œNo Mystery Nodesâ€

Graph content must be traceable to one of:

- STAC/DCAT/PROV metadata (preferred)
- curated narrative content (Story Nodes) with citations
- controlled enrichments (NLP linking / embeddings) that are auditable and provenance-linked

### ğŸ“„ CSV contract expectations (typical)

- `nodes_*.csv` (e.g., `nodes_dataset.csv`, `nodes_place.csv`, `nodes_event.csv`)
- `rels_*.csv` (e.g., `rels_mentions.csv`, `rels_located_in.csv`, `rels_prov_used.csv`)
- `meta_import_manifest.json` (build_id, timestamp, git sha, profile versions)

ğŸ’¡ Determinism matters: CSV generation should be stable across rebuilds (sorted ordering, stable IDs).

### âš™ï¸ Bulk import vs upsert

Use the right tool for the job:

- ğŸ§± **Bulk import** (fastest): great for full rebuilds from scratch.
- ğŸ” **Upsert/merge** (incremental): safer for partial refreshes, but must be carefully constrained.

> Whichever path you use: constraints/indexes must be applied consistently, and health checks must verify integrity afterward.

---

## ğŸ§· Constraints & Indexes (Minimum Baseline)

At minimum, expect:

- Uniqueness constraints on `:Label(id)`
- Indexes on common keys (`name`, `source_id`, `stac_id`, `dcat_id`, `prov_id`)
- Full-text indexes for `Document`, `StoryNode`, `Concept`, and entity names/aliases

<details>
<summary>ğŸ§· Example Cypher (baseline constraints)</summary>

```cypher
// Unique IDs
CREATE CONSTRAINT dataset_id IF NOT EXISTS
FOR (n:Dataset) REQUIRE n.id IS UNIQUE;

CREATE CONSTRAINT place_id IF NOT EXISTS
FOR (n:Place) REQUIRE n.id IS UNIQUE;

CREATE CONSTRAINT event_id IF NOT EXISTS
FOR (n:Event) REQUIRE n.id IS UNIQUE;

// Required fields (Neo4j 5+ supports property existence constraints)
CREATE CONSTRAINT dataset_source_id IF NOT EXISTS
FOR (n:Dataset) REQUIRE n.source_id IS NOT NULL;
```
</details>

---

## ğŸ” Query Design (Curated Traversals Only)

The graph is powerful, but **unbounded traversals** are how you get slow queries and governance leaks.

**Rule of thumb:** the API should call **curated Cypher templates** that:
- enforce max-depth
- enforce label/rel allowlists
- enforce governance filters
- return stable IDs + provenance pointers

Examples of â€œsafeâ€ query helpers:

- `search_entities` â€” entity lookup by name/alias/id
- `expand_neighbors` â€” bounded neighbor expansion with allowlisted rels
- `provenance_chain` â€” bounded lineage walk (PROV-style)
- `storynode_context` â€” gather a Story Nodeâ€™s referenced entities + citations

---

## ğŸ©º Graph Health Check (Integrity + Drift)

KFM expects recurring QA routines that validate:

- âœ… constraints/indexes are present
- âœ… orphan detection (unconnected nodes that should not exist)
- âœ… provenance completeness for publishable nodes
- âœ… drift vs current CSV export (graph contains nodes not in current export)
- âœ… cross-store referential checks (e.g., Place IDs align with PostGIS/canonical catalogs)

<details>
<summary>ğŸ§ª Example Cypher checks</summary>

```cypher
// Orphaned nodes (excluding allowed singletons)
MATCH (n)
WHERE size((n)--()) = 0 AND NOT n:ImportManifest
RETURN labels(n) AS labels, count(*) AS orphans
ORDER BY orphans DESC;
```

```cypher
// Duplicate IDs (should be prevented by constraint, but useful as smoke test)
MATCH (n)
WITH n.id AS id, count(*) AS c
WHERE id IS NOT NULL AND c > 1
RETURN id, c
ORDER BY c DESC;
```
</details>

---

## ğŸ§  Focus Mode Integration (AI + Graph + Search)

Focus Mode is designed to be **retrieval-first**:

1. Parse user question (intent, entities, time/place constraints)
2. Retrieve evidence:
   - ğŸ•¸ï¸ Neo4j graph traversals (entities + relationships)
   - ğŸ” search index results (documents/story text/OCR)
   - ğŸ§² optional embeddings (vector similarity)
3. Compose answer with **citations**
4. Run governance gate:
   - block unsafe content
   - **block uncited assertions** (â€œNo Source, No Answerâ€)
5. Return structured answer to UI (text + citation mapping)

ğŸ“Œ The graph is the â€œmulti-hop context engineâ€ that prevents the LLM from guessing.

---

## ğŸ›¡ï¸ Governance: Provenanceâ€‘First + Safeâ€‘Byâ€‘Default

This module must support:

- âœ… provenance chains (what produced what, using which inputs)
- âœ… auditability (who/what created nodes, when)
- âœ… sensitivity tagging and enforceable redaction pathways

**Rule of thumb:**  
If something lacks provenance (even a stub), it shouldnâ€™t be promoted for UI/AI use.

### ğŸ” How governance should work in practice

- Graph stores `classification` / `sensitivity` tags on nodes/edges.
- API enforces access based on user roles + policy pack.
- Sensitive nodes may be:
  - excluded
  - generalized (e.g., coarse location)
  - returned with limited fields

---

## ğŸ–¥ï¸ UI Integration (Graph-backed Features)

Even though UI never queries Neo4j directly, the graph should enable:

- ğŸ§¾ **Entity panels** (place/person/dataset summaries + provenance)
- ğŸ§­ **Related items** (â€œneighborsâ€ by concept/time/place/citations)
- ğŸ§µ **Story Nodes** with explicit references to datasets + places + docs
- ğŸ§  **Explainability** (â€œwhy this result?â€ via traversal + provenance chain)
- ğŸ§· **Citations** as clickable links (mapped back to stable IDs)

---

## ğŸ§© Extending the Graph (Developer Playbook)

When adding a new concept, label, or relationship:

1. ğŸ§± Define label/rel + required properties in `schema/`
2. ğŸ§¬ Map it to an ontology class/property (when appropriate)
3. ğŸ“„ Update CSV generation â†’ `data/graph/csv/`
4. ğŸ§· Add constraints/indexes (migration file)
5. ğŸ”Œ Expose via API (curated endpoints; no raw Cypher from UI)
6. ğŸ©º Update health checks + tests
7. ğŸ“ Update this README + any architecture/governance docs

---

## ğŸ§ª Testing Guidance (Minimum Coverage)

Recommended coverage for `src/graph`:

- âœ… unit tests for CSV parsing + type coercion
- âœ… golden-file tests for CSV exports (deterministic ordering)
- âœ… integration test: spin up Neo4j container â†’ ingest â†’ run smoke queries
- âœ… contract tests: API returns same node IDs as graph export
- âœ… health-check tests: corrupted fixtures fail loudly

---

## ğŸ—ºï¸ Roadmap Hooks (Graph-Centric)

From the broader KFM roadmap and proposals, graph-adjacent â€œnext winsâ€ include:

- ğŸ§µ **Pulse Threads**: lightweight micro-story nodes capturing emerging signals & references
- ğŸ§  **Conceptual Attention Nodes**: curated theme nodes for clustering + browsing
- ğŸ” **Graph analytics** (hubs, bridges, communities) for narrative pattern detection
- ğŸŒ **Federated graph** / **GraphQL federation** for multi-region â€œFrontier Matrixâ€ networks
- ğŸ§¾ **Explainable traversals** (â€œwhy did we link these?â€) as first-class UI artifacts

---

## ğŸ“š Project Docs & Reference Library (What Informs This Module)

### Core KFM system docs (architecture + behavior)
- **KFM â€“ Comprehensive Platform Overview and Roadmap** ğŸ—ºï¸
- **KFM â€“ Comprehensive UI System Overview (Technical Architecture Guide)** ğŸ›ï¸
- **KFM â€“ Comprehensive Architecture, Features, and Design** ğŸ›ï¸
- **KFM â€“ AI System Overview ğŸ§­ğŸ¤–** ğŸ¤–
- **ğŸ“š KFM â€“ Expanded Technical & Design Guide** ğŸ“š
- **KFM â€“ Comprehensive Technical Documentation** ğŸ§±
- **KFM AI Infrastructure â€“ Ollama Integration Overview** ğŸ§ 

### Engineering & research libraries (PDF portfolios / multi-doc bundles)
These are â€œgrab bagâ€ knowledge packs that influence implementation patterns, modeling approaches, and operational rigor:

- **AI Concepts & more** ğŸ¤–ğŸ“¦ â€” AI foundations & retrieval thinking
- **Maps / GoogleMaps / Virtual Worlds / Archaeological / WebGL** ğŸŒğŸ›°ï¸ â€” mapping + 2D/3D web visualization context
- **Data Management / Theories / Architectures / Bayesian Methods** ğŸ§ ğŸ“š â€” robustness + uncertainty + data lifecycle ideas
- **Mapping / Modeling / Python / Git / HTTP / Docker / GraphQL / Security** ğŸ§°ğŸ” â€” full-stack patterns & hardening
- **Geographic Information / Security / SciPy / ArcGIS / Spark / TypeScript** ğŸ—ºï¸âš™ï¸ â€” GIS + compute + web app tooling
- **Various programming languages & resources** ğŸ§©ğŸ“š â€” language ecosystem references

> ğŸ§­ If youâ€™re unsure where to implement something:
> - **Semantic relationships / provenance / narrative linking?** â†’ `src/graph/`
> - **Geometry / spatial filtering / tiles?** â†’ PostGIS + spatial adapters
> - **Presentation / interaction?** â†’ web UI
> - **Policy / redaction / permissioning?** â†’ API + policy pack

---

## âœ… â€œDoneâ€ Definition for `src/graph`

This folder is â€œhealthyâ€ when:

- [ ] Graph can be rebuilt **entirely** from `data/graph/csv/`
- [ ] Constraints + indexes are applied consistently
- [ ] Health checks run and fail on drift/corruption
- [ ] API exposes curated graph traversals (GraphQL + REST)
- [ ] Focus Mode can cite sources via graph traversal paths
- [ ] Sensitive content is classified + enforceable through the API
- [ ] â€œNo Mystery Nodesâ€ invariant holds (everything traceable)