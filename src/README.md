---
title: "ğŸ§­ Kansas Frontier Matrix (KFM) â€” src/ Core Code Guide"
path: "src/README.md"
version: "v13+"
status: "active"
last_updated: "2026-01-26"
doc_kind: "core-code-guide"
audience:
  - "backend engineers"
  - "data engineers"
  - "graph/ontology maintainers"
  - "AI/Focus Mode engineers"
principles:
  - "contract-first"
  - "provenance-first"
  - "evidence-first"
  - "fail-closed"
fair: true
care: true
care_label: "TBD"
---

# ğŸ§­ Kansas Frontier Matrix (KFM) â€” `src/` Core Code Guide

![KFM](https://img.shields.io/badge/KFM-Kansas%20Frontier%20Matrix-0b7285?style=for-the-badge)
![v13+](https://img.shields.io/badge/version-v13%2B-5c7cfa?style=for-the-badge)
![Contract-first](https://img.shields.io/badge/Contract--first-%E2%9C%85-2f9e44?style=for-the-badge)
![Provenance-first](https://img.shields.io/badge/Provenance--first-%E2%9C%85-2f9e44?style=for-the-badge)
![Evidence-first](https://img.shields.io/badge/Evidence--first-%E2%9C%85-2f9e44?style=for-the-badge)
![Fail-closed](https://img.shields.io/badge/Policy%20Gates-Fail%20Closed-d9480f?style=for-the-badge)

![Python](https://img.shields.io/badge/Python-Backend-blue?style=for-the-badge)
![FastAPI](https://img.shields.io/badge/FastAPI-API-009688?style=for-the-badge)
![PostGIS](https://img.shields.io/badge/PostGIS-Geospatial-336791?style=for-the-badge)
![Neo4j](https://img.shields.io/badge/Neo4j-Knowledge%20Graph-018bff?style=for-the-badge)
![STAC](https://img.shields.io/badge/STAC-Metadata-6741d9?style=for-the-badge)
![DCAT](https://img.shields.io/badge/DCAT-Catalog-6741d9?style=for-the-badge)
![PROV](https://img.shields.io/badge/PROV-Lineage-6741d9?style=for-the-badge)
![OPA](https://img.shields.io/badge/OPA%20%2B%20Conftest-Policy%20Pack-4c6ef5?style=for-the-badge)

> **`src/` is KFMâ€™s canonical home for core implementation**:  
> ğŸ§ª deterministic ETL pipelines â€¢ ğŸ•¸ï¸ graph/ontology tooling â€¢ ğŸŒ governed API layer â€¢ ğŸ¤– Focus Mode orchestration.  
> If you change code here, youâ€™re changing **governed systems** â€” every change must produce **auditable evidence**.

---

## ğŸ§­ Quick Navigation

- ğŸ¯ [What `src/` owns](#-what-src-owns)
- ğŸš¦ [Non-negotiables](#-non-negotiables-v13-invariants)
- ğŸ—‚ï¸ [Repo context](#ï¸-repo-context-v13-layout)
- ğŸ§ªğŸ•¸ï¸ğŸŒ [`src/` layout](#ï¸-src-layout-recommended)
- ğŸ” [Canonical pipeline](#-the-canonical-pipeline)
- ğŸ§± [Architecture mental model](#-architecture-mental-model-how-to-code-inside-src)
- ğŸ§ª [Pipelines playbook](#-pipelines-playbook-srcpipelines)
- ğŸ•¸ï¸ [Graph playbook](#ï¸-graph-playbook-srcgraph)
- ğŸŒ [Server playbook](#-server-playbook-srcserver)
- ğŸ¤– [Focus Mode contract](#-focus-mode-contract-srcserverai)
- âš–ï¸ [Policy pack & quality gates](#ï¸-policy-pack--quality-gates)
- ğŸš€ [Golden paths](#-golden-paths)
- âœ… [Definition of Done](#-definition-of-done-for-src-prs)
- ğŸ“š [Reference library](#-reference-library)

---

## ğŸ¯ What `src/` owns

| Area | `src/` owns it | Boundary notes |
|---|---:|---|
| ğŸ§ª Deterministic ETL pipelines | âœ… | Must be replayable + idempotent; no ad-hoc edits |
| ğŸ§¾ Metadata â€œcatalog tripletâ€ generation (STAC/DCAT/PROV) | âœ… | Must exist **before** graph/UI/story/focus use |
| ğŸ•¸ï¸ Knowledge graph integration + integrity | âœ… | Ontology stability + migrations; prevent orphan/drift |
| ğŸŒ Governed API + redaction layer | âœ… | UI must not talk to Neo4j directly |
| ğŸ¤– Focus Mode orchestration + citations | âœ… | Hybrid retrieval, citations required, refuse when missing |
| ğŸ›ï¸ UI (React/MapLibre/Cesium) | âŒ | Canonical home: `web/` |
| ğŸ§¾ Story Nodes (narratives) | âŒ | Canonical home: `docs/reports/story_nodes/` |
| ğŸ—ƒï¸ Data artifacts & catalogs | âŒ | Canonical home: `data/` (raw/work/processed + STAC/DCAT/PROV) |

---

## ğŸš¦ Non-negotiables (v13 invariants)

> [!IMPORTANT]
> These are **hard gates** (design + CI). If you violate them, youâ€™re not â€œalmost doneâ€ â€” youâ€™re blocked.

1) **Pipeline ordering is absolute** ğŸ§±  
`ETL â†’ Catalogs (STAC/DCAT/PROV) â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode`

2) **API boundary rule** ğŸš§  
Frontend **must never query Neo4j directly**. All graph access goes through `src/server/` for contracts + policy + redaction.

3) **Provenance-first publishing** ğŸ§¾  
No dataset is â€œpublishedâ€ until it has STAC + DCAT + PROV and passes validation.

4) **Evidence-first narrative + AI** ğŸ“Œ  
Story Nodes and Focus Mode must never introduce unsourced claims. If evidence is missing: **refuse**.

5) **Fail-closed policy gates** ğŸ”’  
Missing license, missing CRS, missing provenance, schema drift, missing citations, secrets leakage â†’ **block merge/publish**.

6) **Sovereignty & classification propagation** ğŸª¶  
Outputs cannot be less restricted than inputs. Redaction and approval rules propagate end-to-end.

---

## ğŸ—‚ï¸ Repo context (v13 layout)

`src/` lives inside a larger â€œcontracts + data + narrativeâ€ repo:

```text
ğŸ“ schemas/                 # âœ… machine-validated contract artifacts (STAC/DCAT/PROV/story/ui/telemetry)
ğŸ“ src/                     # ğŸš€ code (pipelines/graph/server)
ğŸ“ tools/                   # policy pack, validators, linters, helpers
ğŸ“ web/                     # UI (React + MapLibre + optional Cesium)
ğŸ“ data/                    # raw/work/processed + catalogs (stac/dcat/prov) + audits
ğŸ“ docs/                    # governance, standards, templates, story nodes, runbooks
ğŸ“ releases/                # immutable, signed build & artifact bundles (optional)
```

> [!TIP]
> **Contract-first** means: schemas/contracts change first, code follows.  
> If youâ€™re editing code without a matching contract update, youâ€™re likely drifting.

---

## ğŸ—‚ï¸ `src/` layout (recommended)

> [!NOTE]
> Top-level `src/` boundaries are stable. Subfolders may evolve, but keep contracts clean.

```text
src/
â”œâ”€â”€ ğŸ§ª pipelines/                         # ingest â†’ validate â†’ transform â†’ publish
â”‚   â”œâ”€â”€ ğŸ—‚ï¸ <domain_or_product>/            # one pipeline per domain/product (config-driven)
â”‚   â”‚   â”œâ”€â”€ ğŸ“¥ ingest.py                   # acquire inputs (ETag caching, receipts, raw snapshot)
â”‚   â”‚   â”œâ”€â”€ ğŸ§ª transform.py                # raw â†’ work â†’ processed (deterministic params/seeds)
â”‚   â”‚   â”œâ”€â”€ âœ… validate.py                 # schema + policy checks (fail-closed)
â”‚   â”‚   â”œâ”€â”€ ğŸ“¦ publish.py                  # publish outputs + write STAC/DCAT/PROV + run manifest
â”‚   â”‚   â””â”€â”€ âš™ï¸ configs/                    # configs only (NO secrets)
â”‚   â””â”€â”€ â™»ï¸ _shared/                        # pipeline utilities (single source of truth)
â”‚       â”œâ”€â”€ ğŸ§° io/                         # canonical paths + atomic writes + receipts + telemetry
â”‚       â”œâ”€â”€ ğŸ” hashing/                    # digests, stable IDs, file hashing (SHA-256)
â”‚       â”œâ”€â”€ ğŸ§¾ catalogs/                   # STAC/DCAT/PROV writers + validators
â”‚       â””â”€â”€ âœ… validators/                 # schema, link integrity, geo sanity, policy hooks
â”‚
â”œâ”€â”€ ğŸ•¸ï¸ graph/
â”‚   â”œâ”€â”€ ğŸ§  ontology/                       # vocab, mappings, versioned ontology definitions
â”‚   â”œâ”€â”€ ğŸ” migrations/                     # explicit migrations (no silent breaking changes)
â”‚   â”œâ”€â”€ ğŸ›¡ï¸ integrity/                      # constraints + drift detection + QA reports
â”‚   â”œâ”€â”€ ğŸ“¥ loaders/                        # STAC/DCAT/PROV â†’ graph (mapping + normalization)
â”‚   â””â”€â”€ ğŸ“¤ exports/                        # graph â†’ digestable outputs (JSON-LD, UI bundles)
â”‚
â””â”€â”€ ğŸŒ server/
    â”œâ”€â”€ ğŸŒ api/                            # REST routers/controllers (thin)
    â”œâ”€â”€ ğŸ§¬ graphql/                        # GraphQL schema/resolvers (optional; enforce depth/cost)
    â”œâ”€â”€ ğŸ§© services/                       # use-cases (search, tiles, story, focus, redaction)
    â”œâ”€â”€ ğŸ§  domain/                         # pure logic: entities + rules (no DB/HTTP)
    â”œâ”€â”€ ğŸ§· adapters/                       # ports/adapters perimeter
    â”‚   â”œâ”€â”€ ğŸ“¤ outbound/                   # PostGIS/Neo4j/OPA/OCI clients
    â”‚   â””â”€â”€ ğŸ“¥ inbound/                    # queues/webhooks/streams (if used)
    â”œâ”€â”€ ğŸ¤– ai/                             # Focus Mode (RAG + citations + answer receipts)
    â”œâ”€â”€ ğŸ” auth/                           # RBAC/ABAC scopes + token validation + policy scopes
    â””â”€â”€ ğŸ§± middleware/                     # tracing, request IDs, rate limits, error mapping, CORS
```

---

## ğŸ” The canonical pipeline

KFM is designed so **each stage consumes validated artifacts from the stage before it**:

```mermaid
flowchart LR
  subgraph Data
    A["Raw Sources"] --> B["ETL + Normalization"]
    B --> C["STAC Items + Collections"]
    C --> D["DCAT Dataset Views"]
    C --> E["PROV Lineage Bundles"]
  end

  C --> G["Neo4j Graph (references back to catalogs)"]
  G --> H["API Layer (contracts + redaction)"]
  H --> I["Map UI â€” React Â· MapLibre Â· (optional) Cesium"]
  I --> J["Story Nodes (governed narratives)"]
  J --> K["Focus Mode (provenance-linked context bundle)"]
```

> [!IMPORTANT]
> The **catalog triplet** (STAC + DCAT + PROV) is the â€œboundary artifactâ€ contract.  
> Graph, API, UI, Story Nodes, and Focus Mode **must link back** to cataloged sources.

---

## ğŸ§± Architecture mental model (how to code inside `src/`)

KFMâ€™s implementation style is **clean, contract-driven, and evidence-led**:

- ğŸ§  **Domain layer**: entities + rules (pure code; no DB/HTTP clients)
- ğŸ§© **Service layer**: use-cases/orchestration (calls ports, returns results)
- ğŸ§· **Ports (interfaces)**: abstractions for PostGIS/Neo4j/policy/caches
- ğŸ“¦ **Adapters**: actual implementations (Neo4j driver, SQLAlchemy, HTTP clients)

> [!TIP]
> If youâ€™re about to import a database client inside `src/server/domain/`â€¦ stop.  
> Thatâ€™s a boundary violation. Move it to an adapter and depend on a port/interface.

---

## ğŸ§ª Pipelines playbook (`src/pipelines/`)

### âœ… Core guarantees

A pipeline is â€œKFM-validâ€ only if it is:

- ğŸ” **Deterministic**: same inputs + same config â†’ same outputs
- â™»ï¸ **Idempotent**: reruns donâ€™t duplicate or corrupt state
- ğŸ§¾ **Accountable**: emits receipts/logs + file hashes + run identifiers
- âœ… **Validated**: schema + geo checks + policy pack checks (fail closed)
- ğŸ§· **Cataloged**: produces STAC/DCAT/PROV at publish time

### ğŸ“¦ Staging rules (do not improvise)

- `data/raw/<domain>/` â†’ immutable snapshots (store original receipts/metadata)
- `data/work/<domain>/` â†’ intermediate work products (throwaway but logged)
- `data/processed/<domain>/` â†’ final published artifacts (stable & referenced)
- `data/stac/...` + `data/catalog/dcat/...` + `data/prov/...` â†’ boundary artifacts

### ğŸ›°ï¸ Data formats: â€œserve performance, preserve traceabilityâ€

Common patterns:
- ğŸ—ºï¸ Vector: GeoJSON / GeoPackage / GeoParquet (export-friendly)
- ğŸŒ„ Raster: Cloud-Optimized GeoTIFF (COG) + pyramids/overviews
- ğŸ§± Tiles: vector tiles (server-side or prebuilt artifacts; treat as datasets)
- ğŸ“„ Documents/OCR: extracted text corpora treated as datasets (with PROV)
- ğŸ”— Everything must link back to licenses + sources + hashes + CRS

### ğŸ“¡ Streaming ingestion (near-real-time)

Streaming is handled as **many small batch ingests**:
- micro-batches append to PostGIS (often time-partitioned)
- provenance is captured in **batched logs / append-only ledgers**
- policy still applies (no provenance â†’ block or tag until stub exists)

### ğŸ§¾ Run manifests (evidence ledger)

Every `publish.py` should emit a compact run record that answers:
- what inputs were used (URIs + hashes + timestamps)
- what configs/params were applied
- what outputs were produced (paths + hashes + record counts)
- what validations passed/failed
- what policy gates were checked
- what commit/build produced the run

> [!NOTE]
> Treat â€œanalysis outputsâ€ (simulations, OCR, AI-derived layers) as **first-class datasets**:  
> processed storage â†’ STAC/DCAT â†’ PROV lineage â†’ (optional) graph integration â†’ governed API exposure.

---

## ğŸ•¸ï¸ Graph playbook (`src/graph/`)

### ğŸ§  Ontology first (and versioned)

- ontology defines node labels, relationship types, and key properties
- changes must be explicit and **migration-backed**
- clients (API/UI/AI) rely on stability â†’ breaking changes require version strategy

### ğŸ” Migrations are mandatory for breaking changes

- no â€œsilentâ€ ontology drift
- prefer **forward-only** migrations
- maintain a migration index + version history

### ğŸ›¡ï¸ Integrity checks are part of normal operation

Examples:
- prevent orphan nodes / dangling relationships
- ensure required properties exist
- ensure graph nodes reference catalog IDs (STAC/DCAT/PROV) rather than duplicating payloads

> [!IMPORTANT]
> The graph models **relationships**, not bulk storage.  
> The â€œsource of truthâ€ for data assets is the catalogs + processed artifacts.

---

## ğŸŒ Server playbook (`src/server/`)

### ğŸ›ï¸ API is the governance boundary

The API layer is responsible for:
- âœ… contract validation (OpenAPI / GraphQL schema)
- ğŸ”’ policy enforcement (OPA decisions, redaction, classification)
- ğŸ§¾ provenance linkage (responses can point to catalog/source artifacts)
- ğŸ§­ consistent query semantics (so UI and AI get stable behavior)

> [!IMPORTANT]
> UI â†’ API â†’ (PostGIS/Neo4j/catalogs).  
> **No direct UIâ†’Neo4j**.

### ğŸ§¬ GraphQL is optional (but must be governed)

If GraphQL is enabled:
- enforce query depth/cost limits
- use contract tests
- keep resolvers thin; call services/use-cases

### ğŸ—ºï¸ Geospatial endpoints (typical)

Examples of API responsibilities (implementation details may vary by deployment):
- tile endpoints (vector/raster)
- spatial search (bbox, radius, polygon)
- temporal filters (time window / timeline)
- layer registry and metadata lookups
- story node retrieval (published narratives)
- â€œevidence panelâ€ queries (show provenance + source links)

---

## ğŸ¤– Focus Mode contract (`src/server/ai/`)

Focus Mode is a **hybrid retrieval** pipeline:
- ğŸ” pulls structured context (Neo4j + PostGIS)
- ğŸ“š pulls catalog evidence (STAC/DCAT/PROV + source docs)
- ğŸ§¾ builds a **context bundle** with links + citations
- âœï¸ generates an answer that **must cite evidence**
- ğŸ›‘ refuses when evidence is missing or policy blocks access

### âœ… Hard requirements

- **No citations â†’ no answer** (fail closed)
- citations must resolve to cataloged sources / datasets
- policy + redaction must be applied before response generation
- return â€œanswer receiptsâ€ (inputs + sources + policy decisions) for auditability

### ğŸ“ˆ Monitoring & reliability

- track latency, refusal rate, citation density, and source coverage
- rebuildability is a feature: indexes can be reconstructed from raw â†’ processed â†’ catalogs

---

## âš–ï¸ Policy pack & quality gates

KFM governance is enforced via:
- **OPA (Rego policies)** + **Conftest** (CI evaluation)
- schema validators for STAC/DCAT/PROV + internal contracts
- security scanning (secrets, dependency health, artifacts integrity)
- geo validation (CRS, geometry validity, bounds sanity)

Example policy classes:
- ğŸ“œ **Data**: license required; CRS required; sensitivity restrictions
- ğŸ¤– **AI**: â€œanswers must include at least one citationâ€; â€œentities referenced must exist in graphâ€
- ğŸ§‘â€ğŸ’» **Dev**: no secrets; review required; lint/tests required

> [!NOTE]
> CI follows **Detect â†’ Validate â†’ Promote**.  
> If Validate fails, Promote does not happen. No exceptions without governance approval.

---

## ğŸš€ Golden paths

> [!TIP]
> These are the â€œhappy pathâ€ workflows. If your change doesnâ€™t fit, stop and document why.

<details>
<summary><strong>ğŸ§ª Add a new data domain (ETL â†’ catalogs â†’ graph â†’ API)</strong></summary>

**1) Create the pipeline skeleton**
- `src/pipelines/<new-domain>/ingest.py`
- `src/pipelines/<new-domain>/transform.py`
- `src/pipelines/<new-domain>/validate.py`
- `src/pipelines/<new-domain>/publish.py`
- `src/pipelines/<new-domain>/configs/`

**2) Add staging paths**
- `data/raw/<new-domain>/`
- `data/work/<new-domain>/`
- `data/processed/<new-domain>/`

**3) Publish boundary artifacts**
- `data/stac/collections/...` + `data/stac/items/...`
- `data/catalog/dcat/...`
- `data/prov/...`

**4) Add runbook**
- `docs/data/<new-domain>/README.md` (sources, caveats, methods, ethics)

**5) Integrate graph**
- add loader mapping only after catalogs exist
- graph nodes point to catalog IDs

**6) Expose via API**
- add endpoint(s) in `src/server/api/`
- add service in `src/server/services/`
- add policy checks + redaction if needed

</details>

<details>
<summary><strong>ğŸ•¸ï¸ Change the graph schema safely</strong></summary>

- update ontology definition (version it)
- add a migration in `src/graph/migrations/`
- add/adjust integrity checks in `src/graph/integrity/`
- update API contract if shape changes
- update UI contracts (if applicable) â€” but keep UI work in `web/`

</details>

<details>
<summary><strong>ğŸŒ Add a new API endpoint (contract-first)</strong></summary>

- update the contract (OpenAPI/GraphQL) first
- implement handler (thin)
- implement service/use-case (business logic)
- add adapter changes as needed (Neo4j/PostGIS/OPA)
- add contract tests + policy tests
- ensure response contains provenance links when relevant

</details>

<details>
<summary><strong>ğŸ¤– Extend Focus Mode retrieval</strong></summary>

- define what evidence counts (cataloged datasets/docs only)
- implement retriever behind a port (adapter pattern)
- enforce policy/redaction before prompt assembly
- require citations for every non-trivial claim
- log an â€œanswer receiptâ€ (sources + hashes + policy decisions)

</details>

---

## ğŸ§ª Testing & validation matrix (recommended)

| Layer | What to test | Where |
|---|---|---|
| ğŸ§ª Pipelines | determinism, idempotency, schema/geo validation, policy checks | `pytest` + CI |
| ğŸ§¾ Catalogs | STAC/DCAT/PROV schema validity; link integrity | `tools/validation/` + CI |
| ğŸ•¸ï¸ Graph | migrations, constraints, integrity checks | `src/graph/integrity/` + CI |
| ğŸŒ API | contract tests, auth/policy checks, redaction correctness | `src/server/tests/` + CI |
| ğŸ¤– Focus Mode | citation presence, refusal behavior, policy gates | `src/server/ai/tests/` + CI |

---

## ğŸ” Security, privacy, and inference control (donâ€™t skip)

- ğŸ”‘ **No secrets in repo** (configs are non-secret; secrets come from env/secret manager)
- ğŸªª **AuthZ everywhere** (RBAC/ABAC + OPA decisions)
- ğŸ§¼ **Redaction is server-side** (UI should not â€œself-policeâ€)
- ğŸ§  **Inference risk exists** even if you hide raw values  
  Consider privacy-preserving methods (aggregation, suppression, k-anonymity/l-diversity/t-closeness, query auditing) for sensitive releases.

> [!IMPORTANT]
> If a dataset is sensitive, its derivatives **inherit** restrictions unless governance approves release.

---

## âœ… Definition of Done for `src/` PRs

- [ ] Pipelines are deterministic + idempotent (re-run safe)
- [ ] STAC/DCAT/PROV emitted/updated **before** graph/UI/story use
- [ ] Graph changes include migrations + integrity checks (when needed)
- [ ] API changes are contract-first and versioned (no silent breakage)
- [ ] Policy gates pass (license, provenance, schema, citations, security)
- [ ] If Focus Mode changed: answers still cite sources or refuse (fail closed)
- [ ] Telemetry/logging added for new critical paths (so governance can audit)

---

## ğŸ“š Reference library

### ğŸ§­ Core KFM design inputs (read these first)
- ğŸ“˜ `docs/MASTER_GUIDE_v13.md` (canonical pipeline + invariants + repo contracts)
- ğŸ—ï¸ `docs/architecture/` (platform architecture, roadmap, subsystem contracts)
- ğŸ¤– `docs/ai/` (Focus Mode rules, evaluation, telemetry expectations)
- ğŸ–¥ï¸ `docs/ui/` (UI integration constraints + layer registry expectations)
- âš–ï¸ `docs/governance/` (FAIR+CARE, ethics, sovereignty, review triggers)
- âœï¸ `docs/templates/` (Universal doc, Story Node, API contract extension templates)

### ğŸ“š Research bundles (reference-only, not runtime)
These are **idea libraries** for implementation choices (GIS, WebGL, security, data science).  
They are not â€œruntime dependencies,â€ but they influence patterns and guardrails.

- ğŸ—ºï¸ Web mapping & virtual worlds references (MapLibre/Cesium/WebGL ecosystem)
- ğŸ§  AI/ML concept portfolio (modeling patterns, evaluation ideas)
- ğŸ—„ï¸ Data management + architectures + Bayesian methods portfolio
- ğŸ§° Programming resources portfolios (Git/Docker/GraphQL/security/tooling)
- ğŸ“ GIS + Python geospatial cookbook (recipes & workflows; adapt to modern Python)
- ğŸ§ª Scientific method + engineering rigor protocol (reproducibility culture)
- ğŸ” Data mining & privacy references (privacy-preserving analytics concepts)

---

## ğŸ§­ If you only remember one thingâ€¦

> [!IMPORTANT]
> **In KFM, code is not â€œdoneâ€ until it produces evidence.**  
> If your change creates or transforms data, it must emit **STAC/DCAT/PROV**, pass policy gates, and remain replayable â€” before it can reach graph, API, UI, stories, or Focus Mode.