---
title: "üèõÔ∏è Kansas Frontier Matrix ‚Äî Architecture Overview (Diamond‚Åπ Œ© / Crown‚àûŒ© Ultimate Certified)"
path: "src/ARCHITECTURE.md"
version: "v10.4.0"
last_updated: "2025-11-16"
review_cycle: "Quarterly ¬∑ Autonomous ¬∑ FAIR+CARE Council Oversight"
commit_sha: "<latest-commit-hash>"
sbom_ref: "../../releases/v10.4.0/sbom.spdx.json"
manifest_ref: "../../releases/v10.4.0/manifest.zip"
telemetry_ref: "../../releases/v10.4.0/focus-telemetry.json"
telemetry_schema: "../../schemas/telemetry/docs-architecture-v3.json"
governance_ref: "../../docs/standards/governance/ROOT-GOVERNANCE.md"
license: "CC-BY 4.0"
mcp_version: "MCP v6.3"
markdown_protocol_version: "KFM-MDP v10.4"
status: "Active / Enforced"
---

<div align="center">

# üèõÔ∏è **Kansas Frontier Matrix ‚Äî Architecture Overview (Diamond‚Åπ Œ© / Crown‚àûŒ© Ultimate Certified)**  
`src/ARCHITECTURE.md`

**Purpose:**  
Define the canonical **system architecture** of the Kansas Frontier Matrix (KFM) v10.4.0, including data/AI pipelines, Neo4j knowledge graph schema, STAC/DCAT catalogs, Focus Mode v2.5+, Story Nodes, governance, and multi-cloud deployment. This is the source of truth for developers implementing and extending KFM.

[![Docs ¬∑ MCP](https://img.shields.io/badge/Docs-MCP_v6.3-blue)](../docs/README.md)  
[![FAIR+CARE](https://img.shields.io/badge/FAIR%2BCARE-Ultimate-orange)](../docs/standards/faircare.md)  
[![License: CC-BY 4.0](https://img.shields.io/badge/License-CC--BY%204.0-green)](../LICENSE)  
[![Status: Stable](https://img.shields.io/badge/Status-Stable-success)]()  

</div>

---

## üìñ Overview

The **Kansas Frontier Matrix (KFM)** is an open-source semantic geospatial-historical platform that fuses Kansas‚Äôs historical, cultural, and environmental data into an interactive **map + timeline + knowledge graph**. The v10.x architecture is:

- **Layered:** ETL/AI pipelines ‚Üí Neo4j Knowledge Graph ‚Üí FastAPI/GraphQL APIs ‚Üí React + MapLibre/Cesium frontend.
- **Semantic:** Aligned with **CIDOC CRM**, **OWL-Time**, **GeoSPARQL**, **schema.org**, **STAC 1.0**, and **DCAT 3.0**.
- **Ethical:** Governed by **MCP v6.3** (documentation-first) and **FAIR+CARE** (data and AI ethics).
- **Resilient:** Implements **Diamond‚Åπ Œ©** rollback safety, multi-cloud deployment, and streaming-aware ETL.
- **Narrative-aware:** Treats **Story Nodes** and **Focus Mode** outputs as schema-linked, first-class entities.

High-level goals of this architecture:

1. Make all data (past, present, projected) **queryable in time and space**.  
2. Ensure every transformation and AI output is **reproducible and provenance-rich**.  
3. Provide a **developer-friendly monorepo** where ETL, graph, API, and frontend code are modular but integrated.  
4. Allow **safe, explainable AI narratives** over the graph (Focus Mode v2.5+).  

---

## üîÑ Data Ingestion & Pipelines

KFM‚Äôs data plane is centered on **reproducible ETL pipelines** that support both **batch** and **streaming** ingestion. All ETL logic lives under `src/pipelines/` (e.g., `src/pipelines/batch/`, `src/pipelines/streaming/`) and is orchestrated via `make`, CI workflows, and/or Airflow-style schedulers.

### üß± Repository Data Layout

Data files and metadata follow the project‚Äôs canonical file/data architecture:

- `data/sources/` ‚Äî JSON manifests describing **external data sources** (DCAT-like), acting as pointers (URL/API, license, spatial/temporal extent, checksums) rather than embedding large files.
- `data/raw/` ‚Äî Workspace for **downloaded raw data**. Typically not checked into Git; tracked via DVC or Git LFS.
- `data/processed/` ‚Äî **Standardized outputs** in open formats (GeoJSON, COG GeoTIFF, CSV/Parquet) generated by ETL.
- `data/stac/` ‚Äî **STAC 1.0 Catalog** (Catalogs/Collections/Items) indexing spatio-temporal assets in `data/processed/`.

Each entry in `data/sources/*.json` includes at minimum:

- `id`, `title`, `description`, `license` (SPDX-style string),
- `spatial` (bbox, CRS), `temporal` (start/end, granularity),
- `endpoint` (HTTP/REST/STAC, optional `streaming` info),
- `outputs` (paths for processed artifacts).

These manifests are the **contracts** for ETL jobs: pipelines read them to know what to fetch, validate, and emit.

### üõ∞ Batch ETL

Batch ETL jobs are used for historical and static datasets (e.g., NOAA archives, USGS maps, BLM land patents, Kansas Memory documents):

1. **Extract**  
   - Download via HTTP/REST/STAC or local copy from `data/raw/`.  
   - Handle pagination, throttling, and retries.  
   - Log every download with timestamp and checksum.

2. **Transform**  
   - Normalize formats:
     - Tables ‚Üí CSV/Parquet with consistent schema (UTF-8, ISO 8601 dates).
     - Vectors ‚Üí GeoJSON (CRS: EPSG:4326).
     - Rasters ‚Üí Cloud-Optimized GeoTIFF (COG) with proper overviews.  
   - Enrich:
     - Geocode place names (USGS GNIS, OSM Nominatim, etc.).
     - Parse and normalize temporal expressions (OWL-Time-compatible).
     - Run NLP (NER + geoparsing) on text docs (see AI section).  
   - Validate:
     - JSON/CSV against JSON Schema or Pydantic models.
     - Spatial checks (geometry validity, CRS conformity).

3. **Load**  
   - Write artifacts to `data/processed/`.  
   - Create/update corresponding **STAC Items** under `data/stac/`:
     - Geometry, bbox, datetime(s), asset links, checksum, lineage.  
   - Upsert entities and relationships into Neo4j (via `src/graph/` Cypher templates).

Batch jobs are designed to be **idempotent** and **incremental**. Re-running them should not create duplicate entities or corrupt the graph; they rely on natural keys (e.g., station IDs, document IDs, map sheet IDs) to decide whether to insert or update.

### üåä Streaming ETL

Streaming ETL extends the architecture for **live feeds** (e.g., river gauges, Mesonet weather, near-real-time hazard data):

- A **Streaming STAC Bridge** listens on Kafka topics, webhooks, or polling APIs for new observations.
- Each new event is:
  - Validated against a schema (e.g., `observation.schema.json`),
  - Converted into a STAC Item with `datetime` and geometry,
  - Inserted into the graph as an `Observation` node linked to:
    - `SensorStream` (the source), and
    - `Place` (the location),
    - optionally `Dataset` (the collection).

Streaming ETL jobs run continuously as long-lived workers. They use **exactly-once semantics** where possible (idempotent writes, transaction management) and log any failures for later reprocessing. This design allows the map/timeline to show **live conditions** side-by-side with historical data.

### üîÆ Predictive ETL (2030‚Äì2100)

Predictive ETL modules generate **future scenarios** (e.g., climate, demography) using historical data and models:

- Models produce forward-looking datasets (e.g., yearly grids for 2030‚Äì2100).
- For each scenario and time slice:
  - A predictive artifact is written (e.g., `climate_rcp45_2050.tif`),
  - A STAC Item is created with:
    - `datetime` set to the modeled year,
    - `properties` including `scenario`, `model`, `version`, `uncertainty`,
  - A `Dataset` node in Neo4j is updated to link to the new STAC Items.

Predictive data is **clearly distinguished** from observational data in both metadata (`properties.kind: "model-projection"`) and UI (labels, styling). Focus Mode and Story Nodes are prompted to use hedged language (‚Äúprojected‚Äù, ‚Äúmodeled‚Äù) when referring to future data.

---

## üìä Knowledge Graph & Ontology Schema

KFM‚Äôs **knowledge graph** is implemented in Neo4j and provides the semantic backbone for Focus Mode, Story Nodes, and all higher-level analytics.

### üß¨ Core Entity Types

The graph is **schema-first** and maps to recognized ontology classes:

- `Person`  
  - CIDOC: `E21 Person`  
  - schema.org: `Person`  
  - Properties: `id`, `name`, `birth_date`, `death_date`, `roles`, etc.

- `Place`  
  - CIDOC: `E53 Place`  
  - schema.org: `Place`  
  - GeoSPARQL: `geo:Feature` with `geo:hasGeometry`  
  - Properties: `id`, `name`, `geometry` (GeoJSON/WKT), `bbox`, `admin_level`.

- `Event`  
  - CIDOC: `E5 Event`  
  - schema.org: `Event`  
  - OWL-Time: `time:Interval` (start/end)  
  - Properties: `id`, `label`, `start_time`, `end_time`, `kind`.

- `Document`  
  - CIDOC: `E31 Document`  
  - schema.org: `CreativeWork`  
  - Properties: `id`, `title`, `type`, `source`, `url`, `text`, `license`.

- `Dataset`  
  - DCAT: `Dataset` (and/or STAC Collection)  
  - Properties: `id`, `title`, `description`, `license`, `publisher`, `landing_page`.

- `SensorStream`  
  - Represents a live data stream (e.g. a station).  
  - Links to `Place`, `Dataset`, and `Observation` nodes.

- `Observation`  
  - Time-stamped measurement or derived value.  
  - Properties: `timestamp`, `value`, `unit`, `quality_flag`.

- `StoryNode`  
  - See Story Nodes section below.  
  - Properties: `id`, `title`, `summary`, narrative/body, `spacetime` attributes.

### üîó Key Relationship Types

Relationships encode semantics and enable higher-order queries:

- `(:Person)-[:ATTENDED]->(:Event)`  
- `(:Person)-[:ASSOCIATED_WITH]->(:Person)`  
- `(:Event)-[:OCCURRED_AT]->(:Place)`  
- `(:Document)-[:MENTIONS]->(:Place|:Person|:Event)`  
- `(:Dataset)-[:DESCRIBES]->(:Event|:Place|:Person)`  
- `(:SensorStream)-[:LOCATED_AT]->(:Place)`  
- `(:SensorStream)-[:PRODUCED]->(:Observation)`  
- `(:StoryNode)-[:ABOUT]->(:Place|:Person|:Event|:Dataset)`  
- `(:StoryNode)-[:FOLLOWS]->(:StoryNode)` (narrative sequencing)  
- `(:Entity)-[:FEDERATED_WITH]->(:ExternalEntity)` (cross-graph federation)  
- `(:Observation)-[:DERIVED_FROM]->(:Dataset)`  

These relationships are enforced via Cypher templates and validation scripts in `src/graph/`. New pipelines must conform to the schema or add schema migrations.

### üåê Ontology Alignment

While Neo4j is not natively RDF, KFM‚Äôs schema is **logically mapped** to RDF/OWL:

- Each node type carries a `rdf_type` or `ontology_class` label (e.g., `cidoc:E5_Event`).
- Temporal properties follow OWL-Time (start/end instants, precision).
- Spatial properties follow GeoSPARQL expectations (WKT geometry, CRS annotations).
- DCAT‚Äôs `Dataset` and STAC‚Äôs `Collection/Item` are bridged via a dedicated mapping layer.

For RDF export or federation, a transform layer (e.g., in `src/graph/export_rdf.py`) can:

- Convert Neo4j nodes/edges to triples.
- Attach JSON-LD contexts for Story Nodes, Focus narratives, and STAC Items.

This alignment allows KFM to interoperate with Linked Data ecosystems while staying practical for Neo4j-centric development.

---

## üß© Story Nodes & Narrative Graph

### ü™∂ Story Node Schema

**Story Nodes** are structured narrative objects that bind text, time, space, and graph references. Their JSON schema (see `schemas/story-node.schema.json`) includes:

- `id` ‚Äì Globally unique identifier (UUID/DOI).
- `type` ‚Äì `"story-node"`.
- `version` ‚Äì Semantic version of the node content.
- `lang` ‚Äì BCP-47 code (e.g. `"en"`).
- `title` ‚Äì Human-readable title.
- `summary` ‚Äì Short abstract for cards/timelines.
- `narrative` ‚Äì Object with:
  - `body` ‚Äì Primary narrative text (Markdown recommended).
  - `format` ‚Äì MIME-type (`text/markdown`, etc.).
  - `alternates` ‚Äì Localized or audience-specific variants.
  - `media` ‚Äì Inline media references (images, audio, etc.).
- `spacetime` ‚Äì Object with:
  - `geometry` ‚Äì GeoJSON geometry (Point/Polygon/Multi*).
  - `bbox` ‚Äì Optional bounding box.
  - `crs` ‚Äì Coordinate reference system (default EPSG:4326).
  - `place_labels` ‚Äì Human place names.
  - `when` ‚Äì OWL-Time-compatible:
    - `start`, `end` ‚Äì ISO 8601 date-time strings.
    - `precision` ‚Äì Granularity (`year`, `month`, `day`, ‚Ä¶).
    - `original_label` ‚Äì e.g. `"circa 1854"` for approximate dates.
- `relations` ‚Äì Array of links to other nodes:
  - `rel` ‚Äì Relation type (`follows`, `references`, `contradicts`, `part-of`, etc.).
  - `target` ‚Äì Target entity ID.
  - `role` ‚Äì Qualifier (`primary-source`, `counterpoint`, etc.).
- `stac` ‚Äì Optional hints for downstream STAC integration (e.g., which assets to load with the story).

In Neo4j, a Story Node is represented as `(:StoryNode)` with properties mirrored from the JSON. Relations in the `relations` array are instantiated as graph edges (e.g., `[:FOLLOWS]`, `[:ABOUT]`).

### üìö Narrative Graph Integration

Story Nodes form a **narrative layer** atop the core fact graph:

- Each Story Node links to People/Places/Events via `:ABOUT`.
- Story Nodes link to each other (`:FOLLOWS`, `:PART_OF`) creating narrative sequences.
- Both a ‚Äústory graph‚Äù and a ‚Äúfact graph‚Äù are thus queryable:
  - ‚ÄúAll stories about the Arkansas River with events between 1850‚Äì1900.‚Äù
  - ‚ÄúNext story in this trail after `story-node:bleeding-kansas-01`.‚Äù

The React frontend renders Story Nodes as **story cards**, synchronized with:

- **Timeline:** Cards appear when the timeline is within their `when` interval.
- **Map:** Cards highlight their `spacetime.geometry` and linked places.

Contributors author Story Nodes via structured JSON/YAML (or a UI form) and commit them to version control, meaning stories are treated as code artifacts (subject to review, versioning, and CI validation).

---

## üîç Focus Mode v2.5 ‚Äî AI Context Engine

### üéØ Focus Mode Concept

**Focus Mode** is an AI-enhanced exploration mode that pivots the entire UI around a selected entity (Person, Place, Event, Document, or Dataset). When a user ‚Äúfocuses‚Äù on an entity:

- The **timeline** emphasizes relevant events (by type and time).
- The **map** pans/zooms to relevant places and toggles contextual layers.
- The **Focus Panel** displays:
  - AI-generated summary,
  - Related entities grouped by type,
  - Story Nodes and documents,
  - Optional explainability overlays.

It is implemented through:

- Backend: A `GET /api/focus/{id}` endpoint (FastAPI/GraphQL) that runs parameterized Cypher to gather the entity‚Äôs **local subgraph**.
- Frontend: React components that render the subgraph and AI outputs.

### üß† Focus Transformer v2.5

The core AI engine is **Focus Transformer v2.5**, a dual-encoder Transformer that consumes:

- Graph neighborhood (nodes + relations),
- Relevant text snippets from Documents/Story Nodes,
- Temporal and spatial metadata,
- Scenario flags (if future/projection).

It outputs:

- A structured summary (paragraphs, bullet points),
- Candidate insights (e.g., pattern descriptions),
- Attribution metadata (what evidence supports what claim).

Key design features:

- **Cross-modal attention:** The model attends jointly over graph structure, text, and metadata.
- **Ethical filters:** Enforced by prompt design and post-filters, ensuring sensitive content is handled per CARE guidelines.
- **Explainability:** It provides attention maps and/or SHAP-like importance scores for graph elements that contributed most to each sentence.

### üßæ Focus API Flow

1. Client calls `GET /api/focus/{id}` (or GraphQL equivalent) with entity ID.
2. Backend:
   - Validates ID and resolves the entity type.
   - Runs Cypher to collect:
     - Direct neighbors (1-hop) and selected 2-hop neighbors.
     - Relevant Story Nodes, Documents, Observations, and Datasets.
   - Feeds this context into Focus Transformer v2.5.
   - Produces:
     - `narrative` (Markdown/HTML),
     - `related_entities` grouped by type,
     - `provenance` (mapping text segments to source IDs),
     - `insights` (patterns, anomalies, suggestions).
3. Response JSON goes to frontend Focus Panel.

### üß© Explainability & Overlays

Frontend Focus Panel includes:

- **Sentence-level provenance:** Hovering over a sentence highlights the graph nodes and documents it came from; clicking provides a mini ‚Äúevidence‚Äù popup.
- **Ethical overlays:** Icons or banners when content is redacted, generalized, or flagged as sensitive.
- **Graph spotlight:** An optional mode where relevant nodes/edges in the map and timeline visually pulse or glow while the narrative is read.

---

## ‚òÅÔ∏è Deployment & Multi-Cloud Infrastructure

### üß± Containerization & Orchestration

KFM is packaged as a set of Docker images, typically orchestrated by:

- **Local / dev:** `docker-compose.yml` for quick spin-up.
- **Prod:** Kubernetes manifests or Helm charts per service (graph, API, web, ETL workers).

Services include:

- `neo4j` (graph DB, with optional clustering),
- `api` (FastAPI/GraphQL),
- `web` (React/MapLibre/Cesium SPA),
- `etl-batch` and `etl-streaming`,
- `kafka` (or equivalent message broker),
- optional `redis`/`pg` for caching and ancillary features.

### üå© Multi-Cloud Strategy

The architecture is **cloud-agnostic**:

- Uses open-source components (Neo4j, Kafka, MinIO/S3-compatible storage) rather than cloud-exclusive services.
- Deployment scripts exist (or are planned) for:
  - AWS (EKS + S3),
  - Azure (AKS + Blob Storage),
  - GCP (GKE + GCS),
  - On-prem clusters.

The **frontend** is a static SPA that can be served by any CDN or static host, giving flexible, global distribution.

### üßØ Diamond‚Åπ Œ© Rollback Safety

Rollback is achieved by:

- **Versioned releases:** Each release has:
  - `releases/{version}/sbom.spdx.json`,
  - `releases/{version}/manifest.zip` listing all artifacts,
  - tags in Git.
- **Data versioning:** Large datasets are tracked via DVC/Git LFS; raw and processed data can be regenerated from manifests.
- **Backup rotation:** Neo4j snapshots are taken regularly (e.g. daily), encrypted, and stored across multiple locations (on-prem + cloud).
- **Environment as code:** Redeploying any historical release simply involves checking out the tag and re-running IaC scripts.

In a catastrophic event, operators can:

1. Restore data from backup or DVC.
2. Redeploy images for the desired version.
3. Verify checksums, re-run validation pipelines.
4. Bring up the restored environment, confident that it matches the historical state.

---

## ‚öñÔ∏è Governance, Provenance & Compliance

### üìú Master Coder Protocol (MCP v6.3)

MCP governs how code, data, and docs are created and maintained:

- **Docs-before-code:** Every new feature requires:
  - Architecture/README update,
  - Experiment log (for models),
  - SOP for recurring tasks, if applicable.
- **Templates:** `docs/templates/` includes:
  - Experiment templates,
  - Model cards,
  - SOPs,
  - Contribution guides.
- **CI enforcement:** If new modules are added without corresponding docs or tests, CI fails.

### üåà FAIR + CARE Implementation

FAIR:

- **Findable:** Datasets indexed with DCAT and STAC; public README indexes all major assets.
- **Accessible:** Open repository, open licenses (MIT/CC-BY), public builds.
- **Interoperable:** Ontology alignment; JSON-LD exports; use of open formats only.
- **Reusable:** Rich metadata and licensing; detailed transformation logs.

CARE:

- **Collective Benefit:** Features like Focus Mode and Story Nodes are used to amplify knowledge for communities, not exploit them.
- **Authority to Control:** Sensitive datasets (e.g., Indigenous oral histories) are flagged and controlled; not exposed without explicit agreement.
- **Responsibility:** Clear guidelines for how contributors handle sensitive content; AI guardrails built into Focus Mode.
- **Ethics:** Regular FAIR+CARE reviews, audit logs, explicit consent fields in data manifests.

### üîç Provenance & Versioning

Every artifact in KFM (code, data, and docs) has:

- Explicit version,
- Origin (source, authors),
- Transformation steps.

This is captured by:

- Front-matter in docs (`version`, `commit_sha`, etc.),
- Data manifests (`source_url`, `license`, `hash`),
- ETL logs and notebooks,
- Graph properties and relationships like `:Observation-[:DERIVED_FROM]->:Dataset`.

---

## üìö Glossary

- **KFM:** Kansas Frontier Matrix.  
- **ETL:** Extract‚ÄìTransform‚ÄìLoad pipeline for data.  
- **STAC:** SpatioTemporal Asset Catalog (1.0).  
- **DCAT:** W3C Data Catalog Vocabulary (v3).  
- **CIDOC CRM:** Ontology for cultural heritage.  
- **OWL-Time:** Temporal ontology for instants/intervals.  
- **GeoSPARQL:** OGC standard for geospatial RDF.  
- **Story Node:** Schema-driven narrative object linking text, time, and space.  
- **Focus Mode:** AI reasoning engine.  
- **Diamond‚Åπ Œ© / Crown‚àûŒ©:** Internal labels for top-tier quality and governance compliance.  
- **MCP:** Master Coder Protocol (v6.3) ‚Äì documentation-first project methodology.  
- **FAIR:** Data principles (Findable, Accessible, Interoperable, Reusable).  
- **CARE:** Indigenous data governance principles (Collective Benefit, Authority to Control, Responsibility, Ethics).

---

## üïì Version History (Architecture Doc)

| Version   | Date       | Notes                                                                                     |
|----------|------------|-------------------------------------------------------------------------------------------|
| v10.4.0  | 2025-11-16 | Full rewrite for KFM v10.4.0; integrated Story Nodes, Focus v2.5, streaming ETL, FAIR+CARE. |
| v10.3.2  | 2025-11-14 | Prior deep-layer architecture; pre-streaming predictive ETL and partial narrative support. |
| v10.0.0  | 2025-09-01 | Major v10 upgrade; predictive modeling, Focus Mode v2, 3D visualization, STAC/DCAT bridge. |
| v9.7.x   | 2025-03-xx | Developer guide architecture; Focus Mode v1, initial Story Node support, stable ETL/graph. |
| ‚â§ v9.x   | 2023-2024  | Early system architecture drafts; single-cloud focus, basic FAIR support, pre-MCP v6.3.     |

---

<div align="center">

**¬© 2025 Kansas Frontier Matrix ‚Äî MIT License**  
Diamond‚Åπ Œ© / Crown‚àûŒ© Certified ¬∑ FAIR+CARE Compliant ¬∑ MCP-DL v6.3  
[Back to Documentation Index](../docs/README.md) ¬∑ [Governance Charter](../docs/standards/governance/ROOT-GOVERNANCE.md)

</div>
