# ğŸ§­ Kansas Frontier Matrix (KFM) â€” Server API

![FastAPI](https://img.shields.io/badge/FastAPI-API%20Layer-informational?logo=fastapi)
![OpenAPI](https://img.shields.io/badge/OpenAPI-Swagger%20Docs-informational?logo=openapi-initiative)
![GraphQL](https://img.shields.io/badge/GraphQL-Query%20Gateway-informational?logo=graphql)
![PostGIS](https://img.shields.io/badge/PostGIS-Spatial%20DB-informational?logo=postgresql)
![Neo4j](https://img.shields.io/badge/Neo4j-Knowledge%20Graph-informational?logo=neo4j)
![OPA](https://img.shields.io/badge/OPA-Policy%20as%20Code-informational?logo=open-policy-agent)

> [!IMPORTANT]  
> **This service is the single supported boundary** between KFM clients (Web UI, automation agents, AR/3D clients) and KFM data stores (PostGIS, Neo4j, catalogs, object storage).  
> âœ… **Clients must not query PostGIS/Neo4j directly.** All access goes through the API so we can enforce policy, provenance, redaction, caching, and observability.

---

## ğŸ”— Quick navigation

- [ğŸ¯ What this API does](#-what-this-api-does)
- [ğŸ§± Architecture](#-architecture)
- [ğŸ“¦ Core concepts](#-core-concepts)
- [ğŸ›£ï¸ Endpoint surface](#ï¸-endpoint-surface)
- [ğŸ” Auth, roles, and policy-as-code](#-auth-roles-and-policy-as-code)
- [ğŸ§¾ Data formats & standards](#-data-formats--standards)
- [ğŸ§  Focus Mode (AI) contract](#-focus-mode-ai-contract)
- [ğŸ“¦ Ingest, pipelines, and idempotency](#-ingest-pipelines-and-idempotency)
- [ğŸ§¯ Errors, pagination, and time](#-errors-pagination-and-time)
- [âš¡ Performance & caching](#-performance--caching)
- [ğŸ”­ Observability](#-observability)
- [ğŸ§ª Testing & CI](#-testing--ci)
- [ğŸ§© Contributing](#-contributing)
- [ğŸ—ºï¸ Roadmap](#ï¸-roadmap)
- [ğŸ“š Reference docs](#-reference-docs)

---

## ğŸ¯ What this API does

This folder (`src/server/api/`) contains the **KFM API Layer** (FastAPI + GraphQL) responsible for:

- ğŸ—ºï¸ **Geospatial data access** (dataset metadata, filtered features, raster/vector tiles)
- ğŸ§  **Focus Mode (AI Assistant)** requests with **evidence + citations** (RAG + graph context)
- ğŸ§© **Knowledge Graph access** (Neo4j-backed relationships + semantics)
- ğŸ§µ **Story Nodes / narratives** (interactive storytelling objects tied to maps & timelines)
- âš™ï¸ **Ingestion + pipelines orchestration** (run pipelines, check status, enforce â€œprovenance-firstâ€)
- ğŸ” **Policy enforcement** (OPA/Rego + Conftest gatekeeping + runtime checks)
- ğŸ”­ **Observability** (logs, traces, audit trails, performance signals)

> [!NOTE]  
> The endpoint list below is the **contract target** derived from the KFM design/architecture documents.  
> Always confirm live paths in the serviceâ€™s **OpenAPI docs** and/or **GraphQL schema** once running.

---

## ğŸ§± Architecture

### ğŸ§© Where the API sits

```mermaid
flowchart LR
  UI[ğŸ–¥ï¸ Web UI<br/>React + MapLibre + 3D/Cesium] -->|REST / GraphQL| API[ğŸ§  KFM API<br/>FastAPI + GraphQL]
  AR[ğŸ“± AR / Mobile Client] -->|REST / GraphQL| API
  Agents[ğŸ¤– Watcherâ€“Plannerâ€“Executor Agents] -->|REST| API

  API -->|policy check| OPA[âš–ï¸ OPA / Rego Policies]
  API --> PG[(ğŸ—ºï¸ PostGIS)]
  API --> G[(ğŸ•¸ï¸ Neo4j Graph)]
  API --> Cat[(ğŸ“š STAC/DCAT Catalogs)]
  API --> Obj[(ğŸ§± Object Storage<br/>COG / NetCDF / GeoParquet / PMTiles)]
  API --> Prov[(ğŸ§¾ Provenance Store<br/>W3C PROV / JSON-LD)]
```

### ğŸ§ª Data lifecycle (why provenance matters)

```mermaid
flowchart TD
  Raw[ğŸ§Š Raw Ingest (read-only)] --> Work[ğŸ§° Work / Staging]
  Work --> Proc[âœ… Processed / Validated]
  Proc --> Catalogs[ğŸ“š Catalogs (STAC / DCAT)]
  Catalogs --> Graph[ğŸ•¸ï¸ Graph (Neo4j)]
  Graph --> API[ğŸ§  API Layer]
  API --> UI[ğŸ–¥ï¸ UI & Story/Focus]
```

**Design intent:** every dataset, analysis output, and AI answer should be traceable back to:
- the input(s),
- the pipeline/config,
- the code version,
- the policy checks passed,
- and the provenance record(s).

---

## ğŸ“¦ Core concepts

### ğŸ§¾ Dataset
A stable logical unit exposed to clients. Usually backed by:
- ğŸ§  **Catalog metadata** (DCAT summary + STAC links)
- ğŸ—ºï¸ **Spatial storage** (PostGIS tables/views, rasters, or external assets)
- ğŸ§¾ **Provenance** (PROV graph records and evidence manifests)

### ğŸ§© STAC / DCAT
- **STAC Items** describe spatiotemporal assets (imagery, scenes, observations).
- **DCAT Datasets** describe higher-level published datasets for discovery and governance.

### ğŸ•¸ï¸ Knowledge graph (Neo4j)
Used for:
- relationships between places/people/events,
- linking datasets to real-world context,
- semantic search + Focus Mode grounding.

### ğŸ§µ Story Node
A narrative step that can reference:
- time ranges (timeline),
- map layers and view states,
- media + citations,
- graph entities.

### ğŸ§  Focus Mode
Evidence-backed AI Q&A with:
- controlled retrieval,
- graph context injection,
- citation/provenance enforcement,
- prompt-security layers.

### ğŸ§ª Pulse Threads (future)
A â€œtraceable streamâ€ concept that packages:
- a **question** / user intent,
- the **evidence** used,
- the **transformations** applied,
- and the **result** (map/story/answer),
into a shareable, verifiable thread.

---

## ğŸ›£ï¸ Endpoint surface

> [!TIP]  
> Keep REST endpoints **resource-oriented** and **versioned** (e.g., `/api/v1/...`).  
> Use GraphQL when you need flexible joins across domains (places â†” datasets â†” events â†” story nodes).

### âœ… Meta & health

- `GET /healthz` â€” liveness
- `GET /readyz` â€” readiness (deps reachable)
- `GET /version` â€” build/version metadata
- `GET /openapi.json` â€” OpenAPI spec
- `GET /docs` â€” Swagger UI (FastAPI)

---

### ğŸ“š Catalog & datasets

- `GET /api/v1/datasets/{id}`  
  Returns dataset metadata (DCAT summary + STAC links).

- `GET /api/v1/datasets/{id}/data?format=geojson&bbox=minx,miny,maxx,maxy&limit=...`  
  Returns filtered features (GeoJSON / JSON / Parquet export â€” depending on implementation).

- `GET /api/v1/catalog/search?keyword=...&bbox=...&time=...`  
  Dataset discovery across STAC/DCAT.

<details>
<summary>ğŸ“Œ Example: fetch dataset metadata</summary>

```bash
curl -s "http://localhost:8000/api/v1/datasets/ks_hydrology_1880" | jq
```
</details>

---

### ğŸ—ºï¸ Spatial query (adâ€‘hoc / safe query surface)

- `GET /api/v1/query?table=geo_counties&bbox=...&select=...&where=...&limit=...`

> [!WARNING]  
> Treat `/query` as a **controlled interface**: parameterize, restrict tables/views, enforce row/column policies, and log PROV for every execution.

<details>
<summary>ğŸ“Œ Example: quick table query</summary>

```bash
curl -s "http://localhost:8000/api/v1/query?table=geo_counties&limit=5" | jq
```
</details>

---

### ğŸ§± Tiles (2D/3D clients)

#### Vector tiles (MVT)
- `GET /tiles/{layer}/{z}/{x}/{y}.pbf`

#### Raster tiles (common patterns)
- `GET /tiles/{layer}/{z}/{x}/{y}.png`
- `GET /tiles/{layer}/{z}/{x}/{y}.webp` (optional)

> [!NOTE]  
> A key KFM goal is that **MapLibre, Cesium/3D clients, and AR/mobile** can all â€œdrink from the same wellâ€ of standardized APIs.

<details>
<summary>ğŸ“Œ Example: fetch a vector tile</summary>

```bash
curl -I "http://localhost:8000/tiles/landcover/7/26/49.pbf"
```
</details>

---

### ğŸ•¸ï¸ Graph access

#### GraphQL gateway
- `POST /graphql`

Use GraphQL for complex, client-shaped queries:
- place â†’ datasets â†’ related events â†’ story nodes
- dataset â†’ provenance â†’ generating pipeline runs

<details>
<summary>ğŸ“Œ Example: GraphQL query</summary>

```graphql
query PlaceContext($placeId: ID!) {
  place(id: $placeId) {
    id
    name
    datasets(limit: 10) { id title }
    relatedEvents(timeRange: { from: "1850-01-01", to: "1900-12-31" }) {
      id
      label
      date
    }
  }
}
```
</details>

---

### ğŸ§µ Story Nodes (narratives)

- `POST /api/v1/story` â€” create a story node (typically contributor+)
- `GET  /api/v1/story/{id}` â€” fetch story node
- `GET  /api/v1/story?bbox=...&time=...&tag=...` â€” browse story nodes

<details>
<summary>ğŸ“Œ Example: create a story node</summary>

```bash
curl -X POST "http://localhost:8000/api/v1/story" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $KFM_TOKEN" \
  -d '{
    "title": "Kansas From Above â€” 1870 to 1900",
    "time_range": {"from": "1870-01-01", "to": "1900-12-31"},
    "map_state": {"center": [-98.0, 38.5], "zoom": 6},
    "layers": ["railroads_1880", "counties_1890"],
    "citations": [{"dataset_id":"ks_railroads_1880","note":"Primary layer"}]
  }'
```
</details>

---

### ğŸ§  Focus Mode (AI)

- `POST /api/v1/ai/query` â€” ask a question
- `POST /api/v1/ai/stream` â€” streaming answer (SSE/WebSocket, if enabled)
- `GET  /api/v1/ai/suggestions?context=...` â€” â€œwhat to ask nextâ€ / dataset suggestions (optional)

See [ğŸ§  Focus Mode (AI) contract](#-focus-mode-ai-contract).

---

### âš™ï¸ Ingest & pipelines

- `POST /api/v1/ingest` â€” direct ingest (typically **admin-only**)
- `POST /api/v1/ingest/runPipeline` â€” run a named pipeline
- `GET  /api/v1/pipelines/status` â€” pipeline run status
- `GET  /api/v1/pipelines/{run_id}` â€” detailed run + provenance links

See [ğŸ“¦ Ingest, pipelines, and idempotency](#-ingest-pipelines-and-idempotency).

---

### ğŸ“¡ Real-time / live feeds (optional, but designed-in)

- `GET /api/v1/transport/buses?since=<iso8601>`  
  A canonical example of live/streaming â€œWatcherâ€ outputs surfaced as queryable data.

---

## ğŸ” Auth, roles, and policy-as-code

### ğŸ‘¥ Roles (conceptual baseline)

- ğŸ‘€ **Public Viewer** â€” read-only access to public datasets & stories
- âœï¸ **Contributor** â€” can submit story nodes and proposed data additions
- ğŸ§° **Maintainer** â€” can approve/curate/merge contributions
- ğŸ›¡ï¸ **Admin** â€” can run privileged ingest actions, manage policies & secrets

> [!IMPORTANT]  
> Every request path must be governed by **RBAC + policy checks** (including data sensitivity labels).

### âš–ï¸ Policy Pack (OPA/Rego + Conftest)

**What policy should enforce (high-level):**
- âœ… **Pipeline ordering** (Raw â†’ Work â†’ Processed â†’ Catalogs â†’ Graph â†’ API â†’ UI)
- ğŸš« **API boundary** (no bypassing the API for data/graph access)
- ğŸ§¾ **Provenance-first publishing** (nothing goes public without provenance + required metadata)
- ğŸ” **Security checks** (no secrets, validated schemas, safe query rules)
- ğŸ§  **AI answer requirements** (e.g., â€œmust include at least one citationâ€)

> [!TIP]  
> Treat policy files as **first-class code**: versioned, tested, reviewed, and run in CI.

---

## ğŸ§¾ Data formats & standards

### ğŸ—ºï¸ Geospatial exchange formats
- **GeoJSON** â€” ad-hoc feature responses / exports
- **MVT (.pbf)** â€” high-performance vector tiles
- **COG (Cloud-Optimized GeoTIFF)** â€” raster assets served via tile APIs
- **NetCDF (chunked)** â€” scientific rasters/time-series (served via derived tiles or subsets)
- **GeoParquet** â€” columnar analytics export (optional)
- **PMTiles** â€” portable offline tile packaging (planned)

### ğŸ“š Catalogs & provenance
- **STAC** (Items/Collections) for spatiotemporal assets
- **DCAT** for dataset-level discovery and governance metadata
- **W3C PROV / PROV-O** (often JSON-LD) for lineage + auditability

---

## ğŸ§  Focus Mode (AI) contract

> [!IMPORTANT]  
> Focus Mode is **not** â€œchat with the database.â€ Itâ€™s a governed system: retrieval is controlled, graph context is used responsibly, and responses **must carry citations**.

### Request (baseline shape)

```json
{
  "question": "What was the water level near Topeka in spring 1951?",
  "context": {
    "bbox": [-96.9, 39.0, -95.9, 39.3],
    "time_range": { "from": "1951-03-01", "to": "1951-06-30" },
    "layers": ["river_gauges", "flood_extent_1951"],
    "place_ids": ["place_topeka_ks"]
  },
  "options": {
    "max_citations": 8,
    "response_style": "explainable",
    "allow_external_web": false
  }
}
```

### Response (evidence-forward)

```json
{
  "answer": "â€¦",
  "citations": [
    {
      "dataset_id": "ks_river_gauges",
      "stac_item": "river_gauges_1951-05-12_topeka",
      "provenance": { "prov_activity": "prov:run/abcd1234" },
      "excerpt": "â€¦"
    }
  ],
  "provenance": {
    "prov_activity": "prov:ai_query/efgh5678",
    "used_entities": ["dataset:ks_river_gauges", "stac:item/river_gauges_1951-05-12_topeka"]
  },
  "safety": {
    "redactions_applied": true,
    "policy_checks": ["ai.citations.required", "data.sensitivity.enforced"]
  }
}
```

---

## ğŸ“¦ Ingest, pipelines, and idempotency

### ğŸ§Š Ingest philosophy (why weâ€™re strict)
- Raw inputs are treated as **immutable**.
- Processing is **deterministic/config-driven**.
- Publishing is **provenance-first** and **policy-gated**.

### ğŸ” Idempotency (must-have for safe automation)
Any mutating endpoint should support:

- `Idempotency-Key: <stable-digest>` header  
- server-side de-duplication + â€œreplay yields the same resultâ€ semantics  
- provenance for each run so we can answer: **â€œwhat created this and why?â€**

### ğŸ§¾ Run manifests (recommended)
For pipelines or automated agents, prefer a **Run Manifest** that includes:
- inputs (dataset refs, digests),
- pipeline/config version,
- parameters,
- expected outputs,
- and policy checks run.

This enables:
- reproducibility,
- artifact signing,
- and â€œevidence manifestsâ€ attached to catalog entries.

---

## ğŸ§¯ Errors, pagination, and time

### ğŸ”¥ Error shape (recommended)

```json
{
  "error": {
    "code": "KFM_FORBIDDEN",
    "message": "You are not allowed to access this dataset.",
    "request_id": "req_01H...",
    "details": { "policy": "data.sensitivity.enforced" }
  }
}
```

### ğŸ“„ Pagination (recommended)
- `limit`, `offset` for simple lists
- `cursor` for stable, scalable pagination in large catalogs

### â±ï¸ Time rules
- Use ISOâ€‘8601 strings (`YYYY-MM-DD` or `YYYY-MM-DDTHH:mm:ssZ`)
- Be explicit about time zones (prefer UTC)

---

## âš¡ Performance & caching

- ğŸ§± **Tile caching** is first-class (HTTP cache headers + CDN where possible)
- ğŸ§  Avoid N+1 graph/data patterns (GraphQL resolvers should batch/cache)
- ğŸ§° Parameterize and restrict query surfaces (especially `/query`)
- ğŸ—ºï¸ Use spatial indexes and simplified geometries for high zoom tiles
- ğŸš¦ Prefer async/background tasks for heavy compute (analysis, bulk exports)

---

## ğŸ”­ Observability

- ğŸ“ˆ **OpenTelemetry traces** (API â†’ PostGIS â†’ Neo4j â†’ object storage)
- ğŸ§¾ **Audit logs** for:
  - sensitive datasets,
  - Focus Mode queries,
  - story publishing,
  - ingestion/pipeline runs.
- âš¡ Optional: â€œenergy / costâ€ instrumentation for compute-heavy steps (design goal)

---

## ğŸ§ª Testing & CI

### âœ… What we expect in CI
- unit tests (routes/services)
- integration tests (PostGIS + Neo4j + catalogs)
- schema validation (STAC/DCAT/PROV + API payloads)
- policy pack checks (Conftest)
- security checks (secrets scanning, dependency checks)

### ğŸ§  Policy tests
Policies should be testable with â€œgoodâ€ and â€œbadâ€ fixtures:
- âœ… compliant dataset metadata passes
- âŒ missing license fails
- âŒ AI output without citations fails
- âŒ bypass attempt fails

---

## ğŸ§© Contributing

### ğŸ§¾ Contract-first workflow
When adding/changing endpoints:

1. âœ… Update request/response schemas (Pydantic + OpenAPI)
2. âœ… Update GraphQL schema/resolvers (if applicable)
3. âœ… Add/adjust OPA policy checks (runtime + CI)
4. âœ… Add tests (unit + integration)
5. âœ… Update this READMEâ€™s endpoint index
6. âœ… Ensure provenance is emitted for any mutating action

> [!TIP]  
> If a change cannot be validated deterministically, it probably needs a tighter contract.

---

## ğŸ—ºï¸ Roadmap

- ğŸ“¦ **Offline Data Packs** for rural/field use (bundled tiles + catalogs + models)
- ğŸŒ **Federation** (multi-region â€œFrontier Matrixâ€ interoperability)
- ğŸ§Š **Artifact distribution via OCI** (signed data packs + verifiable provenance)
- ğŸ§  **GraphQL subscriptions / streaming** for live feeds + Focus Mode streams
- ğŸ›°ï¸ **Remote sensing pipelines** (ML-based products surfaced as datasets)
- ğŸ“± **AR/mobile clients** (same APIs; different UX + filtering strategies)
- ğŸŒ **OGC API Features / WMS/WFS** compatibility (where it helps adoption)

---

## ğŸ“š Reference docs

These docs define the contract and design intent that this API README follows:

- ğŸ“˜ *KFM â€“ Comprehensive Technical Documentation*
- ğŸ—ï¸ *KFM â€“ Comprehensive Architecture, Features, and Design*
- ğŸ§­ğŸ¤– *KFM â€“ AI System Overview*
- ğŸ§© *KFM â€“ Comprehensive UI System Overview*
- ğŸ“š *KFM Data Intake â€“ Technical & Design Guide*
- ğŸŒŸ *KFM â€“ Latest Ideas & Future Proposals*
- ğŸ’¡ *Additional Project Ideas*
- ğŸš€ *Innovative Concepts to Evolve KFM*
- ğŸ—ºï¸ *Maps / WebGL / Virtual Worlds reference portfolio*
- ğŸ§  *AI Concepts reference portfolio*
- ğŸ—ƒï¸ *Data Management / Architecture reference portfolio*
- ğŸ§° *Programming languages & resources reference bundle*

---

> [!NOTE]  
> **If you update APIs, update docs.** The UI, agents, and future AR clients all depend on this contract staying trustworthy. âœ…