<!--
ğŸ“Œ Notebooks are KFMâ€™s â€œlab benchâ€: exploration + prototypes + evidence drafts.
ğŸ—“ï¸ Last updated: 2026-01-11
ğŸ” Review cycle: 90 days (or anytime staging/catalog/story workflows change)
ğŸ” Reminder: anything that influences decisions must become a governed artifact (catalog + provenance),
    not a stray notebook output. No catalog â†’ no graph â†’ no API â†’ no UI.
-->

<div align="center">

# ğŸ““ Notebooks â€” Kansas Frontier Matrix (KFM)

**Exploration with receipts. Prototypes with guardrails. Evidence with governance.** ğŸ§¾ğŸ§ªğŸ—ºï¸ğŸ§¬  
_Notebooks help us think fast â€” KFM helps us ship truthfully._

![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-f37726?logo=jupyter&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.11%2B-3776ab?logo=python&logoColor=white)
![GIS](https://img.shields.io/badge/GIS-GeoPandas%20%7C%20GDAL-success)
![Remote%20Sensing](https://img.shields.io/badge/Remote%20Sensing-EO%20%7C%20GEE-informational)
![Deterministic](https://img.shields.io/badge/Determinism-Preferred-brightgreen)
![Catalogs](https://img.shields.io/badge/Catalogs-STAC%20%7C%20DCAT%20%7C%20PROV-845ef7)
![MCP](https://img.shields.io/badge/MCP-run%20receipts%20%2B%20protocols-8957e5)
![Safety](https://img.shields.io/badge/Safety-no%20secrets%20%7C%20hostile--inputs-critical)
![Docker](https://img.shields.io/badge/Docker-Recommended-2496ED?logo=docker&logoColor=white)

</div>

> [!IMPORTANT]
> âœ… Notebooks are for exploration and learning.  
> ğŸ›ï¸ Anything that becomes â€œrealâ€ must **graduate** into canonical code + tests + governed artifacts:
>
> **ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode** ğŸ§±ğŸ—‚ï¸ğŸ§¬

---

<details>
<summary><b>ğŸ§­ Table of contents</b></summary>

- [ğŸ”— Quick links](#-quick-links)
- [ğŸ§¾ Doc metadata](#-doc-metadata)
- [ğŸ§­ Where notebooks fit](#-where-notebooks-fit)
- [ğŸ§¨ Notebook non-negotiables](#-notebook-non-negotiables)
- [ğŸ—‚ï¸ Suggested folder layout](#ï¸-suggested-folder-layout)
- [ğŸ§© Notebook tracks](#-notebook-tracks)
- [ğŸš€ Quick start](#-quick-start)
- [âœ… Notebook conventions](#-notebook-conventions-kfm-standard)
- [ğŸ§¾ Run manifests](#-run-manifests-highly-recommended)
- [ğŸ§¬ Evidence artifacts & promotion](#-evidence-artifacts--promotion)
- [ğŸ§ª Testing notebooks](#-testing-notebooks-optional-but-powerful)
- [ğŸ” Data, licensing, governance & ethics](#-data-licensing-governance--ethics)
- [ğŸ“Œ â€œMake it citableâ€ (research UX)](#-make-it-citable-research-ux)
- [ğŸ“š Reference library](#-reference-library-all-project-files)
- [ğŸ•°ï¸ Version history](#ï¸-version-history)

</details>

---

## ğŸ”— Quick links

- ğŸ§­ Repo overview: `../README.md`
- ğŸ§© Executable boundary: `../src/README.md` *(if present)*
- ğŸ“¦ Data + metadata boundary: `../data/README.md` *(if present)*
- ğŸ§° Toolchain + validators: `../tools/README.md`
- ğŸ§° Automation wrappers: `../scripts/README.md`
- ğŸ§ª Tests + CI gates: `../tests/README.md`
- ğŸ““ MCP (protocols + runs + model cards): `../mcp/README.md` *(canonical receipts)*
- ğŸ§¾ Story Nodes (governed narratives): `../docs/reports/story_nodes/` *(draft â†’ published, if present)*

---

## ğŸ§¾ Doc metadata

| Field | Value |
|---|---|
| Folder | `notebooks/` |
| Role | ğŸ““ lab bench (exploration, prototypes, drafts) |
| Audience | analysts Â· researchers Â· maintainers Â· collaborators |
| Status | Active âœ… |
| Version | **v1.3.0** |
| Last updated | **2026-01-11** |
| Default output policy | `_artifacts/` + `_runs/` + `_data/` are **gitignored** |
| Evidence policy | decision-influencing outputs must become **cataloged + provenance-linked** |
| Canonical order | **ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ APIs â†’ UI â†’ Story â†’ Focus** |

---

## ğŸ§­ Where notebooks fit

Think of the repo like a **scientific instrument** with a governed â€œoutput chainâ€ ğŸ§ªâ¡ï¸ğŸ§¾:

- ğŸ—ï¸ **Production code** â†’ `src/` (and `src/server/` or `api/` if present)  
- ğŸ§° **Governed tools** â†’ `tools/` (validators, catalog QA, provenance helpers)  
- ğŸ§° **Orchestration glue** â†’ `scripts/` (thin wrappers; safe-by-default)  
- ğŸ§ª **Tests** â†’ `tests/` (contracts + determinism + integration)  
- ğŸ““ **Receipts & methods** â†’ `mcp/` (protocols, run receipts, model cards)  
- ğŸ““ **Notebooks** â†’ `notebooks/` (this folder): rapid exploration, drafts, spikes

> [!NOTE]
> In the v13 layout, **MCP is the canonical home for â€œMethods & Computational Experimentsâ€** (runs, notebooks, model cards).  
> This `notebooks/` folder remains a practical workspace â€” but **anything decision-relevant should be linked into MCP** (or moved into an MCP-tracked structure) so it has durable receipts. ğŸ§¾âœ…

---

## ğŸ§¨ Notebook non-negotiables

These are boring on purpose. Boring = reproducible. ğŸ˜Œâœ…

1) ğŸ” **No secrets** in notebooks, outputs, or logs (tokens, internal URLs, credentials).  
2) ğŸ§¾ **No evidence without receipts**: if it matters, write a run manifest and/or MCP run receipt.  
3) ğŸ—‚ï¸ **No â€œpublished-lookingâ€ files** created outside the governed pipeline.  
4) ğŸ§¬ **If you create an evidence artifact** (model output, derived layer, OCR corpus), treat it like a dataset:
   - store properly (eventually `data/processed/**`)
   - catalog it (STAC/DCAT)
   - trace it (PROV)
5) ğŸ§± **Respect the ordering:** ETL â†’ catalogs â†’ graph â†’ APIs â†’ UI â†’ story â†’ focus  
6) ğŸ§ª **Determinism preferred**: record seeds, stable sorts, pinned versions where feasible.  
7) ğŸ§¯ **Hostile-input mindset**: assume files can be malicious (archives, rasters, JSON, PDFs). Validate + limit.  
8) ğŸ“¦ **Keep notebooks light**: avoid committing huge outputs; save artifacts to `_artifacts/`.  
9) ğŸ“œ **Licensing + attribution is not optional**: record source + license in header/manifest.  
10) ğŸ§  **Be honest about uncertainty**: include checks, diagnostics, and caveats in conclusions.

---

## ğŸ—‚ï¸ Suggested folder layout

Keep this predictable so collaborators can jump in fast ğŸ§­:

```text
ğŸ““ notebooks/
â”œâ”€ ğŸ“˜ README.md
â”œâ”€ ğŸ§© _templates/                # ğŸ“„ notebook templates (EDA, GIS, RS, modeling, sim, report)
â”œâ”€ ğŸš« _data/                     # ğŸ§º local-only datasets (gitignored)
â”œâ”€ ğŸ“¦ _artifacts/                # ğŸ“ exported plots/tables/models (gitignored)
â”œâ”€ ğŸ§¾ _runs/                     # ğŸ§¾ run manifests + params (gitignored)
â”œâ”€ ğŸ–¼ï¸ _figures/                  # ğŸ–¼ï¸ small committed figures used in docs (stable + tiny)
â”œâ”€ ğŸ§­ 00_orientation/            # glossary, invariants, â€œhow KFM worksâ€
â”œâ”€ ğŸ§° 01_tooling/                # env, Docker, reproducibility helpers
â”œâ”€ ğŸ—ºï¸ 02_gis_core/               # CRS, overlays, vector/raster workflows
â”œâ”€ ğŸ›°ï¸ 03_remote_sensing/         # EO/GEE, composites, change detection
â”œâ”€ ğŸ“Š 04_stats/                  # EDA, regression, Bayes, inference checks
â”œâ”€ ğŸ¤– 05_ml_agents/              # baselines, eval, decision logic (human-in-loop)
â”œâ”€ ğŸ§ª 06_simulation_optimization/ # V&V, sensitivity, optimization runs
â”œâ”€ ğŸŒ 07_web_mapping_viz/         # map styles, responsive/UI spikes, WebGL demos
â”œâ”€ ğŸ§¬ 08_language_tools/          # schema/DSL sketches, parsing experiments
â””â”€ ğŸ§  09_human_factors/           # governance, ethics, human-centered notes
```

### ğŸ§· Recommended `.gitignore` additions
```gitignore
# notebooks: keep the repo light ğŸª¶
notebooks/_data/
notebooks/_artifacts/
notebooks/_runs/
notebooks/**/.ipynb_checkpoints/
```

> [!TIP]
> If a notebook depends on real infra (PostGIS/Neo4j/object storage), capture it in a run manifest and prefer containers for reproducibility. ğŸ³âœ…

---

## ğŸ§© Notebook tracks

| Track | Folder | Focus | Typical outputs |
|---|---|---|---|
| ğŸ§­ Foundations | `00_orientation/` | KFM context, glossary, invariants | notes + diagrams |
| ğŸ§° Tooling | `01_tooling/` | env setup, Docker workflows, reproducible runs | run manifests |
| ğŸ—ºï¸ GIS Core | `02_gis_core/` | CRS hygiene, overlays, IO round-trips | small vectors/rasters |
| ğŸ›°ï¸ Remote Sensing | `03_remote_sensing/` | time-series, composites, change detection | quicklooks + draft STAC |
| ğŸ“Š Statistics | `04_stats/` | EDA, regression, Bayes, experimental design discipline | diagnostics + metrics |
| ğŸ¤– ML + Agents | `05_ml_agents/` | baselines, eval, decision logic | eval tables + draft model cards |
| ğŸ§ª Simulation + Optimization | `06_simulation_optimization/` | V&V, UQ, sensitivity sweeps | run bundles + checks |
| ğŸŒ Web Maps + Viz | `07_web_mapping_viz/` | cartography, UI spikes, WebGL | small assets + demos |
| ğŸ§¬ Language Tools | `08_language_tools/` | schema ideas, parsers, DSL sketches | schemas + mini-compilers |
| ğŸ§  Human Factors | `09_human_factors/` | governance, ethics, autonomy notes | decision memos |

---

## ğŸš€ Quick start

### Option A â€” Local (fastest) âš¡
```bash
cd notebooks
python -m venv .venv
source .venv/bin/activate     # Windows: .venv\Scripts\activate
pip install -r requirements.txt
jupyter lab
```

### Option B â€” Docker (recommended) ğŸ³
```bash
docker compose up --build
```

> [!CAUTION]
> ğŸ” Never bake secrets into images. Use `.env` + environment variables and keep `.env` out of git.

### Option C â€” Repro runs (parameterized) ğŸ§¾
If you want repeatable notebook runs, prefer an execution wrapper:
- `papermill` (parameter injection + output notebook)
- `jupyter nbconvert --execute` (scriptable execution)

> If you add a notebook that becomes Tier 2+ (see below), consider adding a â€œrunnerâ€ script under `scripts/` so CI can execute it safely. ğŸ§°âœ…

---

## âœ… Notebook conventions (KFM standard)

### ğŸ·ï¸ Naming (boring & sortable)
Use a **two-digit prefix** + **verb-first slug**:

- `00_intro_kfm_context.ipynb`
- `02_vector_overlay_clip.ipynb`
- `03_gee_ndvi_timeseries.ipynb`
- `04_regression_baseline_diagnostics.ipynb`
- `06_simulation_sensitivity_sweep.ipynb`

### ğŸ§± Standard notebook header (required for shareable work)
Start every notebook with a â€œcontract headerâ€ (first cell, Markdown):

1) ğŸ¯ **Purpose** â€” what question are we answering?  
2) ğŸ“¥ **Inputs** â€” dataset IDs or sources, licenses, classification  
3) ğŸ“¤ **Outputs** â€” where artifacts will be written (`_artifacts/` by default)  
4) ğŸ›ï¸ **Parameters** â€” AOI, dates, EPSG, seeds, thresholds  
5) ğŸ§° **Environment** â€” key versions (and optional lock snapshot)

Template snippet:
```markdown
## ğŸ§¾ Notebook Contract

- **Purpose:** â€¦
- **Primary question:** â€¦
- **Inputs (IDs / sources):**
  - â€¦
- **Licenses / attribution:** â€¦
- **Classification:** public | restricted | (per repo policy)
- **Outputs:**
  - `_artifacts/...`
  - `_runs/...`
- **Parameters:**
  - AOI: â€¦
  - Time window: â€¦
  - EPSG: â€¦
  - Seed: â€¦
- **Environment:**
  - Python: â€¦
  - Key libs: â€¦
```

### âœ‚ï¸ Keep notebooks diff-friendly (recommended)
- avoid giant embedded outputs (save files to `_artifacts/`)
- clear noisy outputs before committing (or use output-stripping tooling)
- stable ordering: sort keys, deterministic joins, fixed random seeds

> [!TIP]
> If you canâ€™t list inputs/assumptions, the notebook is still â€œscratch mode.â€ Thatâ€™s fine â€” just donâ€™t ship it. ğŸ§ âœ…

---

## ğŸ§¾ Run manifests (highly recommended)

For any notebook producing outputs worth keeping, write a run manifest to `_runs/`.

**Suggested path:** `_runs/<notebook_slug>/<timestamp>/run.manifest.json`

Minimal example:
```json
{
  "run_id": "kfm.nb.03_gee_ndvi_timeseries.2026-01-11T12:00:00Z",
  "notebook": "03_remote_sensing/03_gee_ndvi_timeseries.ipynb",
  "git": { "sha": "UNKNOWN", "dirty": true },
  "params": {
    "aoi": "ks_bbox",
    "start": "2020-01-01",
    "end": "2020-12-31",
    "epsg": "EPSG:4326",
    "seed": 42
  },
  "inputs": [
    { "type": "catalog", "id": "stac://<collection_or_item_id>", "license": "â€¦", "classification": "public" }
  ],
  "outputs": [
    { "type": "plot", "path": "_artifacts/ndvi_timeseries.png" },
    { "type": "draft_stac_item", "path": "_artifacts/stac/item.json" }
  ],
  "checks": [
    { "name": "ndvi_range", "status": "pass", "details": "min=-0.12 max=0.74" }
  ],
  "warnings": []
}
```

### ğŸ§¼ Repro checklist âœ…
- [ ] Parameters cell at top (AOI, EPSG, dates, seeds)
- [ ] Deterministic seeds recorded (if stochastic)
- [ ] Environment captured (requirements/lockfile or snapshot)
- [ ] Outputs written to `_artifacts/` (gitignored) **or** promoted to `data/processed/...`
- [ ] No secrets/tokens/internal endpoints in cells, outputs, or logs

---

## ğŸ§¬ Evidence artifacts & promotion

KFM treats analysis outputs (including AI-derived outputs) as **first-class evidence artifacts** when they matter. That means they must follow the same governed lifecycle as â€œregularâ€ datasets ğŸ§¾ğŸ—‚ï¸:

### âœ… Promotion rule of thumb
If someone could cite your notebook output in a memo, map, story, or decision â€” itâ€™s evidence.

### ğŸªœ Reproducibility tiers (what counts as â€œrealâ€)
| Tier | Name | Allowed behavior | Not allowed |
|---|---|---|---|
| ğŸŸ  Tier 0 | Scratch | quick exploration, messy cells | decision claims, publishing |
| ğŸŸ¡ Tier 1 | Shareable | header + params + basic outputs | hidden inputs, unclear licenses |
| ğŸŸ¢ Tier 2 | Evidence-ready | run manifest + stable outputs + provenance pointers | mystery data, unlabeled derivations |
| ğŸ”µ Tier 3 | Productionized | logic moved to `src/` + tests + catalogs | notebook-only business logic |

> [!IMPORTANT]
> Any Tier 2+ output must be traceable: **inputs â†’ transforms â†’ outputs â†’ catalogs â†’ provenance** ğŸ§¾ğŸ§¬

### ğŸ§¬ Lifecycle: notebook â†’ production
```mermaid
flowchart LR
  A["ğŸ§ª Notebook experiment"] --> B["ğŸ“¦ Local artifacts\n_artifacts/"]
  A --> R["ğŸ§¾ Run manifest\n_runs/"]
  A --> C["ğŸ““ MCP note / protocol\n(mcp/)"]
  C --> D["ğŸ—ï¸ Extract core logic\nsrc: pipelines & services"]
  D --> E["âœ… Tests + fixtures\n(tests/)"]
  E --> F["ğŸ—‚ï¸ STAC/DCAT/PROV\n+ validation gates"]
  F --> G["ğŸ•¸ï¸ Graph / APIs / UI\n(governed)"]
```

ğŸ Graduation checklist
- [ ] Extract functions into `src/` (no notebook-only globals)
- [ ] Add tests (unit + integration/contract as needed)
- [ ] Define/validate contracts (schemas, CRS, expected columns)
- [ ] If evidence: store in `data/processed/...` + STAC/DCAT + PROV
- [ ] Confirm classification & redaction are correct (no silent downgrade)

---

## ğŸ§ª Testing notebooks (optional but powerful)

If notebooks become Tier 2+, consider:
- âœ… smoke-running critical notebooks automatically (parameterized)
- âœ… asserting outputs exist and meet schema expectations
- âœ… failing fast on silent drift (CRS mismatch, missing columns, empty exports)

Suggested approaches:
- `nbconvert --execute` on a tiny fixture config
- `pytest` + â€œnotebook runnerâ€ wrappers (prefer deterministic, small IO)
- `nbval`-style testing (great for contract checks; avoid pixel-perfect expectations)

> [!TIP]
> Notebook tests should validate **contracts** and **invariants**, not pixel-perfect plots. ğŸ§ âœ…

---

## ğŸ” Data, licensing, governance & ethics

### ğŸ“œ Licensing & attribution
- Donâ€™t use or publish data with unclear licensing.
- Record source + license in the header and run manifest.
- If you create a derived artifact, carry attribution forward (inputs â†’ outputs).

### ğŸª¶ Governance & â€œno downgradeâ€
- Outputs cannot be **less restricted** than inputs unless a reviewed redaction step exists.
- If sensitivity is unknown, default to **restricted** until reviewed.

### ğŸ§¯ Security posture (defensive)
- Treat inputs as hostile (archives, rasters, JSON, PDFs).
- Validate types, enforce size limits, avoid unsafe shell calls.
- Never log secrets; avoid embedding access tokens or internal endpoints.

### ğŸ¤– AI involvement (label it)
If you use AI-assisted generation (summaries, labels, model output):
- label the involvement (what + where)
- record the tool/model/version/config when permissible
- treat outputs as advisory unless promoted through governed pipeline

---

## ğŸ“Œ â€œMake it citableâ€ (research UX)

To support academic / workshop usage (without sacrificing governance):
- add `CITATION.cff` (software citation)
- consider versioned snapshot releases + DOIs for curated datasets
- explore Binder/JupyterHub launch paths for **example notebooks** (public-safe only)

> [!NOTE]
> One-click notebook launches should only expose **public** datasets/examples and should still point back to STAC/DCAT/PROV for traceability.

---

## ğŸ“š Reference library (all project files)

These files shape notebook templates, sanity checks, and how we reason about uncertainty, maps, systems, and governance. ğŸ§ ğŸ§¾

<details>
<summary><strong>ğŸ›ï¸ Core KFM design, repo discipline, and governed ordering</strong></summary>

- ğŸ“„ `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.docx`
- ğŸ“„ `MARKDOWN_GUIDE_v13.md.gdoc`
- ğŸ“„ `Scientific Method _ Research _ Master Coder Protocol Documentation.pdf`
- ğŸ“„ `Kansas-Frontier-Matrix Design Audit â€“ Gaps and Enhancement Opportunities.pdf`

</details>

<details>
<summary><strong>ğŸ›°ï¸ Remote sensing & Earth observation</strong></summary>

- ğŸ“„ `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf`

</details>

<details>
<summary><strong>ğŸ—ºï¸ GIS, cartography, and mapping UX</strong></summary>

- ğŸ“„ `python-geospatial-analysis-cookbook.pdf`
- ğŸ“„ `making-maps-a-visual-guide-to-map-design-for-gis.pdf`
- ğŸ“„ `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf`

</details>

<details>
<summary><strong>ğŸ“Š Statistics, EDA, regression & Bayesian reasoning</strong></summary>

- ğŸ“„ `Understanding Statistics & Experimental Design.pdf`
- ğŸ“„ `graphical-data-analysis-with-r.pdf`
- ğŸ“„ `regression-analysis-with-python.pdf`
- ğŸ“„ `Regression analysis using Python - slides-linear-regression.pdf`
- ğŸ“„ `think-bayes-bayesian-statistics-in-python.pdf`

</details>

<details>
<summary><strong>ğŸ§ª Simulation, verification & optimization</strong></summary>

- ğŸ“„ `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf`
- ğŸ“„ `Generalized Topology Optimization for Structural Design.pdf`

</details>

<details>
<summary><strong>ğŸ•¸ï¸ Graphs & structure</strong></summary>

- ğŸ“„ `Spectral Geometry of Graphs.pdf`

</details>

<details>
<summary><strong>ğŸ—„ï¸ Data systems & scaling</strong></summary>

- ğŸ“„ `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf`
- ğŸ“„ `Scalable Data Management for Future Hardware.pdf`
- ğŸ“„ `Data Spaces.pdf`

</details>

<details>
<summary><strong>ğŸŒ Web, WebGL, and media correctness</strong></summary>

- ğŸ“„ `responsive-web-design-with-html5-and-css3.pdf`
- ğŸ“„ `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf`
- ğŸ“„ `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf`

</details>

<details>
<summary><strong>ğŸ¤– ML practice & AI governance</strong></summary>

- ğŸ“„ `Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf`
- ğŸ“„ `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf`

</details>

<details>
<summary><strong>ğŸ›¡ï¸ Security, adversarial thinking & concurrency</strong></summary>

- ğŸ“„ `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf`
- ğŸ“„ `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf`
- ğŸ“„ `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf`

</details>

<details>
<summary><strong>ğŸ§  Human factors & systems thinking</strong></summary>

- ğŸ“„ `Introduction to Digital Humanism.pdf`
- ğŸ“„ `Principles of Biological Autonomy - book_9780262381833.pdf`

</details>

<details>
<summary><strong>ğŸ“š Programming reference shelves</strong></summary>

- ğŸ“„ `A programming Books.pdf`
- ğŸ“„ `B-C programming Books.pdf`
- ğŸ“„ `D-E programming Books.pdf`
- ğŸ“„ `F-H programming Books.pdf`
- ğŸ“„ `I-L programming Books.pdf`
- ğŸ“„ `M-N programming Books.pdf`
- ğŸ“„ `O-R programming Books.pdf`
- ğŸ“„ `S-T programming Books.pdf`
- ğŸ“„ `U-X programming Books.pdf`

</details>

---

## ğŸ•°ï¸ Version history

| Version | Date | Summary | Author |
|---:|---|---|---|
| v1.3.0 | 2026-01-11 | Aligned notebooks with v13 governed layout + MCP receipts; clarified non-negotiables, promotion rules for evidence artifacts, story-node location, and â€œmake it citableâ€ research UX; tightened safety + hostile-input posture and added a recommended `.gitignore` snippet. | KFM Engineering |
| v1.2.0 | 2026-01-09 | Updated repo boundary links, standardized pipeline order framing, added emoji folder map, clarified run manifests + tiers + graduation checklist, and enumerated project reference files. | KFM Engineering |
| v1.1.0 | 2026-01-07 | Prior iteration: notebook lab-bench framing, track layout, run manifest pattern, graduation rules. | KFM Engineering |

---

<div align="center">

ğŸ§ª Explore fast. Â· ğŸ§¾ Record assumptions. Â· ğŸ·ï¸ Promote evidence properly. Â· ğŸ›¡ï¸ Keep it governed. âœ…

</div>
