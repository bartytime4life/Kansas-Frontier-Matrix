<!--
ğŸ“Œ Notebooks are KFMâ€™s â€œlab benchâ€: exploration + prototypes + evidence drafts.
ğŸ—“ï¸ Last updated: 2026-01-13
ğŸ” Review cycle: 90 days (or anytime staging/catalog/story workflows change)
ğŸ” Reminder: anything that influences decisions must become a governed artifact (catalog + provenance),
    not a stray notebook output. No catalog â†’ no graph â†’ no API â†’ no UI.
-->

<div align="center">

# ğŸ““ Notebooks â€” Kansas Frontier Matrix (KFM)

**Exploration with receipts. Prototypes with guardrails. Evidence with governance.** ğŸ§¾ğŸ§ªğŸ—ºï¸ğŸ§¬  
_Notebooks help us think fast â€” KFM helps us ship truthfully._

![Jupyter](https://img.shields.io/badge/Jupyter-Notebooks-f37726?logo=jupyter&logoColor=white)
![Python](https://img.shields.io/badge/Python-3.11%2B-3776ab?logo=python&logoColor=white)
![GIS](https://img.shields.io/badge/GIS-GeoPandas%20%7C%20GDAL-success)
![Remote%20Sensing](https://img.shields.io/badge/Remote%20Sensing-EO%20%7C%20GEE-informational)
![Catalogs](https://img.shields.io/badge/Catalogs-STAC%20%7C%20DCAT%20%7C%20PROV-845ef7)
![Postgres](https://img.shields.io/badge/PostgreSQL%20%2B%20PostGIS-Recommended-336791?logo=postgresql&logoColor=white)
![Graph](https://img.shields.io/badge/Graph-knowledge%20%2B%20spectral-6f42c1)
![Determinism](https://img.shields.io/badge/Determinism-Preferred-brightgreen)
![MCP](https://img.shields.io/badge/MCP-run%20receipts%20%2B%20protocols-8957e5)
![Safety](https://img.shields.io/badge/Safety-no%20secrets%20%7C%20hostile--inputs-critical)
![Docker](https://img.shields.io/badge/Docker-Recommended-2496ED?logo=docker&logoColor=white)
![WebGL](https://img.shields.io/badge/WebGL-Demos%20OK-ff6b6b)

</div>

> [!IMPORTANT]
> âœ… Notebooks are for exploration and learning.  
> ğŸ›ï¸ Anything that becomes â€œrealâ€ must **graduate** into canonical code + tests + governed artifacts:
>
> **ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode** ğŸ§±ğŸ—‚ï¸ğŸ§¬  
>
> ğŸ§¾ **Receipts are mandatory** for anything decision-relevant (run manifest + provenance pointers + catalog IDs).

---

<details>
<summary><b>ğŸ§­ Table of contents</b></summary>

- [ğŸ”— Quick links](#-quick-links)
- [ğŸ§¾ Doc metadata](#-doc-metadata)
- [ğŸ§­ Where notebooks fit](#-where-notebooks-fit)
- [ğŸ§¨ Notebook non-negotiables](#-notebook-non-negotiables)
- [ğŸ—‚ï¸ Suggested folder layout](#ï¸-suggested-folder-layout)
- [ğŸ§© Notebook tracks](#-notebook-tracks)
- [ğŸ“¦ Template kit (recommended)](#-template-kit-recommended)
- [ğŸš€ Quick start](#-quick-start)
- [âœ… Notebook conventions](#-notebook-conventions-kfm-standard)
- [ğŸ§¾ Run manifests](#-run-manifests-highly-recommended)
- [ğŸ§¬ Evidence artifacts & promotion](#-evidence-artifacts--promotion)
- [ğŸ§ª Modeling, simulation & optimization playbook](#-modeling-simulation--optimization-playbook)
- [ğŸ“Š Statistics & ML evidence playbook](#-statistics--ml-evidence-playbook)
- [ğŸ—ºï¸ GIS, cartography & remote sensing playbook](#ï¸-gis-cartography--remote-sensing-playbook)
- [ğŸ—„ï¸ Data systems, scaling & performance playbook](#ï¸-data-systems-scaling--performance-playbook)
- [ğŸŒ Web mapping & media correctness playbook](#-web-mapping--media-correctness-playbook)
- [ğŸ›¡ï¸ Security & hostile-input playbook](#ï¸-security--hostile-input-playbook)
- [ğŸ§  Human factors, autonomy & AI governance](#-human-factors-autonomy--ai-governance)
- [ğŸ§ª Testing notebooks](#-testing-notebooks-optional-but-powerful)
- [ğŸ” Data, licensing, governance & ethics](#-data-licensing-governance--ethics)
- [ğŸ“Œ â€œMake it citableâ€](#-make-it-citable)
- [ğŸ“š Reference library](#-reference-library-all-project-files)
- [ğŸ•°ï¸ Version history](#ï¸-version-history)

</details>

---

## ğŸ”— Quick links

- ğŸ§­ Repo overview: `../README.md`
- ğŸ§© Executable boundary: `../src/README.md` *(if present)*
- ğŸ“¦ Data + metadata boundary: `../data/README.md` *(if present)*
- ğŸ§° Toolchain + validators: `../tools/README.md`
- ğŸ§° Automation wrappers: `../scripts/README.md`
- ğŸ§ª Tests + CI gates: `../tests/README.md`
- ğŸ““ MCP (protocols + runs + model cards): `../mcp/README.md` *(canonical receipts)*
- ğŸ§¾ Story Nodes (governed narratives): `../docs/reports/story_nodes/` *(draft â†’ published, if present)*

---

## ğŸ§¾ Doc metadata

| Field | Value |
|---|---|
| Folder | `notebooks/` |
| Role | ğŸ““ lab bench (exploration, prototypes, drafts) |
| Audience | analysts Â· researchers Â· maintainers Â· collaborators |
| Status | Active âœ… |
| Version | **v1.4.0** |
| Last updated | **2026-01-13** |
| Review cycle | 90 days ğŸ” |
| Default output policy | `_artifacts/` + `_runs/` + `_data/` are **gitignored** |
| Evidence policy | decision-influencing outputs must become **cataloged + provenance-linked** |
| Canonical order | **ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ APIs â†’ UI â†’ Story â†’ Focus** |
| Library alignment | all notebook tracks map to the **project PDF library** (see [Reference library](#-reference-library-all-project-files)) |

---

## ğŸ§­ Where notebooks fit

Think of the repo like a **scientific instrument** with a governed â€œoutput chainâ€ ğŸ§ªâ¡ï¸ğŸ§¾:

- ğŸ—ï¸ **Production code** â†’ `src/` (and `src/server/` or `api/` if present)  
- ğŸ§° **Governed tools** â†’ `tools/` (validators, catalog QA, provenance helpers)  
- ğŸ§° **Orchestration glue** â†’ `scripts/` (thin wrappers; safe-by-default)  
- ğŸ§ª **Tests** â†’ `tests/` (contracts + determinism + integration)  
- ğŸ““ **Receipts & methods** â†’ `mcp/` (protocols, run receipts, model cards)  
- ğŸ““ **Notebooks** â†’ `notebooks/` (this folder): rapid exploration, drafts, spikes

> [!NOTE]
> In the v13 layout, **MCP is the canonical home for â€œMethods & Computational Experimentsâ€** (runs, notebooks, model cards).  
> This `notebooks/` folder remains a practical workspace â€” but **anything decision-relevant should be linked into MCP** (or moved into an MCP-tracked structure) so it has durable receipts. ğŸ§¾âœ…

---

## ğŸ§¨ Notebook non-negotiables

These are boring on purpose. Boring = reproducible. ğŸ˜Œâœ…

1) ğŸ” **No secrets** in notebooks, outputs, or logs (tokens, internal URLs, credentials).  
2) ğŸ§¾ **No evidence without receipts**: if it matters, write a run manifest and/or MCP run receipt.  
3) ğŸ—‚ï¸ **No â€œpublished-lookingâ€ files** created outside the governed pipeline.  
4) ğŸ§¬ **If you create an evidence artifact** (model output, derived layer, OCR corpus), treat it like a dataset:
   - store properly (eventually `data/processed/**`)
   - catalog it (STAC/DCAT)
   - trace it (PROV)
5) ğŸ§± **Respect the ordering:** ETL â†’ catalogs â†’ graph â†’ APIs â†’ UI â†’ story â†’ focus  
6) ğŸ§ª **Determinism preferred**: record seeds, stable sorts, pinned versions where feasible.  
7) ğŸ§¯ **Hostile-input mindset**: assume files can be malicious (archives, rasters, JSON, PDFs). Validate + limit.  
8) ğŸ“¦ **Keep notebooks light**: avoid committing huge outputs; save artifacts to `_artifacts/`.  
9) ğŸ“œ **Licensing + attribution is not optional**: record source + license in header/manifest.  
10) ğŸ§  **Be honest about uncertainty**: include checks, diagnostics, and caveats in conclusions.  
11) ğŸ†” **Stable IDs > clever IDs**: donâ€™t encode meaning in identifiers; keep meaning in metadata.  
12) ğŸ§­ **No â€œdata-space driftâ€**: if a dataset leaves the notebook, it must re-enter the governed world via catalogs + provenance.

---

## ğŸ—‚ï¸ Suggested folder layout

Keep this predictable so collaborators can jump in fast ğŸ§­:

```text
ğŸ““ notebooks/
â”œâ”€ ğŸ“˜ README.md
â”œâ”€ ğŸ§© _templates/                 # ğŸ“„ notebook templates (EDA, GIS, RS, modeling, sim, report)
â”œâ”€ ğŸš« _data/                      # ğŸ§º local-only datasets (gitignored)
â”œâ”€ ğŸ“¦ _artifacts/                 # ğŸ“ exported plots/tables/models (gitignored)
â”œâ”€ ğŸ§¾ _runs/                      # ğŸ§¾ run manifests + params (gitignored)
â”œâ”€ ğŸ–¼ï¸ _figures/                   # ğŸ–¼ï¸ small committed figures used in docs (stable + tiny)
â”œâ”€ ğŸ§­ 00_orientation/             # glossary, invariants, â€œhow KFM worksâ€
â”œâ”€ ğŸ§° 01_tooling/                 # env, Docker, reproducibility helpers
â”œâ”€ ğŸ—ºï¸ 02_gis_core/                # CRS, overlays, vector/raster workflows
â”œâ”€ ğŸ›°ï¸ 03_remote_sensing/          # EO/GEE, composites, change detection
â”œâ”€ ğŸ“Š 04_stats/                   # EDA, regression, Bayes, inference checks
â”œâ”€ ğŸ¤– 05_ml_agents/               # baselines, eval, decision logic (human-in-loop)
â”œâ”€ ğŸ§ª 06_simulation_optimization/ # V&V, sensitivity, optimization runs
â”œâ”€ ğŸŒ 07_web_mapping_viz/          # map styles, responsive/UI spikes, WebGL demos
â”œâ”€ ğŸ§¬ 08_language_tools/           # schema/DSL sketches, parsing experiments
â””â”€ ğŸ§  09_human_factors/            # governance, ethics, human-centered notes
```

### ğŸ§· Recommended `.gitignore` additions
```gitignore
# notebooks: keep the repo light ğŸª¶
notebooks/_data/
notebooks/_artifacts/
notebooks/_runs/
notebooks/**/.ipynb_checkpoints/
```

> [!TIP]
> If a notebook depends on real infra (PostGIS/Neo4j/object storage), capture it in a run manifest and prefer containers for reproducibility. ğŸ³âœ…

---

## ğŸ§© Notebook tracks

| Track | Folder | Focus | Typical outputs |
|---|---|---|---|
| ğŸ§­ Foundations | `00_orientation/` | KFM context, glossary, invariants | notes + diagrams |
| ğŸ§° Tooling | `01_tooling/` | env setup, Docker workflows, reproducible runs | run manifests |
| ğŸ—ºï¸ GIS Core | `02_gis_core/` | CRS hygiene, overlays, IO round-trips | small vectors/rasters |
| ğŸ›°ï¸ Remote Sensing | `03_remote_sensing/` | time-series, composites, change detection | quicklooks + draft STAC |
| ğŸ“Š Statistics | `04_stats/` | EDA, regression, Bayes, experimental design discipline | diagnostics + metrics |
| ğŸ¤– ML + Agents | `05_ml_agents/` | baselines, eval, decision logic | eval tables + draft model cards |
| ğŸ§ª Simulation + Optimization | `06_simulation_optimization/` | V&V, UQ, sensitivity sweeps | run bundles + checks |
| ğŸŒ Web Maps + Viz | `07_web_mapping_viz/` | cartography, UI spikes, WebGL | small assets + demos |
| ğŸ§¬ Language Tools | `08_language_tools/` | schema ideas, parsers, DSL sketches | schemas + mini-compilers |
| ğŸ§  Human Factors | `09_human_factors/` | governance, ethics, autonomy notes | decision memos |

---

## ğŸ“¦ Template kit (recommended)

Treat templates as **guardrails**, not bureaucracy. ğŸ§±âœ¨  
Put them in: `notebooks/_templates/`

### âœ… Recommended templates
| Template | Best for | Aligned references |
|---|---|---|
| `template_eda_stats.ipynb` ğŸ“Š | EDA, diagnostics, uncertainty | *Graphical Data Analysis*, *Understanding Statistics & Experimental Design*, *Think Bayes* |
| `template_regression.ipynb` ğŸ“ˆ | baseline regression + diagnostics | *Regression analysis with Python* (+ slides) |
| `template_gis_vector.ipynb` ğŸ—ºï¸ | CRS, overlays, joins, QA | *Python Geospatial Analysis Cookbook* |
| `template_remote_sensing_gee.ipynb` ğŸ›°ï¸ | GEE flows + quicklooks | *Cloud-Based Remote Sensing with GEE* |
| `template_map_design.ipynb` ğŸ¨ | legends, color, projection choices | *Making Maps*, *Mobile Mapping* |
| `template_sim_vvuq.ipynb` ğŸ§ª | V&V + UQ + sensitivity | *Scientific Modeling & Simulation (NASA-grade)* |
| `template_optimization.ipynb` ğŸ§© | optimization runs + constraints | *Generalized Topology Optimization* |
| `template_graph_analytics.ipynb` ğŸ•¸ï¸ | Laplacians, spectra, clustering | *Spectral Geometry of Graphs* |
| `template_db_perf.ipynb` ğŸ—„ï¸ | SQL profiling + query plans | *PostgreSQL Notes*, *Database Performance at Scale* |
| `template_webgl_demo.ipynb` ğŸŒ | WebGL map experiments | *WebGL Programming Guide*, *Responsive Web Design* |
| `template_security_redteam.ipynb` ğŸ›¡ï¸ | hostile-input checks | *Ethical Hackingâ€¦*, *Gray Hat Python* *(defensive use only)* |
| `template_dsl_parser.ipynb` ğŸ§¬ | grammar / parsers / DSL spikes | *Implementing Programming Languages* |

> [!TIP]
> Templates should bake in: **contract header**, **parameters cell**, **run manifest stub**, **export policy**, and **checks/invariants** sections.

---

## ğŸš€ Quick start

### Option A â€” Local (fastest) âš¡
```bash
cd notebooks
python -m venv .venv
source .venv/bin/activate     # Windows: .venv\Scripts\activate
pip install -r requirements.txt
jupyter lab
```

### Option B â€” Docker (recommended) ğŸ³
```bash
docker compose up --build
```

> [!CAUTION]
> ğŸ” Never bake secrets into images. Use `.env` + environment variables and keep `.env` out of git.

### Option C â€” Repro runs (parameterized) ğŸ§¾
If you want repeatable notebook runs, prefer an execution wrapper:
- `papermill` (parameter injection + output notebook)
- `jupyter nbconvert --execute` (scriptable execution)

> If you add a notebook that becomes Tier 2+ (see below), consider adding a â€œrunnerâ€ script under `scripts/` so CI can execute it safely. ğŸ§°âœ…

---

## âœ… Notebook conventions (KFM standard)

### ğŸ·ï¸ Naming (boring & sortable)
Use a **two-digit prefix** + **verb-first slug**:

- `00_intro_kfm_context.ipynb`
- `02_vector_overlay_clip.ipynb`
- `03_gee_ndvi_timeseries.ipynb`
- `04_regression_baseline_diagnostics.ipynb`
- `06_simulation_sensitivity_sweep.ipynb`

### ğŸ§± Standard notebook header (required for shareable work)
Start every notebook with a â€œcontract headerâ€ (first cell, Markdown):

1) ğŸ¯ **Purpose** â€” what question are we answering?  
2) ğŸ“¥ **Inputs** â€” dataset IDs or sources, licenses, classification  
3) ğŸ“¤ **Outputs** â€” where artifacts will be written (`_artifacts/` by default)  
4) ğŸ›ï¸ **Parameters** â€” AOI, dates, EPSG, seeds, thresholds  
5) ğŸ§° **Environment** â€” key versions (and optional lock snapshot)  
6) âœ… **Checks** â€” what invariants must hold for results to be meaningful?

Template snippet:
```markdown
## ğŸ§¾ Notebook Contract

- **Purpose:** â€¦
- **Primary question:** â€¦
- **Inputs (IDs / sources):**
  - â€¦
- **Licenses / attribution:** â€¦
- **Classification:** public | restricted | (per repo policy)
- **Outputs:**
  - `_artifacts/...`
  - `_runs/...`
- **Parameters:**
  - AOI: â€¦
  - Time window: â€¦
  - EPSG: â€¦
  - Seed: â€¦
- **Checks / invariants:**
  - CRS must be: â€¦
  - No empty exports: â€¦
  - Value ranges: â€¦
- **Environment:**
  - Python: â€¦
  - Key libs: â€¦
```

### ğŸ·ï¸ Parameters cell (for reproducible execution)
If using papermill/nbconvert, add a top code cell tagged `parameters`:

```python
# parameters
AOI_ID = "ks_bbox"
START = "2020-01-01"
END = "2020-12-31"
EPSG = 4326
SEED = 42
```

### âœ‚ï¸ Keep notebooks diff-friendly (recommended)
- avoid giant embedded outputs (save files to `_artifacts/`)
- clear noisy outputs before committing (or use output-stripping tooling)
- stable ordering: sort keys, deterministic joins, fixed random seeds

> [!TIP]
> If you canâ€™t list inputs/assumptions, the notebook is still â€œscratch mode.â€ Thatâ€™s fine â€” just donâ€™t ship it. ğŸ§ âœ…

---

## ğŸ§¾ Run manifests (highly recommended)

For any notebook producing outputs worth keeping, write a run manifest to `_runs/`.

**Suggested path:** `_runs/<notebook_slug>/<timestamp>/run.manifest.json`

Minimal example:
```json
{
  "run_id": "kfm.nb.03_gee_ndvi_timeseries.2026-01-13T12:00:00Z",
  "notebook": "03_remote_sensing/03_gee_ndvi_timeseries.ipynb",
  "git": { "sha": "UNKNOWN", "dirty": true },
  "params": {
    "aoi": "ks_bbox",
    "start": "2020-01-01",
    "end": "2020-12-31",
    "epsg": "EPSG:4326",
    "seed": 42
  },
  "inputs": [
    { "type": "catalog", "id": "stac://<collection_or_item_id>", "license": "â€¦", "classification": "public" }
  ],
  "outputs": [
    { "type": "plot", "path": "_artifacts/ndvi_timeseries.png" },
    { "type": "draft_stac_item", "path": "_artifacts/stac/item.json" }
  ],
  "checks": [
    { "name": "ndvi_range", "status": "pass", "details": "min=-0.12 max=0.74" }
  ],
  "warnings": []
}
```

### ğŸ”— Link notebooks to MCP (durable receipts)
If a run is Tier 2+, add a tiny MCP stub (or link) that points to:
- notebook path
- run manifest path
- catalog IDs produced
- provenance bundle IDs

Example MCP note header (markdown):
```markdown
# MCP â€” Run: kfm.nb.03_gee_ndvi_timeseries.2026-01-13T12:00:00Z

- Notebook: notebooks/03_remote_sensing/03_gee_ndvi_timeseries.ipynb
- Run manifest: notebooks/_runs/03_gee_ndvi_timeseries/2026-01-13T12-00-00Z/run.manifest.json
- Outputs:
  - STAC Item: stac://...
  - PROV Bundle: prov://...
- Summary: ...
```

### ğŸ§¼ Repro checklist âœ…
- [ ] Parameters cell at top (AOI, EPSG, dates, seeds)
- [ ] Deterministic seeds recorded (if stochastic)
- [ ] Environment captured (requirements/lockfile or snapshot)
- [ ] Outputs written to `_artifacts/` (gitignored) **or** promoted to `data/processed/...`
- [ ] No secrets/tokens/internal endpoints in cells, outputs, or logs
- [ ] Evidence outputs referenced by **catalog IDs**, not raw file paths

---

## ğŸ§¬ Evidence artifacts & promotion

KFM treats analysis outputs (including AI-derived outputs) as **first-class evidence artifacts** when they matter. That means they must follow the same governed lifecycle as â€œregularâ€ datasets ğŸ§¾ğŸ—‚ï¸.

### âœ… Promotion rule of thumb
If someone could cite your notebook output in a memo, map, story, or decision â€” itâ€™s evidence.

### ğŸªœ Reproducibility tiers (what counts as â€œrealâ€)
| Tier | Name | Allowed behavior | Not allowed |
|---|---|---|---|
| ğŸŸ  Tier 0 | Scratch | quick exploration, messy cells | decision claims, publishing |
| ğŸŸ¡ Tier 1 | Shareable | header + params + basic outputs | hidden inputs, unclear licenses |
| ğŸŸ¢ Tier 2 | Evidence-ready | run manifest + stable outputs + provenance pointers | mystery data, unlabeled derivations |
| ğŸ”µ Tier 3 | Productionized | logic moved to `src/` + tests + catalogs | notebook-only business logic |

> [!IMPORTANT]
> Any Tier 2+ output must be traceable: **inputs â†’ transforms â†’ outputs â†’ catalogs â†’ provenance** ğŸ§¾ğŸ§¬

### ğŸ§¬ Lifecycle: notebook â†’ production
```mermaid
flowchart LR
  A["ğŸ§ª Notebook experiment"] --> B["ğŸ“¦ Local artifacts\n_artifacts/"]
  A --> R["ğŸ§¾ Run manifest\n_runs/"]
  A --> C["ğŸ““ MCP note / protocol\n(mcp/)"]
  C --> D["ğŸ—ï¸ Extract core logic\nsrc: pipelines & services"]
  D --> E["âœ… Tests + fixtures\n(tests/)"]
  E --> F["ğŸ—‚ï¸ STAC/DCAT/PROV\n+ validation gates"]
  F --> G["ğŸ•¸ï¸ Graph / APIs / UI\n(governed)"]
  G --> H["ğŸ§¾ Story Nodes + Focus\n(citable narratives)"]
```

ğŸ Graduation checklist
- [ ] Extract functions into `src/` (no notebook-only globals)
- [ ] Add tests (unit + integration/contract as needed)
- [ ] Define/validate contracts (schemas, CRS, expected columns)
- [ ] If evidence: store in `data/processed/...` + STAC/DCAT + PROV
- [ ] Confirm classification & redaction are correct (no silent downgrade)

---

## ğŸ§ª Modeling, simulation & optimization playbook

This section is informed by the project simulation/optimization library (NASA-grade modeling & simulation, topology optimization) and exists to keep â€œcool experimentsâ€ from turning into **uncalibrated mythology**. ğŸ§ªğŸ§¯

### âœ… Always separate these three
1) **Verification** â€” did we solve the equations right? (code/solver correctness)  
2) **Validation** â€” are we solving the right equations? (model vs reality)  
3) **Uncertainty quantification** â€” how wrong could we be? (ranges, sensitivity)

### ğŸ“Œ Simulation notebook must include
- **Model statement** (what physics/assumptions are included/excluded) ğŸ§ 
- **Discretization details** (mesh, timestep, resolution, tolerances) ğŸ§©
- **Convergence / stability checks** (refinement sweeps) âœ…
- **Sensitivity analysis** (inputs that dominate outputs) ğŸšï¸
- **Calibration notes** (if tuned, say how + against what data) ğŸ¯
- **Optimization constraints** (what is allowed to change, what is fixed) ğŸ§±

### ğŸ§¾ Run manifest extras for simulation
Add solver + hardware info to avoid irreproducible â€œit worked on my laptopâ€ outcomes:
```json
{
  "solver": { "name": "â€¦", "version": "â€¦", "tolerances": { "abs": 1e-8, "rel": 1e-6 } },
  "discretization": { "mesh": "â€¦", "dt": 0.1, "steps": 1000 },
  "hardware": { "cpu": "â€¦", "ram_gb": 64, "gpu": "â€¦" }
}
```

> [!TIP]
> If optimization is involved, always export the **objective**, **constraints**, and **stopping criteria** in machine-readable form (JSON/YAML) so production code can reproduce it.

---

## ğŸ“Š Statistics & ML evidence playbook

This section aligns notebook practice with the projectâ€™s stats/EDA/regression/Bayes/ML theory references so results are **defensible**, not just pretty. ğŸ“ˆğŸ§¾

### âœ… Statistical â€œtruthfulnessâ€ checklist (minimum)
- [ ] What is the **unit of analysis**? (pixel? parcel? county? household?) ğŸ§ğŸ—ºï¸
- [ ] What is the **sampling mechanism**? (and whatâ€™s missing?) ğŸ§²
- [ ] Are observations **independent**? If not, model the correlation (space/time). ğŸŒªï¸
- [ ] Are you mixing **training** and **evaluation**? (no leakage) ğŸš«
- [ ] Do plots show **uncertainty** (intervals, bands, distributions) not just means? ğŸ›ï¸
- [ ] Are assumptions checked (residuals, heteroskedasticity, outliers)? âœ…
- [ ] Are multiple comparisons / p-hacking risks addressed? ğŸ§¯

### ğŸ“ˆ Regression notebooks should always include
- baseline model (simple, explainable) ğŸªµ
- diagnostics (residual plots, leverage/influence, collinearity) ğŸ”
- robustness checks (different splits, transformations, alternate specs) ğŸ§±
- error reporting (MAE/RMSE + distribution + subgroup errors) ğŸ“Š

### ğŸ§  Bayesian notebooks should always include
- prior justification (even weakly informative) ğŸ§¾
- posterior predictive checks (PPC) ğŸ¯
- sensitivity to priors (if it changes everything, say so) ğŸ§¨

### ğŸ¤– ML notebooks (Tier 2+) should add
- a **model card draft** (task, data, limitations, intended use) ğŸªª
- an **evaluation card** (metrics, slices, failure modes) ğŸ§ª
- a **deployment boundary note** (what must move to `src/` before â€œreal useâ€) ğŸ§±

> [!IMPORTANT]
> â€œAccuracyâ€ without **dataset lineage + evaluation design** is not evidence in KFM. Itâ€™s a demo. ğŸ­

---

## ğŸ—ºï¸ GIS, cartography & remote sensing playbook

This section aligns GIS/RS notebook practice with the project mapping + EO library, so map outputs are **correct**, not just persuasive. ğŸ—ºï¸ğŸ§¾

### ğŸ§­ CRS hygiene (non-negotiable)
- record the CRS on import and export
- do spatial operations in an appropriate projected CRS (not always EPSG:4326)
- validate areas/lengths after reprojection (unit sanity check)

### ğŸ›°ï¸ Remote sensing notebooks should include
- sensor/product identifiers (collection ID, band names, scaling) ğŸ›°ï¸
- masking strategy (clouds, shadows, QA bands) â˜ï¸
- compositing logic (median? mosaic? timeframe?) ğŸ§ª
- change detection caveats (seasonality, illumination, phenology) ğŸ‚

### ğŸ¨ Cartography rules (minimum)
- projection choice explained (distortion tradeoff) ğŸŒ
- legend that matches data semantics (no misleading bins) ğŸ§¾
- color ramps that are interpretable + accessible (colorblind-safe if possible) ğŸ¨
- scale + north + attribution when exporting â€œpresentation mapsâ€ ğŸ§­

### ğŸ§Š 3D / volumetric GIS (when used)
If your notebook touches 3D scenes/volumes (e.g., archaeology, subsurface, point clouds):
- state vertical datum / units
- document simplification/decimation choices
- export metadata alongside geometry (not just meshes)

> [!TIP]
> â€œLooks rightâ€ is not a GIS QA method. Add numeric checks (bounds, area totals, overlaps, CRS, nodata). âœ…

---

## ğŸ—„ï¸ Data systems, scaling & performance playbook

Notebooks are great at exploration, terrible at becoming accidental production systems. This playbook keeps us honest while aligning with the projectâ€™s database + scaling references. ğŸ—„ï¸âš¡

### âœ… When to use a notebook vs pipeline
- Notebook âœ…: profile a query, test an index idea, validate a schema, prototype transforms
- Pipeline âœ…: scheduled loads, heavy transforms, repeated jobs, production APIs
- Notebook ğŸš«: long-running ingestion daemons, â€œforever dashboardsâ€, fragile cron logic

### ğŸ“Œ Minimum DB hygiene in notebooks
- explicitly set `LIMIT` during exploration (remove only when needed) ğŸ§¯
- use EXPLAIN/ANALYZE for slow queries and capture it in artifacts ğŸ§¾
- donâ€™t run destructive ops without a safety flag (`DRY_RUN=True`) ğŸš«
- document workload type (read-heavy, write-heavy, mixed) ğŸ§ª

### ğŸ§Š Scaling notes (especially for EO + rasters)
- prefer chunked formats and lazy loading (xarray/dask patterns) ğŸ§©
- avoid reading full-resolution rasters into memory if you only need stats ğŸ§ 
- record downsampling / resampling methods (nearest/bilinear/cubic) ğŸšï¸
- make hardware constraints explicit in run manifests ğŸ§¾

### ğŸ”— â€œData spacesâ€ mindset
If youâ€™re bridging datasets across domains/teams:
- treat metadata + access policy as first-class
- keep stable identifiers and compatibility layers
- use catalogs (STAC/DCAT/PROV) as the â€œinterop handshakeâ€ ğŸ¤

---

## ğŸŒ Web mapping & media correctness playbook

These rules align notebook â†’ web experiments with the projectâ€™s WebGL/web design/media references so we donâ€™t ship broken visuals. ğŸŒğŸ§­

### âœ… Web mapping notebook scope
- prototype layer styling
- test tile math / coordinate transforms
- benchmark WebGL rendering paths
- validate export formats and size budgets

### ğŸ–¼ï¸ Media correctness (maps/imagery)
- document export format choices (PNG/JPEG) and why ğŸ§¾
- donâ€™t re-encode evidence imagery without noting compression artifacts ğŸ§¯
- store â€œpresentation derivativesâ€ separately from â€œevidence derivativesâ€ ğŸ“¦

### ğŸ“± Responsive UI expectations (even in demos)
- mobile-friendly layout
- readable legends + tap targets
- accessibility basics (contrast, alt text where possible)

> [!TIP]
> If a notebook exports assets used in docs/UI, keep them **small + stable** in `_figures/` and treat them like source-controlled documentation assets. ğŸ–¼ï¸âœ…

---

## ğŸ›¡ï¸ Security & hostile-input playbook

Notebooks touch files. Files can bite. ğŸğŸ§¨  
This playbook aligns with the project security references and is **defensive by default**.

### ğŸš« Forbidden in notebooks (Tier 1+)
- hardcoded tokens/keys/credentials
- unreviewed `eval()` / `exec()` on data inputs
- running unknown binaries from archives
- â€œdownload and executeâ€ patterns

### âœ… Minimum hostile-input posture
- treat archives (zip/tar) as untrusted: limit file counts/sizes; avoid path traversal ğŸ§¯
- validate file types (magic bytes) not just extensions ğŸ§¾
- cap raster sizes and memory usage (avoid decompression bombs) ğŸ’£
- prefer safe parsers; avoid shelling out with untrusted strings ğŸ›‘
- log **redacted** metadata only (never secrets) ğŸ”

### ğŸ§ª Security checks worth automating
- dependency audit in CI (where possible)
- notebook output stripping
- â€œsecrets scanâ€ pre-commit hooks
- containerized execution for Tier 2+ notebooks ğŸ³

> [!CAUTION]
> Security books in the library exist to improve our defenses. Do **not** use this repo to publish offensive tradecraft. ğŸ›¡ï¸âœ…

---

## ğŸ§  Human factors, autonomy & AI governance

KFM is not just data plumbing. Itâ€™s a **human system**. ğŸ§‘â€ğŸ¤â€ğŸ§‘  
This section aligns notebook practice with the projectâ€™s humanism/autonomy/AI governance references.

### ğŸ¤– AI assistance rules (label it)
If you use AI for:
- summarization
- labeling
- classification
- extraction
- drafting narratives

â€¦then in the notebook header and/or run manifest, record:
- tool/model (when permissible)
- what was generated
- what was verified by a human
- what remains uncertain ğŸ§¾

### ğŸ§­ â€œAutonomy boundaryâ€
- AI is **advisory** in KFM
- decisions must remain human-owned
- outputs must remain source-linked and contestable âœ…

### âš–ï¸ Legal / policy sensitivity
If notebook outputs might influence policy, land rights, health, or regulated decisions:
- raise the evidence bar (Tier 2+ expectations)
- include limitations and known failure modes
- avoid overstating causal claims ğŸ§¯

---

## ğŸ§ª Testing notebooks (optional but powerful)

If notebooks become Tier 2+, consider:
- âœ… smoke-running critical notebooks automatically (parameterized)
- âœ… asserting outputs exist and meet schema expectations
- âœ… failing fast on silent drift (CRS mismatch, missing columns, empty exports)

Suggested approaches:
- `nbconvert --execute` on a tiny fixture config
- `pytest` + â€œnotebook runnerâ€ wrappers (prefer deterministic, small IO)
- `nbval`-style testing (great for contract checks; avoid pixel-perfect expectations)

> [!TIP]
> Notebook tests should validate **contracts** and **invariants**, not pixel-perfect plots. ğŸ§ âœ…

---

## ğŸ” Data, licensing, governance & ethics

### ğŸ“œ Licensing & attribution
- Donâ€™t use or publish data with unclear licensing.
- Record source + license in the header and run manifest.
- If you create a derived artifact, carry attribution forward (inputs â†’ outputs).

### ğŸª¶ Governance & â€œno downgradeâ€
- Outputs cannot be **less restricted** than inputs unless a reviewed redaction step exists.
- If sensitivity is unknown, default to **restricted** until reviewed.

### ğŸ§¯ Security posture (defensive)
- Treat inputs as hostile (archives, rasters, JSON, PDFs).
- Validate types, enforce size limits, avoid unsafe shell calls.
- Never log secrets; avoid embedding access tokens or internal endpoints.

---

## ğŸ“Œ â€œMake it citableâ€

To support academic / workshop usage (without sacrificing governance):
- add `CITATION.cff` (software citation)
- consider versioned snapshot releases + DOIs for curated datasets
- keep â€œexample notebooksâ€ public-safe (tiny fixtures, no restricted data)

> [!NOTE]
> One-click notebook launches should only expose **public** datasets/examples and should still point back to STAC/DCAT/PROV for traceability.

---

## ğŸ“š Reference library (all project files)

These files shape notebook templates, sanity checks, and how we reason about uncertainty, maps, systems, scaling, and governance. ğŸ§ ğŸ§¾

<details>
<summary><strong>ğŸ›ï¸ Core KFM design, repo discipline, and governed ordering</strong></summary>

- ğŸ“„ `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf`

</details>

<details>
<summary><strong>ğŸ›°ï¸ Remote sensing & Earth observation</strong></summary>

- ğŸ“„ `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf`

</details>

<details>
<summary><strong>ğŸ—ºï¸ GIS, cartography, mobile & 3D</strong></summary>

- ğŸ“„ `python-geospatial-analysis-cookbook.pdf`
- ğŸ“„ `making-maps-a-visual-guide-to-map-design-for-gis.pdf`
- ğŸ“„ `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf`
- ğŸ“„ `Archaeological 3D GIS_26_01_12_17_53_09.pdf`

</details>

<details>
<summary><strong>ğŸ“Š Statistics, EDA, regression & Bayesian reasoning</strong></summary>

- ğŸ“„ `Understanding Statistics & Experimental Design.pdf`
- ğŸ“„ `graphical-data-analysis-with-r.pdf`
- ğŸ“„ `regression-analysis-with-python.pdf`
- ğŸ“„ `Regression analysis using Python - slides-linear-regression.pdf`
- ğŸ“„ `think-bayes-bayesian-statistics-in-python.pdf`

</details>

<details>
<summary><strong>ğŸ§ª Simulation, verification/validation & optimization</strong></summary>

- ğŸ“„ `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf`
- ğŸ“„ `Generalized Topology Optimization for Structural Design.pdf`

</details>

<details>
<summary><strong>ğŸ•¸ï¸ Graphs & structure</strong></summary>

- ğŸ“„ `Spectral Geometry of Graphs.pdf`

</details>

<details>
<summary><strong>ğŸ—„ï¸ Data systems, scaling & performance</strong></summary>

- ğŸ“„ `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf`
- ğŸ“„ `Database Performance at Scale.pdf`
- ğŸ“„ `Scalable Data Management for Future Hardware.pdf`
- ğŸ“„ `Data Spaces.pdf`

</details>

<details>
<summary><strong>ğŸŒ Web, WebGL, responsive UX & media correctness</strong></summary>

- ğŸ“„ `responsive-web-design-with-html5-and-css3.pdf`
- ğŸ“„ `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf`
- ğŸ“„ `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf`

</details>

<details>
<summary><strong>ğŸ¤– ML practice & AI governance</strong></summary>

- ğŸ“„ `Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf`
- ğŸ“„ `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf`

</details>

<details>
<summary><strong>ğŸ›¡ï¸ Security, adversarial thinking & concurrency</strong></summary>

- ğŸ“„ `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf`
- ğŸ“„ `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf`
- ğŸ“„ `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf`

</details>

<details>
<summary><strong>ğŸ§  Human factors & systems thinking</strong></summary>

- ğŸ“„ `Introduction to Digital Humanism.pdf`
- ğŸ“„ `Principles of Biological Autonomy - book_9780262381833.pdf`

</details>

<details>
<summary><strong>ğŸ“š Programming reference shelves (mega-packs)</strong></summary>

These are â€œmany-books-in-oneâ€ references for quick lookups and language context during prototyping. âœ…

- ğŸ“„ `A programming Books.pdf`
- ğŸ“„ `B-C programming Books.pdf`
- ğŸ“„ `D-E programming Books.pdf`
- ğŸ“„ `F-H programming Books.pdf`
- ğŸ“„ `I-L programming Books.pdf`
- ğŸ“„ `M-N programming Books.pdf`
- ğŸ“„ `O-R programming Books.pdf`
- ğŸ“„ `S-T programming Books.pdf`
- ğŸ“„ `U-X programming Books.pdf`

</details>

---

## ğŸ•°ï¸ Version history

| Version | Date | Summary | Author |
|---:|---|---|---|
| v1.4.0 | 2026-01-13 | Expanded notebook governance into playbooks (simulation V&V/UQ, stats/ML evidence, GIS/RS QA, data systems performance, web/media correctness, security/hostile-input posture, human factors/AI governance). Added template kit guidance mapped to the full project PDF library; added `Database Performance at Scale` and made stable-IDs + data-space interop explicit. | KFM Engineering |
| v1.3.0 | 2026-01-11 | Aligned notebooks with v13 governed layout + MCP receipts; clarified non-negotiables, promotion rules for evidence artifacts, story-node location, and â€œmake it citableâ€ research UX; tightened safety + hostile-input posture and added a recommended `.gitignore` snippet. | KFM Engineering |
| v1.2.0 | 2026-01-09 | Updated repo boundary links, standardized pipeline order framing, added emoji folder map, clarified run manifests + tiers + graduation checklist, and enumerated project reference files. | KFM Engineering |
| v1.1.0 | 2026-01-07 | Prior iteration: notebook lab-bench framing, track layout, run manifest pattern, graduation rules. | KFM Engineering |

---

<div align="center">

ğŸ§ª Explore fast. Â· ğŸ§¾ Record assumptions. Â· ğŸ·ï¸ Promote evidence properly. Â· ğŸ›¡ï¸ Keep it governed. âœ…

</div>