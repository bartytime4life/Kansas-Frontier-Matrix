# ğŸ§¬ PROV Schemas â€” Provenance & Lineage (KFM)

![JSON Schema](https://img.shields.io/badge/contract-JSON%20Schema-2b6cb0)
![W3C PROV-O](https://img.shields.io/badge/standard-W3C%20PROV--O-0f766e)
![Provenance First](https://img.shields.io/badge/KFM-provenance%E2%80%91first-16a34a)
![Cross-Layer Links](https://img.shields.io/badge/links-STAC%20%2B%20DCAT%20%2B%20PROV-7c3aed)

> **Purpose:** make every dataset, map layer, and evidence artifact *explainable* â€” **where it came from**, **how it was produced**, and **who/what produced it**. ğŸ§¾ğŸ”—  
> This folder contains the **PROV-focused JSON Schemas** used by the **web samples** (and any schema-driven UI tooling) to validate + document provenance bundles.

---

<details>
  <summary><strong>ğŸ“Œ Table of contents</strong></summary>

- [ğŸ—‚ï¸ Whatâ€™s in this folder?](#ï¸-whats-in-this-folder)
- [ğŸš¦ Where PROV sits in the KFM pipeline](#-where-prov-sits-in-the-kfm-pipeline)
- [ğŸ§  What PROV is used for in KFM](#-what-prov-is-used-for-in-kfm)
- [ğŸ§© Core model](#-core-model)
- [âœ… KFM â€œminimum viable provenanceâ€](#-kfm-minimum-viable-provenance)
- [ğŸ”— Cross-layer linking rules of thumb](#-cross-layer-linking-rules-of-thumb)
- [ğŸ§± Bundle shape conventions](#-bundle-shape-conventions)
- [ğŸ§ª Example: minimal PROV bundle](#-example-minimal-prov-bundle)
- [ğŸ§ª Example: evidence artifact or AI output](#-example-evidence-artifact-or-ai-output)
- [ğŸ›¡ï¸ Governance & safety notes](#ï¸-governance--safety-notes)
- [ğŸ” Versioning & compatibility](#-versioning--compatibility)
- [ğŸ¤ Contributing](#-contributing)
- [ğŸ“š Related docs](#-related-docs)

</details>

---

## ğŸ—‚ï¸ Whatâ€™s in this folder?

Typical layout (exact filenames may differ):

```text
ğŸ“ web/assets/samples/_shared/schemas/prov/
â”œâ”€ ğŸ“„ README.md
â”œâ”€ ğŸ“„ *.schema.json        # top-level PROV bundle + type schemas
â”œâ”€ ğŸ“ _defs/               # reusable schema fragments (hashes, refs, ids, timestampsâ€¦)
â””â”€ ğŸ“ examples/            # demo bundles used by web samples/tests (optional)
```

> [!NOTE]
> This is under **web/assets** because itâ€™s meant to be **loadable by the frontend** for demos, schema viewers, and schema-backed editors.  
> If your repo also has a canonical `/schemas/prov/` folder, treat that as the **source-of-truth** and mirror/export into this web asset folder as needed. ğŸ“¦

---

## ğŸš¦ Where PROV sits in the KFM pipeline

KFM treats provenance as a **first-class â€œboundary artifactâ€** alongside STAC & DCAT.

```mermaid
flowchart LR
  A[Raw Sources] --> B[ETL + Normalization]
  B --> C[Catalog Outputs]
  C --> D[Graph]
  D --> E[API]
  E --> F[UI]
  F --> G[Story Nodes]
  G --> H[Focus Mode]

  subgraph C[Catalog Outputs]
    C1[STAC Items + Collections]
    C2[DCAT Dataset Views]
    C3[PROV Lineage Bundles]
  end
```

**Why this matters:** PROV is not â€œextra documentationâ€ â€” itâ€™s part of the contract that allows downstream stages (graph/API/UI/story/focus) to safely consume an artifact. âœ…

---

## ğŸ§  What PROV is used for in KFM

PROV bundles power:

- **Trust & transparency** ğŸ§¾  
  â€œWhat is this layer? Where did it come from? What did we do to it?â€
- **Reproducibility** ğŸ”  
  Stable run IDs, parameters/config references, and input/output hashes enable â€œsame input â‡’ same outputâ€ expectations.
- **Debugging & auditability** ğŸ•µï¸  
  Trace errors back to a specific source or pipeline step.
- **UI evidence panels / provenance popovers** ğŸ—ºï¸  
  The UI can display sources, methods, licenses, and caveats directly from provenance-linked metadata.
- **Story Nodes + Focus Mode integrity** ğŸ“š  
  Focus Mode content is only allowed when itâ€™s provenance-linked to cataloged sources (no â€œmystery layersâ€).

---

## ğŸ§© Core model

We use the PROV mental model (PROVâ€‘O concepts):

| Concept | Meaning | KFM examples ğŸ§  |
|---|---|---|
| **Entity** | A thing (usually data) | Raw CSV, scanned map TIFF, processed GeoParquet, generated raster COG, STAC Item JSON |
| **Activity** | A process that acts | â€œDownload NOAA normalsâ€, â€œNormalize county keysâ€, â€œRasterize polygonsâ€, â€œRun model vXâ€ |
| **Agent** | Who/what is responsible | A contributor, an organization, a pipeline job, a container image, a service account |

Core relationships youâ€™ll see (names vary by encoding):

- **Activity â†’ uses â†’ Entity** (`prov:used`)
- **Entity â†’ wasGeneratedBy â†’ Activity** (`prov:wasGeneratedBy`)
- **Activity â†’ wasAssociatedWith â†’ Agent** (`prov:wasAssociatedWith`)
- **Entity â†’ wasDerivedFrom â†’ Entity** (`prov:wasDerivedFrom`)
- **Entity â†’ wasAttributedTo â†’ Agent** (`prov:wasAttributedTo`)

```mermaid
flowchart TD
  E1[ğŸŸ¦ prov:Entity<br/>raw input] -->|prov:used| A1[ğŸŸ§ prov:Activity<br/>transform]
  A1 -->|prov:wasGeneratedBy| E2[ğŸŸ¦ prov:Entity<br/>processed output]
  A1 -->|prov:wasAssociatedWith| AG1[ğŸŸ© prov:Agent<br/>pipeline / person]
  E2 -->|prov:wasDerivedFrom| E1
```

---

## âœ… KFM â€œminimum viable provenanceâ€

> [!IMPORTANT]
> If a dataset / artifact is **published**, it must have **end-to-end lineage**: **raw inputs â†’ intermediate â†’ processed outputs**.  
> Provenance should identify the **specific run/config** that produced outputs (run ID, commit hash, container tag, etc.). ğŸ§¾

Minimum expectations for a *useful* bundle:

### 1) Identify the bundle
- A stable **bundle identifier** (dataset + run + version).
- A creation timestamp.

### 2) Capture the chain
- **At least one** output Entity.
- The Activity that generated it.
- The input Entities that Activity used.
- The Agent responsible (person and/or SoftwareAgent).

### 3) Determinism helpers (strongly recommended)
- Input + output **hashes** (or stable IDs) âœ…
- A **config reference** (file path, commit hash, or config ID)
- Tooling identifiers: pipeline name, version, container image digest/tag

### 4) Evidence + uncertainty (optional but encouraged)
- Quality flags (uncertainty/confidence)
- Notes about limitations or transformations that affect interpretation

---

## ğŸ”— Cross-layer linking rules of thumb

KFM relies on **STAC + DCAT + PROV** moving together.

Use these patterns:

- **STAC Items â†’ Data assets**  
  STAC points at the actual files/endpoints.
- **DCAT â†’ Distributions**  
  DCAT provides discovery-level links (often to STAC, plus direct download endpoints).
- **PROV â†’ End-to-end lineage**  
  PROV is the â€œhow it was madeâ€ chain (including run/config identity).
- **Graph nodes â†’ Catalog references**  
  The graph should reference identifiers (STAC Item IDs, DOIs, dataset IDs), not duplicate heavy payloads.

> [!TIP]
> If you canâ€™t answer **â€œwhich exact inputs produced this output?â€** from the PROV bundle alone, itâ€™s not complete enough yet.

---

## ğŸ§± Bundle shape conventions

These schemas typically validate a **pragmatic subset** of provenance, optimized for:

- **machine validation** âœ…
- **UI rendering** ğŸ–¥ï¸
- **cross-reference linking** ğŸ”—

You may see one of these common approaches:

1) **JSON-LD flavored** bundles (PROVâ€‘O concepts, `@context`, often `@graph`)  
2) **â€œPROV-like JSONâ€** bundles with explicit `entities[]`, `activities[]`, `agents[]`, and `relations[]`

> [!NOTE]
> Donâ€™t guess the exact formatâ€”open the top-level schema in this folder and follow the contract. The README is the *intent*, the schema is the *truth*. ğŸ§ âœ…

---

## ğŸ§ª Example: minimal PROV bundle

A compact example (illustrative; field names vary by schema):

```json
{
  "@context": {
    "prov": "http://www.w3.org/ns/prov#",
    "kfm": "https://kfm.example/ns#"
  },
  "@id": "kfm:prov/bundle/usgs_dem_30m/run-2026-01-18T120000Z",
  "@type": "prov:Bundle",
  "prov:generatedAtTime": "2026-01-18T12:05:00Z",
  "@graph": [
    {
      "@id": "kfm:entity/raw/usgs_dem_30m.zip",
      "@type": "prov:Entity",
      "prov:label": "USGS DEM 30m (raw download)",
      "kfm:hash": { "algo": "sha256", "value": "â€¦" }
    },
    {
      "@id": "kfm:agent/pipeline/dem_ingest",
      "@type": "prov:SoftwareAgent",
      "prov:label": "Pipeline: dem_ingest",
      "kfm:version": "git:abcdef123",
      "kfm:container": "ghcr.io/kfm/pipelines:2026.01.18"
    },
    {
      "@id": "kfm:activity/etl/dem_ingest/run-2026-01-18T120000Z",
      "@type": "prov:Activity",
      "prov:label": "ETL: ingest + normalize DEM",
      "prov:startedAtTime": "2026-01-18T12:00:00Z",
      "prov:endedAtTime": "2026-01-18T12:05:00Z",
      "prov:used": [{ "@id": "kfm:entity/raw/usgs_dem_30m.zip" }],
      "prov:wasAssociatedWith": { "@id": "kfm:agent/pipeline/dem_ingest" },
      "kfm:parameters": { "targetCRS": "EPSG:4326", "tileSize": 512 }
    },
    {
      "@id": "kfm:entity/processed/usgs_dem_30m.cog.tif",
      "@type": "prov:Entity",
      "prov:label": "USGS DEM 30m (COG output)",
      "prov:wasGeneratedBy": { "@id": "kfm:activity/etl/dem_ingest/run-2026-01-18T120000Z" },
      "kfm:hash": { "algo": "sha256", "value": "â€¦" },
      "kfm:artifact": { "path": "data/processed/elevation/usgs_dem_30m/usgs_dem_30m.cog.tif" }
    }
  ]
}
```

---

## ğŸ§ª Example: evidence artifact or AI output

Evidence artifacts (analysis results / AI outputs) should be treated like any other dataset: **STAC + DCAT + PROV**, plus explicit computational origin and quality metadata.

```json
{
  "bundleId": "kfm:prov/bundle/ocr_letters_1870s/run-2026-01-18T141500Z",
  "createdAt": "2026-01-18T14:22:10Z",
  "entities": [
    {
      "id": "kfm:entity/raw/scan_box_12/page_0042.tif",
      "type": "prov:Entity",
      "role": "input",
      "hash": { "algo": "sha256", "value": "â€¦" }
    },
    {
      "id": "kfm:entity/processed/letters_1870s/box_12_page_0042.txt",
      "type": "prov:Entity",
      "role": "output",
      "hash": { "algo": "sha256", "value": "â€¦" },
      "quality": { "ocrConfidence": 0.93 }
    }
  ],
  "activities": [
    {
      "id": "kfm:activity/ocr/tesseract/run-2026-01-18T141500Z",
      "type": "prov:Activity",
      "startedAt": "2026-01-18T14:15:00Z",
      "endedAt": "2026-01-18T14:22:10Z",
      "used": ["kfm:entity/raw/scan_box_12/page_0042.tif"],
      "generated": ["kfm:entity/processed/letters_1870s/box_12_page_0042.txt"],
      "method": {
        "tool": "tesseract",
        "toolVersion": "5.3.0",
        "params": { "lang": "eng", "psm": 6 }
      }
    }
  ],
  "agents": [
    {
      "id": "kfm:agent/pipeline/ocr_batch",
      "type": "prov:SoftwareAgent",
      "name": "Pipeline: ocr_batch",
      "version": "git:abcdef123"
    }
  ]
}
```

> [!TIP]
> For evidence artifacts, include **confidence/uncertainty** and label them clearly as derived/AI-generated where appropriate. ğŸ·ï¸

---

## ğŸ›¡ï¸ Governance & safety notes

> [!IMPORTANT]
> Provenance is often *public-facing* via UI panels. Treat it like published documentation.

- ğŸš« **Do not embed secrets** (API keys, tokens, private endpoints).
- ğŸ§­ **Respect sovereignty & sensitivity**: avoid leaking precise sensitive locations or restricted inputs; use stable references and redaction-aware IDs.
- ğŸ”’ **Classification should not weaken**: an output should not be less restricted than its inputs.
- ğŸ§¾ Prefer **references + hashes** over embedding raw sensitive payloads directly in PROV.

---

## ğŸ” Versioning & compatibility

Recommended practices:

- Use **SemVer** for schema IDs / versions.
- Breaking changes â‡’ **new major** version.
- Keep old schemas around if the UI must render historical bundles.
- Make provenance bundles self-describing: include a `schemaVersion` / `$schema` / profile reference when possible.

---

## ğŸ¤ Contributing

When you change or add a PROV schema:

1) âœ… Update or add at least one example bundle in `examples/` (if present)
2) âœ… Ensure schema references (`$id`, `$ref`) resolve correctly in the web build
3) âœ… Keep the â€œminimum viable provenanceâ€ requirements intact
4) âœ… Donâ€™t break downstream rendering (think: â€œschema-driven UI editor / viewerâ€)

---

## ğŸ“š Related docs

- ğŸ“˜ `docs/standards/` â€” governed profiles (STAC/DCAT/PROV)
- ğŸ—‚ï¸ `data/prov/` â€” canonical PROV lineage bundles produced at publish time
- ğŸ§¾ STAC / DCAT schema folders â€” discovery metadata that should cross-link with PROV
- ğŸ§  Story Node templates â€” evidence-first narratives that reference provenance-linked assets

---

**If youâ€™re unsure what to record:** capture enough so a future maintainer can answer  
âœ… *â€œWhich inputs produced this output, using what method, at what version, and under what constraints?â€* ğŸ§ ğŸ”
