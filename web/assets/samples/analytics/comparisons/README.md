# ğŸ“Š Analytics Samples â€” Comparisons  
`web/assets/samples/analytics/comparisons/`

![KFM v13](https://img.shields.io/badge/KFM-v13.0.0--draft-1f6feb)
![sample](https://img.shields.io/badge/sample-analytics%2Fcomparisons-8250df)
![governance](https://img.shields.io/badge/governance-provenance--first-2da44e)
![rule](https://img.shields.io/badge/rule-API%20boundary-critical)
![data](https://img.shields.io/badge/data-config--first%20%7C%20synthetic-lightgrey)

> [!IMPORTANT]  
> **These samples must not become a â€œside-channelâ€ around KFM governance.**  
> In KFM v13, the pipeline ordering is strict (ETL â†’ catalogs â†’ graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode) and the **frontend must not query the graph directly**â€”all access goes through the API layer.  [oai_citation:0â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ¯ What this folder is

A small library of **comparison â€œpacksâ€** used by the **KFM web app (`web/`)** to demo, develop, and test analytics UI patterns like:

- side-by-side metric charts (A vs B)  
- delta / percent-change summaries  
- cohort comparisons (place vs place / time vs time / version vs version)  
- â€œevidence-awareâ€ comparisons that keep provenance visible

The `web/` directory is the frontend home in the v13 repo layout.  [oai_citation:1â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## âœ… What belongs here (and what doesnâ€™t)

### âœ… Good fits
- **Config-first** comparison manifests (what to compare, how to render, what to cite)
- **Preview images** (lightweight, non-sensitive)
- **Synthetic fixtures** *only when needed* for Storybook / offline UI tests (explicitly labeled)

### ğŸš« Not allowed
- Any **authoritative dataset** or â€œrealâ€ production data embedded in the frontend  
- Anything that bypasses the governed API boundary (no direct graph access)  [oai_citation:2â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
- Anything that violates sovereignty/classification propagation (outputs canâ€™t be less restricted than inputs)  [oai_citation:3â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

> [!NOTE]  
> KFMâ€™s UI contract expectations include things like **layer registry config**, **accessibility audits**, and **usage analytics hooks**â€”samples in this folder should exercise those pathways instead of inventing new ones.  [oai_citation:4â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ§± Nonâ€‘negotiables this folder must respect (KFM v13)

### 1) Canonical pipeline ordering (inviolable)
Samples here should **only reference** artifacts that exist downstream of the canonical pipeline:
ETL â†’ Catalogs (STAC/DCAT/PROV) â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode.  [oai_citation:5â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

### 2) API boundary rule
The web UI **must never** query Neo4j directly; comparisons should call API endpoints (or use explicitly synthetic fixtures for offline rendering).  [oai_citation:6â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

### 3) Provenance-first
Any comparison that presents results as â€œrealâ€ should point back to **cataloged evidence** (STAC/DCAT + PROV lineage) before itâ€™s used in UI/story contexts.  [oai_citation:7â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

### 4) Evidence-first UX (especially in â€œinspectâ€ / â€œwhyâ€ affordances)
KFMâ€™s design intent is that users can inspect sources and citations for layers/analyses. Comparisons should keep that affordance intact (e.g., â€œEvidenceâ€ drawer per series). 

### 5) Auditability & telemetry signals
Where sensitivity/redaction is relevant, emit telemetry events so governance can answer **â€œwho saw what and why.â€** (Example event: `focus_mode_redaction_notice_shown`.)  [oai_citation:8â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ—‚ï¸ Suggested layout

> This repo may evolveâ€”treat the following as the **recommended** structure for comparison samples.

```text
ğŸ“ web/assets/samples/analytics/comparisons/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“„ index.json                       # registry of available comparison packs (recommended)
â””â”€â”€ ğŸ“ packs/
    â””â”€â”€ ğŸ“ <comparison_id>/
        â”œâ”€â”€ ğŸ“„ manifest.json            # comparison definition (config-first)
        â”œâ”€â”€ ğŸ–¼ï¸ preview.png              # optional
        â””â”€â”€ ğŸ“„ fixture.response.json    # optional; synthetic-only; for Storybook/tests
```

---

## ğŸ§¾ Comparison Pack Manifest (contract-first)

A â€œcomparison packâ€ is **a UI-friendly contract** describing:

- **what** is being compared (series A/B/â€¦)  
- **how** the UI should render the comparison  
- **where** evidence comes from (STAC/DCAT/PROV references)  
- **what** telemetry should fire (for governance + analytics)

<details>
<summary><b>ğŸ“¦ Example <code>manifest.json</code></b> (config-first; API-backed)</summary>

```json
{
  "id": "compare__hydrology__streamflow_vs_precip__1900_1950",
  "title": "Streamflow vs Precipitation (1900â€“1950)",
  "summary": "Side-by-side time series with delta + correlation summary.",
  "kind": "timeseries",
  "mode": "api",
  "classification": {
    "level": "public",
    "notes": "No sensitive locations; derived metrics are aggregated."
  },
  "series": [
    {
      "seriesId": "streamflow",
      "label": "Streamflow",
      "api": {
        "endpoint": "/analytics/timeseries",
        "params": { "metric": "streamflow", "timeRange": "1900-01-01/1950-12-31" }
      },
      "evidence": {
        "stacItemIds": ["stac:item:..."],
        "dcatDatasetIds": ["dcat:dataset:..."],
        "provBundleIds": ["prov:bundle:..."]
      }
    },
    {
      "seriesId": "precip",
      "label": "Precipitation",
      "api": {
        "endpoint": "/analytics/timeseries",
        "params": { "metric": "precip", "timeRange": "1900-01-01/1950-12-31" }
      },
      "evidence": {
        "stacItemIds": ["stac:item:..."],
        "dcatDatasetIds": ["dcat:dataset:..."],
        "provBundleIds": ["prov:bundle:..."]
      }
    }
  ],
  "comparison": {
    "derived": [
      { "id": "delta", "label": "Î” (A âˆ’ B)" },
      { "id": "pct_change", "label": "% change vs baseline" },
      { "id": "corr", "label": "Correlation (Pearson)" }
    ]
  },
  "viz": {
    "defaultView": "lines",
    "units": { "streamflow": "cfs", "precip": "in" },
    "a11y": { "requiresTableView": true }
  },
  "telemetry": {
    "onOpen": "comparison_opened",
    "onRun": "comparison_run_started",
    "onComplete": "comparison_run_completed",
    "onExport": "comparison_export_clicked"
  }
}
```
</details>

### Manifest principles
- **`mode: "api"` is the default.** It respects the API boundary rule by design.  [oai_citation:9â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
- **Evidence is not optional** for anything that might be treated as â€œreal.â€ KFM is explicitly provenance-first and evidence-first.  [oai_citation:10â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
- **Classification is explicit** to prevent accidental â€œleak-by-UI.â€ Outputs cannot be less restricted than inputs.  [oai_citation:11â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ”Œ How the web UI should use these samples

```mermaid
flowchart LR
  P[ğŸ“¦ Comparison Pack<br/>(manifest + evidence)] --> UI[ğŸŒ Web UI<br/>(web/)]
  UI -->|governed requests| API[ğŸ§± API Layer<br/>(src/server)]
  API --> G[ğŸ•¸ï¸ Graph]
  API --> C[ğŸ“š Catalogs<br/>STAC/DCAT/PROV]
  UI --> T[ğŸ“¡ Telemetry<br/>(events + audit trails)]
```

### Expected runtime behavior
1. UI loads `index.json` (or equivalent registry)  
2. User selects a comparison â†’ UI loads `packs/<id>/manifest.json`  
3. UI runs API queries described in the manifest (**never** direct graph calls)  [oai_citation:12â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
4. UI renders:
   - side-by-side chart(s)
   - derived metrics (delta, % change, etc.)
   - evidence panel per series (STAC/DCAT/PROV links)
5. UI emits telemetry events (open/run/complete/export + any redaction notices)  [oai_citation:13â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## â™¿ Accessibility expectations (donâ€™t skip)

Comparisons should be usable in multiple modalities:

- keyboard navigation (no mouse required)
- â€œtable viewâ€ fallback for charts (screen reader friendly)
- clear labeling of units and baselines (whatâ€™s A? whatâ€™s B?)
- avoid color-only meaning

These samples should help exercise **accessibility audit hooks** as part of the UI contract surface.  [oai_citation:14â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ§ª Using these samples for QA

Comparison packs are great fixtures for:
- Storybook states (stable UI snapshots)
- integration tests that validate API â†’ UI rendering
- end-to-end flows (select â†’ run â†’ inspect evidence â†’ export)

KFMâ€™s QA strategy includes unit/integration/E2E testing and mentions tools such as **pytest** and **Cypress**.  [oai_citation:15â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)

---

## âœ… Contribution checklist

Before adding/editing a comparison pack:

- [ ] **API-boundary compliant** (no direct graph calls)  [oai_citation:16â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- [ ] **Provenance referenced** (STAC/DCAT/PROV IDs or links where applicable)  [oai_citation:17â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- [ ] **Classification declared** and consistent with inputs  [oai_citation:18â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- [ ] **No real sensitive data** embedded in the frontend  
- [ ] **Telemetry hooks named** (open/run/complete/export + redaction events if relevant)  [oai_citation:19â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- [ ] **A11y fallback** exists (table view / labels / baselines)  [oai_citation:20â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- [ ] If fixtures exist: they are **synthetic**, deterministic, and clearly labeled

---

## âœï¸ Adding a new comparison pack (recipe)

1. **Choose an ID**  
   Convention suggestion:  
   `compare__<domain>__<metricA>_vs_<metricB>__<time_or_scope>`

2. **Create pack directory**  
   `web/assets/samples/analytics/comparisons/packs/<comparison_id>/`

3. **Write `manifest.json`**  
   - define series and API queries  
   - include evidence pointers  
   - define default viz + telemetry event names

4. **(Optional) Add `preview.png`**  
   Keep it small + non-sensitive.

5. **(Optional) Add `fixture.response.json`**  
   Only if you truly need offline rendering; must be synthetic.

6. **Register in `index.json`**  
   So UI pickers can discover it.

---

## ğŸ“š References (project sources)

- KFM v13 directory layout + canonical subsystem locations (including `web/`).  [oai_citation:21â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- KFM v13 invariants: pipeline ordering, API boundary, provenance-first, classification propagation, validation gates.  [oai_citation:22â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- Audit trail / telemetry example for redaction notices.  [oai_citation:23â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- KFM transparency intent: users should be able to inspect layer sources/citations.   
- Testing/QA toolchain mentions (unit/integration/E2E; pytest/Cypress).  [oai_citation:24â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)  
