# ğŸ§ª `web/__tests__` â€” KFM Web Test Suite

<kbd>ğŸ§ª Unit</kbd> <kbd>ğŸ§© Integration</kbd> <kbd>ğŸ—ºï¸ Map UI</kbd> <kbd>ğŸ§­ Provenance</kbd> <kbd>ğŸ›¡ï¸ Policy Gates</kbd> <kbd>â™¿ a11y</kbd> <kbd>ğŸ§Š Deterministic</kbd>

> **Mission:** Keep the KFM Web UI *trustworthy*, *repeatable*, and *governed* â€” so every user-facing view (maps, stories, AI answers) is auditable, policy-compliant, and stable across time.

---

## ğŸ“Œ Contents

- ğŸ§­ [What makes KFM testing â€œdifferentâ€](#-what-makes-kfm-testing-different)
- âš¡ [Quickstart](#-quickstart)
- ğŸ§± [Test pyramid](#-test-pyramid)
- ğŸ—‚ï¸ [Recommended folder layout](#ï¸-recommended-folder-layout)
- ğŸ§ª [Test types & what to cover](#-test-types--what-to-cover)
- ğŸ§° [Fixtures, mocks, and utilities](#-fixtures-mocks-and-utilities)
- ğŸ—ºï¸ [Testing maps without WebGL pain](#ï¸-testing-maps-without-webgl-pain)
- ğŸ¤– [Testing Focus Mode & AI UX](#-testing-focus-mode--ai-ux)
- ğŸ›¡ï¸ [Policy tests (treat governance like tests)](#ï¸-policy-tests-treat-governance-like-tests)
- â™¿ [Accessibility](#-accessibility)
- ğŸ§¯ [Flake control & debugging](#-flake-control--debugging)
- âœ… [Definition of Done checklist](#-definition-of-done-checklist)
- ğŸ“š [Project reference shelf](#-project-reference-shelf)

---

## ğŸ§­ What makes KFM testing â€œdifferentâ€?

KFM is not â€œjust a React map app.â€ The UI is the *last* stage of a governed pipeline (data â†’ catalogs â†’ graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode). That implies these non-negotiables for tests:

1. **API boundary is sacred**  
   The Web UI must never reach around the API layer (no â€œdirect graph/db queriesâ€). If a component needs data, it comes from contracted endpoints.

2. **Evidence-first UX**  
   Story Nodes and Focus Mode must never display unsourced narrative. The UX must visibly surface provenance (citations, dataset IDs, evidence panels, etc.) â€” and tests should fail if it regresses.

3. **Fail-closed for sensitive data**  
   If a dataset/layer/answer is classified as sensitive, the UI must **generalize**, **blur**, **omit**, or **block** it (depending on rules). No â€œside-channel leaksâ€ via tooltips, URL params, debug panels, or cached responses.

4. **Determinism is a feature**  
   Tests must be reproducible: freeze time, seed randomness, mock network, and avoid â€œlive dataâ€ dependencies.

---

## âš¡ Quickstart

> Commands vary slightly by repo scripts â€” **check `web/package.json`** for exact names. These are the common patterns.

```bash
# from repo root
cd web

# unit/integration
npm test
# or: pnpm test / yarn test

# watch mode (if available)
npm run test:watch

# coverage (if available)
npm run test:coverage
```

### ğŸ§­ E2E (if configured)

```bash
cd web

# headless
npm run test:e2e

# interactive runner
npm run test:e2e:open
```

---

## ğŸ§± Test pyramid

```mermaid
flowchart TD
  A["ğŸ§ª Unit tests (fast)\nPure logic: filters, transforms,\ntime mapping, formatters"] --> B["ğŸ§© Integration tests\nReact components + state + mocked API\n(Testing Library + MSW)"]
  B --> C["ğŸŒ E2E tests (few but critical)\nBrowser flows: map + timeline + story + Focus Mode"]
  C --> D["ğŸ›¡ï¸ Policy & governance tests\nMetadata required, citations present,\nno sensitive leaks, fail closed"]
```

**Rule of thumb:**  
- Most coverage comes from **unit + integration**.  
- **E2E** is for *critical user journeys only* (avoid a flaky wall of tests).  
- **Policy tests** are first-class â€” they protect trust like any other test suite.

---

## ğŸ—‚ï¸ Recommended folder layout

This folder can serve as a shared â€œtest harnessâ€ (fixtures + utilities), while feature tests may still live closer to the code they cover.

```text
web/
  __tests__/
    ğŸ“„ README.md                        # you are here âœ…
    ğŸ§° setupTests.(ts|js)               # jest/vitest global setup
    ğŸ§ª unit/
      *.test.(ts|tsx)
    ğŸ§© integration/
      *.test.(ts|tsx)
    ğŸŒ e2e/
      *.spec.(ts|js)                   # cypress/playwright specs (if stored here)
    ğŸ§ª fixtures/
      ğŸ“¦ dcat/                          # dataset discovery metadata
      ğŸ›° stac/                          # spatial assets + items
      ğŸ§¬ prov/                          # lineage bundles
      ğŸ“š story_nodes/                   # story node samples w/ citations
      ğŸ§µ pulse_threads/                 # â€œpulseâ€ feed items (if used)
      ğŸ§  focus_mode/                    # AI responses w/ citations + flags
    ğŸ§± mocks/
      ğŸ—º maplibre.ts                     # map stub
      ğŸŒ cesium.ts                       # 3D stub (optional)
      ğŸŒ msw/
        handlers.ts
        server.ts
    ğŸ§· utils/
      renderWithProviders.tsx           # wraps app providers (router/store/theme)
      testIds.ts                        # centralized testid conventions
      freezeTime.ts                     # deterministic clocks
      buildFixture.ts                   # typed builders for fixtures
```

> If the repo already has a different structure, **donâ€™t fight it** â€” adapt these ideas into the existing layout.

---

## ğŸ§ª Test types & what to cover

### 1) Unit tests ğŸ§ª (fast, pure logic)
Best targets:
- timeline/date window mapping (including boundary conditions)
- layer filtering / query-building (bbox, time range, domain filters)
- formatting of provenance chips (license, source, dataset IDs)
- story node parsing / citation extraction helpers
- â€œclassification propagationâ€ helpers (e.g., max(input classifications))

âœ… Characteristics:
- no DOM (or minimal)
- no network
- deterministic inputs/outputs

---

### 2) Integration tests ğŸ§© (UI behavior with mocked APIs)
Best targets:
- layer browser â†’ enabling a layer triggers the expected API request(s)
- timeline movement triggers re-fetch / re-style / re-render behavior
- story node opens â†’ citations panel renders â†’ â€œView Evidenceâ€ behaves
- Focus Mode panel shows: AI label, citations, uncertainty/confidence, governance flags
- sensitive layer behavior: blur/generalize/blocked UI states

Recommended tools/patterns:
- React Testing Library (`screen`, `userEvent`)
- Network mocking via MSW (or your repoâ€™s equivalent)

---

### 3) E2E tests ğŸŒ (few, critical user journeys)
Pick only the flows that must never break:

- **Map load â†’ enable layer â†’ visible change**
- **Timeline drag â†’ layer updates**
- **Open Story Node â†’ citations visible â†’ evidence panel opens**
- **Open Focus Mode â†’ ask question â†’ citations shown**
- **Sensitive content**: attempt access â†’ UI blocks/redacts with explanation
- **Offline mode**: simulate offline â†’ app degrades gracefully

> Keep E2E stable by selecting elements via semantic roles + stable labels (avoid brittle CSS selectors).

---

### 4) Contract / schema tests ğŸ“œ (UI â†” API alignment)
Because KFM is contract-first, add tests that ensure the UI matches API contracts:

- expected response shape for dataset search
- STAC items & assets fields used by UI
- provenance links (DCAT â†” STAC â†” PROV) are present before UI renders certain modules

This can be done in web tests by validating mocked fixtures against JSON Schema (if schemas are exposed to the web workspace) or by type-level assertions in TypeScript.

---

## ğŸ§° Fixtures, mocks, and utilities

### Fixtures philosophy ğŸ“¦
KFM is evidence-first, so your fixtures should look like â€œmini KFMâ€:

- **DCAT** fixture includes: `title`, `description`, `license`, `publisher`, distributions
- **STAC** fixture includes: `bbox`, `geometry`, `datetime`, `assets`, links to provenance
- **PROV** fixture includes: inputs, activities, agents, and parameters (where applicable)
- **Story Node** fixture includes: citations block + evidence manifest pointer
- **Focus Mode** fixture includes: citations per claim + governance flags (and maybe an audit panel payload)

âœ… Pro-tip: Use â€œbuilderâ€ functions to generate fixtures consistently, e.g.:
- `makeDcatDataset({ license: "CC-BY", classification: "public" })`
- `makeStoryNode({ citations: [...], evidenceManifest: ... })`

---

## ğŸ—ºï¸ Testing maps without WebGL pain

Map rendering in CI/headless environments is famously flaky. KFM uses WebGL-heavy mapping (2D and optional 3D), so the strategy is:

### âœ… For unit/integration tests
- **Stub the map implementation** (MapLibre/Cesium) to:
  - accept layer additions
  - emit events (move, click, hover)
  - store â€œcurrent viewport/timeâ€ in a fake state
- Assert your app calls the right map APIs **and** renders the correct UI chrome (legend, layer list, provenance badges), instead of snapshotting pixels.

### âœ… For E2E tests
- Run in a real browser where WebGL works.
- Still avoid fragile pixel assertions unless you have visual regression infrastructure.

---

## ğŸ¤– Testing Focus Mode & AI UX

Focus Mode is a *trust boundary*, not just another widget.

### Must-test behaviors âœ…
- **Citations required:** answers must show citations (not â€œtrust meâ€ text).
- **Advisory-only:** UI must not imply the AI performed actions (publishing, deleting, auto-hiding, etc.).
- **Opt-in AI:** AI-generated text is explicitly labeled (and ideally visually distinct).
- **Uncertainty:** where applicable, show confidence/uncertainty metadata.
- **Governance flags:** sensitive-topic requests or restricted datasets trigger a clear block/redaction UX.
- **Audit panel (if present):** â€œwhy this answerâ€ surfaces supporting entities and governance notices.

### Suggested test cases ğŸ§ª
- When API returns `citations: []` â†’ UI should render a **refusal / â€œcannot answer without sourcesâ€** state.
- When response includes `governance.flags = ["sensitive_location"]` â†’ UI must redact or generalize details.
- When user clicks a citation â†’ UI opens the linked dataset/doc view (or evidence drawer).

---

## ğŸ›¡ï¸ Policy tests (treat governance like tests)

KFM treats policy enforcement like CI tests â€” the web suite should mirror that mindset at the UI layer.

### Examples of â€œpolicy testsâ€ you can run in `web/__tests__`
- **Layer Registry Lint:** every layer config must include:
  - `datasetId` (or stable evidence ID)
  - license + attribution
  - classification/sensitivity tag
  - legend/provenance rendering hooks
- **Story Node Readiness:** any Story Node referenced by the UI must include:
  - citations block
  - evidence manifest pointer (if the project uses it)
  - graph entity references (stable IDs)
- **No Sensitive Leaks:** if a dataset is restricted:
  - UI must not show exact coordinates
  - UI must not allow raw download links
  - UI must not cache restricted payloads in localStorage without encryption/controls

> Treat these as **non-negotiable**. They protect moral debt and technical debt at the same time.

---

## â™¿ Accessibility

Accessibility is not optional â€” itâ€™s part of KFMâ€™s â€œpublic atlasâ€ duty.

Minimum expectations:
- keyboard navigation works for:
  - layer lists
  - timeline controls
  - story navigation
  - Focus Mode panel
- visible labels and accessible names for interactive controls
- contrast modes (if supported) donâ€™t break layout/meaning

Recommended automation:
- `axe` checks in integration tests (or `cypress-axe` in E2E)
- RTL queries by role (`getByRole`) before test IDs

---

## ğŸ§¯ Flake control & debugging

### Flake killers âœ…
- Freeze time (`Date.now`, `new Date()`) for timeline-sensitive tests
- Seed randomness (`Math.random`) if used in styling/IDs
- Use MSW to mock network and **avoid live endpoints**
- Avoid snapshot tests for large DOM trees (prefer behavioral assertions)
- In E2E: wait for **UI state**, not timeouts (e.g., â€œlayer loadedâ€ indicator)

### Debugging tips ğŸ› 
- Add a `debug` flag to log:
  - outbound API calls
  - current bbox/time window
  - layer registry state
  - governance classification state
- Prefer â€œscreen.debug()â€ (RTL) or interactive runner (Cypress/Playwright) over sprinkling sleeps.

---

## âœ… Definition of Done checklist

When you ship a new UI feature, youâ€™re done when:

- [ ] Unit tests cover any non-trivial logic (filters, transforms, parsing)
- [ ] Integration tests cover the main UI states:
  - [ ] loading / empty / error
  - [ ] happy path
  - [ ] restricted/sensitive path (if applicable)
- [ ] Provenance is visible somewhere the user can reach (tooltips, info panel, citations)
- [ ] AI output (if any) is labeled + cited + opt-in
- [ ] Accessibility checks pass (manual keyboard + automated a11y where reasonable)
- [ ] No new network calls bypass the API boundary
- [ ] CI is stable (no flaky tests introduced)

---

## ğŸ“š Project reference shelf

These project docs/resources inform how tests should be written (governance, UI/AI expectations, geospatial constraints, privacy principles, and future roadmap). Keep them in mind when authoring tests:

### ğŸ§­ Core governance & invariants
- **Master Guide v13 / Markdown Guide v13** â€” pipeline ordering, evidence-first narrative, Focus Mode hard gates, contract-first philosophy  
- **Data Intake Guide** â€” STAC/DCAT/PROV â€œevidence tripletâ€, deterministic ETL assumptions, policy packs mindset  
- **Technical Documentation** â€” QA strategy, CI expectations, E2E philosophy

### ğŸ–¥ UI & user experience
- **Comprehensive UI System Overview** â€” modular UI patterns, map + story integration expectations  
- **Architecture, Features, and Design** â€” front-end components, accessibility expectations, MapLibre/Cesium usage patterns

### ğŸ¤– AI / Focus Mode
- **AI System Overview** â€” citations, explainability/audit panels, prompt security layers, policy checks

### ğŸŒ± Future-facing UX & governance evolution
- **Latest Ideas & Future Proposals** â€” new governance patterns, maintenance agents, supply-chain thinking  
- **Innovative Concepts** â€” AR, cultural protocols, sensitive location handling concepts  
- **Additional Project Ideas** â€” â€œpolicies as testsâ€, evidence manifests, Pulse Threads, narrative auditability

### ğŸ§  Background resource packs (for deeper implementation work)
- **AI Concepts & more** â€” AI patterns and concepts (reference pack)  
- **Data management / Bayesian / architecture notes** â€” data quality and systems thinking (reference pack)  
- **Maps / WebGL / virtual worlds** â€” WebGL + 3D mapping context (reference pack)  
- **Programming languages & resources** â€” general engineering reference pack  
- **Data Mining Concepts & applications** â€” privacy/anonymization/inference control concepts  
- **Python geospatial analysis cookbook** â€” spatial processing patterns you may mirror in fixtures

---

ğŸ§­ **Reminder:** The UI is where trust is won or lost. If a test feels â€œtoo strict,â€ it probably protects a KFM invariant. âœ…

