<!--
ğŸ“„ Doc: Domain Service Test Runbook
ğŸ“ Path: web/src/services/domain/__tests__/README.md
ğŸ§­ Status: active
ğŸ” Last reviewed: 2026-01-05
-->

# ğŸ§ª Domain Service Tests (`web/src/services/domain/__tests__`)

![scope](https://img.shields.io/badge/scope-web%20frontend-2ea44f)
![layer](https://img.shields.io/badge/layer-domain%20services-6f42c1)
![goal](https://img.shields.io/badge/goal-deterministic%20business%20rules-0ea5e9)
![style](https://img.shields.io/badge/style-contract--first%20%26%20evidence--first-f59e0b)

This folder contains **unit/contract-style tests** for the **domain service layer** in the KFM web app.

> âœ… If itâ€™s *business logic* (rules, policy, mapping/normalization, â€œwhat should happenâ€), it belongs here.  
> âŒ If itâ€™s *UI rendering* (React components) or *real network I/O*, it belongs elsewhere.

---

## ğŸ¯ What we test here

### âœ… In-scope
- **Pure domain rules** (calculations, transforms, filtering, sorting, thresholds, aggregation)
- **Use-case orchestration logic** (domain â€œservicesâ€ that coordinate smaller pure functions)
- **Input/output contracts** for domain services (types, invariants, edge-cases)
- **Determinism guarantees** (same input â†’ same output)
- **Safety & governance behaviors** *at the domain boundary* (e.g., â€œdonâ€™t leak sensitive locationsâ€, â€œpreserve provenance fieldsâ€, â€œrespect classification propagationâ€)

### ğŸš« Out-of-scope
- React component behavior (thatâ€™s component testing)
- Real API calls / live servers / real graph access
- Browser-only behavior (thatâ€™s e2e)
- Large dataset validation (thatâ€™s pipeline/data validation)

---

## ğŸ§± Architectural intent (why these tests matter)

KFM follows a layered approach where **domain logic stays independent** from technical details. That separation is intentional because it makes domain logic:
- easier to reason about,
- easier to change safely,
- and **easy to test in isolation**. âœ…

### ğŸ—ºï¸ Dependency flow (mental model)

```mermaid
flowchart LR
  UI["ğŸ–¥ï¸ UI (React components)"] --> DS["ğŸ§  Domain Services (this layer)"]
  DS --> PORT["ğŸ”Œ Ports / Interfaces (API client, storage, clock, etc.)"]
  PORT --> API["ğŸŒ Governed API layer"]
  API --> DATA["ğŸ“¦ Data/Catalog/Graph backends"]
```

**Rule of thumb:**  
Domain services may *call ports* (interfaces), but tests should **stub/fake those ports**.

---

## ğŸ—‚ï¸ Suggested layout

> Your actual folder may differ â€” keep this as the default pattern.

```text
ğŸ“ web/
  ğŸ“ src/
    ğŸ“ services/
      ğŸ“ domain/
        ğŸ“„ index.ts
        ğŸ“„ <domainService>.ts
        ğŸ“ __tests__/
          ğŸ“„ README.md  ğŸ‘ˆ you are here
          ğŸ“„ <domainService>.spec.ts
          ğŸ“ fixtures/
            ğŸ“„ <scenario>.json
          ğŸ“ factories/
            ğŸ“„ make<Thing>.ts
          ğŸ“ fakes/
            ğŸ“„ fake<ApiPort>.ts
```

---

## â–¶ï¸ Running the tests

Because this repo may be configured with different package managers, use the one already used by the project.

### Option A: run from repo root (common)
```bash
# run the full test suite
npm test

# or
yarn test

# or
pnpm test
```

### Option B: run from the `web/` workspace (common in monorepos)
```bash
cd web
npm test
```

### Running only domain tests (patterns)
```bash
# run tests in a folder (runner-dependent)
npm test -- domain/__tests__

# run one file (runner-dependent)
npm test -- <domainService>.spec.ts
```

> ğŸ” If these flags donâ€™t work, check the test runnerâ€™s docs or the repoâ€™s root README/scripts.

---

## ğŸ§ª Test design rules (non-negotiable)

### 1) âœ… Prefer contract-first tests
Treat each domain service like a contract:

- **Given** valid/invalid inputs  
- **When** the service runs  
- **Then** it returns *exactly* what the contract promises

**This keeps refactors safe** while still allowing internal implementation changes.

### 2) ğŸ” Deterministic outputs
Domain services should produce stable outputs for a given input:
- Freeze time (inject a `clock` port instead of using `Date.now()` directly)
- Avoid randomness; if needed, inject a `rng` port and seed it in tests

### 3) ğŸ”Œ Stub the world (ports/adapters)
No network calls. No browser storage. No global mutable singletons.

Use fakes/stubs:
- `FakeApiClient`
- `FakeStorage`
- `FakeClock`

### 4) ğŸ§¾ Keep provenance and classification intact
If a domain service processes data that contains provenance/classification metadata:
- It must **not drop** that data unintentionally
- It must **not â€œdowngradeâ€** restrictions (public output cannot be less restricted than inputs)

> ğŸ§¯ When in doubt: write a regression test that proves we donâ€™t leak sensitive info.

---

## âœï¸ Naming conventions

### Test file names
Pick one style and be consistent:
- `something.spec.ts`
- `something.test.ts`

### Test case names
Use behavior language:
- âœ… `it('returns empty collection when no layers are visible')`
- âœ… `it('preserves provenance references for derived layers')`
- âœ… `it('rejects invalid bounding boxes')`

---

## ğŸ§© Test templates

### âœ… Pure function test (fastest, best)
```ts
import { describe, it, expect } from "vitest"; // or jest globals

import { computeSomething } from "../computeSomething";

describe("computeSomething()", () => {
  it("handles the happy path", () => {
    const input = { /* ... */ };

    const result = computeSomething(input);

    expect(result).toEqual({ /* expected */ });
  });

  it("handles edge cases", () => {
    expect(computeSomething({ /* ... */ })).toEqual({ /* ... */ });
  });
});
```

### âœ… Domain service test with a fake port
```ts
import { describe, it, expect } from "vitest"; // or jest globals

import { buildTimeline } from "../buildTimeline";
import { makeFakeClock } from "./fakes/fakeClock";
import { makeFakeApiClient } from "./fakes/fakeApiClient";

describe("buildTimeline()", () => {
  it("is deterministic given the same inputs", async () => {
    const clock = makeFakeClock("2026-01-05T00:00:00Z");
    const api = makeFakeApiClient({
      // return stable fixtures
      stacItems: [/* ... */],
    });

    const out1 = await buildTimeline({ api, clock }, { /* params */ });
    const out2 = await buildTimeline({ api, clock }, { /* params */ });

    expect(out1).toEqual(out2);
  });
});
```

---

## ğŸ§¯ Common pitfalls (and how to avoid them)

<details>
  <summary>âš ï¸ â€œThis test is flaky in CIâ€</summary>

- Youâ€™re probably depending on:
  - real time (`Date.now()`),
  - non-seeded randomness,
  - ordering from object iteration,
  - or unstable fixtures.

âœ… Fix:
- inject a clock
- sort outputs explicitly (or assert as sets)
- use stable fixtures
</details>

<details>
  <summary>âš ï¸ â€œThis is hard to test without mocking half the appâ€</summary>

Thatâ€™s a design smell for domain services.

âœ… Fix:
- split orchestration from pure transforms
- introduce a thin port interface (dependency injection)
- move IO-heavy behavior to adapters outside the domain layer
</details>

<details>
  <summary>âš ï¸ â€œWhy is this test rendering React?â€</summary>

If youâ€™re rendering components, youâ€™re no longer testing domain services.

âœ… Fix:
- move UI tests to the component test suite
- keep domain tests pure and fast
</details>

---

## âœ… Definition of Done for domain-service changes

Use this checklist in PRs touching `web/src/services/domain/**`:

- [ ] Added/updated tests for new or changed behavior ğŸ§ª
- [ ] Tests cover at least: happy path + 2 edge cases (null/empty/invalid) ğŸ§Š
- [ ] No real network/IO used (ports are faked) ğŸ”Œ
- [ ] Behavior is deterministic (seed/freeze time if needed) ğŸ”
- [ ] Contracts/invariants are explicitly asserted (types + runtime behavior) ğŸ“
- [ ] No leakage of sensitive/classified info (add regression test if relevant) ğŸ›¡ï¸
- [ ] CI should pass locally before pushing âœ…

---

## ğŸ”— Related project docs (recommended reading)
- ğŸ“˜ `docs/MASTER_GUIDE_v13.md` (repo-level invariants, contracts, CI gates)
- ğŸ§­ `docs/architecture/` (system layering and boundaries)
- âš–ï¸ `docs/governance/ETHICS.md` + `docs/governance/SOVEREIGNTY.md` (safety constraints)

---

## ğŸ’¬ When youâ€™re unsureâ€¦
**Write the test first** as a *question the code must answer*:

> â€œGiven X input, do we *always* do Y â€” and *never* do Z?â€

Then implement the smallest change that makes the test pass. âœ…