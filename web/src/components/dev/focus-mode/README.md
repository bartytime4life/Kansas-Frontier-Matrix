# ğŸ§  Focus Mode (Dev UI) â€” `web/src/components/dev/focus-mode/`

![React](https://img.shields.io/badge/UI-React%20%2B%20TypeScript-informational)
![Evidence First](https://img.shields.io/badge/Policy-Evidence--First%20âœ…-success)
![No Source No Answer](https://img.shields.io/badge/Rule-No%20Source%2C%20No%20Answer-critical)
![Ollama](https://img.shields.io/badge/LLM-Ollama-blue)
![OPA](https://img.shields.io/badge/Governance-OPA%20Policy%20Checks-purple)
![RAG](https://img.shields.io/badge/Pattern-RAG%20(Neo4j%20%2B%20PostGIS%20%2B%20Search%20%2B%20Vectors)-informational)

> ğŸ§­ **Purpose:** Focus Mode is KFMâ€™s map-and-timeline-aware assistant surface. This folder contains the **dev-facing UI component(s)** that render a Focus Mode chat experience, **without ever calling the LLM directly**.  
> âœ… The UI talks only to the **governed API boundary** and renders **clickable citations** (or refuses to display ungrounded output).

---

## âœ¨ What â€œFocus Modeâ€ means in KFM

Focus Mode is not â€œjust a chatbotâ€.

Itâ€™s a **governed reading + exploration mode** where:
- a **Story Node** (curated narrative) can be presented alongside **map + timeline context** ğŸ—ºï¸ğŸ•°ï¸
- optional AI assistance is **user-triggered (optâ€‘in)** and **visibly labeled** ğŸ¤–
- any dynamic content must be provenance-linked, and **citations are mandatory** ğŸ”—

---

## ğŸ“š Contents

<details>
<summary><strong>Click to expand</strong></summary>

- [Key invariants (must not regress)](#-key-invariants-must-not-regress)
- [UI responsibilities](#-ui-responsibilities)
- [Suggested folder layout](#-suggested-folder-layout)
- [Core UI anatomy](#-core-ui-anatomy)
- [API contract expectations](#-api-contract-expectations)
  - [Non-streaming query](#non-streaming-query)
  - [Streaming query](#streaming-query)
- [Citation rendering rules](#-citation-rendering-rules)
- [State machine](#-state-machine)
- [Sensitive data + sovereignty guardrails](#-sensitive-data--sovereignty-guardrails)
- [Accessibility](#-accessibility)
- [Performance notes](#-performance-notes)
- [Testing checklist](#-testing-checklist)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)

</details>

---

## âœ… Key invariants (must not regress)

These are â€œproject lawâ€ for Focus Mode UI:

- **API boundary rule:** UI must never query data stores directly (e.g., Neo4j). All access goes through the governed API layer.  
- **Evidence-first narrative:** No unsourced narrative content in Focus Mode.  
- **Provenance-only display:** If content lacks a source/ID/provenance, it does not render.  
- **AI is optâ€‘in + transparent:** AI content never appears by default; it must be user-triggered and clearly labeled.
- **No sensitive location leaks:** The UI must not become a side-channel for restricted data (e.g., exact points for sensitive places).

> ğŸ§  Mental model: Focus Mode is where users â€œexperience the storyâ€ â€” but everything they see should be traceable back to evidence.

---

## ğŸ›ï¸ UI responsibilities

The Focus Mode dev UI should:

### Must do âœ…
- Render a **chat-style** interface (messages + composer).
- Show current **context** (location/time/layers/story node scope) in a compact â€œcontext barâ€.
- Send user prompts to the **backend Focus Mode endpoint** (never to an LLM runtime).
- Render returned citations as **clickable footnotes** / **source chips**.
- Gracefully handle **policy-blocked responses** (e.g., missing citations, restricted data).
- Clearly label AI outputs with an **AI-generated** tag and (if provided) confidence/uncertainty metadata.

### Must not do ğŸš«
- Never call Ollama (or any LLM) directly from the browser.
- Never â€œinventâ€ citations client-side.
- Never display â€œhelpful guessesâ€ if the server returns â€œinsufficient evidenceâ€.
- Never leak raw coordinates or restricted identifiers if the server redacts/generalizes them.

---

## ğŸ—‚ï¸ Suggested folder layout

> This is a **recommended** shape for maintainable UI code. Your actual filenames may differ.

```text
ğŸ“ web/src/components/dev/focus-mode/
â”œâ”€ ğŸ“„ README.md
â”œâ”€ ğŸ§© FocusModePanel.tsx          # container (layout + orchestration)
â”œâ”€ ğŸ’¬ FocusModeChat.tsx           # message list + composer
â”œâ”€ ğŸ§± FocusModeMessageList.tsx    # virtualization-friendly list rendering
â”œâ”€ âœï¸ FocusModeComposer.tsx       # input + send + shortcuts
â”œâ”€ ğŸ”– FocusModeCitations.tsx      # citations list + source drawer
â”œâ”€ ğŸ§  FocusModeContextBar.tsx     # map/timeline/story context summary
â”œâ”€ ğŸŒ focusMode.api.ts            # API client wrapper (query/stream)
â”œâ”€ ğŸ§¾ focusMode.types.ts          # shared types
â”œâ”€ ğŸ§° focusMode.utils.ts          # parsing, formatting, safety helpers
â””â”€ ğŸ§ª __tests__/
   â”œâ”€ citations.parse.test.ts
   â”œâ”€ citations.render.test.tsx
   â””â”€ focusMode.state.test.ts
```

---

## ğŸ§± Core UI anatomy

A good Focus Mode UI typically has:

### 1) Context bar ğŸ—ºï¸ğŸ•°ï¸
Shows what the assistant is â€œlooking atâ€, e.g.:
- selected place(s) (county, town, feature id)
- active timeline year/range
- active data layers
- story node(s) in scope (if any)

> Tip: send **IDs + bounded context**, not huge blobs. Prefer stable identifiers over raw geometry.

### 2) Message list ğŸ’¬
- user messages
- assistant messages (with citations)
- system messages (policy-blocked, no-evidence, redaction notices)

### 3) Composer âœï¸
- single-line by default; expand to multi-line
- `Enter` to send, `Shift+Enter` newline
- supports â€œsuggested promptsâ€ (optional)

### 4) Citations + evidence drawer ğŸ”
- sources list: title + snippet + type (dataset/story/doc) + link target
- clicking `[1]` in the answer scrolls/opens the relevant source entry

---

## ğŸŒ API contract expectations

The backend is the orchestrator: it sanitizes prompts, retrieves evidence, runs the model, then applies governance checks before returning an answer.

This README documents what the **frontend should expect** and how to behave defensively.

### Non-streaming query

**Request (illustrative):**
```json
POST /api/v1/ai/query
{
  "question": "What happened here during the 1930s drought?",
  "context": {
    "place": { "type": "county", "id": "finney_ks" },
    "time": { "start": "1930-01-01", "end": "1939-12-31" },
    "layers": ["drought_index", "historic_newspapers"],
    "viewport": { "bbox": [-101.2, 37.6, -100.6, 38.1] },
    "storyNodeIds": ["story_ks_dust_bowl_intro"]
  },
  "client": {
    "surface": "web.focus-mode.dev",
    "sessionId": "optional-session-id"
  }
}
```

**Response (illustrative):**
```json
{
  "answer": "The 1930s brought prolonged drought conditions and major agricultural stress in this region [1][2].",
  "citations": [
    {
      "n": 1,
      "kind": "dataset",
      "title": "1935 Drought Index (Kansas)",
      "snippet": "â€¦relevant excerptâ€¦",
      "href": "/datasets/ks_drought_1935"
    },
    {
      "n": 2,
      "kind": "document",
      "title": "1936 Newspaper excerpt",
      "snippet": "â€¦relevant excerptâ€¦",
      "href": "/archives/doc/abc123"
    }
  ],
  "meta": {
    "model": "kfm-llama2:latest",
    "policy": { "decision": "allow" },
    "requestId": "req_..."
  }
}
```

### Streaming query

If the backend supports streaming, the UI should prefer it for responsiveness:
- show partial tokens as they arrive
- preserve the final â€œanswer + citationsâ€ structure when complete

**Implementation patterns:**
- SSE (`text/event-stream`)
- NDJSON chunking
- WebSocket

**UI rule:** donâ€™t render â€œfinal answerâ€ formatting until:
- the stream ends cleanly **and**
- citations are present/validated

---

## ğŸ”– Citation rendering rules

### What to support
- Citation markers like: `[1]`, `[2]`, â€¦ (including multi-digit like `[12]`)
- Repeated markers (`[1]` used multiple times)
- Dense clusters (`â€¦[1][2][3]`)

### What to enforce in UI (defense-in-depth)
Even if the backend already gates outputs, the UI should still be strict:

- If **no citation markers** exist in `answer` â†’ treat as **policy-blocked** and do not render as authoritative output.
- If markers exist but **no matching `citations[]` entries** â†’ render the answer as **untrusted** and show a fallback:
  - â€œEvidence list missing; please retry.â€

### Suggested parsing approach
- Regex: `\[(\d+)\]`
- Build a map: `citationByNumber[n] => citation`
- Render:
  - inline markers as `<button role="link">[n]</button>`
  - citations list as numbered entries with titles/snippets

---

## ğŸ§­ State machine

```mermaid
stateDiagram-v2
  [*] --> Idle
  Idle --> Typing: user types
  Typing --> Sending: submit
  Sending --> Streaming: stream begins
  Sending --> Complete: non-stream response
  Streaming --> Complete: stream ends OK + citations valid
  Sending --> Blocked: policy deny OR no citations
  Streaming --> Blocked: policy deny OR citations invalid
  Sending --> Error: network/timeout
  Streaming --> Error: stream broken
  Blocked --> Typing: user edits question
  Error --> Typing: user retries
  Complete --> Typing: follow-up question
```

---

## ğŸ›¡ï¸ Sensitive data + sovereignty guardrails

Focus Mode UI must treat redaction/generalization as a **first-class UX pattern**:

- If a location is sensitive, prefer:
  - region highlight instead of point
  - blurred marker
  - â€œgeneralized locationâ€ badge
- If a citation/source is restricted:
  - show title but hide snippet (or show â€œrestrictedâ€)
  - keep links behind role-based access checks

> ğŸ”’ The UI must never reconstruct or infer redacted coordinates from other fields.

---

## â™¿ Accessibility

Minimum expectations:

- Full keyboard navigation:
  - tab through composer, send button, citation markers
  - `Esc` closes drawers/modals
- Screen-reader friendly:
  - aria-label for citation buttons (e.g., â€œOpen source 2â€)
  - message roles and clear speaker labels (â€œUserâ€, â€œFocus Modeâ€)
- Motion + streaming:
  - avoid excessive auto-scrolling that steals focus
  - prefer â€œNew contentâ€ indicator if user has scrolled up

---

## âš¡ Performance notes

- **Virtualize** message list if it grows large.
- Stream tokens to reduce perceived latency (but buffer just enough to avoid rerender storms).
- Memoize expensive formatting (citation parsing, markdown rendering).
- Keep â€œcontext barâ€ updates cheap; do not recompute full context on every keystroke.

---

## ğŸ§ª Testing checklist

### Unit tests
- citation parsing (multi-digit, duplicates, missing)
- â€œno source, no answerâ€ gating logic
- context serialization (stable IDs, bounded fields)

### UI tests
- keyboard navigation (composer â†’ send â†’ citations)
- policy-blocked responses
- restricted citation rendering

### Contract tests (recommended)
- validate that `/api/v1/ai/query` response schema matches what the UI expects
- ensure streaming emits a final â€œcompleteâ€ chunk with citations

---

## ğŸ§¯ Troubleshooting

### â€œAnswer returned but UI shows Blockedâ€
Likely causes:
- answer missing `[n]` markers
- citations array missing/empty
- policy decision deny

âœ… Expected UI behavior: show a helpful message like:
- â€œNo Source, No Answer â€” try narrowing the place/time or enabling more layers.â€

### Citations render but links 404
- source is not published
- role lacks access
- stale IDs

âœ… Expected UI behavior:
- keep the citation visible
- show â€œsource unavailableâ€ without breaking the whole response

---

## ğŸ¤ Contributing

Before changing Focus Mode UI, confirm:

- [ ] No direct LLM calls were added (browser â†’ API only).
- [ ] New UI features still honor provenance and sensitivity rules.
- [ ] Any new map overlays include provenance-linked metadata / source visibility.
- [ ] Any new API usage is contract-first and documented.
- [ ] Citation UI remains strict (no ungrounded â€œhelpfulnessâ€).

> ğŸ§© If youâ€™re adding new capability, also update the relevant docs in `docs/architecture/` and/or `docs/governance/` so the invariants stay explicit.
