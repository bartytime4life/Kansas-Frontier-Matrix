# ğŸ§ª `tests/data/` â€” Fixture Datasets & Golden Files

![tests](https://img.shields.io/badge/tests-unit%20%7C%20integration-informational)
![fixtures](https://img.shields.io/badge/fixtures-small%20%26%20deterministic-brightgreen)
![metadata](https://img.shields.io/badge/metadata-STAC%20%7C%20DCAT%20%7C%20PROV-8a2be2)
![governance](https://img.shields.io/badge/safety-no%20PII%20%7C%20no%20sensitive%20locations-red)

This folder holds **tiny, deterministic, version-controlled datasets** used by automated tests to validate the KFM â€œtruth pathâ€ endâ€‘toâ€‘end: **ETL â†’ catalogs (STAC/DCAT/PROV) â†’ graph â†’ API contracts** (and, optionally, UI expectations).:contentReference[oaicite:0]{index=0}:contentReference[oaicite:1]{index=1}

> ğŸ§­ Why this exists: KFM treats data like codeâ€”**nothing enters without metadata + provenance**â€”so our tests need fixture data that mirrors the same contracts, just at micro scale.:contentReference[oaicite:2]{index=2}:contentReference[oaicite:3]{index=3}

---

## ğŸ§¬ Core Rules (nonâ€‘negotiable)

### âœ… 1) Mirror the canonical staging layout
Even for tests, keep data in the same lifecycle â€œlanesâ€:
- `raw/` â†’ `work/` â†’ `processed/`:contentReference[oaicite:4]{index=4}
- Then publish **boundary artifacts** (metadata + provenance) before anything is treated as â€œreadyâ€:  
  `stac/` + `catalog/dcat/` + `prov/`:contentReference[oaicite:5]{index=5}

### âœ… 2) Determinism over cleverness
Fixture generation must behave like real pipelines: **idempotent, reproducible, and stable given the same inputs** (fixed seeds, no prompts, no manual steps).:contentReference[oaicite:6]{index=6}:contentReference[oaicite:7]{index=7}

### âœ… 3) No sensitive/PII content â€” ever
Fixtures must be **sanitized**:
- No real peopleâ€™s names, emails, phone numbers.
- No precise coordinates for protected/sensitive sites.
- No â€œconfidential â†’ publicâ€ classification downgrade without explicit, approved deâ€‘identification steps (tests should help catch this).:contentReference[oaicite:8]{index=8}

### âœ… 4) Keep fixtures tiny (CIâ€‘friendly)
- Prefer **microâ€‘slices** (10â€“200 rows, 1â€“5 features, small rasters).
- If a file grows large, move it to **LFS or external fetch** (keep identity tracked). The blueprint even calls out size thresholds as a practical approach.:contentReference[oaicite:9]{index=9}

---

## ğŸ—‚ï¸ Recommended Layout

> This layout is designed to match KFMâ€™s required staging + catalog boundaries while keeping fixture sets selfâ€‘contained.:contentReference[oaicite:10]{index=10}

```text
tests/data/
â”œâ”€â”€ ğŸ“ fixtures/
â”‚   â”œâ”€â”€ ğŸ“ kfm_minimal/                      # One self-contained fixture set âœ…
â”‚   â”‚   â”œâ”€â”€ ğŸ“ raw/                          # Immutable source inputs
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ <domain>/                 # e.g. historical/, hydrology/, air-quality/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ work/                         # Intermediate artifacts (optional but supported)
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ <domain>/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ processed/                    # Golden processed outputs (what pipelines should produce)
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ <domain>/
â”‚   â”‚   â”œâ”€â”€ ğŸ“ stac/
â”‚   â”‚   â”‚   â”œâ”€â”€ ğŸ“ collections/              # STAC Collections
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ items/                    # STAC Items
â”‚   â”‚   â”œâ”€â”€ ğŸ“ catalog/
â”‚   â”‚   â”‚   â””â”€â”€ ğŸ“ dcat/                     # DCAT dataset entries (JSON-LD)
â”‚   â”‚   â”œâ”€â”€ ğŸ“ prov/                         # PROV lineage bundles (JSON/JSON-LD)
â”‚   â”‚   â”œâ”€â”€ ğŸ“ db/                           # Optional: PostGIS/Neo4j seed dumps for integration tests
â”‚   â”‚   â””â”€â”€ ğŸ“„ README.md                     # Fixture runbook: â€œwhat this set provesâ€
â”‚   â””â”€â”€ ğŸ“ <another_fixture_set>/
â”‚
â”œâ”€â”€ ğŸ“ snapshots/
â”‚   â”œâ”€â”€ ğŸ“ api/                              # Golden HTTP responses (contract tests)
â”‚   â””â”€â”€ ğŸ“ graphql/                          # Golden GraphQL responses (if used)
â”‚
â””â”€â”€ ğŸ“ generated/                            # Optional: test outputs (should be gitignored)
```

### ğŸ§© Domain naming
Use domain folder names that mirror your real data domains (e.g., `historical/`, `hydrology/`, `air-quality/`). The v13 guidance emphasizes keeping each domain isolated and documented.:contentReference[oaicite:11]{index=11}

---

## ğŸ—ºï¸ The â€œTruth Pathâ€ for Fixtures

```mermaid
flowchart LR
  R["ğŸ“¥ raw/ (immutable)"] --> P["ğŸ§ª pipeline under test"]
  P --> W["ğŸ§° work/ (optional intermediates)"]
  W --> O["âœ… processed/ (golden outputs)"]

  O --> S["ğŸ—ºï¸ stac/ (items + collections)"]
  O --> D["ğŸ“‡ catalog/dcat/"]
  O --> V["ğŸ§¾ prov/ (lineage)"]

  S --> G["ğŸ§  graph fixture (Neo4j)"]
  D --> G
  V --> G

  G --> A["ğŸŒ API contract tests"]
```

This mirrors the required KFM ordering (no bypassing catalogs/provenance) and keeps fixture data honest.:contentReference[oaicite:12]{index=12}:contentReference[oaicite:13]{index=13}

---

## ğŸ“¦ What Goes in Each Folder

### ğŸ“¥ `raw/`
Small, readable inputs that represent a real ingest scenario:
- CSV/TSV
- GeoJSON (few features)
- Tiny rasters (if needed), or metadata-only stubs

Pipelines should **read raw** and **never mutate it** (raw = snapshot).:contentReference[oaicite:14]{index=14}

### ğŸ§° `work/`
Intermediate artifacts (optional):
- Reprojected geometries
- Normalized tables
- Temporary joins/derivations

Use this when you want tests to assert intermediate correctness (helpful for tricky transforms).:contentReference[oaicite:15]{index=15}

### âœ… `processed/`
Golden outputs:
- Stable schemas
- Normalized units
- Consistent CRS expectations (if a fixture is spatial)

Processed outputs are the â€œauthoritativeâ€ artifacts your downstream components should consume.:contentReference[oaicite:16]{index=16}

### ğŸ—ºï¸ `stac/` + ğŸ“‡ `catalog/dcat/` + ğŸ§¾ `prov/`
These are **required boundary artifacts**:
- **STAC**: item/collection metadata (spatiotemporal index):contentReference[oaicite:17]{index=17}
- **DCAT**: dataset discovery entry (JSON-LD):contentReference[oaicite:18]{index=18}
- **PROV**: lineage bundle (inputs â†’ activities â†’ agents â†’ outputs):contentReference[oaicite:19]{index=19}:contentReference[oaicite:20]{index=20}

KFMâ€™s CI philosophy expects â€œprocessed dataâ€ to be paired with catalog + provenance, even in review workflows.:contentReference[oaicite:21]{index=21}

---

## ğŸ§¾ Naming & Versioning Conventions

### Suggested filenames
- Processed: `<dataset_slug>.<ext>`  
  Example: `census_1900_population.geojson`
- PROV: `<dataset_slug>.prov.json` (or `.prov.jsonld`)  
  The blueprint explicitly uses this naming pattern (example: `census_1900.prov.json`).:contentReference[oaicite:22]{index=22}

### Dataset IDs (recommended)
Use **stable IDs** in fixture datasets so snapshots donâ€™t churn:
- Prefer deterministic IDs (hash of stable fields, or fixed UUIDs checked into fixtures)
- Avoid timestamp-based IDs unless thatâ€™s exactly what youâ€™re testing

---

## ğŸ§ª How Tests Should Use These Fixtures

### 1) Pipeline tests (ETL correctness)
Typical assertions:
- Running the pipeline on `raw/` produces byte-stable outputs in `processed/`:contentReference[oaicite:23]{index=23}
- `stac/`, `catalog/dcat/`, and `prov/` are generated/updated accordingly:contentReference[oaicite:24]{index=24}
- Metadata + provenance validates against schemas/profiles (when schemas exist in-repo):contentReference[oaicite:25]{index=25}

### 2) Graph tests (ontology/integrity)
- Load a small fixture graph (or build it from `processed/ + catalogs`)
- Run constraint checks to prevent ontology regressions:contentReference[oaicite:26]{index=26}

### 3) API contract tests (behavior)
- Boot API with mocked repositories or ephemeral DB seeded from `fixtures/*/db/`
- Compare endpoint responses to golden JSON in `snapshots/api/`:contentReference[oaicite:27]{index=27}

---

## âœ… â€œAdd a Fixture Setâ€ Checklist

When introducing a new fixture set under `tests/data/fixtures/<name>/`:

- [ ] `raw/` inputs are tiny and immutable  
- [ ] `processed/` outputs are committed (golden)  
- [ ] STAC + DCAT + PROV artifacts exist and cross-link correctly:contentReference[oaicite:28]{index=28}  
- [ ] No PII or sensitive coordinates (run any repo scanners locally if available):contentReference[oaicite:29]{index=29}  
- [ ] A fixture-level `README.md` explains:  
  - What scenario is represented  
  - What invariants the tests enforce  
  - Any edge cases being targeted  
- [ ] If a fixture file is large, move to LFS/external fetch pattern:contentReference[oaicite:30]{index=30}

---

## ğŸ”— References (design sources)

- KFM canonical staging + boundary artifacts: raw â†’ work â†’ processed; STAC/DCAT/PROV as required publication artifacts.:contentReference[oaicite:31]{index=31}
- Canonical pipeline ordering (no stage-skipping).:contentReference[oaicite:32]{index=32}:contentReference[oaicite:33]{index=33}
- CI expectation: processed data must have corresponding catalog + provenance entries.:contentReference[oaicite:34]{index=34}
- PROV contents (entities, activities, agents) and purpose (traceability).:contentReference[oaicite:35]{index=35}
- Contract tests + governance scans (PII/sensitive checks) as part of CI gates philosophy.:contentReference[oaicite:36]{index=36}:contentReference[oaicite:37]{index=37}

