# ğŸ§ª `tests/graph/` â€” Knowledge Graph QA + Test Reports ğŸ•¸ï¸ğŸ“ˆ

![scope](https://img.shields.io/badge/scope-graph%20%2B%20provenance-blue)
![quality-gate](https://img.shields.io/badge/quality-gate%20enabled-success)
![contracts](https://img.shields.io/badge/contracts-STAC%20%2F%20DCAT%20%2F%20PROV-informational)
![neo4j](https://img.shields.io/badge/graph-neo4j-black)

> **TL;DR**  
> This folder is the **quality gate** for the Kansas Frontier Matrix (KFM) **Knowledge Graph** + graph-adjacent workflows.  
> If a change breaks provenance, schema integrity, time semantics, or query guarantees â€” it should fail here âœ…

---

## ğŸ§­ What â€œgraphâ€ means in KFM (in practice)

In KFM, â€œgraphâ€ is **not just an algorithmic data structure** â€” itâ€™s the **semantic layer** that connects:

- ğŸ—ºï¸ **Places** (counties, rivers, towns, sites)
- ğŸ§‘â€ğŸ« **People** & ğŸ›ï¸ **Organizations**
- ğŸ—“ï¸ **Events** (historical + contemporary)
- ğŸ§¾ **Documents** (articles, photos, legal docs)
- ğŸ“¦ **Datasets** and their **lineage / provenance**

This test suite protects the *relationship fabric* that makes KFM more than â€œa pile of layersâ€.

---

## ğŸ§¬ Canonical flow (what we test around)

```mermaid
flowchart LR
  A[ETL / Pipelines] --> B[STAC + DCAT + PROV Catalogs]
  B --> C[Neo4j Knowledge Graph]
  C --> D[Contracted APIs]
  D --> E[Map + Narrative UI]
  E --> F[Story Nodes]
  F --> G[Focus Mode]
```

âœ… `tests/graph/` focuses primarily on **C**, plus the boundaries **Bâ†’C** and **Câ†’D**.

---

## ğŸ¯ Goals

### âœ… Must-pass guarantees
- ğŸ§¾ **No â€œmystery nodes/edgesâ€**: graph content must remain traceable to versioned evidence & contracts
- ğŸ§± **Schema stability**: label/relationship changes require migrations + tests
- â³ **Temporal correctness**: time-enabled entities/relations behave predictably
- ğŸ”— **Referential integrity**: no orphan edges, missing canonical nodes, or broken cross-links to catalog IDs
- ğŸš¦ **Query contracts**: â€œknown-goodâ€ queries return expected shapes and constraints (even as data grows)
- ğŸ“ˆ **Performance budgets**: important traversals stay within agreed limits

### ğŸš« Non-goals (by default)
- Running full production-scale rebuilds in PRs
- Hosting long-lived external services (tests should spin up ephemeral dependencies)

---

## ğŸ—‚ï¸ Suggested layout for this folder

> Your repo may differ â€” this is the **intended** structure for a clean `tests/graph/` suite.

```text
tests/
â””â”€â”€ graph/ ğŸ•¸ï¸
    â”œâ”€â”€ README.md ğŸ“„  (you are here)
    â”œâ”€â”€ conftest.py ğŸ§°
    â”œâ”€â”€ fixtures/ ğŸ§ª
    â”‚   â”œâ”€â”€ small/ ğŸœ        # tiny deterministic graphs (golden fixtures)
    â”‚   â”œâ”€â”€ generated/ ğŸ§¬    # synthetic graphs for property/perf tests
    â”‚   â””â”€â”€ sample_data/ ğŸ“¦  # minimal STAC/DCAT/PROV + CSV/Cypher snippets
    â”œâ”€â”€ test_schema.py ğŸ§±
    â”œâ”€â”€ test_provenance.py ğŸ§¾
    â”œâ”€â”€ test_temporal.py â³
    â”œâ”€â”€ test_queries.py ğŸ”
    â”œâ”€â”€ test_integrations.py ğŸ”Œ
    â”œâ”€â”€ test_performance.py ğŸš€
    â””â”€â”€ reports/ ğŸ“ˆ
        â”œâ”€â”€ benchmarks/ â±ï¸
        â”œâ”€â”€ plots/ ğŸ–¼ï¸
        â””â”€â”€ snapshots/ ğŸ“¸
```

---

## ğŸš€ Running the tests

### ğŸ Python-first (recommended)
```bash
# from repo root
pytest -q tests/graph
```

### ğŸ¯ Run just the â€œfast gateâ€ locally
```bash
pytest -q tests/graph -m "not integration and not perf"
```

### ğŸ§± Run schema + query contract tests
```bash
pytest -q tests/graph -k "schema or queries"
```

### ğŸ³ Integration tests (Neo4j/Postgres/etc.)
If your repo uses Docker for ephemeral test infra:

```bash
# Example only â€” align with your repoâ€™s docker-compose/devcontainer
docker compose up -d neo4j postgres
pytest -q tests/graph -m integration
docker compose down -v
```

---

## ğŸ§ª Test types (what belongs here)

| Type | Purpose | Typical runtime | Stored outputs |
|------|---------|------------------|----------------|
| ğŸ§± Schema tests | constraints, indices, migrations, stable labels/edges | fast | snapshots |
| ğŸ§¾ Provenance tests | every node/edge traces back to contracts/evidence | fast | JSON reports |
| â³ Temporal tests | valid-time / transaction-time / timeline semantics | fastâ€“medium | snapshots |
| ğŸ” Query contract tests | â€œFocus Mode-safeâ€ traversals + expected shapes | medium | snapshots |
| ğŸ”Œ Integration tests | full graph load into ephemeral Neo4j + query assertions | medium | logs + dumps |
| ğŸš€ Performance tests | benchmark traversals, import speed, cardinality scaling | slower | benchmark JSON + plots |

---

## ğŸ§¾ Provenance-first invariants (examples)

These are the â€œnever breakâ€ rules that tests should encode:

- Every node/edge has:
  - ğŸ†” stable identifier strategy
  - ğŸ§¾ provenance pointer(s) (catalog record / source reference / derivation chain)
  - ğŸ“œ license / usage metadata where applicable
- No orphan edges (relationship endpoints must exist)
- Canonical â€œglossaryâ€ nodes do not fragment into near-duplicates
- Graph state is reproducible from contracts + pipelines (no manual-only mutations)

---

## â³ Temporal graph expectations

KFM is time-aware (historical + current + predictive). Graph entities should support:

- ğŸ—“ï¸ valid-time (real-world time a thing is true)
- ğŸ§¾ transaction-time (when the system recorded it)

Even if your implementation starts simple, keep tests shaped so we can grow into
**bi-temporal** query behavior without breaking consumers later.

---

## ğŸ” Query contracts (Focus Mode safety)

Graph queries should be testable as **contracts**, similar to APIs:

âœ… Good tests here:
- â€œFind events involving Person X in Place Y during Time Range Zâ€
- â€œReturn all datasets linked to Concept C and their citationsâ€
- â€œTraverse from a story node to all referenced evidence itemsâ€

ğŸš« Avoid in this folder:
- UI-level E2E (belongs in `tests/e2e/` or similar)
- Long exploratory notebooks (belongs in `mcp/`)

---

## ğŸ“ˆ Reports + Graphing outputs (this folder should produce artifacts)

Suggested artifact contract:

- `reports/benchmarks/*.json` â±ï¸ raw benchmark runs
- `reports/plots/*.png` ğŸ–¼ï¸ plots (runtime vs size, query latency distributions)
- `reports/snapshots/*.json` ğŸ“¸ golden query outputs / schema snapshots
- `reports/summary.md` ğŸ§¾ human-readable rollup (generated)

### ğŸ§° Typical â€œmake me a plotâ€ workflow
- Use **Python** for quick plots & CI-friendly rendering
- Use **R** for exploratory statistical graphics when needed
- Keep plots deterministic (fixed seeds, pinned sampling)

---

## ğŸ§© How to add a new graph feature (checklist)

When you add **a new node type**, **edge type**, or **query**, ship it with:

- [ ] ğŸ§± schema/migration update (Cypher/DDL/etc.)
- [ ] ğŸ§ª unit tests for parsing/transform logic (domain layer)
- [ ] ğŸ”Œ integration test that loads a tiny graph and validates:
  - [ ] constraint exists
  - [ ] query returns expected shape
  - [ ] provenance fields are present
- [ ] ğŸ“¸ snapshot / golden fixture update (if output shape changes)
- [ ] ğŸ“ˆ benchmark update if traversal costs change materially

---

## ğŸ” Security + data sovereignty considerations (graph-specific)

Graph is a **high-value** aggregation layer. Tests here can also enforce:

- ğŸ”‘ access control expectations (who can query what)
- ğŸ§¾ redaction policies (sensitive attributes donâ€™t leak into public graph exports)
- ğŸ“¦ â€œdata spaceâ€ style requirements: encryption-in-transit, mutual auth, auditability

---

## ğŸ“š Project Library (the files that shape these tests)

This test suite is built to reflect the **projectâ€™s full knowledge base** â€” architecture, GIS, data engineering, statistics, security, UI, and governance.

<details>
<summary>ğŸ“– Click to expand the full library list (all project files)</summary>

### ğŸ§  Core KFM docs / governance / workflow
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf`
- `MARKDOWN_GUIDE_v13.md.gdoc` *(project structure + canonical pipeline ordering)*
- `Scientific Method _ Research _ Master Coder Protocol Documentation.pdf`
- `Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf`

### ğŸ•¸ï¸ Graph theory & graph computing
- `Spectral Geometry of Graphs.pdf`
- `Scalable Data Management for Future Hardware.pdf`

### ğŸ—„ï¸ Databases & scale
- `Database Performance at Scale.pdf`
- `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf`

### ğŸ“Š Statistics, experiments, modeling
- `Understanding Statistics & Experimental Design.pdf`
- `think-bayes-bayesian-statistics-in-python.pdf`
- `regression-analysis-with-python.pdf`
- `Regression analysis using Python - slides-linear-regression.pdf`
- `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf`

### ğŸ›°ï¸ GIS, mapping, remote sensing, spatial pipelines
- `python-geospatial-analysis-cookbook.pdf`
- `making-maps-a-visual-guide-to-map-design-for-gis.pdf`
- `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf`
- `Archaeological 3D GIS_26_01_12_17_53_09.pdf`
- `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf`

### ğŸ§© UI + visualization + rendering
- `responsive-web-design-with-html5-and-css3.pdf`
- `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf`
- `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf`

### ğŸ” Security, ethics, law, humanism
- `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf`
- `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf`
- `Data Spaces.pdf`
- `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf`
- `Introduction to Digital Humanism.pdf`

### ğŸ§  Systems / concurrency / optimization / broader theory
- `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf`
- `Generalized Topology Optimization for Structural Design.pdf`
- `Principles of Biological Autonomy - book_9780262381833.pdf`
- `graphical-data-analysis-with-r.pdf`

### ğŸ“š Programming compendiums (multi-book reference packs)
- `A programming Books.pdf`
- `B-C programming Books.pdf`
- `D-E programming Books.pdf`
- `F-H programming Books.pdf`
- `I-L programming Books.pdf`
- `M-N programming Books.pdf`
- `O-R programming Books.pdf`
- `S-T programming Books.pdf`
- `U-X programming Books.pdf`
- `Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf`

</details>

---

## ğŸ§¯ Troubleshooting (common pain points)

- **Tests fail only in CI**: check pinned dependency versions + ensure docker services are available (Neo4j/Postgres)
- **Flaky graph results**: enforce deterministic ordering + stable IDs + seed all RNG sources
- **Slow traversals**: add indices/constraints, reduce cardinality early, and re-check query patterns
- **Snapshot churn**: when output format must change, update snapshots *and* add a migration note

---

## âœ… Maintainer note

If youâ€™re unsure where a test belongs:

- Graph build logic â†’ `src/graph/`
- Graph QA + contracts â†’ `tests/graph/` âœ…
- Story narrative correctness â†’ `docs/reports/story_nodes/` + related tests
- Long experiments / notebooks â†’ `mcp/`

Keep the graph trustworthy. Keep the story provable. ğŸ§¾ğŸ—ºï¸âœ¨
