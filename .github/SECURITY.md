# ğŸ›¡ï¸ Kansas Frontier Matrix (KFM) â€” Security, Safety & Governance Policy

<div align="left">

![Security Policy](https://img.shields.io/badge/security-policy-blue)
![Coordinated Disclosure](https://img.shields.io/badge/disclosure-coordinated-success)
![Private Reporting](https://img.shields.io/badge/reporting-private%20channel-important)
![PSA](https://img.shields.io/badge/PSA-no%20issues%2FPR%20comments-red)

![Supply Chain](https://img.shields.io/badge/supply--chain-SBOM%20%2B%20attestations-black)
![SLSA](https://img.shields.io/badge/SLSA-attestations%20%2B%20provenance-0f172a)
![Policy as Code](https://img.shields.io/badge/policy-as%20code-OPA%20%2B%20Conftest-111827)

![Kill Switch](https://img.shields.io/badge/safety-kill--switch%20%2B%20fail--closed-red)
![Contract First](https://img.shields.io/badge/data-contract--first-required-0ea5e9)
![Evidence Triplet](https://img.shields.io/badge/evidence-STAC%20%2B%20DCAT%20%2B%20PROV-334155)
![Data Integrity](https://img.shields.io/badge/data-integrity-checksums%20%2B%20manifests-purple)

![AI Governance](https://img.shields.io/badge/AI-evidence--first%20%2B%20human--in--loop-8b5cf6)
![Governance](https://img.shields.io/badge/governance-FAIR%20%2B%20CARE%20%2B%20cultural%20protocols-7c3aed)

</div>

> [!IMPORTANT]
> ğŸš¨ **Do not report security vulnerabilities via public GitHub Issues, Discussions, or PR comments.**  
> Use **private vulnerability reporting** (preferred) or the alternative contact methods below.

> [!NOTE]
> KFM is a **geospatial + knowledge + modeling + narrative** system. Security issues can live in:
> **code**, **infra**, **catalog metadata (STAC/DCAT)**, **provenance (PROV)**, **data contracts**, **Story Nodes**, **3D/WebGL assets**, **offline packs**, and **AI/Focus Mode outputs**. ğŸ§¾ğŸ—ºï¸ğŸ§   
> Treat reports as potentially sensitive.

---

## âš¡ TL;DR (reporting in 60 seconds)

âœ… **Preferred (private):** Repo **Security** tab â†’ **Report a vulnerability**  
âœ… Include: **impact**, **repro steps**, **affected component**, **commit/tag**, and (if relevant) **dataset IDs** + **Contract/STAC/DCAT/PROV paths**

If you suspect **active exploitation**, put **â€œğŸš¨ ACTIVE EXPLOITATION SUSPECTEDâ€** in the title and report privately ASAP.

---

## ğŸ“Œ Table of contents

- [ğŸ§¾ Policy metadata](#-policy-metadata)
- [ğŸ§­ Policy goals & principles](#-policy-goals--principles)
- [ğŸ§‘â€âš–ï¸ Governance model, roles & responsibilities](#ï¸-governance-model-roles--responsibilities)
- [â­ Security invariants](#-security-invariants)
- [ğŸ¯ Scope](#-scope)
- [ğŸ§© Threat model (KFM-shaped)](#-threat-model-kfm-shaped)
- [ğŸ§± Trust boundaries](#-trust-boundaries)
- [ğŸ”’ Data classification & sensitive location policy](#-data-classification--sensitive-location-policy)
- [ğŸ§¾ Metadata, provenance & data contract requirements](#-metadata-provenance--data-contract-requirements)
- [ğŸªª Identity, access & auditability](#-identity-access--auditability)
- [ğŸ” Artifact integrity, reproducibility & release discipline](#-artifact-integrity-reproducibility--release-discipline)
- [ğŸ¤– Focus Mode AI & automation security](#-focus-mode-ai--automation-security)
- [âš–ï¸ Policy-as-code enforcement](#ï¸-policy-as-code-enforcement)
- [âœ… Supported versions](#-supported-versions)
- [ğŸ› Reporting a vulnerability](#-reporting-a-vulnerability)
- [ğŸ§¾ What to include](#-what-to-include)
- [ğŸ—ºï¸ Dataset / sensitive data takedown requests](#-dataset--sensitive-data-takedown-requests)
- [ğŸ—ï¸ Advisories & notifications](#-advisories--notifications)
- [â±ï¸ Coordinated disclosure](#-coordinated-disclosure)
- [ğŸ§­ Safe harbor](#-safe-harbor)
- [ğŸš« Out of scope](#-out-of-scope)
- [ğŸ§° Secure development guidelines](#-secure-development-guidelines)
- [ğŸ§ª Security gates in CI](#-security-gates-in-ci)
- [ğŸš¨ Incident response expectations](#-incident-response-expectations)
- [ğŸ—‚ï¸ Recommended repo security files](#-recommended-repo-security-files)
- [ğŸ“š Project reference library](#-project-reference-library)
- [ğŸ§¾ Appendix: Checklists & templates](#-appendix-checklists--templates)

---

## ğŸ§¾ Policy metadata

| Field | Value |
|---|---|
| Policy file | `SECURITY.md` *(canonical location: repo root **or** `.github/` â€” pick one and avoid drift)* |
| Status | Active âœ… |
| Last updated | **2026-01-19** |
| Review cycle | Quarterly ğŸ” *(or after material security/governance changes)* |
| v13 alignment | âœ… `KFM_REDESIGN_BLUEPRINT_v13` + `MASTER_GUIDE_v13` conventions |
| Evidence profiles baseline | **KFM-STAC v11.0.0** Â· **KFM-DCAT v11.0.0** Â· **KFM-PROV v11.0.0** *(profiled standards for catalogs + lineage)* |
| Default posture | **Fail-closed** for promotion-critical gates ğŸš¦ |
| Applies to | This repo + official releases + supported deployments + offline packs |
| â€œMetadata as codeâ€ posture | **Contracts + catalogs + provenance must validate** (CI gates) âœ… |

> [!TIP]
> GitHub recognizes `SECURITY.md` in the **repo root**, `.github/`, or `docs/`.  
> Keep **one canonical** file; mirrors are allowed, but **drift is a security risk**.

---

## ğŸ§­ Policy goals & principles

KFMâ€™s security stance is shaped by geospatial realities, â€œevidence-firstâ€ system design, and human-centered governance.

### ğŸ¯ What this policy optimizes for

- **Safety of people, places, and communities** ğŸ§‘â€ğŸ¤â€ğŸ§‘ğŸ—ºï¸  
  Especially for **cultural heritage and sensitive locations**, where map precision can cause real-world harm.
- **Trustworthy knowledge & narratives** ğŸ§¾âœ…  
  If itâ€™s in the UI, Story Nodes, or Focus Mode, it must be **traceable, attributable, and reproducible**.
- **Supply-chain resilience (code + data)** ğŸ”—ğŸ§±  
  Datasets + catalogs + provenance are treated like dependencies (SBOM/attestation mindset).
- **Operational containment & rollback** ğŸ§¯â™»ï¸  
  Incidents are expected; KFM is designed to **fail closed** and **roll back cleanly**.

### ğŸ§  â€œSecurity is not just AppSecâ€ (KFM-specific)

In KFM, security includes:
- **Catalog integrity** *(STAC/DCAT link safety, schema correctness, licensing terms, domain allowlists)*
- **Provenance integrity** *(PROV + run records as audit trail + reproducibility)*
- **Modeling integrity** *(verification/validation/uncertainty labeling â€” V&V/UQ as risk reduction)*
- **Narrative integrity** *(Story Nodes must cite evidence; AI assistance must be labeled + provenance-linked)*
- **Cultural protocol integrity** *(CARE + community rules; prevent â€œopen-by-defaultâ€ harm)*

---

## ğŸ§‘â€âš–ï¸ Governance model, roles & responsibilities

> [!NOTE]
> KFM is interdisciplinary: maintainers + data stewards + domain experts (historians, geographers, scientists) all contribute. Governance needs clear lanes. ğŸ›¤ï¸

### ğŸ‘¤ Core roles (recommended)

- **Security Response Lead (SRL)** ğŸ§¯  
  Owns triage, incident coordination, advisory publishing, and vulnerability comms.
- **FAIR+CARE & Cultural Protocol Council** ğŸ§¾ğŸŒ¿ğŸ·ï¸  
  Owns data classification, sensitive location review, licensing/attribution, and cultural protocol requirements (e.g., TK labels).
- **Data Intake Steward** ğŸ§°  
  Owns intake gates, contract/cat/prov validity, and â€œno mystery nodesâ€ enforcement.
- **Release Manager** ğŸ“¦  
  Owns signed releases, SBOM/attestations, and promotion lane gating.
- **Maintainers / Reviewers** ğŸ‘€  
  Own branch protection enforcement and code/data review quality.
- **Deployment Operator (self-hosted installs)** ğŸ§‘â€ğŸ’»  
  Owns runtime hardening, secrets management, monitoring, and incident containment actions.

### ğŸ§¾ Governance ledger (recommended)

Maintain a lightweight, append-only **governance ledger** (human approvals + hashes) for:
- Sensitive data approvals (who/when/why)
- Exceptions to default precision restrictions
- Takedown/restriction events + remediations
- Publication approvals for â€œhigh impactâ€ releases (major datasets, new public layers, offline packs)

> [!TIP]
> Keep decisions in `docs/architecture/adr/` and approvals in `docs/guides/governance/` (or a dedicated ledger path) so governance doesnâ€™t live only in tribal memory.

---

## â­ Security invariants

KFMâ€™s architecture uses **non-negotiable invariants** that double as security controls (intended to be enforced by CI) âœ…ğŸ¤–

1) ğŸ§¬ **Pipeline ordering is absolute**  
**Raw â†’ Work â†’ Processed â†’ Contract â†’ (STAC/DCAT/PROV) â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**  
No stage consumes artifacts that havenâ€™t passed the previous stageâ€™s **formal outputs + checks**.

2) ğŸ§¾ **Contract-first + evidence-triplet is mandatory**  
If something shows up in the UI / Focus Mode, it must be traceable to:
- âœ… a **data contract** (schema + governance metadata)  
- âœ… the **evidence triplet**: **STAC + DCAT + PROV**  
No â€œmystery layers.â€ No â€œtrust me bro.â€ ğŸš«

3) ğŸ§Š **`data/raw` is immutable (append-only)**  
Raw intake is a **preservation zone**. Never rewrite raw inputs.  
Processing produces **new versions** (with new digests + PROV).

4) ğŸ§ª **Deterministic, idempotent ETL**  
Same input + config â‡’ same output. Runs must be re-runnable safely.  
No partial publishes. No unreproducible outputs.

5) ğŸ•¸ï¸ **Graph is derived, not hand-edited**  
The knowledge graph is built from validated catalogs/contracts/provenance (e.g., bulk CSV import snapshots).  
If the graph changes, the source artifacts must explain why.

6) ğŸ”Œ **API boundary rule**  
The UI must **never** talk to the graph DB or raw object storage directly.  
All access goes through governed APIs (authZ, redaction, schema contracts). ğŸ”

7) ğŸŒ¿ **Sovereignty + classification propagate**  
No output artifact may be **less restricted** than its inputs.  
Redaction/generalization is required to publish sensitive inputs safely.

8) ğŸš¦ **Fail-closed promotion gates**  
Missing provenance, broken catalogs, unsafe links, secrets, or sensitive precision leakage â†’ **block merge/publish**.

9) ğŸ¬ **Evidence-first narrative (Story Nodes)**  
No unsourced narrative content.  
Facts must cite evidence, and AI-assisted text must be labeled + provenance-linked.

10) ğŸ¤ **Humans approve publishing**  
Automation may open PRs, run checks, and attach evidence â€” but merges/promotion remain governed and reviewable. ğŸ‘€âœ…

> [!IMPORTANT]
> In KFM, **metadata is security-critical**. A broken catalog link, missing license, unsafe remote href, or unvalidated contract can become a supply-chain issue for downstream consumers.

---

## ğŸ¯ Scope

KFM is a **geospatial + historical mapping + modeling platform** that typically includes:

- ğŸ–¥ï¸ Web UI *(React; 2D MapLibre + 3D Cesium; story/narrative panels)*
- ğŸ“± Mobile / PWA mode *(offline caching; field workflows; potential AR integration)*
- ğŸ”Œ APIs/services *(FastAPI + REST/GraphQL; policy-aware access control)*
- ğŸ§° Workers/pipelines *(ETL + analytics + publishing; deterministic jobs)*
- ğŸ—„ï¸ Spatial storage *(PostgreSQL/PostGIS)*
- ğŸ•¸ï¸ Knowledge graph *(Neo4j; ontologies; citations)*
- ğŸª£ Object storage *(tiles, COGs, docs, artifacts, offline packs)*
- ğŸ—‚ï¸ Catalog + provenance layer *(STAC/DCAT/PROV + contracts + evidence manifests)*
- ğŸ¤– AI layer *(Focus Mode; optional agent workflows; PR-only execution)*
- ğŸ§‘â€ğŸ¤â€ğŸ§‘ Collaboration features *(now: Git-based; future: in-app comments/annotations/moderation)*

### âœ… In-scope vulnerability examples

- AuthN/authZ bypass (including IDOR), privilege escalation
- Injection (SQL/command/graph query), SSRF, stored/reflected XSS, CSRF with real impact
- Unsafe file upload, path traversal, deserialization issues, RCE
- Secrets exposure (tokens/keys), sensitive data leakage (**including precise coordinates**)
- Supply-chain risks introduced by this repo (dependencies, CI scripts, GitHub Actions)
- Geo + graph specific:
  - **Catalog poisoning** (malicious STAC/DCAT links/fields) â†’ unsafe fetches or consumer compromise
  - **Retrieval poisoning** (malicious citations/graph nodes influencing Focus Mode answers)
  - Integrity tampering of published assets (COGs/tiles/docs/model artifacts/offline packs)
  - â€œGeospatial DoSâ€ payloads (massive geometries, decompression bombs, pathological tilesets) that crash pipelines/UI
  - Graph query complexity DoS (deep traversals, path explosion)

### âœ… Offline packs / mobile / AR are in scope

If KFM supports **offline data packs**, **PWA caching**, or **AR overlays**, vulnerabilities are in scope, including:
- Pack signature/attestation bypass
- Pack containing misclassified/restricted data
- Sensitive coordinate exposure via device caches
- Permission misuse (GPS/camera) or privacy leaks

---

## ğŸ§© Threat model (KFM-shaped)

KFMâ€™s threat surface includes more than code.

### ğŸ¯ Assets we protect
- ğŸ” Credentials (cloud keys, DB creds, service tokens, CI secrets)
- ğŸ§¾ Contract + catalog integrity (Contracts/STAC/DCAT) + provenance integrity (PROV)
- ğŸ—ºï¸ Sensitive location data (protected/cultural sites, private infrastructure)
- ğŸ“¦ Published artifacts (tiles/COGs/GeoJSON/GeoParquet, reports, model outputs, offline packs)
- ğŸ¬ Narrative trust (Story Nodes/Focus Mode must be evidence-backed and labeled)
- ğŸ¤– CI/CD supply chain (workflows/actions, artifact promotion, attestations)
- ğŸ§‘â€ğŸ’» User privacy (analytics/logs; accounts if enabled; moderation content)

### ğŸ‘¤ Likely threat actors
- Opportunistic attackers (common web vulns, exposed secrets, misconfig)
- Malicious data contributors (poisoning/tampering)
- Supply-chain attackers (dependencies/CI)
- Data scrapers targeting sensitive coordinates or operational details
- Well-meaning contributors who accidentally leak restricted data

### ğŸ§¨ Common KFM-specific failure modes
- â€œItâ€™s just metadataâ€ mindset â†’ unsafe STAC/DCAT hrefs, licensing gaps, missing provenance
- UI bypassing the API boundary â†’ authZ/redaction failure
- Pipelines fetching remote assets without allowlists â†’ SSRF + internal exposure
- Publishing exact sensitive coordinates (maps, story text, exports, offline caches)
- Weak integrity controls â†’ silent tampering, untraceable outputs
- LLM prompt injection / retrieval poisoning â†’ untrusted text instructing Focus Mode to ignore rules
- Graph query/path explosion â†’ DoS via overly deep traversals
- High-risk parsers (PDFs/images/3D assets) â†’ decompression bombs / memory exhaustion
- Offline packs â†’ restricted data â€œwalks out the doorâ€ if misclassified or unsigned
- Automation without kill-switch â†’ autopublish drift during an incident

> [!NOTE]
> KFM treats â€œtrustworthy outputsâ€ as a security property: verification/validation, uncertainty labeling, and reproducibility reduce both scientific and security risk.

---

## ğŸ§± Trust boundaries

<details>
<summary><strong>ğŸ§© KFM trust boundaries at a glance</strong></summary>

```mermaid
flowchart LR
  EXT[ğŸ›°ï¸ External Providers<br/>archives â€¢ APIs â€¢ feeds â€¢ GEE] -->|untrusted| INTAKE[ğŸ§° Intake Gate<br/>contract + checksums]
  INTAKE --> RAW[(ğŸ§Š data/raw<br/>immutable)]
  RAW --> WORK[(ğŸ§ª data/work<br/>scratch)]
  WORK --> PROC[(ğŸ“¦ data/processed<br/>versioned outputs)]

  PROC --> EVID[ğŸ§¾ Evidence Triplet<br/>STAC + DCAT + PROV]
  EVID --> GRAPH[(ğŸ•¸ï¸ Knowledge Graph<br/>Neo4j â€¢ CSV import)]
  EVID --> OBJ[(ğŸª£ Object Storage<br/>tiles â€¢ COGs â€¢ docs)]
  GRAPH --> API[ğŸ”Œ API / Services<br/>REST + GraphQL]
  OBJ --> API

  U[ğŸŒ User / Client] -->|HTTPS| FE[ğŸ§‘â€ğŸ’» Web UI<br/>(MapLibre + Cesium)]
  FE -->|governed calls| API

  API --> AUTH[(ğŸ” AuthN/AuthZ<br/>RBAC + ABAC)]
  API --> PACK[ğŸ“¦ Offline Pack Builder<br/>(signed + attested)]
  PACK --> U
  API --> FM[ğŸ¤– Focus Mode Runtime<br/>(retrieval + citations)]
  FM --> GRAPH
  FM --> API
```

</details>

> [!IMPORTANT]
> Anything crossing a trust boundary must assume **untrusted input** until validated  
> (files, JSON, GeoJSON, tilesets, STAC catalogs, external API responses, PDFs, images, and 3D assets). ğŸš§

---

## ğŸ”’ Data classification & sensitive location policy

KFM is â€œmostly openâ€ â€” but **not everything should be public**.

### ğŸ§­ Recommended classification levels

| Classification | Who can access | Typical examples |
|---|---|---|
| **Public** ğŸŒ | Everyone | Published layers with clear licensing |
| **Internal** ğŸ¢ | Maintainers/collaborators | Draft catalogs, staging pipelines, runbooks |
| **Confidential** ğŸ” | Explicitly approved | Sensitive layers requiring controlled sharing |
| **Restricted** ğŸ§¨ | Admin/Owners only | Credentials, security logs, protected exact coordinates |

> [!IMPORTANT]
> Some datasets require **cultural protocols / indigenous data sovereignty constraints** beyond â€œPublic vs Private.â€  
> These must be encoded in contracts + catalogs and enforced at access time. ğŸŒ¿ğŸ·ï¸

### ğŸ§¬ Propagation rule (non-negotiable)

**No output artifact can be less restricted than its inputs.**  
If a source is sensitive, all derivatives inherit equal-or-higher restrictions unless explicitly reviewed and redacted. âš–ï¸âœ…

### ğŸ—ºï¸ Sensitive location precision tiers (recommended)

| Precision tier | Examples | Allowed in Public? |
|---|---|---|
| **Exact** ğŸ¯ | point GPS, parcel centroid, address-level | âŒ unless explicitly permitted |
| **Neighborhood / small area** ğŸ§­ | 0.5â€“2km buffers | âš ï¸ only with governance approval |
| **County / region** ğŸ—ºï¸ | county polygon, watershed, broad bbox | âœ… typically safe |
| **Grid / index** ğŸ§Š | H3 / geohash cells | âœ… commonly safe if size is appropriate |
| **Redacted** ğŸ•³ï¸ | â€œlocation protectedâ€ + narrative context | âœ… preferred for cultural sensitivity |

### ğŸ›¡ï¸ Sensitive-location publishing defaults

- **Default deny** for â€œExactâ€ precision in Public.
- Prefer **grid/index** publication for public discovery.
- Require **explicit review** for any public release that could enable:
  - looting/vandalism (archaeology, cultural heritage)
  - targeting private infrastructure
  - harassment or stalking
- Add a **â€œlocation inference riskâ€** note when a dataset could be re-identified by joining layers.
- Prefer **rounding / jitter / aggregation** when appropriate (document the method + impact in PROV).

### ğŸ·ï¸ Cultural protocol controls (recommended)

When a dataset involves cultural heritage, sacred sites, or community-governed knowledge:

- Encode protocol fields in the **contract** and **catalogs** (e.g., `cultural_protocols`, `tk_labels`, `authority_to_control`).
- Apply **access control beyond RBAC** (ABAC rules based on protocol tags).
- Provide â€œ**why restricted**â€ user-facing explanations without revealing sensitive details.
- Require **Council sign-off** for any policy exceptions.
- Treat violations as security incidents.

### ğŸ” Privacy and user logs (deployment-aware)

KFM deployments may collect logs/analytics. Treat those as potentially sensitive:
- **Data minimization**: log only what you need.
- **Pseudonymize** user identifiers where feasible.
- Restrict access to logs (often **Restricted**).

---

## ğŸ§¾ Metadata, provenance & data contract requirements

KFM treats metadata and lineage as **security controls**, not â€œnice-to-have docs.â€

### âœ… Required boundary artifacts (publish bar)

Every dataset or evidence artifact that is promoted/published must have:

- ğŸ§¾ **Data contract JSON** *(KFM schema; includes license + classification + FAIR/CARE + cultural protocol flags where needed)*  
- ğŸ§¾ **STAC Collection + Item(s)** *(geospatial indexing + assets; include KFM profile fields like dataset ID + classification)*
- ğŸ—ƒï¸ **DCAT dataset entry** *(discovery + distributions + license; include sovereignty/protocol metadata where applicable)*
- ğŸ§¬ **PROV lineage bundle** *(inputs â†’ activities â†’ outputs, with agents + parameters)*
- ğŸ” **Cross-layer linkage** (bidirectional where possible):
  - Contract â†” STAC â†” DCAT â†” PROV
  - Graph references catalogs/contracts (no bulky raw data embedded)

> [!IMPORTANT]
> If the contract, catalogs, or provenance donâ€™t validate, **it does not ship**. ğŸš«ğŸ“¦

### ğŸ—‚ï¸ Data contracts (KFM â€œmetadata as codeâ€)

A **data contract** is required for ingestion and promotion. It must include, at minimum:

- `id` *(stable, unique)*  
- `title`, `description`
- `license` + attribution fields
- `schema_version`
- spatial + temporal extent *(including CRS and any reprojection notes)*
- provenance sources + processing summary
- **classification** + sensitive location policy fields
- **FAIR+CARE** fields *(recommended)*
- **cultural protocol / sovereignty** fields *(when applicable)*
- **approvals** *(when applicable: e.g., IRB / institutional approvals / data use agreements)*

<details>
<summary><strong>ğŸ§¾ Simplified contract example (shape only)</strong></summary>

```json
{
  "id": "usgs_historic_topo_1894",
  "title": "USGS Historical Topographic Map (Ellsworth County, 1894)",
  "description": "Digitized 1894 USGS topographic survey of Ellsworth County, Kansas.",
  "license": { "spdx": "PDDL-1.0", "notes": "Public domain (US Gov data)" },
  "schema_version": "v3.0.0",
  "classification": "Public",
  "sensitive_location_precision": "County / region",
  "spatial": { "bbox": [-99.5, 38.3, -98.8, 38.9], "crs": "EPSG:4326" },
  "temporal": { "start": "1894-01-01", "end": "1894-12-31" },
  "provenance": {
    "source_url": "https://www.usgs.gov/historical-topo",
    "creator": "U.S. Geological Survey",
    "issued": "1894-03-15"
  },
  "governance": {
    "faircare": {
      "collective_benefit": "Preserves environmental and cartographic heritage of Kansas.",
      "authority_to_control": "Open",
      "responsibility": "Data Engineering & FAIR+CARE Council",
      "ethics": "Culturally neutral archival content"
    },
    "cultural_protocols": null,
    "approvals": []
  }
}
```

</details>

### ğŸ—ºï¸ Catalog paths (v13 guidance)

Pick **one canonical** layout and enforce it with policy to prevent drift:

- STAC: `data/stac/collections/` + `data/stac/items/` *(recommended canonical)*
- PROV: `data/prov/`
- DCAT: either `data/catalogs/` **or** `data/catalog/dcat/` *(choose one and enforce; do not allow both)*

> [!TIP]
> Directory drift is a real security risk: it can hide unvalidated artifacts and bypass gates.

### ğŸ•¸ï¸ Knowledge graph integrity rules

- The graph is a **derived view** of governed artifacts.
- Prefer reproducible bulk import snapshots (e.g., `data/graph/csv/nodes.csv` and `data/graph/csv/edges.csv`).
- Use stable IDs, ontology alignment (e.g., CIDOC-CRM + GeoSPARQL + OWL-Time), and strict referential integrity checks.
- The graph must carry classification/protocol metadata so the API can enforce ABAC.

### ğŸ“¦ Evidence artifacts (analysis/AI outputs)

Any analysis output or AI-generated dataset is treated as a **first-class dataset**:
- stored like a dataset
- cataloged like a dataset
- traced like a dataset
- exposed only via governed APIs (never hard-coded into the UI)

---

## ğŸªª Identity, access & auditability

KFM assumes **role-based access** plus **attribute-based access** for classification and cultural protocols.

### ğŸ§‘â€ğŸ’¼ RBAC baseline roles (recommended)

| Role | Typical capabilities |
|---|---|
| **Public Viewer** ğŸŒ | Read Public datasets; view published stories; export public views |
| **Contributor** ğŸ§‘â€ğŸ”§ | Propose data/stories via PR; run local validators; cannot publish |
| **Maintainer** ğŸ‘€ | Review + merge; trigger promotion lanes; cannot bypass gates |
| **Data Steward** ğŸ§¾ğŸŒ¿ | Approve classification/protocol changes; authorize exceptions |
| **Admin** ğŸ§¨ | Manage users/secrets; emergency actions; incident containment |

> [!IMPORTANT]
> â€œContributor can upload but not publish without reviewâ€ is a deliberate safety posture. âœ…

### ğŸ§· ABAC requirements (classification-aware)

- Every request that returns data must enforce:
  - dataset `classification`
  - `sensitive_location_precision`
  - `cultural_protocols` / sovereignty tags
- The same ABAC rules apply to:
  - exports
  - offline pack builds
  - Story Node renders
  - Focus Mode evidence retrieval

### ğŸ§¾ Auditability expectations

- Privileged actions must be logged:
  - publish/promote
  - redact/remove
  - user/role changes
  - policy overrides
- Logs must be access-controlled and retained per deployment needs.

---

## ğŸ” Artifact integrity, reproducibility & release discipline

KFM treats both **code** and **data** as a supply chain.

### ğŸ” Integrity signals (recommended baseline)

- **Checksums/digests** (SHA-256) for artifacts and large assets
- **`checksums.sha256`** per dataset/work unit (or equivalent manifest)
- **`source.json`** *(or similar)* to record upstream URL, license, retrieved time, ETag/Last-Modified if available
- **Manifests** for dataset releases (files + hashes + contract/cat/prov IDs)
- **Immutability** for published artifacts (object storage versioning or content-addressed paths)
- **Reproducibility lane** for promotion (rebuild + compare hashes where feasible)
- **SBOM** for software releases + dependency review for PRs
- **Build provenance attestations** for release artifacts (CI-signed evidence)

### ğŸ§¾ Dataset BOM (DBOM) concept (recommended)

Think â€œSBOM, but for datasets.â€ For a release, publish:

- contract ID + schema version
- STAC/DCAT identifiers
- PROV run record (inputs, activities, agents)
- asset list with digests
- license summary + attribution bundle
- classification + precision tier + protocol tags

Example (shape only):

```json
{
  "release": "kfm.data.catalog.2026-01",
  "commit": "abc1234",
  "contract_id": "usgs_historic_topo_1894",
  "stac_collection": "kfm.stac.usgs.topo",
  "prov_bundle": "data/prov/run_2026-01-12T02-14-00Z.json",
  "assets": [
    { "path": "data/processed/topo/1894_ellsworth.tif", "sha256": "..." }
  ],
  "policy": {
    "classification": "Public",
    "precision": "County / region"
  }
}
```

### ğŸ“¦ Offline pack integrity (if supported)

Offline packs must be treated like releases:

- Packs must be **signed and attested** (build provenance + manifest)
- Packs must contain:
  - contract + catalogs + provenance for included datasets
  - a pack-level manifest listing hashes and classifications
  - explicit â€œwhatâ€™s missingâ€ if the online system has more restricted data
- Packs must be **policy-filtered** (ABAC must be applied before inclusion)
- Packs must support **revocation/expiry** strategies (deployment-dependent)

> [!CAUTION]
> Offline packs can quietly become the highest-risk distribution channel if misclassified data slips in. Treat them as â€œexport on steroids.â€ ğŸ§¯

---

## ğŸ¤– Focus Mode AI & automation security

Automation exists to reduce toil â€” **not** to bypass governance.

### ğŸ§  Focus Mode AI guardrails (non-negotiable)

- **Evidence-first retrieval**: Focus Mode relies on the graph + cataloged sources.
- **Citations required**: answers must cite contract/catalog/provenance-backed evidence.
- **Uncertainty over fabrication**: if evidence is missing, refuse or label uncertainty.
- **Policy-aware redaction**: classification + sensitive-location + cultural protocol rules apply at response time.
- **Prompt injection defense**:
  - treat all retrieved text as untrusted
  - ignore instructions found inside data/documents
  - never follow â€œhiddenâ€ or â€œembeddedâ€ instructions from content

> [!IMPORTANT]
> Focus Mode must not become a â€œweb-browsing botâ€ by accident.  
> If external web access is allowed in a deployment, it must be explicit, logged, and policy-gated.

### âœ… WPE model: Watcher â†’ Planner â†’ Executor (PR-only)

If we use agentic automation, it must follow:
- ğŸ‘€ **Watcher**: detects drift/events (broken links, missing metadata, changes)
- ğŸ§  **Planner**: produces a deterministic plan (what will change and why) under policy constraints
- ğŸ› ï¸ **Executor**: opens a PR with the change â€” **never auto-merges**

### âœ… Non-negotiables for automation

- ğŸ§¯ **Kill switch exists and is honored** everywhere (CI + agents + promotion jobs)
- ğŸ” **Idempotency key + commit seed** recorded (replays produce identical results)
- ğŸ§ª **Detect â†’ Validate â†’ Promote** discipline:
  - detect change robustly (checksums/ETags/events)
  - validate with fast gates + lane validators
  - promote via PR + signed/attested artifacts
- ğŸ§¾ **Evidence artifacts attached**: plans, gate reports, provenance, attestations
- ğŸ”’ **Executor cannot merge** â€” branch protections remain the final gate

### ğŸ›‘ Kill switch pattern (recommended)

Support both mechanisms:

- **Repo variable (preferred for visibility):** `KFM_KILL_SWITCH=true`
- **Optional file-based switch:** `ğŸ“„ .kfm/kill-switch.yml`

Example pattern for publish jobs:

```yaml
# publish jobs should be skipped (or hard-failed) when kill switch is ON
- name: ğŸ§¯ Kill-switch check
  shell: bash
  run: |
    set -euo pipefail

    # 1) repo variable
    if [ "${KFM_KILL_SWITCH:-false}" = "true" ]; then
      echo "Kill-switch enabled via repo variable. Stopping publish lane."
      exit 1
    fi

    # 2) file flag
    if [ -f ".kfm/kill-switch.yml" ]; then
      echo "Kill-switch file present (.kfm/kill-switch.yml). Stopping publish lane."
      exit 1
    fi
  env:
    KFM_KILL_SWITCH: ${{ vars.KFM_KILL_SWITCH }}
```

### ğŸ§¾ Model cards & bias testing (recommended)

Any AI model used in production-facing features should ship with:
- model card (purpose, training data sources, limitations)
- evaluation summary (including bias checks if relevant)
- provenance record tying the model artifact to its data + code + config

---

## âš–ï¸ Policy-as-code enforcement

KFM governance rules should be enforceable by machines. ğŸ§ âœ…

### âœ… OPA/Rego + Conftest (recommended)

Policy-as-code must cover:
- contract required fields
- catalog validity and link safety
- provenance required on publish
- classification propagation
- sensitive location precision rules
- workflow least privilege (CI)
- action pinning and dependency hygiene

> [!TIP]
> KFM references a **â€œpolicy packâ€** concept. Keep it in a canonical location (e.g., `api/scripts/policy/` or `tools/validation/policy/`) and avoid duplicates.

### ğŸ·ï¸ Example rule IDs (recommended style)

Use stable IDs for policy violations so CI output is actionable:

- `KFM-PROV-001`: Processed data changed without matching PROV update
- `KFM-CAT-002`: STAC/DCAT link domain not in allowlist (SSRF prevention)
- `KFM-CLASS-001`: Output classification lower than input classification
- `KFM-STORY-001`: Story markdown contains unsafe HTML / injection risk
- `KFM-PACK-001`: Offline pack includes Restricted/Confidential data

---

## âœ… Supported versions

We prioritize fixes for actively developed code and active public distributions.

| Target | Supported for security fixes | Notes |
|---|---:|---|
| `main` branch | âœ… | Always supported |
| Latest tagged release | âœ… | Recommended for deployments |
| Latest data catalog / pack release | âœ… | If distributed publicly |
| Older releases | âš ï¸ Best effort | Fixes may not be backported |

---

## ğŸ› Reporting a vulnerability

### âœ… Preferred: GitHub Private Vulnerability Reporting

1. Go to this repositoryâ€™s **Security** tab  
2. Click **Report a vulnerability**  
3. Provide details (see the checklist below)

Direct route (repo-specific):
- `https://github.com/bartytime4life/Kansas-Frontier-Matrix/security/advisories/new`

> [!NOTE]
> If a security report is accidentally posted publicly, maintainers may **edit/remove** it to reduce exposure, then ask you to re-submit privately.

### ğŸ“§ Alternative: security contact (fallback)

If GitHub private reporting is not available:

- ğŸ“§ **Security email:** `security@YOUR-DOMAIN.example` *(maintainers: replace with a real monitored inbox)*  
- ğŸ” **PGP key (recommended):**
  - ğŸ“ `docs/security/`
    - ğŸ“„ `pgp-public-key.asc`
  - Fingerprint: `XXXX XXXX XXXX XXXX XXXX  XXXX XXXX XXXX XXXX XXXX`

> [!CAUTION]
> Avoid sending secrets in plaintext. If you must include credentials for reproduction:
> - use short-lived test creds  
> - label them **â€œTEMP FOR REPRO ONLYâ€**  
> - include revocation instructions

### ğŸ§¯ Suspected active exploitation?

If you believe there is **active exploitation** or imminent risk:
- Report privately immediately
- Include **â€œğŸš¨ ACTIVE EXPLOITATION SUSPECTEDâ€** in the title
- If safe: include redacted logs/IoCs and scope estimates

---

## ğŸ§¾ What to include

To speed up triage, include:

- **Summary** (what is vulnerable?)
- **Impact** (what can an attacker do?)
- **Attack scenario** (realistic path)
- **Reproduction steps** (minimal)
- **Affected component(s)** (UI/API/DB/pipelines/catalogs/CI/Focus Mode/offline packs)
- **Safe proof of concept** *(non-destructive, no public exploit chains)*
- **Suggested fix** *(optional)*
- **Version/commit** tested
- **Environment** (OS/browser/runtime/container tags)

### ğŸ§­ KFM-specific context that helps a lot
- Dataset IDs (e.g., `kfm.ks.<domain>.<layer>.<time>.vN`)
- Contract paths: `docs/data/contracts/**`
- STAC paths: `data/stac/**`
- DCAT paths: `data/catalogs/**` *(or `data/catalog/dcat/**` if thatâ€™s your canonical layout)*
- PROV paths: `data/prov/**`
- Graph snapshot paths: `data/graph/csv/**` *(if applicable)*
- Whether the issue leaks **exact coordinates** vs redacted/generalized outputs
- Whether the issue could be:
  - **catalog poisoning** (unsafe `links[].href`)
  - **retrieval poisoning** (graph nodes/docs altering Focus Mode behavior)
  - **offline pack leakage** (device storage, caches, pack manifest issues)

### ğŸ§¾ Copy/paste report template

```text
Title:
Severity guess (optional):
Component(s):
Tested version/commit:
Environment:

Summary:
Impact:
Attack scenario:

Reproduction steps:
1)
2)
3)

Proof of concept (safe):
Expected result:
Actual result:

KFM-specific context (if relevant):
- Dataset ID(s):
- Contract/STAC/DCAT paths or IDs:
- PROV run record:
- Graph snapshot (if applicable):
- Offline pack involved? (Y/N)
- Does it expose sensitive coordinates? (Y/N)

Suggested fix (optional):

Notes:
- Auth required? Y/N
- User interaction required? Y/N
- Network: public/private/internal-only
- Data exposure: metadata/PII/secrets/infra access
```

---

## ğŸ—ºï¸ Dataset / sensitive data takedown requests

Sometimes the risk is **data**, not code:
- license/attribution problems
- accidental publication of sensitive coordinates
- inclusion of culturally sensitive data without approval
- misclassified artifacts (public when they should be restricted)
- archaeology/cultural heritage location exposure
- offline pack accidentally includes restricted datasets

**How to request a takedown / restriction change**
- Preferred: private vulnerability report (Security tab) labeled **â€œDATA TAKEDOWN / SENSITIVE DATAâ€**
- Include:
  - dataset ID(s)
  - contract ID(s) + classification + protocol tags
  - where itâ€™s published (STAC/DCAT links, UI pages, offline pack name)
  - why it must be restricted/removed
  - requested remediation (remove, redact, generalize, move to private, revoke pack)

> [!IMPORTANT]
> We treat sensitive-location mistakes as **security incidents** (containment + remediation), not â€œcontent disagreements.â€ ğŸ§¯

---

## ğŸ—ï¸ Advisories & notifications

We use GitHub security tooling when available:
- ğŸ§¾ **GitHub Security Advisories** for private triage + coordinated disclosure
- ğŸ“¦ **Tagged releases** for patched versions (when applicable)

How to stay informed:
- â­ Watch this repo for **Releases**
- ğŸ”” Subscribe to advisories when published

---

## â±ï¸ Coordinated disclosure

We follow coordinated disclosure:

- ğŸ“© **Acknowledgement**: confirm receipt promptly  
- ğŸ” **Triage & validation**: reproduce + assess  
- ğŸ› ï¸ **Fix & test**: patch + regression coverage  
- ğŸ“£ **Release & advisory**: disclose with mitigations  

### â³ Target response timelines (guidance)

| Stage | Target |
|---|---|
| Initial acknowledgement | **â‰¤ 2 business days** |
| Triage started | **â‰¤ 7 days** |
| Fix ETA communicated | **after validation** |
| Patch release (Critical/High) | **as fast as feasible** |
| Patch release (Medium/Low) | **scheduled / best effort** |

### ğŸ·ï¸ Severity rubric (quick)

| Severity | Examples |
|---|---|
| **Critical** | RCE, auth bypass, secrets exfiltration, full DB compromise |
| **High** | privilege escalation, SSRF into internal services, major sensitive data exposure |
| **Medium** | stored XSS with meaningful impact, IDOR with limited scope |
| **Low** | minor info leaks, non-exploitable misconfigurations |

---

## ğŸ§­ Safe harbor

We support goodâ€‘faith security research that is:
- âœ… Non-destructive
- âœ… Minimal necessary testing
- âœ… Avoids privacy violations and data exfiltration
- âœ… Reported privately with reasonable detail

**Please do not:**
- âŒ Disrupt service (DoS / load testing) without explicit permission
- âŒ Access or modify data that isnâ€™t yours
- âŒ Attempt social engineering (phishing, impersonation)
- âŒ Publish details before a patch is available (unless otherwise agreed)

> [!IMPORTANT]
> If you follow this policy in good faith, we consider your actions authorized and we will not pursue legal action against you for accidental, goodâ€‘faith violations. If unsure, **stop and report privately**.

---

## ğŸš« Out of scope

- Issues requiring **physical access** to devices
- **Denial of Service** via high-traffic/brute-force load testing
- Vulnerabilities **only in upstream providers** (report upstream), unless KFM configuration makes them exploitable
- Automated scanner output **without** actionable context or plausible impact

Usually out of scope unless chained:
- Missing headers without exploitability
- Clickjacking on non-sensitive pages
- Open redirects with no meaningful impact
- Self-XSS without a privilege chain

---

## ğŸ§° Secure development guidelines

Security is a design constraint, not a patch. ğŸ§±

### ğŸ”‘ Secrets & credentials
- Never commit secrets (`.env`, keys, tokens, credentials)
- Use `.env` locally + `.gitignore`
- Prefer secret stores in production (GitHub Secrets/Environments, vaults, cloud secret managers)
- Rotate anything potentially exposed
- Treat logs as sensitive; avoid printing tokens/PII
- Prefer short-lived credentials (OIDC â†’ cloud) where possible

### ğŸŒ Web/UI security (including WebGL & 3D)
- Validate inputs on **server** (client validation is UX, not security)
- Encode outputs; avoid unsafe HTML injection
- Render Story Node Markdown with a sanitizer (deny raw HTML by default)
- Use secure cookies, CSRF protections where relevant, and a strict CSP
- Treat 3D assets (glTF/3D Tiles/etc.) as untrusted input
- Keep CORS least-privilege (avoid `*` with credentials)
- Set request size limits (GeoJSON uploads, shader strings, style JSON, etc.)

> [!CAUTION]
> WebGL + large assets can crash GPUs/browsers. Enforce size limits, progressive loading, and resource budgets.

### ğŸ”Œ API/service security
- AuthN + AuthZ for all sensitive routes
- RBAC/ABAC as needed (classification-aware)
- Rate limit expensive endpoints (exports, deep graph traversals, heavy spatial queries)
- Request/response schema validation (OpenAPI contracts)
- Audit logging for privileged actions (publish, promote, redact, delete)
- â€œDefault denyâ€ for promotion endpoints

### ğŸ•¸ï¸ Knowledge graph security
- Parameterized graph queries (avoid string concatenation)
- Query budgets:
  - max depth / hop count
  - max results
  - timeouts
- Guard against path-explosion DoS
- Separate read/write roles; restrict administrative procedures
- Ensure graph â†” catalog referential integrity checks are enforced

### ğŸ—„ï¸ Database security (PostgreSQL/PostGIS)
- Separate read/write roles (and separate migration role if possible)
- Use parameterized queries everywhere (no string-built SQL)
- Enable TLS for DB connections; avoid â€œtrust without verificationâ€
- Use timeouts:
  - `statement_timeout`
  - `lock_timeout`
- Validate geometry (types, SRID, bounds) before insert
- Rate-limit expensive geospatial queries and exports
- Backups encrypted; restore paths audited

### âš™ï¸ Pipeline & worker safety (race conditions + resource safety)
- Make pipeline runs idempotent; avoid partial publishes
- Use staging directories + atomic â€œcommitâ€ step
- Run decoders/parsers with guardrails (size limits, timeouts)
- Treat ZIPs, PDFs, images, and large geometries as hostile until validated
- Avoid downloading arbitrary remote URLs; use allowlists + SSRF defenses

### ğŸ“¦ Offline pack safety (if supported)
- Packs must be signed + attested and include a manifest
- Packs must be policy-filtered and never include Restricted data
- Pack UI should show â€œclassification + provenanceâ€ banners even offline
- Prefer encryption at rest on device (deployment-dependent)

### â™»ï¸ Dependency & CI supply-chain hygiene
- Use lockfiles (`package-lock.json`, `pnpm-lock.yaml`, `poetry.lock`, etc.)
- Keep dependencies updated; avoid abandoned packages
- Pin base images; rebuild regularly
- Pin GitHub Actions by commit SHA when feasible
- Generate SBOMs for releases (recommended)

---

## ğŸ§ª Security gates in CI

Security must be repeatable and boring. âœ…

### âœ… Code security (baseline)
- CodeQL scanning (SAST)
- Dependency Review (PRs)
- Secret scanning + push protection (repo settings)
- Lint/typecheck/tests as required checks
- Container scanning (recommended)

### ğŸ—‚ï¸ Contract/catalog/data integrity checks (geo-specific)
- **Contract validator gate** (JSON schema, required governance fields)
- STAC/DCAT quick gate (required fields, license/providers/extensions)
- Link-check critical `links[].href` (prevents â€œcatalog poisoningâ€ + SSRF)
- CRS + bounds validation (Kansas bounds where applicable)
- Provenance presence (PROV required before publish)
- â€œClassification propagationâ€ checks (prevent public publish of restricted inputs)
- Raster/vector safety checks (size limits, geometry validity, decompression defenses)
- Story Node lint:
  - markdown sanitization (deny raw HTML by default)
  - ensure referenced layer IDs exist
  - link safety checks
  - citations present for claims (policy-driven)

### âš–ï¸ Governance gates via policy-as-code
Use **OPA/Rego** via **Conftest** (or equivalent) to enforce â€œdefault denyâ€ rules.

<details>
<summary><strong>ğŸ“ Suggested policy pack layout</strong></summary>

```text
ğŸ“ api/scripts/policy/            # (canonical in v13 docs) OR mirror in tools/validation/policy/
â”œâ”€ ğŸ“„ README.md
â”œâ”€ ğŸ“ rego/
â”‚  â”œâ”€ ğŸ“ common/
â”‚  â”‚  â”œâ”€ ğŸ“„ helpers.rego
â”‚  â”‚  â”œâ”€ ğŸ“„ license_allowlist.rego
â”‚  â”‚  â””â”€ ğŸ“„ url_allowlist.rego
â”‚  â”œâ”€ ğŸ“ contracts/
â”‚  â”‚  â”œâ”€ ğŸ“„ contract_required.rego
â”‚  â”‚  â””â”€ ğŸ“„ classification_required.rego
â”‚  â”œâ”€ ğŸ“ catalogs/
â”‚  â”‚  â”œâ”€ ğŸ“„ stac_required.rego
â”‚  â”‚  â”œâ”€ ğŸ“„ dcat_required.rego
â”‚  â”‚  â”œâ”€ ğŸ“„ prov_required.rego
â”‚  â”‚  â””â”€ ğŸ“„ link_safety.rego
â”‚  â”œâ”€ ğŸ“ governance/
â”‚  â”‚  â”œâ”€ ğŸ“„ classification_propagation.rego
â”‚  â”‚  â”œâ”€ ğŸ“„ sensitive_locations.rego
â”‚  â”‚  â”œâ”€ ğŸ“„ cultural_protocols.rego
â”‚  â”‚  â””â”€ ğŸ“„ attribution.rego
â”‚  â”œâ”€ ğŸ“ supply_chain/
â”‚  â”‚  â”œâ”€ ğŸ“„ workflows_least_privilege.rego
â”‚  â”‚  â””â”€ ğŸ“„ actions_pinning.rego
â”‚  â””â”€ ğŸ“„ bundles.rego
â””â”€ ğŸ“ tests/
   â”œâ”€ ğŸ“„ *_test.rego
   â””â”€ ğŸ“ samples/
      â”œâ”€ ğŸ“ good/
      â””â”€ ğŸ“ bad/
```

</details>

Example Conftest call (shape only â€” adapt to your repo layout):

```bash
conftest test \
  --policy api/scripts/policy/rego \
  --all-namespaces \
  docs/data/contracts/ data/stac/ data/prov/ .github/workflows/
```

### ğŸ” Supply-chain controls (recommended for releases; optional for PRs)
- SBOM generation (SPDX/CycloneDX)
- Build provenance attestations (GitHub attestations / Sigstore-ish)
- Reproducibility lane compares rebuilt hashes
- Signed tags/releases (where feasible)

---

## ğŸš¨ Incident response expectations

KFM treats these as security incidents:
- secrets exposure
- sensitive location publication
- cultural protocol violation (unauthorized access/disclosure)
- catalog poisoning / unsafe remote fetch behavior
- retrieval poisoning that affects Focus Mode trust
- integrity tampering of published artifacts/offline packs
- unauthorized access to DB/storage/graph
- compromised CI runners or supply-chain breakage

### âœ… Minimum expectations (for maintainers)

- **Containment first**:
  - flip kill-switch
  - restrict access / revoke tokens
  - disable promotions (fail-closed)
  - pause offline pack distribution (if applicable)
- **Preserve evidence**:
  - keep logs, artifacts, provenance records (donâ€™t destroy audit trails)
- **Correct the catalogs/contracts**:
  - remove/disable affected STAC/DCAT entries
  - invalidate unsafe external links
  - correct misclassification and republish redacted outputs
- **Patch & validate**:
  - fix root cause
  - add regression tests + policy rules
  - rerun gates
- **Document**:
  - short incident note (private if needed)
  - public advisory if appropriate

---

## ğŸ—‚ï¸ Recommended repo security files

<details>
<summary><strong>ğŸ“ Suggested layout (v13-friendly)</strong></summary>

```text
ğŸ“¦ .github/
 â”œâ”€ ğŸ“„ dependabot.yml
 â”œâ”€ ğŸ“„ CODEOWNERS
 â”œâ”€ ğŸ“ workflows/
 â”‚  â”œâ”€ ğŸ“„ ci.yml
 â”‚  â”œâ”€ ğŸ“„ codeql.yml
 â”‚  â”œâ”€ ğŸ“„ contract-validate.yml
 â”‚  â”œâ”€ ğŸ“„ catalog-qa.yml
 â”‚  â”œâ”€ ğŸ“„ policy-gate.yml
 â”‚  â”œâ”€ ğŸ“„ sbom.yml
 â”‚  â””â”€ ğŸ“„ attest.yml

ğŸ“¦ docs/
 â”œâ”€ ğŸ“ architecture/
 â”‚  â”œâ”€ ğŸ“ adr/
 â”‚  â””â”€ ğŸ“„ KFM_REDESIGN_BLUEPRINT_v13.md
 â”œâ”€ ğŸ“ guides/
 â”‚  â””â”€ ğŸ“ governance/
 â”‚     â”œâ”€ ğŸ“„ faircare-oversight.md
 â”‚     â””â”€ ğŸ“„ cultural-protocols.md
 â”œâ”€ ğŸ“ security/
 â”‚  â”œâ”€ ğŸ“„ incident-response.md
 â”‚  â”œâ”€ ğŸ“„ secrets-policy.md
 â”‚  â”œâ”€ ğŸ“„ threat-model.md
 â”‚  â””â”€ ğŸ“„ pgp-public-key.asc
 â””â”€ ğŸ“ data/
    â””â”€ ğŸ“ contracts/
       â”œâ”€ ğŸ“ examples/
       â””â”€ ğŸ“„ schema.json

ğŸ“¦ api/
 â””â”€ ğŸ“ scripts/
    â””â”€ ğŸ“ policy/                   # policy pack (OPA/Rego + tests)

ğŸ“¦ tools/
 â””â”€ ğŸ“ validation/
    â”œâ”€ ğŸ“ contract_validate/
    â”œâ”€ ğŸ“ catalog_qa/
    â””â”€ ğŸ“ policy/                   # optional mirror (avoid drift)

ğŸ“¦ data/
 â”œâ”€ ğŸ“ raw/                         # immutable
 â”œâ”€ ğŸ“ work/
 â”œâ”€ ğŸ“ processed/
 â”œâ”€ ğŸ“ stac/
 â”‚  â”œâ”€ ğŸ“ collections/
 â”‚  â””â”€ ğŸ“ items/
 â”œâ”€ ğŸ“ prov/
 â”œâ”€ ğŸ“ catalogs/                    # OR ğŸ“ catalog/dcat/ (pick one)
 â””â”€ ğŸ“ graph/
    â””â”€ ğŸ“ csv/

ğŸ“¦ .kfm/
 â””â”€ ğŸ“„ kill-switch.yml
```

</details>

---

## ğŸ“š Project reference library

> [!NOTE]
> These project files inform KFMâ€™s defensive posture (governance, integrity, reproducibility, performance, privacy, and secure engineering).  
> They are **not** a request for offensive tooling contributions. ğŸš«ğŸ§¨

### ğŸ§­ Core KFM system documentation
- ğŸ“„ `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf`
- ğŸ“„ `Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf`
- ğŸ“„ `Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf`
- ğŸ“„ `Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf`
- ğŸ“„ `ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf`
- ğŸ“„ `ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals.docx.pdf`
- ğŸ“„ `Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf`

### ğŸ“¦ Reference bundles (PDF portfolios; multi-book)
- ğŸ“š `AI Concepts & more.pdf` *(digital humanism, accountability, AI governance framing)*
- ğŸ“š `Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf` *(data management + CI/CD + cryptography references)*
- ğŸ“š `Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf` *(GIS ethics + WebGL/3D + archaeology sensitivity)*
- ğŸ“š `Various programming langurages & resources 1.pdf` *(secure implementation references; defensive awareness)*

<details>
<summary><strong>ğŸ§  Why keep these bundles?</strong></summary>

They serve as a shared reference shelf for:
- threat modeling + secure engineering habits
- location privacy and cultural sensitivity
- data integrity, provenance, and reproducibility discipline
- secure UI and WebGL asset handling

</details>

---

## ğŸ§¾ Appendix: Checklists & templates

### âœ… PR checklist (maintainers & contributors)

- [ ] No secrets committed (checked)
- [ ] Contract JSON updated/added (if data changed)
- [ ] STAC/DCAT/PROV updated/added (if publishable artifact changed)
- [ ] Graph snapshot regenerated (if relevant) and derived from governed artifacts
- [ ] Classification + sensitive precision reviewed (if location data present)
- [ ] Cultural protocol tags reviewed (if applicable)
- [ ] Link safety (no unsafe remote hrefs)
- [ ] Tests + validation gates passing
- [ ] Story content is sanitized + cites evidence (if Story Nodes changed)
- [ ] Focus Mode prompts/rules unchanged or reviewed (if AI layer touched)
- [ ] Offline pack changes reviewed + signed/attested (if applicable)

### âœ… â€œReady to publishâ€ checklist (promotion lane)

- [ ] All CI gates passing (contract + catalogs + provenance + policy)
- [ ] SBOM generated (software)
- [ ] Attestation generated (build provenance)
- [ ] Dataset DBOM manifests present (data releases)
- [ ] Release notes include security + governance changes (if any)
- [ ] Kill switch verified OFF (or publish lane must block)

---

<!--
Maintainersâ€™ TODOs (keep this short and actionable):
- Replace security@YOUR-DOMAIN.example with a real monitored inbox.
- Add PGP key at ğŸ“ docs/security/ğŸ“„ pgp-public-key.asc and publish its fingerprint.
- Add incident-response runbook: containment, comms, logging, recovery, postmortem.
- Wire CI gates: CodeQL, dependency review, secret scanning, container scanning, contract validation, STAC/DCAT/PROV validation, policy-gate, story-lint.
- Keep OPA/Conftest policies tested (good/bad samples) and deny-by-default for promotion.
- Ensure kill switch is implemented and honored by all publish/sign workflows and agents.
-->