name: CI Â· Catalogs Validate

'on':
  pull_request:
    paths:
      - "data/stac/**"
      - "data/catalog/dcat/**"
      - "data/prov/**"
      - "schemas/**"
      - ".github/workflows/ci__catalogs_validate.yml"
  push:
    paths:
      - "data/stac/**"
      - "data/catalog/dcat/**"
      - "data/prov/**"
      - "schemas/**"
      - ".github/workflows/ci__catalogs_validate.yml"
  workflow_dispatch:

concurrency:
  group: catalogs-validate-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  validate-catalogs:
    name: Validate STAC / DCAT / PROV catalogs
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip
          cache-dependency-path: |
            requirements.txt
            requirements-dev.txt
            pyproject.toml
            setup.cfg

      - name: Install validation dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install \
            "pystac[validation]==1.10.1" \
            "rdflib==7.0.0" \
            "pyshacl==0.25.0" \
            "prov==2.0.0"

      - name: Validate STAC (STAC 1.0)
        run: |
          python - <<'PY'
          from __future__ import annotations

          import json
          import sys
          from pathlib import Path

          from pystac import StacIO
          from pystac.errors import STACError
          from pystac.validation import identify_stac_object, validate_all_dict, validate_dict

          STAC_DIR = Path("data/stac")

          if not STAC_DIR.exists():
              print("::notice::No 'data/stac' directory found; skipping STAC validation.")
              sys.exit(0)

          candidates = []
          for pat in ("*.json", "*.geojson"):
              candidates.extend(STAC_DIR.rglob(pat))

          stac_files = sorted({p for p in candidates if p.is_file()})
          if not stac_files:
              print("::notice::No JSON/GeoJSON files found under 'data/stac'; skipping STAC validation.")
              sys.exit(0)

          errors = 0
          validated = 0

          # 1) Validate every STAC-looking file (schema only; no link traversal)
          for path in stac_files:
              try:
                  obj = json.loads(path.read_text(encoding="utf-8"))
              except Exception as e:
                  print(f"::error file={path}::Invalid JSON: {e}")
                  errors += 1
                  continue

              if not isinstance(obj, dict) or "stac_version" not in obj:
                  # Not a STAC object (or not STAC-formatted); ignore.
                  continue

              try:
                  info = identify_stac_object(obj)
                  validate_dict(
                      stac_dict=obj,
                      stac_object_type=info.object_type,
                      stac_version=str(info.version_range.latest_valid_version()),
                      extensions=list(info.extensions),
                      href=path.resolve().as_uri(),
                  )
                  validated += 1
              except Exception as e:
                  print(f"::error file={path}::STAC schema validation failed: {e}")
                  errors += 1

          print(f"STAC schema validation: {validated} STAC object(s) validated across {len(stac_files)} JSON/GeoJSON file(s).")

          # 2) Validate link integrity by traversing from one or more roots
          roots: list[Path] = []

          # Prefer an explicit root catalog if present
          if (STAC_DIR / "catalog.json").exists():
              roots = [STAC_DIR / "catalog.json"]
          else:
              # Common KFM layout: data/stac/collections/*/collection.json
              collections_dir = STAC_DIR / "collections"
              if collections_dir.exists():
                  roots = sorted(collections_dir.rglob("collection.json"))

              # Fallback: any catalog.json / collection.json under data/stac
              if not roots:
                  roots = sorted(STAC_DIR.rglob("catalog.json")) + sorted(STAC_DIR.rglob("collection.json"))

          roots = sorted({p.resolve() for p in roots})

          if roots:
              io = StacIO.default()
              if len(roots) > 50:
                  print(f"::notice::Found {len(roots)} potential STAC roots; validating first 50 to keep CI bounded.")
                  roots = roots[:50]

              for root in roots:
                  href = root.resolve().as_uri()
                  print(f"Validating STAC tree from root: {root}")
                  try:
                      stac_dict = io.read_json(href)
                      validate_all_dict(stac_dict=stac_dict, href=href, stac_io=io)
                  except Exception as e:
                      print(f"::error file={root}::STAC tree validation failed: {e}")
                      errors += 1
          else:
              print(
                  "::notice::No STAC root found (e.g., data/stac/catalog.json or collections/*/collection.json). "
                  "Skipping recursive link validation."
              )

          if errors:
              print(f"STAC validation failed with {errors} error(s).")
              sys.exit(1)

          print("STAC validation passed.")
          PY

      - name: Validate DCAT (DCAT 3)
        run: |
          python - <<'PY'
          from __future__ import annotations

          import sys
          from pathlib import Path

          from rdflib import Graph

          try:
              from pyshacl import validate as shacl_validate
          except Exception:
              shacl_validate = None

          DCAT_DIR = Path("data/catalog/dcat")
          SCHEMAS_DIR = Path("schemas")

          if not DCAT_DIR.exists():
              print("::notice::No 'data/catalog/dcat' directory found; skipping DCAT validation.")
              sys.exit(0)

          # Common RDF serializations for DCAT outputs
          exts = {".ttl", ".rdf", ".xml", ".jsonld", ".json", ".nt", ".n3", ".trig"}
          files = sorted({p for p in DCAT_DIR.rglob("*") if p.is_file() and p.suffix.lower() in exts})

          if not files:
              print("::notice::No DCAT RDF/JSON-LD files found under 'data/catalog/dcat'; skipping DCAT validation.")
              sys.exit(0)

          # Optional SHACL shapes (repo-dependent). If none found, we still parse to ensure RDF validity.
          shape_candidates: list[Path] = [
              Path("schemas/dcat/shapes.ttl"),
              Path("schemas/dcat/dcat3_shapes.ttl"),
              Path("schemas/dcat/dcat3_shacl.ttl"),
              Path("schemas/dcat/dcat.shacl.ttl"),
              Path("schemas/dcat/dcat_shapes.ttl"),
          ]

          if Path("schemas/dcat").exists():
              for p in Path("schemas/dcat").rglob("*.ttl"):
                  name = p.name.lower()
                  if "shape" in name or "shacl" in name:
                      shape_candidates.append(p)

          shape_path = next((p for p in shape_candidates if p.exists()), None)
          shapes_graph = None
          if shape_path is not None and shacl_validate is not None:
              shapes_graph = Graph()
              shapes_graph.parse(shape_path.as_posix(), format="turtle")
              print(f"Using SHACL shapes: {shape_path}")
          elif shape_path is not None and shacl_validate is None:
              print(f"::notice::Found DCAT SHACL shapes at {shape_path}, but pyshacl is unavailable; skipping SHACL validation.")
          else:
              print("::notice::No DCAT SHACL shapes found under 'schemas/dcat'; running parse-only validation.")

          def parse_graph(path: Path) -> Graph:
              g = Graph()
              ext = path.suffix.lower()
              fmt = None
              if ext == ".ttl":
                  fmt = "turtle"
              elif ext in {".rdf", ".xml"}:
                  fmt = "xml"
              elif ext in {".jsonld", ".json"}:
                  fmt = "json-ld"
              elif ext == ".nt":
                  fmt = "nt"
              elif ext == ".n3":
                  fmt = "n3"
              elif ext == ".trig":
                  fmt = "trig"

              # rdflib can often guess, but we set formats explicitly for the common ones.
              if fmt is not None:
                  g.parse(path.as_posix(), format=fmt)
              else:
                  g.parse(path.as_posix())
              return g

          errors = 0
          for f in files:
              try:
                  data_graph = parse_graph(f)
                  triple_count = len(data_graph)
                  print(f"Parsed DCAT file: {f} ({triple_count} triple(s))")

                  if shapes_graph is not None and shacl_validate is not None:
                      conforms, report_graph, report_text = shacl_validate(
                          data_graph,
                          shacl_graph=shapes_graph,
                          inference="rdfs",
                          abort_on_first=False,
                          allow_infos=True,
                          allow_warnings=True,
                      )
                      if not conforms:
                          print(f"::error file={f}::DCAT SHACL validation failed")
                          # Keep report reasonably sized in logs
                          print(report_text[:8000])
                          errors += 1
              except Exception as e:
                  print(f"::error file={f}::DCAT parse/validation failed: {e}")
                  errors += 1

          if errors:
              print(f"DCAT validation failed with {errors} error(s).")
              sys.exit(1)

          print("DCAT validation passed.")
          PY

      - name: Validate PROV (W3C PROV)
        run: |
          python - <<'PY'
          from __future__ import annotations

          import sys
          from pathlib import Path

          from prov.model import ProvDocument
          from rdflib import Graph

          PROV_DIR = Path("data/prov")

          if not PROV_DIR.exists():
              print("::notice::No 'data/prov' directory found; skipping PROV validation.")
              sys.exit(0)

          files = sorted({p for p in PROV_DIR.rglob("*") if p.is_file()})
          if not files:
              print("::notice::No files found under 'data/prov'; skipping PROV validation.")
              sys.exit(0)

          errors = 0
          validated = 0

          for f in files:
              ext = f.suffix.lower()
              try:
                  if ext == ".json":
                      # Expecting PROV-JSON
                      ProvDocument.deserialize(f.as_posix(), format="json")
                      validated += 1
                  elif ext in {".provn", ".pn", ".prov"}:
                      ProvDocument.deserialize(f.as_posix(), format="provn")
                      validated += 1
                  elif ext in {".xml", ".provxml"}:
                      ProvDocument.deserialize(f.as_posix(), format="xml")
                      validated += 1
                  elif ext in {".ttl", ".rdf", ".n3", ".trig", ".nt", ".jsonld"}:
                      # PROV-O (RDF serializations)
                      g = Graph()
                      fmt = None
                      if ext == ".ttl":
                          fmt = "turtle"
                      elif ext in {".rdf", ".xml"}:
                          fmt = "xml"
                      elif ext == ".nt":
                          fmt = "nt"
                      elif ext == ".n3":
                          fmt = "n3"
                      elif ext == ".trig":
                          fmt = "trig"
                      elif ext == ".jsonld":
                          fmt = "json-ld"
                      if fmt is not None:
                          g.parse(f.as_posix(), format=fmt)
                      else:
                          g.parse(f.as_posix())
                      validated += 1
                  else:
                      # Unknown/irrelevant file type for PROV validation
                      continue
              except Exception as e:
                  print(f"::error file={f}::PROV parse/validation failed: {e}")
                  errors += 1

          print(f"PROV validation: {validated} file(s) parsed successfully.")

          if errors:
              print(f"PROV validation failed with {errors} error(s).")
              sys.exit(1)

          print("PROV validation passed.")
          PY

