<div align="center">

# âš™ï¸ GitHub Workflows (CI/CD)

**KFMâ€™s automated â€œtrust pipelineâ€ â€” policy-governed, provenance-first, and merge-safe.**  
`./.github/workflows/*`

<p>
  <a href="../../README.md"><img alt="Repo README" src="https://img.shields.io/badge/README-Repo-0b7285?style=for-the-badge"></a>
  <a href="../README.md"><img alt=".github README" src="https://img.shields.io/badge/.github-Docs-7950f2?style=for-the-badge"></a>
  <a href="../actions/README.md"><img alt="Actions README" src="https://img.shields.io/badge/Actions-Composite%20Blocks-0ca678?style=for-the-badge"></a>
  <a href="../ISSUE_TEMPLATE/README.md"><img alt="Issue templates README" src="https://img.shields.io/badge/Issue%20Templates-Intake%20Forms-f08c00?style=for-the-badge"></a>
</p>

<p>
  <img alt="CI/CD" src="https://img.shields.io/badge/CI%2FCD-GitHub%20Actions-2088FF?logo=githubactions&logoColor=white&style=for-the-badge">
  <img alt="Policy as Code" src="https://img.shields.io/badge/Policy%20as%20Code-OPA%20%2F%20Rego-0b7285?style=for-the-badge">
  <img alt="Provenance" src="https://img.shields.io/badge/Provenance-PROV%20%2B%20SBOM-f08c00?style=for-the-badge">
  <img alt="Default Deny" src="https://img.shields.io/badge/Default-Deny%20%28Fail%20Closed%29-d6336c?style=for-the-badge">
</p>

</div>

---

## ğŸ§­ Quick index

- [ğŸ¯ Purpose](#-purpose)
- [ğŸ—ºï¸ KFM invariants enforced by CI](#ï¸-kfm-invariants-enforced-by-ci)
- [ğŸ§­ Folder map](#-folder-map)
- [ğŸ§¬ Canonical â€œtruth pathâ€](#-canonical-truth-path-pr--merge)
- [ğŸ§© Workflow inventory](#-workflow-inventory-recommended)
- [ğŸ§  Change-aware gating](#-change-aware-gating-scope--risk)
- [ğŸ›¡ï¸ Policy as Code](#ï¸-policy-as-code-oparego)
- [ğŸ—‚ï¸ Metadata + schema validation](#ï¸-metadata--schema-validation-geo--catalog)
- [ğŸ§¾ Provenance](#-provenance-guardrails)
- [ğŸ“¦ Supply-chain defaults](#-supply-chain-defaults-sbom-attestations)
- [ğŸ¤– AI / agentic workflows](#-ai--agentic-workflows-llms-rag-tools)
- [ğŸ“ˆ Performance + observability](#-performance--observability)
- [ğŸ§ª Local debugging](#-local-debugging-tips-fast-iteration)
- [ğŸ§¯ When CI fails](#-when-ci-fails-how-to-fix-fast)
- [ğŸ“š Project reference library](#-project-reference-library)

---

## ğŸ¯ Purpose

This folder defines **GitHub Actions workflows** that keep Kansas Frontier Matrix (KFM) contributions:

- âœ… **reproducible** (consistent builds & deterministic checks),
- ğŸ§¾ **traceable** (metadata + provenance expectations),
- ğŸ›¡ï¸ **governed** (policy as code + safety rails),
- ğŸš¦ **merge-safe** (fail-closed gates).

> [!IMPORTANT]
> KFM is designed to **fail closed**: if policy/permission/provenance is uncertain, the system blocks the change rather than letting it slip through.[^fail_closed][^validation_gates]

---

## ğŸ—ºï¸ KFM invariants enforced by CI

Workflows here exist to protect *architectural invariants* (not just â€œlint + testsâ€):

### 1) ğŸ§± Canonical pipeline order (no shortcuts)
KFM treats the data path as non-negotiable: **ETL â†’ catalog/provenance â†’ databases/graph â†’ API â†’ UI/stories/AI**.[^pipeline_order]

### 2) ğŸ§­ Layer boundaries are enforced (UI never touches DB)
The UI should not directly access database layers; all access is mediated via governed backend APIs.[^ui_boundary]

### 3) ğŸ§¾ Provenance is not optional
If new artifacts are introduced, provenance logs must exist. Example from the blueprint: if an output file exists but the corresponding provenance entry is missing, CI fails.[^validation_gates]

### 4) ğŸ›¡ï¸ Policy is versioned + machine enforced
Governance is policy-as-code: rules live in Git, are tested, and gate merges through CI (OPA/Rego via tools like Conftest). Policies are versioned for auditability.[^policy_as_code]

### 5) ğŸŒ FAIR + CARE are enforced at the gate
If contributions donâ€™t meet baseline documentation/metadata expectations (FAIR/CARE alignment), they donâ€™t enter the system.[^fair_care]

---

## ğŸ§­ Folder map

```text
.github/workflows/
â”œâ”€ â™»ï¸ reusables/            # reusable workflow_call building blocks
â”œâ”€ ğŸš¦ *.yml                 # entrypoint workflows (PR, release, schedule, manual)
â””â”€ ğŸ“˜ README.md             # you are here
```

### ğŸ”— Related building blocks (outside this folder)

```text
.github/
â”œâ”€ ğŸ§© actions/              # composite actions (reused across workflows)
â”œâ”€ ğŸ§¾ ISSUE_TEMPLATE/       # governance + intake forms
â””â”€ ğŸ›¡ï¸ CODEOWNERS            # reviewers for sensitive paths (policy, schemas, etc.)
```

> [!TIP]
> Prefer **reusable workflows** for job graphs and **composite actions** for step bundles.
> That keeps governance centralized and reduces â€œcopy/paste driftâ€.

---

## â™»ï¸ What counts as a â€œreusable workflowâ€?

Reusable workflows live under `reusables/` and are called from entry workflows via `workflow_call`.

Think of them as **macro building blocks**:
- `pr-validate.yml` â†’ the â€œtrust pathâ€
- `policy-gate.yml` â†’ allow/deny decisions
- `metadata-validate.yml` â†’ schema + catalog checks
- `docker-build.yml` â†’ image build + artifact upload

---

## ğŸ§¬ Canonical truth path (PR â†’ merge)

```mermaid
flowchart TD
  PR["ğŸ”€ Pull Request"] --> CI["ğŸš¦ Entrypoint Workflow(s)"]
  CI --> LINT["ğŸ§¹ Lint/Format"]
  CI --> TEST["ğŸ§ª Unit/Integration Tests"]
  CI --> META["ğŸ—‚ï¸ Metadata Validate"]
  CI --> PROV["ğŸ§¾ Provenance Guard"]
  CI --> POL["ğŸ›¡ï¸ Policy Gate (OPA/Rego)"]
  CI --> SBOM["ğŸ“¦ SBOM / Attestation (as needed)"]
  LINT --> PASS["âœ… Required checks green"]
  TEST --> PASS
  META --> PASS
  PROV --> PASS
  POL --> PASS
  SBOM --> PASS
  PASS --> MERGE["ğŸ‰ Merge Allowed"]
```

This mirrors KFMâ€™s pipeline philosophy: **data + stories must follow a governed pipeline**, and CI is the automated enforcement layer.[^pipeline_order][^validation_gates]

---

## ğŸ§  Change-aware gating (scope + risk)

To keep PR feedback fast **and** keep governance strict, workflows should be path-aware:

### âœ… Suggested change classes (pattern)

- ğŸ“ **Docs-only** (`docs/**`, `README.md`)  
  â†’ Markdown lint + link check (fast)

- ğŸ—ºï¸ **Story changes** (`stories/**`, `narratives/**`)  
  â†’ story schema + citation hygiene + link check + policy gate for claims[^stories]

- ğŸ—‚ï¸ **Metadata/catalog changes** (`catalog/**`, `metadata/**`, `schemas/**`)  
  â†’ JSON schema validation + STAC/DCAT checks + policy gate[^metadata_standards]

- ğŸ§¾ **Data outputs** (`data/processed/**`, `exports/**`)  
  â†’ provenance required + metadata required + (optional) QA regression[^validation_gates]

- ğŸ›¡ï¸ **Governance/policy** (`policy/**`, `.github/**`, `schemas/**`)  
  â†’ conftest/OPA tests + CODEOWNER review + â€œno bypassâ€ checks[^policy_as_code]

> [!IMPORTANT]
> â€œFast pathâ€ â‰  â€œunguarded pathâ€. Even doc-only PRs should still fail closed on unsafe or forbidden patterns
> (e.g., secrets, malware artifacts, policy violations).

---

## ğŸ§© Workflow inventory (recommended)

> [!NOTE]
> Filenames can evolve â€” what matters is the **intent taxonomy** staying stable.

### ğŸ”€ PR workflows
- `pr-validate.yml` â†’ standard trust path: lint + tests + metadata + provenance + policy
- `pr-docs.yml` â†’ docs-only optimizations (still guarded)
- `pr-policy.yml` â†’ stricter, policy-only checks (Rego test matrix)

### ğŸ§· Release workflows
- `release.yml` â†’ build/publish containers + generate SBOM + attestations
- `tag.yml` â†’ version stamping, changelog automation, provenance snapshot

### ğŸ•°ï¸ Scheduled workflows
- `nightly-governance.yml` â†’ policy regression suite, dependency hygiene
- `nightly-catalog-qa.yml` â†’ metadata drift, link rot, schema drift

### ğŸ§‘â€âœˆï¸ Manual workflows
- `rebuild-catalog.yml` â†’ on-demand catalog/index rebuild
- `full-validation.yml` â†’ heavyweight suite (slow, but definitive)

---

## ğŸ§© How workflows relate to composite actions

Most jobs should be assembled from **composite actions** in:

- `../actions/` â†’ see **`.github/actions/README.md`** for details.

Common action blocks (by intent) include:

- ğŸ§ª `setup-conftest/` â†’ policy testing setup
- ğŸ›¡ï¸ `policy-gate/` â†’ allow/deny enforcement
- ğŸ§¾ `provenance-guard/` + `pr-provenance/` â†’ provenance completeness checks
- ğŸ—‚ï¸ `metadata-validate/` â†’ metadata schema checks (dataset cards, STAC/DCAT, etc.)
- ğŸ—ºï¸ `story-lint/` â†’ story node format + citation hygiene
- ğŸ§° `setup-kfm/` â†’ repo toolchain bootstrap
- ğŸ§± `docker-build/` â†’ build container images
- ğŸ§¾ `sbom/` + âœ… `attest/` â†’ supply-chain artifacts (SBOM/attestation)

> [!TIP]
> Treat composite actions as **audited primitives**. If you need a new step bundle, prefer adding a new
> composite action rather than sprinkling shell scripts across multiple workflows.

---

## ğŸ›¡ï¸ Policy as Code (OPA/Rego)

KFM governance is designed to run as policy checks in CI and runtime enforcement in the stack.[^policy_as_code]

### âœ… CI responsibilities
- run policy tests on PRs (fail closed),
- verify policy bundles compile,
- verify â€œdenyâ€ decisions include actionable messages,
- verify required reviewers on policy/schema changes (CODEOWNERS),
- verify no bypass routes are introduced.

### ğŸŒ Policy layering (global vs local)
DataSpaces research emphasizes **global** and **local** policies in a â€œtrust integrated dataspaceâ€ model.[^dataspaces]
In KFM CI, mirror that idea with layered enforcement:

- ğŸŒ **Global policies** â†’ org/repo-wide constraints (licensing, security, provenance, minimum metadata)
- ğŸ§© **Local policies** â†’ domain rules (dataset type rules, story node schemas, API contract rules)

> [!NOTE]
> When policies conflict, default to **deny** and force explicit governance discussion.[^fail_closed]

---

## ğŸ—‚ï¸ Metadata + schema validation (geo + catalog)

KFM treats metadata as a first-class CI concern: new datasets should not enter without documentation and structure.[^validation_gates]

### âœ… What â€œgood metadataâ€ means in practice
Map/geo design guidance highlights metadata categories commonly required for map products and datasets:
identification, quality, spatial reference, distribution, citation/reference, temporal reference, and contact.[^metadata_standards]

### Recommended checks
- JSON/YAML schema validation for dataset cards and story nodes
- STAC validation where relevant
- CRS/EPSG presence and projection sanity checks for geodata
- link checks + citation presence checks (for narratives)

> [!TIP]
> Add a â€œschema test corpusâ€ folder (tiny fixtures) so schema changes are validated in CI
> without needing full datasets.

---

## ğŸ§¾ Provenance guardrails

Provenance must be present wherever â€œprocessed outputsâ€ exist.[^validation_gates]

### Minimum expectations (pattern)
- Each produced artifact has:
  - source references
  - transformation summary
  - tool versions / parameters
  - timestamp + contributor identity (where appropriate)
- The provenance check runs on PRs that introduce/modify outputs.

> [!IMPORTANT]
> The blueprint gives a concrete example: if an output exists but a corresponding provenance entry is missing, CI fails.[^validation_gates]

---

## ğŸ“¦ Supply-chain defaults (SBOM, attestations)

Recommended baseline:
- ğŸ”’ Pin third-party actions by SHA
- ğŸ§¾ Generate SBOM for releases (and optionally PR builds)
- âœ… Use attestations for release artifacts (containers/binaries)
- ğŸ§¯ Keep a kill-switch path to prevent publication when governance flags trigger

These defaults align with KFMâ€™s â€œauditable & governed operationsâ€ stance.[^fail_closed]

---

## ğŸ¤– AI / agentic workflows (LLMs, RAG, tools)

KFMâ€™s blueprint anticipates agentic, tool-using models (multi-step reasoning) operating via **safe backend tool APIs**.[^agentic_tools]

### When to trigger â€œAI gatesâ€
If a PR touches:
- `ai/**`, `prompts/**`, `rag/**`, `embeddings/**`, `models/**`
- or any â€œtool surfaceâ€ exposed to an agent (search/query endpoints)

Then require:
- ğŸ“„ model card + license check
- ğŸ” prompt/policy lint (no disallowed tool calls)
- ğŸ§ª eval harness smoke tests (golden queries)
- ğŸ›¡ï¸ policy gate (what tools can be invoked; what data can be accessed)

### Local model workflows (Ollama)
Ollama supports pulling/running models via CLI (`ollama pull <model>` / `ollama run <model>`), and positions itself as a â€œDocker-likeâ€ local model manager.[^ollama]

> [!TIP]
> Use CI to validate *configuration* (model cards, tool permission policy, eval baselines) â€” not to run heavy GPU inference by default.

---

## ğŸ“ˆ Performance + observability

CI isnâ€™t just correctness â€” itâ€™s also keeping KFM shippable under real conditions.

A database performance reference used in this project emphasizes:
- â€œAlways expect spikesâ€ (hardware failures, surprise load)
- â€œObservability is key in distributed systemsâ€ (investigate failures + real-time alerts)[^observability]

### Recommended CI patterns
- ğŸ•°ï¸ Nightly â€œperformance budgetâ€ runs (timeboxed)
- ğŸ“Š Query plan regression checks (when applicable)
- ğŸ§¯ â€œBackups + recoveryâ€ runbooks verified as docs/tests (where relevant)

---

## ğŸ§ª Local debugging tips (fast iteration)

### Option A) Re-run jobs in GitHub UI
- Use â€œRe-run jobsâ€ for failed runs.
- Add debug logs using `ACTIONS_STEP_DEBUG` (repo/org setting) when needed.

### Option B) Use `act` locally (best-effort parity)
You can dry-run many workflows locally with `act`.  
Itâ€™s not perfect parity, but great for speeding up iteration on bash steps and composite actions.

```bash
# list workflows / jobs
act -l

# run a pull_request workflow (example)
act pull_request

# run a specific job
act -j <job_id>
```

> [!CAUTION]
> OIDC, protected secrets, and some marketplace integrations wonâ€™t behave the same locally.
> Treat `act` as a developer convenience, not a source of truth.

### Option C) Run gates directly
Typical fast loops (examples; use the repoâ€™s real scripts):

```bash
# policy unit tests
conftest test policy/ -p policy/

# schema checks
python -m pytest tests/schema/

# story lint
python -m pytest tests/stories/
```

---

## ğŸ§¯ When CI fails (how to fix fast)

### Common failure causes
- Missing dataset metadata / license fields
- Missing provenance artifacts for new processed outputs
- Story nodes missing citations or template fields
- Governance policy violation (OPA/Rego / Conftest)
- Broken links or schema drift

### How to respond
1. Read the failing job summary (it should tell you *what invariant you broke*).
2. Fix the underlying data/doc issue (not just the symptom).
3. Re-run only the necessary jobs.
4. If CI policy seems wrong, open a governance issue using the appropriate template:
   - `governance_form.yml`
   - `governance_question.yml`

---

## ğŸ“š Project reference library

> [!NOTE]
> These project files inform **what CI enforces** (governance invariants, metadata expectations, data quality, and operational safety).

<details>
<summary><strong>ğŸ“¦ Core architecture + governance</strong></summary>

- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint** :contentReference[oaicite:0]{index=0}  
  Canonical pipeline order, fail-closed governance, policy enforcement patterns, provenance expectations.[^pipeline_order][^fail_closed][^policy_as_code][^validation_gates]

- **Data Spaces** :contentReference[oaicite:1]{index=1}  
  Trust-integrated dataspace concepts; global vs local policy layering.[^dataspaces]

</details>

<details>
<summary><strong>ğŸ—‚ï¸ Metadata, mapping, time-series, and storytelling UX</strong></summary>

- **Making Maps: A Visual Guide to Map Design for GIS** :contentReference[oaicite:2]{index=2}  
  Practical metadata categories and map product considerations.[^metadata_standards]

- **Visualization of Time-Oriented Data** :contentReference[oaicite:3]{index=3}  
  Interaction vocabulary for time-series exploration (navigation, brushing/linking, dynamic queries).[^time_viz]

- **Cloud-Based Remote Sensing with Google Earth Engine (Fundamentals & Applications)** :contentReference[oaicite:4]{index=4}  
  Multi-temporal data handling patterns and time-series property expectations (`system:time_start`).[^gee_timeseries]

</details>

<details>
<summary><strong>ğŸ§ª Reproducibility, QA, and performance</strong></summary>

- **Scientific Method / Research / Master Coder Protocol Documentation** :contentReference[oaicite:5]{index=5}  
  Emphasizes documenting ETL stages and pipelines (inputs/outputs/versions).[^pipeline_docs]

- **Understanding Statistics & Experimental Design** :contentReference[oaicite:6]{index=6}  
  Highlights how multiple testing inflates false alarms â€” relevant for rigorous evaluation pipelines.[^stats_multiple_testing]

- **Database Performance at Scale** :contentReference[oaicite:7]{index=7}  
  Reinforces observability and planning for spikes â€” informs performance/ops checks.[^observability]

</details>

<details>
<summary><strong>ğŸ¤– Local LLM operations</strong></summary>

- **Comprehensive Guide to Ollama and Its Supported Open-Source LLMs** :contentReference[oaicite:8]{index=8}  
  CLI usage (`ollama pull/run`) and â€œDocker-likeâ€ local model management; used for AI workflow conventions.[^ollama]

</details>

---

## ğŸ§¾ Sources

[^pipeline_order]: KFM treats the pipeline order as a core invariant (ETL â†’ catalog/provenance â†’ DB/graph â†’ API â†’ UI/stories/AI).:contentReference[oaicite:9]{index=9}

[^ui_boundary]: UI should not directly touch database layers; access is mediated via backend APIs (separation of concerns).:contentReference[oaicite:10]{index=10}

[^fail_closed]: KFM governance principle: â€œfail closed / default denyâ€ â€” when uncertain, deny/stop rather than allow changes through CI gates.:contentReference[oaicite:11]{index=11}

[^fair_care]: The blueprint frames FAIR + CARE alignment as baseline expectations for data entering the system (â€œif not met, data doesnâ€™t enterâ€).:contentReference[oaicite:12]{index=12}

[^policy_as_code]: Governance is policy-as-code (OPA/Rego); policies are versioned for audit, executed by OPA, and logs can include decision id + policy version + input hash for traceability.:contentReference[oaicite:13]{index=13}

[^validation_gates]: CI is treated as a validation gate; example given where missing provenance entries cause CI failure. Also, processed datasets require metadata/provenance to pass ingestion checks.:contentReference[oaicite:14]{index=14}:contentReference[oaicite:15]{index=15}

[^stories]: Story nodes include metadata and sources/citations (narratives as structured, governed artifacts).:contentReference[oaicite:16]{index=16}

[^dataspaces]: DataSpaces emphasizes trust-integrated dataspaces with policy enforcement and discusses global vs local policies in the same ecosystem.:contentReference[oaicite:17]{index=17}

[^metadata_standards]: Map design guidance highlights common metadata categories (identification, quality, spatial reference, distribution, citation/reference, temporal reference, contact).:contentReference[oaicite:18]{index=18}

[^time_viz]: Time-series visualization interaction vocabulary includes navigating in time, brushing & linking, and dynamic queries as foundational capabilities to support.:contentReference[oaicite:19]{index=19}

[^gee_timeseries]: Earth Engine time-series handling often relies on temporal properties like `system:time_start` and supports interactive time-series plots/series evaluation patterns.:contentReference[oaicite:20]{index=20}

[^pipeline_docs]: Research protocol guidance calls for documenting ETL pipeline stages, inputs/outputs, and implementation details for reproducibility.:contentReference[oaicite:21]{index=21}

[^stats_multiple_testing]: Multiple comparisons inflate the probability of false alarms (Type I errors), motivating rigorous evaluation practices and corrections where applicable.:contentReference[oaicite:22]{index=22}

[^observability]: Performance guidance emphasizes expecting spikes and treating observability as key in distributed systems (for investigating failures and real-time alerts).:contentReference[oaicite:23]{index=23}

[^ollama]: Ollama supports pulling/running models via CLI (`ollama pull`, `ollama run`) and describes a â€œDocker-likeâ€ model management approach for local LLMs.:contentReference[oaicite:24]{index=24}:contentReference[oaicite:25]{index=25}

[^agentic_tools]: The blueprint describes an agentic approach where models can use a controlled tool surface via backend APIs; it also notes agent-capable models (e.g., Qwen-3 / GPT-OSS) can run locally via Ollama.:contentReference[oaicite:26]{index=26}
