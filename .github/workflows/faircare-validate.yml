# üî∂ Kansas Frontier Matrix ‚Äî FAIR+CARE Validation Workflow
# File: .github/workflows/faircare-validate.yml
# Purpose: Enforce FAIR (Findable, Accessible, Interoperable, Reusable) + CARE (Collective Benefit,
#          Authority to Control, Responsibility, Ethics) compliance for datasets and metadata.
# Governance: Master Coder Protocol (MCP v6.3) ¬∑ FAIR+CARE ¬∑ Diamond‚Åπ Œ© / Crown‚àûŒ©

name: FAIR+CARE Validate

on:
  workflow_dispatch:
  push:
    paths:
      - "data/**"
      - "schemas/**"
      - "tools/validate_data.py"
      - ".github/workflows/faircare-validate.yml"
  pull_request:
    paths:
      - "data/**"
      - "schemas/**"
      - "tools/validate_data.py"
      - ".github/workflows/faircare-validate.yml"

permissions:
  contents: read
  actions: read
  checks: write

concurrency:
  group: faircare-validate-${{ github.ref }}
  cancel-in-progress: true

env:
  PYTHON_VERSION: "3.11"
  SOURCES_DIR: "data/sources"
  PROCESSED_DIR: "data/processed"
  REPORT_DIR: "reports/fair"
  GOVERNANCE_LEDGER: "reports/audit/github-workflows-ledger.json"

jobs:
  faircare:
    name: Validate FAIR+CARE (manifests, licenses, provenance)
    runs-on: ubuntu-latest

    steps:
      - name: ‚¨áÔ∏è Checkout
        uses: actions/checkout@v4

      - name: üêç Setup Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: "pip"

      - name: üì¶ Install validation toolchain
        run: |
          python -m pip install --upgrade pip
          pip install jsonschema pydantic rfc3986 ruamel.yaml click jinja2

      - name: üóÇ Ensure report directories
        run: |
          mkdir -p "${REPORT_DIR}"
          mkdir -p "$(dirname "${GOVERNANCE_LEDGER}")"
          echo "SOURCES_DIR=${SOURCES_DIR}"
          echo "PROCESSED_DIR=${PROCESSED_DIR}"
          echo "REPORT_DIR=${REPORT_DIR}"

      - name: üîé Discover dataset manifests
        id: discover
        shell: bash
        run: |
          shopt -s nullglob
          mapfile -t files < <(find "${SOURCES_DIR}" -type f -name "*.json" | sort)
          echo "found=${#files[@]}" >> "$GITHUB_OUTPUT"
          printf "%s\n" "${files[@]}" > "${REPORT_DIR}/source_manifests.txt"
          echo "Discovered ${#files[@]} manifest(s)."

      - name: üß™ FAIR+CARE checks (inline)
        if: steps.discover.outputs.found != '0'
        shell: bash
        run: |
          set -euo pipefail
          python - << 'PY'
import os, json, re, glob, hashlib, sys, datetime
from pathlib import Path

SOURCES_DIR = os.environ["SOURCES_DIR"]
REPORT_DIR  = os.environ["REPORT_DIR"]

# Allowed license identifiers (expand as needed)
LICENSE_ALLOWLIST = {
    "MIT", "CC-BY-4.0", "CC0-1.0", "ODbL-1.0", "Public Domain", "US Government Works", "U.S. Government Works"
}

# Simple keyword heuristic to require CARE annotation
CARE_KEYWORDS = [
    "indigenous","tribe","tribal","treaty","reservation","first nations","native","aboriginal","affiliated tribes"
]

# Minimal required fields for FAIR metadata
REQUIRED_FIELDS = ["id","title","description","type","license","provenance","checksum","updated"]
REQUIRED_SPATIAL = "spatial"
REQUIRED_TEMPORAL = "temporal"  # expect {start,end}

def is_sha256(value: str) -> bool:
    if not isinstance(value,str): return False
    return bool(re.fullmatch(r"sha256-[A-Fa-f0-9]{64}", value) or re.fullmatch(r"[A-Fa-f0-9]{64}", value))

def load_json(p: Path):
    with p.open("r", encoding="utf-8") as f:
        return json.load(f)

def needs_care(m: dict) -> bool:
    text = " ".join([
        json.dumps(m, ensure_ascii=False).lower()
    ])
    return any(k in text for k in CARE_KEYWORDS)

results = []
fails = 0
passes = 0

manifests = sorted(Path(SOURCES_DIR).rglob("*.json"))
for mf in manifests:
    status = {"path": str(mf), "ok": True, "errors": [], "warnings": [], "care": {"required": False, "present": False}}
    try:
        data = load_json(mf)
    except Exception as e:
        status["ok"] = False
        status["errors"].append(f"Invalid JSON: {e}")
        results.append(status)
        fails += 1
        continue

    # Required fields
    for f in REQUIRED_FIELDS:
        if f not in data or (isinstance(data[f], str) and not data[f].strip()):
            status["ok"] = False
            status["errors"].append(f"Missing required field: {f}")

    # Spatial / Temporal
    if REQUIRED_SPATIAL not in data:
        status["ok"] = False
        status["errors"].append("Missing spatial (bbox or extent).")
    if REQUIRED_TEMPORAL not in data or not isinstance(data["temporal"], dict) or "start" not in data["temporal"]:
        status["ok"] = False
        status["errors"].append("Missing temporal (start/end).")

    # License check
    lic = data.get("license","").strip()
    if lic not in LICENSE_ALLOWLIST:
        # Allow SPDX-like strings but warn
        if not lic:
            status["ok"] = False
            status["errors"].append("License is missing.")
        else:
            status["warnings"].append(f"License '{lic}' not in allowlist; ensure SPDX-compatible identifier.")

    # Provenance present
    if not str(data.get("provenance","")).strip():
        status["ok"] = False
        status["errors"].append("Provenance is missing (source/URL/agency).")

    # Checksum format
    chk = str(data.get("checksum","")).strip()
    if not is_sha256(chk):
        status["ok"] = False
        status["errors"].append("Checksum must be SHA-256 (hex or 'sha256-<hex>').")

    # CARE detection
    care_req = needs_care(data)
    status["care"]["required"] = care_req
    care_block = data.get("care", {})
    if care_req:
        # Expect care annotations when keywords detected
        if not isinstance(care_block, dict) or not care_block.get("statement"):
            status["ok"] = False
            status["errors"].append("CARE required: add `care.statement` and relevant annotations.")
        else:
            status["care"]["present"] = True

    if status["ok"]:
        passes += 1
    else:
        fails += 1
    results.append(status)

# Write ndjson + summary
Path(REPORT_DIR).mkdir(parents=True, exist_ok=True)
with open(os.path.join(REPORT_DIR, "faircare_results.ndjson"), "w", encoding="utf-8") as out:
    for r in results:
        out.write(json.dumps(r, ensure_ascii=False) + "\n")

summary = {
    "manifests": len(manifests),
    "passed": passes,
    "failed": fails,
    "timestamp": datetime.datetime.utcnow().isoformat()+"Z"
}
with open(os.path.join(REPORT_DIR, "faircare_summary.json"), "w", encoding="utf-8") as f:
    json.dump(summary, f, indent=2)

print(json.dumps(summary, indent=2))
if fails > 0:
    # Exit non-zero to fail the job
    sys.exit(1)
PY

      - name: üßæ Append to Governance Ledger
        if: always()
        shell: bash
        run: |
          set -euo pipefail
          ts="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"
          mkdir -p "$(dirname "${GOVERNANCE_LEDGER}")"
          jq -n --arg ts "$ts" \
                --arg run "${GITHUB_RUN_ID}" \
                --arg sha "${GITHUB_SHA}" \
                --arg wf "${GITHUB_WORKFLOW}" \
                --arg summ "${REPORT_DIR}/faircare_summary.json" \
                '{event:"faircare-validate", timestamp:$ts, github:{run_id:$run, sha:$sha, workflow:$wf}, summary:$summ}' \
            | tee -a "${GOVERNANCE_LEDGER}"

      - name: üì§ Upload FAIR+CARE artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: faircare-validation-reports
          path: |
            ${{ env.REPORT_DIR }}/faircare_results.ndjson
            ${{ env.REPORT_DIR }}/faircare_summary.json
            ${{ env.REPORT_DIR }}/source_manifests.txt
            ${{ env.GOVERNANCE_LEDGER }}
          if-no-files-found: warn

      - name: üßæ Job summary
        if: always()
        run: |
          echo "### FAIR+CARE Validation Summary" >> $GITHUB_STEP_SUMMARY
          if [ -f "${REPORT_DIR}/faircare_summary.json" ]; then
            echo "\`\`\`json" >> $GITHUB_STEP_SUMMARY
            cat "${REPORT_DIR}/faircare_summary.json" >> $GITHUB_STEP_SUMMARY
            echo "\`\`\`" >> $GITHUB_STEP_SUMMARY
          else
            echo "No summary available." >> $GITHUB_STEP_SUMMARY
          fi
```
