# .github/workflows/.pre-commit-config.yaml
# Kansas-Frontier-Matrix — CI Pre-Commit Hooks
# ------------------------------------------------
# CI-focused hooks for schema validation, STAC integrity,
# Python style, JSON/YAML correctness, and docs hygiene.
# Mirrors key checks from the root config, but kept lean for CI.

minimum_pre_commit_version: "3.6.0"

default_language_version:
  # Keep aligned with CI; Python hooks will run in their own venvs.
  python: python3

# CI runs on push; keep commit-time UX concerns out of this file.
default_stages: [push]

# Skip heavy/binary paths when hooks support "exclude"
exclude: |
  (?x)^(
    data/(processed|cogs|outputs|raw)/|
    assets/(tiles|images|fonts)/|
    web/(dist|build|tiles|assets)/|
    (?:^|.*/)?node_modules/|
    (?:^|.*/)?dist/|
    build/|
    _site/|
    earth/|
    docs/_build/|
    \.venv/|
    \.mypy_cache/|
    \.ruff_cache/|
    \.pytest_cache/|
    .*\.ipynb_checkpoints/|
    .*\.pmtiles$|
    .*\.mbtiles$|
    .*\.tif{1,2}$|
    .*\.la[sz]$|
    .*\.gpkg$|
    .*\.parquet$|.*\.geoparquet$|
    .*\.7z$|.*\.zip$|.*\.tar(\.gz)?$|.*\.zst$|
    .*\.pdf$
  )

repos:
  # --- Core file hygiene -----------------------------------------------------
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.6.0
    hooks:
      - id: check-yaml
      - id: check-json
      - id: check-toml
      - id: check-xml
      - id: check-merge-conflict
      - id: check-added-large-files
        # CI threshold aligns with root (LFS/DVC gate)
        args: ["--maxkb=5000"]
      - id: detect-private-key
      - id: trailing-whitespace
      - id: end-of-file-fixer

  # --- Python: formatting + linting -----------------------------------------
  # NOTE: upstream moved from charliermarsh -> astral-sh
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.6.9
    hooks:
      - id: ruff
        args: ["--fix"]
      - id: ruff-format

  - repo: https://github.com/psf/black
    rev: 24.8.0
    hooks:
      - id: black
        # Keep CI Python aligned with workflows (3.11 OK too);
        # black doesn't require pin here, but we set a sane default.
        language_version: python3.10

  # --- Shell scripts ---------------------------------------------------------
  - repo: https://github.com/shellcheck-py/shellcheck-py
    rev: v0.10.0.1
    hooks:
      - id: shellcheck

  # --- Markdown (keep simple for CI) ----------------------------------------
  # Use the Node CLI variant; avoids ruby deps collisions in CI images.
  - repo: https://github.com/igorshubovych/markdownlint-cli
    rev: v0.41.0
    hooks:
      # Correct hook id for this repo is "markdownlint"
      - id: markdownlint
        args: ["--fix"]
        # Include repo docs + root README + web docs
        files: "(^README\\.md$)|(^docs/.*\\.(md|markdown)$)|(^web/.*\\.(md|markdown)$)"

  # --- STAC validation (self-contained for CI) -------------------------------
  # Use a Python hook so CI doesn't need global installs.
  - repo: local
    hooks:
      - id: stac-validate
        name: STAC Validator (kgt if available; else stac-validator)
        language: python
        additional_dependencies: ["stac-validator>=3.3.0"]
        pass_filenames: false
        files: "^stac/.*\\.json$"
        entry: >
          python - <<'PY'
          import os, sys, shutil, json, subprocess
          from pathlib import Path
          def run(cmd):
            try:
              return subprocess.run(cmd, check=True, text=True)
            except subprocess.CalledProcessError as e:
              return e

          root = Path("stac")
          if not root.exists():
            print("::notice::No stac/ directory found; skipping.")
            sys.exit(0)

          # Prefer project-native kgt if present
          kgt = shutil.which("kgt")
          if kgt:
            rc = 0
            cols = Path("stac/collections")
            items = Path("stac/items")
            if cols.exists():
              res = run([kgt, "validate-stac", str(cols), "--no-strict"])
              rc |= 0 if isinstance(res, subprocess.CompletedProcess) else 1
            if items.exists():
              res = run([kgt, "validate-stac", str(items), "--no-strict"])
              rc |= 0 if isinstance(res, subprocess.CompletedProcess) else 1
            sys.exit(rc)

          # Fallback: Python stac-validator (installed via additional_dependencies)
          targets = []
          for d in (root / "items", root / "collections"):
            if d.exists():
              targets.extend(p for p in d.rglob("*.json") if p.is_file())

          if not targets:
            print("::notice::No STAC items/collections to validate.")
            sys.exit(0)

          rc = 0
          for f in targets:
            res = run(["stac-validator", str(f)])
            if not isinstance(res, subprocess.CompletedProcess):
              rc = 1
          sys.exit(rc)
          PY

  # --- JSON schema validation for web configs --------------------------------
  # Validate specific configs (legend/categories/sources) against your packed schema.
  # This version is resilient to the actual path: tries web/config/schema.json,
  # then web/config/layers.schema.json (as used in this repo).
  - repo: local
    hooks:
      - id: jsonschema-validate-pack
        name: JSON Schema Validation (web/config pack)
        language: python
        additional_dependencies: ["jsonschema>=4.23.0"]
        files: "^web/config/.*\\.json$"
        pass_filenames: false
        entry: >
          python - <<'PY'
          import json, sys
          from pathlib import Path
          from jsonschema import Draft202012Validator as V

          base = Path('web/config')
          # Try both common locations
          candidates = [base / 'schema.json', base / 'layers.schema.json']
          pack = next((p for p in candidates if p.exists()), None)
          if not pack:
              # No schema pack in repo; nothing to do.
              sys.exit(0)

          schema_doc = json.loads(pack.read_text(encoding='utf-8'))
          defs = schema_doc.get('$defs') or schema_doc.get('definitions') or {}

          # Expected docs to validate if present
          wanted = ('legend', 'categories', 'sources')
          ok = True
          for name in wanted:
              sch = defs.get(name)
              doc = base / f'{name}.json'
              if not (sch and doc.exists()):
                  continue
              data = json.loads(doc.read_text(encoding='utf-8'))
              try:
                  V.check_schema(sch)
                  V(sch).validate(data)
              except Exception as e:
                  print(f"- {name}: {e}")
                  ok = False
          sys.exit(0 if ok else 1)
          PY

  # --- Files that declare $schema (auto-discovery across web/config + web/data)
  - repo: local
    hooks:
      - id: jsonschema-validate-dollar-schema
        name: JSON Schema Validation ($schema discovery)
        language: python
        additional_dependencies:
          [ "jsonschema>=4.23.0", "rfc3339-validator", "rfc3987", "requests" ]
        files: "^(web/config|web/data)/.*\\.json$"
        pass_filenames: false
        entry: >
          python - <<'PY'
          import json, pathlib, sys, urllib.parse, contextlib, requests
          from jsonschema import Draft202012Validator as V
          def load_json(p: pathlib.Path):
              return json.loads(p.read_text(encoding="utf-8"))
          def fetch_schema(uri: str, base: pathlib.Path):
              parsed = urllib.parse.urlparse(uri)
              if parsed.scheme in ("http", "https"):
                  r = requests.get(uri, timeout=20)
                  r.raise_for_status()
                  return r.json()
              if parsed.scheme == "file":
                  return load_json(pathlib.Path(parsed.path))
              candidate = (base.parent / uri).resolve()
              if candidate.exists():
                  return load_json(candidate)
              candidate = pathlib.Path(uri)
              if candidate.exists():
                  return load_json(candidate)
              raise FileNotFoundError(f"Schema not found: {uri}")
          roots = []
          for root in ("web/config", "web/data"):
              p = pathlib.Path(root)
              if p.exists():
                  roots.extend(p.rglob("*.json"))
          errors = 0
          checked = 0
          for j in roots:
              try:
                  data = load_json(j)
              except Exception:
                  continue
              schema_uri = isinstance(data, dict) and data.get("$schema")
              if not schema_uri:
                  continue
              try:
                  schema = fetch_schema(schema_uri, j)
                  V.check_schema(schema)
                  V(schema).validate(data)
                  print(f"✔ $schema OK: {j}")
                  checked += 1
              except Exception as e:
                  print(f"::error file={j}::Schema validation failed: {e}")
                  errors += 1
          if checked == 0:
              print("::notice::No JSON files declared $schema; skipping.")
          sys.exit(errors)
          PY

  # --- Security scanning (basic) --------------------------------------------
  - repo: https://github.com/PyCQA/bandit
    rev: 1.7.9
    hooks:
      - id: bandit
        args: ["-q", "-r", "src"]
        files: "^src/.*\\.py$"

  # --- GitHub Actions workflow linter ---------------------------------------
  - repo: https://github.com/rhysd/actionlint
    rev: v1.7.4
    hooks:
      - id: actionlint
      # Keep default file filter; we only lint workflows
      # Avoids accidental linting of other yaml files
      - id: actionlint
        files: "^\\.github/workflows/.*\\.ya?ml$"
