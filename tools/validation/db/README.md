# ğŸ§ªğŸ—„ï¸ DB Validation Toolkit

![DB](https://img.shields.io/badge/DB-PostgreSQL%20%2B%20PostGIS-blue)
![Scope](https://img.shields.io/badge/scope-schema%20%7C%20data%20%7C%20security%20%7C%20performance-purple)
![CI](https://img.shields.io/badge/CI-quality%20gate-critical)
![Output](https://img.shields.io/badge/reports-json%20%7C%20junit%20%7C%20markdown-informational)

> **Path:** `tools/validation/db/`  
> Contract-first, provenance-first **database** quality gates for Kansas Frontier Matrix (KFM). âœ…

---

## ğŸ§­ TL;DR

- **Run DB checks** before merging, releasing, or ingesting new datasets.
- Catch issues early: **schema drift**, **broken constraints**, **invalid geometries**, **missing provenance**, **unsafe privileges**, **perf regressions**.
- Produce CI-friendly reports (JSON/JUnit/Markdown) with consistent **exit codes**.

> [!NOTE]
> This folder focuses on **database-layer** validation. It complements higher-level validation (catalog/manifest checks, API contract checks, etc.).

---

## ğŸ§© Where this fits in the KFM pipeline

KFM is designed around **contract-first** + **provenance-first** delivery. DB validation is one of the â€œhard stopsâ€ that prevents silent data drift from reaching the UI, analytics, or narratives.

```mermaid
flowchart LR
  A[ğŸ“¥ Raw Sources] --> B[ğŸ§° Ingest / ETL]
  B --> C[(ğŸ—„ï¸ Postgres/PostGIS)]
  C --> D[ğŸ§ª tools/validation/db]
  D -->|pass âœ…| E[ğŸ“¡ API / Services]
  D -->|fail âŒ| F[ğŸ§¯ Block CI / Release]
  E --> G[ğŸ—ºï¸ UI / WebGL / Maps]
  E --> H[ğŸ“Š Analytics / Models]
```

---

## âœ… What gets validated

### 1) ğŸ§± Schema & Migration Integrity
- Required extensions installed (e.g., PostGIS)
- Expected schemas/tables/views exist
- Column types match contracts (no accidental `text` vs `uuid` drift)
- Primary keys / foreign keys present and enforceable
- â€œNo surpriseâ€ DDL changes (detected via schema snapshot)

### 2) ğŸ”— Relational Integrity
- PK uniqueness (no duplicate IDs)
- FK referential integrity (no orphan rows)
- `NOT NULL` expectations honored
- Domain constraints (enumerations, ranges, regex rules)
- Deduplication rules (canonical uniqueness constraints)

### 3) ğŸ§¬ Provenance & Metadata Completeness
- Every â€œpublishedâ€ record is traceable to a **source** and an **ingest run**
- Required lineage fields populated (`source_id`, `ingested_at`, `license`, etc.)
- Dataset/collection identifiers are stable and present
- Optional governance fields present where applicable (classification, consent, retention)

### 4) ğŸŒ Geospatial Validity (PostGIS)
- Geometry validity (e.g., `ST_IsValid`)
- Consistent SRID / coordinate reference system expectations
- Bounding boxes inside expected world/region envelopes
- Topology checks for specific layers (no self-intersections, overlaps, etc.)
- Raster policy enforcement: **store footprints + metadata** instead of stuffing huge rasters into DB

### 5) ğŸ›¡ï¸ Security & Access Controls
- Least privilege for application roles
- No accidental `PUBLIC` grants on sensitive schemas
- Default privileges sane for new tables
- Optional: RLS policies enabled where required
- Sensitive columns labeled/guarded (depending on KFM governance tier)

### 6) âš¡ Performance & Operational Guardrails
- Missing index detection for critical access paths
- Table/index bloat warnings (threshold-based)
- Query plan sanity checks for â€œgolden queriesâ€
- Backup/restore smoke tests (where safe to run)
- Replication/connection pool sanity (if applicable in environment)

---

## ğŸš€ Quickstart

> [!TIP]
> In CI, run **core + security + geospatial** at minimum. Add **performance** checks on nightly / release branches.

### 0) Set your DB connection

```bash
export DATABASE_URL="postgresql://USER:PASSWORD@HOST:5432/DBNAME"
# Optional:
export DB_SCHEMA="public"
export KFM_ENV="dev"   # dev|ci|staging|prod
```

### 1) Run the validator

Pick the runner style that matches your repo wiring:

#### Option A â€” Python module runner (recommended pattern)
```bash
python -m tools.validation.db validate \
  --packs core,geospatial,security \
  --format pretty
```

#### Option B â€” Make target wrapper (if present)
```bash
make validate-db
```

#### Option C â€” Docker Compose (if your services run in containers)
```bash
docker compose run --rm api \
  python -m tools.validation.db validate --packs core,geospatial
```

---

## âš™ï¸ Configuration

### Environment variables

| Variable | Purpose | Example |
|---|---|---|
| `DATABASE_URL` | Connection string | `postgresql://...` |
| `DB_SCHEMA` | Target schema(s) | `public` |
| `KFM_ENV` | Enables env-specific thresholds | `ci` |
| `VALIDATION_PACKS` | Default packs if CLI omits | `core,security` |
| `VALIDATION_STRICT` | Treat warnings as failures | `1` |

### Profiles & thresholds

Recommended: store profiles in `tools/validation/db/config/`:

- `dev.yml` â†’ relaxed thresholds, verbose output
- `ci.yml` â†’ strict correctness checks, minimal logs
- `staging.yml` â†’ adds backup/restore + perf smoke tests
- `prod.yml` â†’ read-only checks unless explicitly allowed

---

## ğŸ“¦ Check packs

| Pack | Purpose | Typical severity |
|---|---|---|
| `core` | schema + constraints + invariants | âŒ blocker/error |
| `geospatial` | PostGIS validity + SRID + topology | âŒ blocker/error |
| `provenance` | lineage + metadata completeness | âŒ error / âš ï¸ warn |
| `security` | grants + roles + default privileges | âŒ blocker/error |
| `performance` | index coverage + regression heuristics | âš ï¸ warn / âŒ error (release) |
| `simulation` | reproducibility + run metadata + UQ fields | âš ï¸ warn / âŒ error (publish) |
| `stats` | distribution sanity + drift + missingness | âš ï¸ warn |

> [!IMPORTANT]
> Packs are meant to be composable: start small, add domain checks as datasets mature.

---

## ğŸ“ Folder layout (expected)

```text
tools/validation/db/
â”œâ”€â”€ ğŸ“˜ README.md
â”œâ”€â”€ ğŸ§  runner/                 # orchestration (python/ts/etc.)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ cli.py
â”‚   â”œâ”€â”€ engine.py
â”‚   â””â”€â”€ reporters/
â”œâ”€â”€ âœ… checks/
â”‚   â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ geospatial/
â”‚   â”œâ”€â”€ provenance/
â”‚   â”œâ”€â”€ security/
â”‚   â”œâ”€â”€ performance/
â”‚   â”œâ”€â”€ simulation/
â”‚   â””â”€â”€ stats/
â”œâ”€â”€ ğŸ§¾ sql/                    # raw SQL checks (optional)
â”œâ”€â”€ âš™ï¸ config/                 # profiles, thresholds, allowlists
â””â”€â”€ ğŸ§ª fixtures/               # tiny seed DBs / snapshots for tests
```

> If your repo uses a different layout, keep the **concepts** the same:
> checks are modular, declarative where possible, and CI-friendly.

---

## ğŸ§¾ Output format

### JSON (machine-friendly)
Example record:
```json
{
  "id": "geospatial.geom_valid",
  "pack": "geospatial",
  "severity": "error",
  "status": "fail",
  "summary": "Found 12 invalid geometries in public.parcels",
  "evidence": {
    "table": "public.parcels",
    "invalid_count": 12,
    "sample_ids": ["..."]
  }
}
```

### JUnit (CI-friendly)
- Each check becomes a testcase.
- Any `error`/`blocker` failure fails the suite.

### Markdown (human-friendly)
- Great for PR comments and audit trails.

---

## ğŸš¦ Exit codes & CI behavior

| Code | Meaning |
|---:|---|
| `0` | All checks passed (or only allowed warnings) âœ… |
| `1` | At least one check failed âŒ |
| `2` | Misconfiguration / cannot connect to DB ğŸ§¯ |

Recommended gating rule:
- `blocker` + `error` â†’ **fail CI**
- `warn` â†’ fail only under `--strict` or in release workflows

---

## â• Adding a new DB check

### âœ… Design rules
- **Deterministic:** same DB state â‡’ same result
- **Fast by default:** avoid full scans unless behind a flag
- **Actionable output:** include table/column and sample IDs
- **Safe:** prefer read-only queries; guard any write tests behind `--allow-writes`

### Suggested check contract (declarative)
Create a file like:
- `checks/geospatial/geom_valid.yml`
- `sql/geospatial/geom_valid.sql`

`geom_valid.yml`:
```yaml
id: geospatial.geom_valid
pack: geospatial
severity: error
description: "All geometries must be ST_IsValid()"
sql: sql/geospatial/geom_valid.sql
expect:
  fail_if_rows_gt: 0
```

`geom_valid.sql`:
```sql
SELECT id
FROM public.parcels
WHERE geom IS NOT NULL
  AND NOT ST_IsValid(geom)
LIMIT 50;
```

> [!TIP]
> Store â€œwhy this check existsâ€ right next to the check (short + direct). Future you will thank you. ğŸ™

---

## ğŸŒ PostGIS validation patterns (grab bag)

Use these patterns to build checks:

- Validity: `ST_IsValid(geom)`
- SRID: `ST_SRID(geom) = 4326` (or your canonical SRID)
- Intersections / containment: `ST_Intersects`, `ST_Within`
- Reprojection: `ST_Transform`
- Buffers: `ST_Buffer` (use carefully; it can be expensive)

---

## ğŸ” Security validation patterns (PostgreSQL)

Common checks:
- Ensure `PUBLIC` doesnâ€™t have broad privileges on schemas/tables.
- Ensure default privileges are explicit.
- Ensure app role has only what it needs.

---

## ğŸ§ª Simulation & model-result validation (optional but recommended)

If the DB stores simulation/model outputs:
- Every run should be traceable to:
  - code version / commit hash
  - input dataset versions
  - parameter set ID
  - random seed(s) if stochastic
- Store **uncertainty quantification (UQ)** fields where relevant (CI for â€œpublishableâ€ runs).
- Validate required run metadata before results become â€œpublishedâ€.

---

## ğŸ§¯ Troubleshooting

<details>
<summary>ğŸ”Œ â€œCannot connect to databaseâ€</summary>

- Confirm `DATABASE_URL` is set and reachable.
- Confirm SSL requirements (if any).
- Confirm network access from CI runner / container.

</details>

<details>
<summary>ğŸ§© â€œPostGIS functions missingâ€</summary>

- Ensure PostGIS extension is installed in the target DB:
  - `CREATE EXTENSION postgis;` (admin only)
- Ensure your validation user can `SELECT` from `geometry_columns` / `spatial_ref_sys` if needed.

</details>

<details>
<summary>ğŸ¢ â€œChecks are slowâ€</summary>

- Move expensive checks into the `performance` pack.
- Add sampling / `LIMIT` and evidence queries.
- Add indexes (and validate their existence to prevent regressions).

</details>

---

## ğŸ“š Project reference library (why these checks exist)

<details>
<summary>ğŸ“– Show project files that inform DB validation</summary>

### ğŸ§  Core architecture & documentation
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf`
- `MARKDOWN_GUIDE_v13.md.gdoc`

### ğŸ—„ï¸ Databases & performance
- `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf`
- `Database Performance at Scale.pdf`
- `Scalable Data Management for Future Hardware.pdf`
- `Data Spaces.pdf`

### ğŸŒ Geospatial, GIS, cartography, remote sensing
- `python-geospatial-analysis-cookbook.pdf`
- `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf`
- `making-maps-a-visual-guide-to-map-design-for-gis.pdf`
- `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf`
- `Archaeological 3D GIS_26_01_12_17_53_09.pdf`

### ğŸ§ª Modeling, simulation, statistics, ML
- `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf`
- `Scientific Method _ Research _ Master Coder Protocol Documentation.pdf`
- `Understanding Statistics & Experimental Design.pdf`
- `regression-analysis-with-python.pdf`
- `Regression analysis using Python - slides-linear-regression.pdf`
- `think-bayes-bayesian-statistics-in-python.pdf`
- `graphical-data-analysis-with-r.pdf`
- `Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf` *(library reference)*

### ğŸ•¸ï¸ Graphs & optimization
- `Spectral Geometry of Graphs.pdf`
- `Generalized Topology Optimization for Structural Design.pdf`

### ğŸ” Security mindset (defensive use)
- `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf`
- `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf`

### ğŸ§‘â€âš–ï¸ Governance, law, human factors
- `Introduction to Digital Humanism.pdf`
- `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf`
- `Principles of Biological Autonomy - book_9780262381833.pdf`

### ğŸ§° Build & UI references (supporting ecosystem)
- `responsive-web-design-with-html5-and-css3.pdf`
- `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf`
- `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf`

### ğŸ“¦ Programming compendiums (general reference shelf)
- `A programming Books.pdf`
- `B-C programming Books.pdf`
- `D-E programming Books.pdf`
- `F-H programming Books.pdf`
- `I-L programming Books.pdf`
- `M-N programming Books.pdf`
- `O-R programming Books.pdf`
- `S-T programming Books.pdf`
- `U-X programming Books.pdf`

</details>

---

## âœ… Definition of Done (for DB validation work)

A DB validation change is â€œdoneâ€ when:
- [ ] New checks have clear IDs, severity, and pack ownership
- [ ] Checks are deterministic + safe by default
- [ ] CI runs them (or theyâ€™re explicitly gated behind a profile)
- [ ] Failures include actionable evidence (table, column, sample IDs)
- [ ] Docs updated (this README + check-local docs if needed)

---

â¬…ï¸ Back: `../README.md` (tools/validation)  
ğŸ  Repo root: `../../../README.md`
