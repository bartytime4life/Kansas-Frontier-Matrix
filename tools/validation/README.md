# ğŸ§ª Validation Toolkit

![stage](https://img.shields.io/badge/stage-active-success)
![quality-gate](https://img.shields.io/badge/quality-gate_required-critical)
![policy](https://img.shields.io/badge/policy-OPA%20%2B%20Conftest-6f42c1)
![stac](https://img.shields.io/badge/metadata-STAC-informational)
![geo](https://img.shields.io/badge/geospatial-PostGIS%20%7C%20GDAL-orange)
![stats](https://img.shields.io/badge/validation-stats%20%7C%20ML-blue)
![security](https://img.shields.io/badge/security-defensive%20checks-important)

> âœ… **If it ships, it validates.**  
> This folder defines the *quality gates* for Kansas Frontier Matrix (KFM) data, catalogs, models, simulations, databases, and UI outputs.

---

## ğŸ“Œ What this folder is for

`tools/validation/` exists to make the KFM ecosystem **provably reliable**:

- ğŸ§¾ **Traceability**: every produced asset can be traced back to inputs + pipeline version + policy decisions.
- ğŸ§ª **Scientific rigor**: verification & validation (V&V), uncertainty thinking, reproducibility.
- ğŸŒ **Geospatial correctness**: CRS, bbox/extent, topology, raster/vector integrity.
- ğŸ§  **Model accountability**: regression/ML evaluation, drift detection, explainability artifacts.
- ğŸ›¡ï¸ **Security posture**: defensive scanning and safe-by-default checks.
- ğŸ§­ **Governance**: licensing, provenance, FAIR/CARE-aligned publishing, ethical constraints.

---

## ğŸ§­ Table of contents

- [âš¡ Quickstart](#-quickstart)
- [ğŸ§± Validation layers](#-validation-layers)
- [ğŸ—‚ï¸ Directory map](#-directory-map)
- [ğŸ›°ï¸ STAC and catalog QA](#-stac-and-catalog-qa)
- [ğŸŒ Geospatial validation](#-geospatial-validation)
- [ğŸ“ˆ Statistics and ML validation](#-statistics-and-ml-validation)
- [ğŸ§® Modeling and simulation V&V](#-modeling-and-simulation-vv)
- [ğŸ—ƒï¸ Data engineering and database validation](#-data-engineering-and-database-validation)
- [ğŸ–¥ï¸ Web UI and 3D visualization validation](#-web-ui-and-3d-visualization-validation)
- [ğŸ” Security validation](#-security-validation)
- [ğŸ“œ Governance and ethics checks](#-governance-and-ethics-checks)
- [ğŸ§© Adding a new validator](#-adding-a-new-validator)
- [ğŸ“¦ Artifacts and reporting](#-artifacts-and-reporting)
- [ğŸ—ºï¸ Reference library used by this folder](#-reference-library-used-by-this-folder)

---

## âš¡ Quickstart

Run validations from the **repo root**.

### Option A: Make targets

```bash
make validate
make validate-stac
make validate-geo
make validate-stats
make validate-ml
make validate-db
make validate-web
make validate-security
```

### Option B: Python module entrypoint

```bash
python -m tools.validation all
python -m tools.validation stac ./data/catalog
python -m tools.validation geo  ./data/derived
```

### Option C: CI lanes only

```bash
# run only checks that are mandatory for merge
python -m tools.validation ci
```

> ğŸ§  **Design rule:** every validator must run locally *and* in CI with identical semantics.

---

## ğŸ§± Validation layers

KFM validation is deliberately **layered** so failures are fast, actionable, and auditable:

1. ğŸ§¹ **Lint & Type**  
   Formatting, static analysis, typing, doc lint.
2. ğŸ“ **Schema**  
   JSON Schema, STAC JSON Schema, DCAT/metadata schema, telemetry schema.
3. ğŸ§© **Policy as code**  
   OPA/Conftest rules (what we *allow* to ship).
4. ğŸ›°ï¸ **Catalog integrity**  
   STAC relationships, links, collections, paging, provenance chains.
5. ğŸŒ **Geospatial integrity**  
   CRS, extents, topology, raster metadata, no silent reprojection.
6. ğŸ“ˆ **Stats & Drift**  
   sanity checks, distributions, regression diagnostics, anomaly detection.
7. ğŸ§  **ML evaluation**  
   baselines, cross-validation, calibration, fairness flags, reproducibility.
8. ğŸ§® **Modeling & simulation V&V**  
   numerical checks, conservation checks, UQ, sensitivity.
9. ğŸ—ƒï¸ **DB & performance**  
   constraints, migrations, query plans, scalability smoke tests.
10. ğŸ–¥ï¸ **UI & viz**  
   accessibility, responsive behavior, WebGL stability, visual regression.
11. ğŸ” **Security**  
   dependency scanning, secrets, SBOM, config hardening checks.
12. ğŸ“œ **Governance**  
   licenses, provenance, human-centered constraints, publish readiness.

---

## ğŸ—‚ï¸ Directory map

> ğŸ§© This is the recommended layout. Adjust to match the repo, but keep the *conceptual lanes*.

```text
ğŸ§° tools/validation/
â”œâ”€ ğŸ“„ README.md                         ğŸ‘ˆ you are here
â”œâ”€ ğŸ§¾ manifest.yml                      ğŸ§¾ single source of truth for validators
â”œâ”€ ğŸƒ runners/
â”‚  â”œâ”€ ğŸ run_all.py                     ğŸ orchestrator (local + CI)
â”‚  â”œâ”€ ğŸ›£ï¸ run_lane.py                    ğŸ›£ï¸ run one lane by name
â”‚  â””â”€ ğŸ“¦ report.py                      ğŸ“¦ unify outputs into artifacts
â”œâ”€ ğŸ›°ï¸ stac/
â”‚  â”œâ”€ ğŸ›°ï¸ catalog_qa.py                  ğŸ›°ï¸ fast STAC static checks
â”‚  â”œâ”€ ğŸ“ jsonschema_validate.py         ğŸ“ schema-based validation
â”‚  â””â”€ ğŸ§ª fixtures/                      ğŸ§ª minimal reproducible catalogs
â”œâ”€ ğŸ§© policy/
â”‚  â”œâ”€ ğŸ§© stac_provenance.rego           ğŸ§© required fields, provenance rules
â”‚  â”œâ”€ âš™ï¸ faircare.rego                  âš™ï¸ sensitive-layer governance
â”‚  â””â”€ ğŸ“˜ conftest.md                    ğŸ“˜ how to run policy gates
â”œâ”€ ğŸŒ geo/
â”‚  â”œâ”€ ğŸ§­ check_crs.py                   ğŸ§­ CRS & axis sanity checks
â”‚  â”œâ”€ ğŸ“¦ check_bbox.py                  ğŸ“¦ bbox/extent correctness
â”‚  â”œâ”€ ğŸ§± check_geometries.py            ğŸ§± topology/validity checks
â”‚  â””â”€ ğŸ—ºï¸ check_rasters.py               ğŸ—ºï¸ raster metadata + nodata + tiling
â”œâ”€ ğŸ“ˆ stats/
â”‚  â”œâ”€ ğŸ“ˆ drift_checks.py                ğŸ“ˆ distribution + drift
â”‚  â”œâ”€ ğŸ“‰ regression_diagnostics.py      ğŸ“‰ residuals, leverage, outliers
â”‚  â””â”€ ğŸ“Š eda_report.R                   ğŸ“Š optional R-based visual EDA report
â”œâ”€ ğŸ¤– ml/
â”‚  â”œâ”€ ğŸ§  eval_baselines.py              ğŸ§  metrics + baselines
â”‚  â”œâ”€ ğŸ¯ calibration.py                 ğŸ¯ calibration + uncertainty
â”‚  â””â”€ ğŸªª model_card_check.py            ğŸªª model card completeness gate
â”œâ”€ ğŸ§® sim/
â”‚  â”œâ”€ ğŸ§® invariants.py                  ğŸ§® conservation / invariants
â”‚  â”œâ”€ ğŸ“ convergence.py                 ğŸ“ grid/time-step convergence
â”‚  â””â”€ ğŸŒ«ï¸ uq.py                          ğŸŒ«ï¸ uncertainty quantification helpers
â”œâ”€ ğŸ—ƒï¸ db/
â”‚  â”œâ”€ ğŸ—ƒï¸ constraints.sql                ğŸ—ƒï¸ constraints & invariants
â”‚  â”œâ”€ ğŸŒ postgis_checks.sql             ğŸŒ geometry validity & SRID checks
â”‚  â””â”€ âš¡ explain_guard.py               âš¡ query plan smoke tests
â”œâ”€ ğŸ–¥ï¸ web/
â”‚  â”œâ”€ ğŸ’¡ lighthouse_ci/                 ğŸ’¡ performance + accessibility
â”‚  â”œâ”€ ğŸ–¼ï¸ visual_regression/             ğŸ–¼ï¸ map layer snapshots
â”‚  â””â”€ ğŸ® webgl_smoke/                   ğŸ® context + capability checks
â”œâ”€ ğŸ” security/
â”‚  â”œâ”€ ğŸ” secrets_scan.yml               ğŸ” secrets policy
â”‚  â”œâ”€ ğŸ“¦ sbom_check.py                  ğŸ“¦ SBOM presence & diffs
â”‚  â””â”€ ğŸ§· dependency_audit.py            ğŸ§· dependency health checks
â””â”€ ğŸ“¦ artifacts/
   â””â”€ ğŸ“Œ .gitkeep                        ğŸ“¦ CI writes reports here
```

---

## ğŸ›°ï¸ STAC and catalog QA

KFM treats the catalog as a **product**: if the catalog lies, the UI lies.

### âœ… What we validate for STAC

- **Schema correctness**: STAC version alignment, item/collection/catalog schema validity.
- **Extensions**: required STAC extensions present (e.g., projection when we publish geospatial assets).
- **Provenance**: explicit â€œderived fromâ€ relationships and version tagging.
- **Links**: hrefs resolve, rel types are correct, no circular loops unless explicitly allowed.
- **Providers & license**: publishing posture is explicit.

### Example required fields pattern

```json
{
  "stac_version": "1.0.0",
  "stac_extensions": [
    "https://stac-extensions.github.io/projection/v2.0.0/schema.json"
  ],
  "properties": {
    "kfm:mdp_version": "v11.2.6",
    "proj:epsg": 4326
  },
  "providers": [
    { "name": "Kansas Frontier Matrix", "roles": ["processor"] }
  ],
  "license": "CC-BY 4.0",
  "links": [
    {
      "rel": "derived_from",
      "href": "stac://raw/source_asset_01",
      "type": "application/json",
      "title": "Provenance chain"
    }
  ]
}
```

### Policy gate with OPA and Conftest

Use policy as code to enforce **non-negotiables**:

```bash
conftest test ./data/catalog \
  --policy tools/validation/policy \
  --namespace kfm
```

> ğŸ§© Policies should be small, composable, and written like contracts.

### `catalog_qa.py` fast checks

This lane is your â€œlint for STACâ€:

- Missing required keys (`stac_version`, `stac_extensions`, `providers`, `license`)
- Broken `href` targets
- Provenance gaps (`derived_from` absent where expected)
- Version mismatches (`kfm:mdp_version`)
- Duplicate IDs, orphan items, invalid rels

---

## ğŸŒ Geospatial validation

Geospatial validation is split into **format**, **geometry**, and **meaning**:

### âœ… Format and metadata

- Raster:
  - CRS defined and consistent
  - nodata present and sane
  - tiling and overviews for web delivery when required
- Vector:
  - valid geometries (no self-intersections, no NaNs)
  - SRID set and consistent
  - attributes schema stable

### âœ… Spatial integrity

- bbox matches geometry/raster extent
- no accidental axis flips
- reprojection performed deliberately (and recorded)
- tolerances documented (meters vs degrees)

### âœ… Cartographic integrity

Map design and legend correctness are treated as validation targets:

- legend keys exist for every layer class
- ramps are consistent across versions
- accessibility constraints (contrast, colorblind safety) are checked in UI snapshot tests

---

## ğŸ“ˆ Statistics and ML validation

### Statistical sanity checks

- distribution checks (range, missingness, spikes)
- drift detection between releases
- outlier audit trails (why a point is extreme)

### Regression diagnostics

- residual behavior checks
- leverage & influence
- multicollinearity flags
- train/test leakage detectors

### Bayesian checks

- posterior predictive checks
- calibration diagnostics
- uncertainty reporting requirements (when the UI shows â€œconfidenceâ€)

### Deep learning checks

- learning curve artifacts
- overfitting detection gates
- reproducibility checks (seeds, deterministic ops when feasible)

---

## ğŸ§® Modeling and simulation V&V

We follow a NASA-grade mindset:

- âœ… **Code verification**: â€œdid we implement the equations right?â€
- âœ… **Solution verification**: â€œdid we solve the equations accurately?â€
- âœ… **Validation**: â€œdoes the model match reality for the intended use?â€
- ğŸŒ«ï¸ **Uncertainty quantification**: â€œhow wrong might we be, and why?â€

Suggested checks:

- invariants and conservation laws
- mesh/time-step convergence
- sensitivity analysis
- benchmark problems (known analytic/empirical references)

---

## ğŸ—ƒï¸ Data engineering and database validation

### PostgreSQL and PostGIS

- constraints are enforced (NOT NULL, FK, CHECK)
- geometry validity enforced in DB
- SRID constraints checked in SQL
- migration safety checks (no destructive changes without flags)

### Scalability and performance

- benchmark queries (representative workloads)
- plan regressions (EXPLAIN guardrails)
- streaming and incremental workloads where relevant

### Data spaces mindset

When data is federated, validation must travel with it:

- interoperability checks (contracts, schemas, semantics)
- trust checks (provenance, policy compliance)
- governance checks (usage controls, licensing posture)

---

## ğŸ–¥ï¸ Web UI and 3D visualization validation

### Responsive and accessibility

- responsive breakpoints donâ€™t break map usability
- keyboard navigation works
- ARIA labels exist for core controls
- map legends are readable and consistent

### WebGL stability

- context creation smoke tests
- capability detection
- crash regression tests on shader changes
- performance budgets for critical scenes

### Visual regression testing

This is *mandatory* for map-heavy products:

- layer snapshots pinned per release
- legend snapshots pinned per release
- tolerance-based image diffs
- â€œsemantic diffsâ€ for vector symbology when possible

---

## ğŸ” Security validation

Defensive checks only âœ…

- secrets scanning (keys, tokens, credentials)
- dependency audits (known vulnerable versions)
- SBOM required for release artifacts
- config sanity checks (CORS, CSP, headers)

> ğŸ›¡ï¸ **Important:** we do not ship offensive security tooling in this folder.  
> Use security references for defensive hardening and awareness.

---

## ğŸ“œ Governance and ethics checks

These checks exist because KFM is **not** just a codebaseâ€”itâ€™s a public-facing research tool.

- license presence and correctness
- provenance chain completeness
- â€œsensitive layerâ€ publishing rules
- FAIR/CARE-aligned posture (especially for hydrology and culturally sensitive content)
- AI governance checks (model cards, dataset cards, limitations, non-alert disclaimers)

---

## ğŸ§© Adding a new validator

A validator is considered â€œKFM-gradeâ€ when it has:

- âœ… deterministic behavior
- âœ… clear input contract (what it consumes)
- âœ… explicit output artifacts (what evidence it produces)
- âœ… an exit code contract (pass/fail/warn)
- âœ… a CI lane mapping (where it runs)

### Checklist

- [ ] Add your validator under the appropriate lane folder  
- [ ] Register it in `tools/validation/manifest.yml`  
- [ ] Ensure it writes artifacts under `tools/validation/artifacts/<validator-name>/`  
- [ ] Provide at least one fixture in `fixtures/`  
- [ ] Add it to CI lane runner  
- [ ] Document it in this README (one paragraph + example run)

---

## ğŸ“¦ Artifacts and reporting

All validators should emit:

- `report.json` (machine-readable)
- `report.md` (human-readable summary)
- `junit.xml` (CI-friendly)
- optional: plots, snapshots, diffs, notebook exports

Recommended folder pattern:

```text
tools/validation/artifacts/
â””â”€ <lane>/
   â””â”€ <check>/
      â”œâ”€ report.json
      â”œâ”€ report.md
      â”œâ”€ junit.xml
      â””â”€ extras/
```

---

## ğŸ—ºï¸ Reference library used by this folder

This validation suite is intentionally grounded in the projectâ€™s internal reference library ğŸ“š  
These files inform *how we define correctness* across science, geospatial, UI, security, and governance.

### Core KFM documents

- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Engineering Design.docx` ğŸ—ï¸
- `Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf` ğŸ—ºï¸
- `Latest Ideas.docx` ğŸ’¡
- `Other Ideas.docx` ğŸ§¾

### Modeling, simulation, and math

- `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf` ğŸš€
- `Generalized Topology Optimization for Structural Design.pdf` ğŸ§±
- `Spectral Geometry of Graphs.pdf` ğŸ§ 

### Statistics, experiment design, and ML

- `Understanding Statistics & Experimental Design.pdf` ğŸ§ª
- `regression-analysis-with-python.pdf` ğŸ“‰
- `Regression analysis using Python - slides-linear-regression.pdf` ğŸ“
- `think-bayes-bayesian-statistics-in-python.pdf` ğŸ²
- `graphical-data-analysis-with-r.pdf` ğŸ“Š
- `Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf` ğŸ¤–

### Geospatial, cartography, and remote sensing

- `python-geospatial-analysis-cookbook.pdf` ğŸŒ
- `making-maps-a-visual-guide-to-map-design-for-gis.pdf` ğŸ¨
- `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf` ğŸ“±
- `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf` ğŸ›°ï¸

### Data management and databases

- `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf` ğŸ—ƒï¸
- `Scalable Data Management for Future Hardware.pdf` âš¡
- `Data Spaces.pdf` ğŸ§©

### Web, visualization, and media formats

- `responsive-web-design-with-html5-and-css3.pdf` ğŸ§±
- `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf` ğŸ®
- `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf` ğŸ–¼ï¸

### Concurrency, distributed systems, and software practice

- `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf` ğŸ§µ
- `A programming Books.pdf` ğŸ§°
- `B-C programming Books.pdf` ğŸ§°
- `D-E programming Books.pdf` ğŸ§°
- `F-H programming Books.pdf` ğŸ§°
- `I-L programming Books.pdf` ğŸ§°
- `M-N programming Books.pdf` ğŸ§°
- `O-R programming Books.pdf` ğŸ§°
- `S-T programming Books.pdf` ğŸ§°
- `U-X programming Books.pdf` ğŸ§°

### Governance, law, and human-centered constraints

- `Introduction to Digital Humanism.pdf` ğŸ¤
- `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf` âš–ï¸
- `Principles of Biological Autonomy - book_9780262381833.pdf` ğŸ§¬

### Security references

- `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf` ğŸ›¡ï¸
- `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf` âš ï¸ *(defensive awareness only)*

---

<div align="center">

**KFM Validation Toolkit** Â· ğŸ§ª Evidence-driven Â· ğŸ›°ï¸ Catalog-first Â· ğŸŒ Geo-correct Â· ğŸ” Defensive  
</div>

