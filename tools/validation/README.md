# ğŸ§ª Validation Toolkit

![stage](https://img.shields.io/badge/stage-active-success)
![quality-gate](https://img.shields.io/badge/quality-gate_required-critical)
![pipeline](https://img.shields.io/badge/pipeline-v13%20canonical-0aa)
![policy](https://img.shields.io/badge/policy-OPA%20%2B%20Conftest-6f42c1)
![catalog](https://img.shields.io/badge/catalog-STAC%20%7C%20DCAT%20%7C%20PROV-informational)
![graph](https://img.shields.io/badge/graph-Neo4j-008cc1)
![docs](https://img.shields.io/badge/docs-Markdown%20Protocol-important)
![geo](https://img.shields.io/badge/geospatial-PostGIS%20%7C%20GDAL-orange)
![stats](https://img.shields.io/badge/validation-stats%20%7C%20ML-blue)
![security](https://img.shields.io/badge/security-defensive%20checks-important)
![supply-chain](https://img.shields.io/badge/supply%20chain-SBOM%20%7C%20Signed%20Releases-9cf)

> âœ… **If it ships, it validates.**  
> This folder defines the **quality gates** for Kansas Frontier Matrix (KFM) data, catalogs, graphs, APIs, models, simulations, databases, Story Nodes, and UI outputs.

---

## ğŸ“Œ What this folder is for

`tools/validation/` exists to make the KFM ecosystem **provably reliable**:

- ğŸ§¾ **Traceability**: every asset is traceable to inputs + pipeline version + policy decisions + provenance.
- ğŸ§ª **Scientific rigor**: verification & validation (V&V), uncertainty thinking, reproducibility.
- ğŸŒ **Geospatial correctness**: CRS, extent, topology, raster/vector integrity, cartographic discipline.
- ğŸ§  **Model accountability**: regression/ML evaluation, drift detection, calibration, model cards.
- ğŸ•¸ï¸ **Graph integrity**: Neo4j constraints, ontology stability, cross-layer references.
- ğŸ›¡ï¸ **Security posture**: defensive scanning and safe-by-default checks (no offensive tooling).
- âš–ï¸ **Governance**: licensing, provenance, FAIR/CARE-aligned publishing, sovereignty & sensitivity controls.

---

## ğŸ§± Nonâ€‘negotiables we enforce (KFM v13 contracts)

These are *pipeline invariants* â€” theyâ€™re validated as **hard gates**:

- ğŸ” **Canonical pipeline order:** **ETL â†’ Catalogs (STAC/DCAT/PROV) â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**
- ğŸ“¦ **Boundary artifacts required to â€œpublishâ€:** processed data + catalog records + provenance bundle + validation evidence
- ğŸ§© **Evidence artifacts are first-class datasets:** AI/analysis outputs must be stored, cataloged, and traced like any dataset
- ğŸ§· **Cross-layer linkage must be real:** catalogs â†” graph â†” story nodes must reference the same stable IDs (no drift)
- ğŸ§­ **No silent policy downgrade:** classification/sensitivity cannot be reduced unless an approved deâ€‘identification/redaction step is documented and proven
- ğŸ”’ **UI never bypasses governance:** the UI must only expose governed data via the API layer (no direct â€œside loadsâ€)

---

## ğŸ§­ Where validation fits in the KFM v13 pipeline

```mermaid
flowchart LR
  A[ğŸ—ï¸ ETL - data/raw to data/work to data/processed] --> B[ğŸ›°ï¸ Catalogs - STAC + DCAT + PROV]
  B --> C[ğŸ•¸ï¸ Graph - Neo4j references catalogs]
  C --> D[ğŸ§© API - contract + redaction rules]
  D --> E[ğŸ–¥ï¸ UI - maps + timeline + WebGL]
  E --> F[ğŸ“š Story Nodes - citations + graph IDs]
  F --> G[ğŸ§  Focus Mode - evidence backed Q and A]

  V[âœ… tools/validation] -.-> A
  V -.-> B
  V -.-> C
  V -.-> D
  V -.-> E
  V -.-> F
  V -.-> G
```

---

## ğŸ§­ Table of contents

- [âš¡ Quickstart](#-quickstart)
- [âœ… CI gate matrix](#-ci-gate-matrix)
- [ğŸ§± Validation layers](#-validation-layers)
- [ğŸ—‚ï¸ Directory map](#-directory-map)
- [ğŸ“¦ Repo-wide contracts validated](#-repo-wide-contracts-validated)
- [ğŸ›°ï¸ Catalog QA: STAC + DCAT + PROV](#-catalog-qa-stac--dcat--prov)
- [ğŸ•¸ï¸ Graph validation](#ï¸-graph-validation)
- [ğŸŒ Geospatial validation](#-geospatial-validation)
- [ğŸ“ˆ Statistics and ML validation](#-statistics-and-ml-validation)
- [ğŸ§® Modeling and simulation V&V](#-modeling-and-simulation-vv)
- [ğŸ—ƒï¸ Data engineering and database validation](#-data-engineering-and-database-validation)
- [ğŸ–¥ï¸ Web UI and 3D visualization validation](#-web-ui-and-3d-visualization-validation)
- [ğŸ“š Story Nodes and Focus Mode gates](#-story-nodes-and-focus-mode-gates)
- [ğŸ” Security validation](#-security-validation)
- [âš–ï¸ Governance, FAIR+CARE, and sovereignty checks](#ï¸-governance-faircare-and-sovereignty-checks)
- [ğŸ§© Adding a new validator](#-adding-a-new-validator)
- [ğŸ“¦ Artifacts and reporting](#-artifacts-and-reporting)
- [ğŸ—ºï¸ Reference library used by this folder](#-reference-library-used-by-this-folder)

---

## âš¡ Quickstart

Run validations from the **repo root**.

### Option A: Make targets

```bash
make validate
make validate-docs
make validate-catalog     # STAC + DCAT + PROV
make validate-graph
make validate-api
make validate-geo
make validate-stats
make validate-ml
make validate-sim
make validate-db
make validate-web
make validate-story
make validate-security
make validate-governance
```

### Option B: Python module entrypoint

```bash
python -m tools.validation all
python -m tools.validation catalog ./data
python -m tools.validation geo     ./data/processed
python -m tools.validation story   ./docs/story
```

### Option C: CI lanes only

```bash
# run only checks that are mandatory for merge
python -m tools.validation ci
```

> ğŸ§  **Design rule:** every validator must run locally *and* in CI with identical semantics.  
> ğŸ§¾ **Evidence rule:** every validator must emit artifacts (see [Artifacts and reporting](#-artifacts-and-reporting)).

---

## âœ… CI gate matrix

> ğŸ§© Recommended defaults â€” tuned for â€œfail fastâ€ on PRs and â€œdeep verificationâ€ on releases.

| Lane ğŸ§° | PR (required) âœ… | Main (required) âœ… | Release (required) âœ… | Evidence output ğŸ“¦ |
|---|---:|---:|---:|---|
| `docs/` ğŸ“ | âœ… | âœ… | âœ… | Markdown lint + front-matter + link map |
| `policy/` ğŸ§© | âœ… | âœ… | âœ… | Conftest/OPA decision report |
| `catalog/` ğŸ›°ï¸ | âœ… | âœ… | âœ… | Schema validation + cross-link report |
| `graph/` ğŸ•¸ï¸ | âœ… (fixture) | âœ… (fixture) | âœ… (full/expanded) | Constraint & ontology test results |
| `api/` ğŸ§© | âœ… | âœ… | âœ… | Contract tests + schema diffs |
| `geo/` ğŸŒ | âœ… | âœ… | âœ… | CRS/topology/raster reports |
| `stats/` ğŸ“ˆ | âœ… (sanity) | âœ… | âœ… | drift/regression diagnostics |
| `ml/` ğŸ¤– | âœ… (baseline) | âœ… | âœ… | eval + calibration + model card gate |
| `sim/` ğŸ§® | âœ… (smoke) | âœ… | âœ… | invariants + convergence + UQ |
| `db/` ğŸ—ƒï¸ | âœ… | âœ… | âœ… | constraints + explain guard |
| `web/` ğŸ–¥ï¸ | âœ… | âœ… | âœ… | Lighthouse + visual diffs + WebGL smoke |
| `security/` ğŸ” | âœ… | âœ… | âœ… | secrets + deps + SBOM gate (release) |
| `governance/` âš–ï¸ | âš ï¸ triggers | âš ï¸ triggers | âœ… | license + provenance + sensitivity review |

âš ï¸ **Governance note:** Some changes *must* trigger manual review (see [Governance triggers](#ï¸-governance-faircare-and-sovereignty-checks)).

---

## ğŸ§± Validation layers

KFM validation is deliberately **layered** so failures are fast, actionable, and auditable:

1. ğŸ“ **Markdown protocol** (docs + Story Nodes)  
   Front-matter, required sections, citations, link integrity.
2. ğŸ§¹ **Lint & Type**  
   Formatting, static analysis, typing, doc lint.
3. ğŸ“ **Schema**  
   JSON Schema for STAC/DCAT/PROV + Story Node schemas + UI config schemas.
4. ğŸ§© **Policy as code**  
   OPA/Conftest rules (what we *allow* to ship).
5. ğŸ›°ï¸ **Catalog integrity**  
   STAC relationships, links, collections, paging, provenance chains, DCAT distributions.
6. ğŸ•¸ï¸ **Graph integrity**  
   Neo4j constraints, ontology stability, catalog references (no payload duplication).
7. ğŸ§© **API contract**  
   OpenAPI/GraphQL contracts, backward compatibility, redaction rules.
8. ğŸŒ **Geospatial integrity**  
   CRS, extents, topology, raster metadata, no silent reprojection.
9. ğŸ“ˆ **Stats & Drift**  
   sanity checks, distributions, regression diagnostics, anomaly detection.
10. ğŸ¤– **ML evaluation**  
   baselines, cross-validation, calibration, fairness flags, reproducibility.
11. ğŸ§® **Modeling & simulation V&V**  
   numerical checks, conservation checks, convergence, UQ.
12. ğŸ—ƒï¸ **DB & performance**  
   constraints, migrations, query plans, scalability smoke tests.
13. ğŸ–¥ï¸ **UI & viz**  
   accessibility, responsive behavior, WebGL stability, visual regression.
14. ğŸ” **Security**  
   dependency scanning, secrets, SBOM, config hardening checks.
15. âš–ï¸ **Governance**  
   licenses, provenance, sovereignty, publish readiness, review triggers.

---

## ğŸ—‚ï¸ Directory map

> ğŸ§© Recommended layout. Keep conceptual lanes even if filenames differ.

```text
ğŸ§° tools/validation/
â”œâ”€ ğŸ“„ README.md                         ğŸ‘ˆ you are here
â”œâ”€ ğŸ§¾ manifest.yml                      ğŸ§¾ single source of truth for validators
â”œâ”€ ğŸƒ runners/
â”‚  â”œâ”€ ğŸ run_all.py                     ğŸ orchestrator (local + CI)
â”‚  â”œâ”€ ğŸ›£ï¸ run_lane.py                    ğŸ›£ï¸ run one lane by name
â”‚  â””â”€ ğŸ“¦ report.py                      ğŸ“¦ unify outputs into artifacts
â”œâ”€ ğŸ“ docs/
â”‚  â”œâ”€ ğŸ§¾ frontmatter_check.py           ğŸ§¾ YAML front-matter + required sections
â”‚  â”œâ”€ ğŸ”— link_check.py                  ğŸ”— internal links + citation refs
â”‚  â””â”€ ğŸ§ª fixtures/
â”œâ”€ ğŸ§© policy/
â”‚  â”œâ”€ ğŸ§© stac_provenance.rego           ğŸ§© required fields, provenance rules
â”‚  â”œâ”€ âš™ï¸ faircare.rego                  âš™ï¸ sovereignty + sensitive-layer governance
â”‚  â””â”€ ğŸ“˜ conftest.md                    ğŸ“˜ how to run policy gates
â”œâ”€ ğŸ›°ï¸ catalog/
â”‚  â”œâ”€ ğŸ›°ï¸ stac_validate.py               ğŸ›°ï¸ STAC JSON schema + lint
â”‚  â”œâ”€ ğŸ§¾ dcat_validate.py               ğŸ§¾ DCAT schema + distribution checks
â”‚  â”œâ”€ ğŸ§¬ prov_validate.py               ğŸ§¬ PROV bundle validation + lineage checks
â”‚  â””â”€ ğŸ”— crosslink_check.py             ğŸ”— STACâ†”DCATâ†”PROVâ†”Graph link integrity
â”œâ”€ ğŸ•¸ï¸ graph/
â”‚  â”œâ”€ ğŸ§· constraints_check.py           ğŸ§· required labels/properties/uniqueness
â”‚  â”œâ”€ ğŸ§  ontology_regression.py         ğŸ§  â€œdo not breakâ€ ontology tests
â”‚  â””â”€ ğŸ§ª fixtures/                      ğŸ§ª minimal sample graph
â”œâ”€ ğŸ§© api/
â”‚  â”œâ”€ ğŸ“œ openapi_diff.py                ğŸ“œ contract drift guard
â”‚  â”œâ”€ ğŸ§ª contract_tests.py              ğŸ§ª endpoint behavior vs fixtures
â”‚  â””â”€ ğŸ”’ redaction_rules_check.py       ğŸ”’ governance enforcement tests
â”œâ”€ ğŸŒ geo/
â”‚  â”œâ”€ ğŸ§­ check_crs.py                   ğŸ§­ CRS & axis sanity checks
â”‚  â”œâ”€ ğŸ“¦ check_bbox.py                  ğŸ“¦ bbox/extent correctness
â”‚  â”œâ”€ ğŸ§± check_geometries.py            ğŸ§± topology/validity checks
â”‚  â”œâ”€ ğŸ—ºï¸ check_rasters.py               ğŸ—ºï¸ raster metadata + nodata + tiling
â”‚  â””â”€ ğŸ›°ï¸ rs_checks.py                   ğŸ›°ï¸ remote sensing QA (cloud masks, bands, scaling)
â”œâ”€ ğŸ“ˆ stats/
â”‚  â”œâ”€ ğŸ“ˆ drift_checks.py                ğŸ“ˆ distribution + drift
â”‚  â”œâ”€ ğŸ“‰ regression_diagnostics.py      ğŸ“‰ residuals, leverage, outliers
â”‚  â””â”€ ğŸ“Š eda_report.R                   ğŸ“Š optional R-based visual EDA report
â”œâ”€ ğŸ¤– ml/
â”‚  â”œâ”€ ğŸ§  eval_baselines.py              ğŸ§  metrics + baselines
â”‚  â”œâ”€ ğŸ¯ calibration.py                 ğŸ¯ calibration + uncertainty
â”‚  â””â”€ ğŸªª model_card_check.py            ğŸªª model card completeness gate
â”œâ”€ ğŸ§® sim/
â”‚  â”œâ”€ ğŸ§® invariants.py                  ğŸ§® conservation / invariants
â”‚  â”œâ”€ ğŸ“ convergence.py                 ğŸ“ grid/time-step convergence
â”‚  â””â”€ ğŸŒ«ï¸ uq.py                          ğŸŒ«ï¸ uncertainty quantification helpers
â”œâ”€ ğŸ—ƒï¸ db/
â”‚  â”œâ”€ ğŸ—ƒï¸ constraints.sql                ğŸ—ƒï¸ constraints & invariants
â”‚  â”œâ”€ ğŸŒ postgis_checks.sql             ğŸŒ geometry validity & SRID checks
â”‚  â””â”€ âš¡ explain_guard.py               âš¡ query plan smoke tests
â”œâ”€ ğŸ–¥ï¸ web/
â”‚  â”œâ”€ ğŸ’¡ lighthouse_ci/                 ğŸ’¡ performance + accessibility
â”‚  â”œâ”€ ğŸ–¼ï¸ visual_regression/             ğŸ–¼ï¸ map + legend snapshots
â”‚  â”œâ”€ ğŸ® webgl_smoke/                   ğŸ® context + capability checks
â”‚  â””â”€ ğŸ–¼ï¸ media_format_check.py          ğŸ–¼ï¸ PNG/JPEG/GIF format & metadata checks
â”œâ”€ ğŸ“š story/
â”‚  â”œâ”€ ğŸ§¾ story_schema_check.py          ğŸ§¾ Story Node schema + front-matter
â”‚  â”œâ”€ ğŸ”— citation_gate.py               ğŸ”— every claim references evidence
â”‚  â””â”€ ğŸ§· graph_ref_check.py             ğŸ§· references to stable graph IDs
â”œâ”€ ğŸ§  focus/
â”‚  â”œâ”€ ğŸ§ª focus_mode_gate.py             ğŸ§ª evidence-only response constraints
â”‚  â””â”€ ğŸ·ï¸ labeling_check.py              ğŸ·ï¸ fact vs interpretation labeling
â”œâ”€ ğŸ” security/
â”‚  â”œâ”€ ğŸ” secrets_scan.yml               ğŸ” secrets policy
â”‚  â”œâ”€ ğŸ“¦ sbom_check.py                  ğŸ“¦ SBOM presence & diffs
â”‚  â””â”€ ğŸ§· dependency_audit.py            ğŸ§· dependency health checks
â”œâ”€ âš–ï¸ governance/
â”‚  â”œâ”€ ğŸ“œ license_check.py               ğŸ“œ license presence + compatibility
â”‚  â”œâ”€ ğŸ§¾ provenance_completeness.py     ğŸ§¾ provenance required for publish
â”‚  â””â”€ ğŸ review_triggers.py             ğŸ flags manual governance review
â””â”€ ğŸ“¦ artifacts/
   â””â”€ ğŸ“Œ .gitkeep                        ğŸ“¦ CI writes reports here
```

---

## ğŸ“¦ Repo-wide contracts validated

These validations intentionally â€œreach outsideâ€ this folder because the contracts are repo-wide.

<details>
<summary><strong>ğŸ“ Expected data lifecycle layout (validated)</strong></summary>

```text
data/
â”œâ”€ raw/<domain>/                # source materials (immutable inputs)
â”œâ”€ work/<domain>/               # intermediates (re-buildable)
â”œâ”€ processed/<domain>/          # publishable outputs (versioned)
â”œâ”€ stac/                        # STAC catalogs (collections + items)
â”œâ”€ catalog/dcat/                # DCAT discovery layer
â””â”€ prov/                        # PROV bundles (how outputs were produced)
docs/
â””â”€ data/<domain>/               # domain runbooks + source documentation
```

</details>

âœ… **Domain expansion rule:** new domains must be isolated by folder and published through STAC/DCAT/PROV, not via adâ€‘hoc metadata.

---

## ğŸ›°ï¸ Catalog QA: STAC + DCAT + PROV

KFM treats catalogs as **product surfaces**: if catalogs drift, the UI and narratives drift.

### âœ… Required alignment (hard gate)

Every **new dataset or evidence artifact** must include:

- ğŸ›°ï¸ **STAC** Collection + Item(s) (even for many â€œnon-spatialâ€ datasets, for consistency)
- ğŸ§¾ **DCAT** Dataset entry (title, description, license, keywords, distribution links)
- ğŸ§¬ **PROV** activity bundle (inputs â†’ steps â†’ outputs, agents, parameters, run IDs)

### ğŸ”— Cross-layer linkage expectations (hard gate)

- **STAC Items â†’ Data**: items must link to real assets in `data/processed/**` (or stable storage) and carry attribution + license.
- **DCAT â†’ Distribution**: DCAT must link to the STAC record and/or direct downloads.
- **PROV end-to-end**: lineage must cover raw â†’ work â†’ processed, including run/config identifiers.
- **Graph references catalogs**: Neo4j stores IDs/refs (STAC IDs, DOIs), not bulky payloads.

### ğŸ§¾ Example â€œrequired fieldsâ€ pattern (STAC-ish)

```json
{
  "stac_version": "1.0.0",
  "stac_extensions": [
    "https://stac-extensions.github.io/projection/v2.0.0/schema.json"
  ],
  "properties": {
    "kfm:mdp_version": "v13.x.y",
    "proj:epsg": 4326,
    "kfm:classification": "public",
    "kfm:sensitivity": "open"
  },
  "providers": [
    { "name": "Kansas Frontier Matrix", "roles": ["processor"] }
  ],
  "license": "CC-BY 4.0",
  "links": [
    {
      "rel": "derived_from",
      "href": "stac://raw/source_asset_01",
      "type": "application/json",
      "title": "Provenance chain"
    }
  ]
}
```

### ğŸ§¬ Versioning expectations (validated)

- Dataset revisions link back via PROV/DCAT (e.g., `prov:wasRevisionOf`)
- Graph schema stays backward compatible unless migrated (with explicit scripts)
- API breaking changes require versioned endpoints/contracts
- Repo releases follow semantic versioning (major breaks, minor additive changes)

---

## ğŸ•¸ï¸ Graph validation

KFMâ€™s graph is the **relationship layer** â€” it should not become a shadow data lake.

### âœ… What we validate

- required labels/types exist (ontology â€œdo not breakâ€ rules)
- uniqueness constraints (stable IDs are stable)
- relationship validity (no impossible edges, no orphan nodes)
- catalog references exist (graph nodes reference STAC/DCAT/DOIs, not payload blobs)
- regression tests on fixtures to catch unintended ontology changes early

> ğŸ§  Bonus (optional lane): graph analytics reproducibility checks (e.g., clustering outputs are versioned and re-runnable).

---

## ğŸŒ Geospatial validation

Geospatial validation is split into **format**, **geometry**, and **meaning**.

### âœ… Format and metadata

- Raster:
  - CRS defined and consistent
  - nodata present and sane
  - tiling and overviews for web delivery when required
- Vector:
  - valid geometries (no self-intersections, no NaNs)
  - SRID set and consistent
  - attribute schemas stable

### âœ… Spatial integrity

- bbox matches geometry/raster extent
- no accidental axis flips
- reprojection performed deliberately (and recorded in PROV)
- tolerances documented (meters vs degrees)

### âœ… Remote sensing QA (Earth Engine & friends)

- band naming + scaling factors + QA bits are explicit
- cloud/shadow masks are applied or explicitly documented as absent
- temporal compositing rules are declared and reproducible
- spatial resolution and resampling strategy are recorded

### âœ… Cartographic integrity (maps are validated assets ğŸ¨)

- legends are complete (every layer class has a key)
- ramps are consistent across releases
- accessibility constraints (contrast + colorblind safety) are checked via UI snapshot tests

---

## ğŸ“ˆ Statistics and ML validation

### Statistical sanity checks ğŸ“Š

- distribution checks (range, missingness, spikes)
- drift detection between releases
- outlier audit trails (why a point is extreme)

### Regression diagnostics ğŸ“‰

- residual behavior checks (assumptions + anomalies)
- leverage & influence
- multicollinearity flags
- train/test leakage detectors

### Bayesian checks ğŸ²

- posterior predictive checks
- calibration diagnostics
- uncertainty reporting requirements (when UI shows â€œconfidenceâ€)

### Deep learning checks ğŸ¤–

- learning curve artifacts
- overfitting detection gates
- reproducibility checks (seeds, deterministic ops when feasible)

---

## ğŸ§® Modeling and simulation V&V

We follow a NASA-grade mindset ğŸš€:

- âœ… **Code verification**: â€œdid we implement the equations right?â€
- âœ… **Solution verification**: â€œdid we solve the equations accurately?â€
- âœ… **Validation**: â€œdoes the model match reality for the intended use?â€
- ğŸŒ«ï¸ **Uncertainty quantification**: â€œhow wrong might we be, and why?â€

Suggested checks:

- invariants and conservation laws
- mesh/time-step convergence
- sensitivity analysis
- benchmark problems (analytic/empirical references)
- uncertainty reporting (what uncertainty is, how computed, how propagated)

---

## ğŸ—ƒï¸ Data engineering and database validation

### PostgreSQL and PostGIS ğŸ˜ğŸŒ

- constraints are enforced (NOT NULL, FK, CHECK)
- geometry validity enforced in DB (SRID + validity checks)
- migration safety checks (no destructive changes without flags)
- query plan smoke tests (EXPLAIN guardrails)

### Scalability and performance âš¡

- benchmark queries (representative workloads)
- plan regressions (EXPLAIN guardrails)
- concurrency-aware smoke tests (avoid nondeterministic flakes)

### Data Spaces mindset ğŸ§©

When data is federated, validation must travel with it:

- interoperability checks (contracts, schemas, semantics)
- trust checks (provenance, policy compliance)
- governance checks (usage controls, licensing posture)

---

## ğŸ–¥ï¸ Web UI and 3D visualization validation

### Responsive and accessibility ğŸ“±â™¿

- responsive breakpoints donâ€™t break map usability
- keyboard navigation works
- ARIA labels exist for core controls
- map legends are readable and consistent

### WebGL stability ğŸ®

- context creation smoke tests
- capability detection
- crash regression tests on shader changes
- performance budgets for critical scenes

### Visual regression testing ğŸ–¼ï¸

Mandatory for map-heavy products:

- layer snapshots pinned per release
- legend snapshots pinned per release
- tolerance-based image diffs
- â€œsemantic diffsâ€ for vector symbology when possible

### Media format correctness ğŸ–¼ï¸

- snapshots use appropriate formats (lossless where required)
- metadata sanity (dimensions, color profiles where relevant)
- no accidental recompression that changes meaning

---

## ğŸ“š Story Nodes and Focus Mode gates

Story Nodes turn narrative into **governed, machine-ingestible research**.

### âœ… Story Node requirements (hard gate)

- ğŸ“Œ **Provenance for every claim**: every factual statement references evidence (KFM catalogs or cataloged external sources)
- ğŸ§· **Graph entity references**: key entities are linked to stable graph identifiers
- ğŸ§  **Fact vs interpretation separation**: narrative distinguishes direct evidence from inference/analysis

### ğŸ§  Focus Mode rules (hard gate)

Focus Mode is an interactive reading experience that must preserve trust:

- answers must be evidence-backed and cite sources
- AI assistance must be opt-in, labeled, and constrained (no unsourced claims)
- sensitivity and sovereignty controls are respected end-to-end
- no direct UI bypass of the API governance layer

---

## ğŸ” Security validation

Defensive checks only âœ…

- secrets scanning (keys, tokens, credentials)
- dependency audits (known vulnerable versions)
- SBOM required for release artifacts
- config sanity checks (CORS, CSP, headers)
- repository hygiene checks (unsafe CI patterns, risky runner configs)

> ğŸ›¡ï¸ **Important:** we do not ship offensive security tooling in this folder.  
> Security references are used for **defensive hardening and awareness**.

---

## âš–ï¸ Governance, FAIR+CARE, and sovereignty checks

These checks exist because KFM is **not** just a codebaseâ€”itâ€™s a public-facing research tool.

### âœ… Automated governance checks

- license presence + compatibility
- provenance chain completeness
- â€œsensitive layerâ€ publishing rules
- FAIR/CARE posture (especially for culturally sensitive content)
- AI governance checks (model cards, dataset cards, limitations, disclosures)

### ğŸ§¯ Governance review triggers (manual)

Some changes require a human review beyond CI:

- introducing sensitive or sovereignty-governed datasets/layers
- new AI-driven narrative features that could be perceived as factual
- new external data sources (license/provenance scrutiny)
- new public-facing endpoints/exports that could expose sensitive info
- classification/sensitivity changes (reclassification must be justified and documented)

### ğŸ§Š Redaction and generalization (must be end-to-end)

If data is sensitive, controls must apply at every layer:

- processed data is redacted/generalized
- STAC/DCAT metadata reflects the redaction
- API enforces access rules and labeling
- UI adds safeguards (no accidental leakage via interactions)

---

## ğŸ§© Adding a new validator

A validator is considered â€œKFM-gradeâ€ when it has:

- âœ… deterministic behavior
- âœ… clear input contract (what it consumes)
- âœ… explicit output artifacts (what evidence it produces)
- âœ… an exit code contract (pass/fail/warn)
- âœ… a CI lane mapping (where it runs)
- âœ… a fixture (minimum reproducible test case)

### Checklist âœ…

- [ ] Add your validator under the appropriate lane folder  
- [ ] Register it in `tools/validation/manifest.yml`  
- [ ] Ensure it writes artifacts under `tools/validation/artifacts/<lane>/<validator-name>/`  
- [ ] Provide at least one fixture in `fixtures/`  
- [ ] Add it to CI lane runner  
- [ ] Document it in this README (one paragraph + example run)

### Example manifest entry (illustrative)

```yaml
validators:
  - name: "catalog.crosslink_check"
    lane: "catalog"
    entrypoint: "tools.validation.catalog.crosslink_check:main"
    inputs:
      - "data/stac/**"
      - "data/catalog/dcat/**"
      - "data/prov/**"
    outputs:
      - "tools/validation/artifacts/catalog/crosslink_check/**"
    severity: "error"
    ci:
      - "pr"
      - "release"
```

---

## ğŸ“¦ Artifacts and reporting

All validators should emit:

- `report.json` (machine-readable)
- `report.md` (human-readable summary)
- `junit.xml` (CI-friendly)
- optional: plots, snapshots, diffs, notebook exports
- optional: `manifest.json` with checksums for evidence bundles

Recommended folder pattern:

```text
tools/validation/artifacts/
â””â”€ <lane>/
   â””â”€ <check>/
      â”œâ”€ report.json
      â”œâ”€ report.md
      â”œâ”€ junit.xml
      â””â”€ extras/
```

> ğŸ“Œ Tip: prefer **artifacts over caches** for anything you need to audit later.

---

## ğŸ—ºï¸ Reference library used by this folder

This validation suite is intentionally grounded in KFMâ€™s internal reference library ğŸ“š  
These files inform *how we define correctness* across science, geospatial, UI, security, and governance.

### Core KFM protocols & architecture

- `MARKDOWN_GUIDE_v13.md.gdoc` ğŸ§­ *(canonical pipeline + contracts + CI gates)*
- `Comprehensive Markdown Guide_ Syntax, Extensions, and Best Practices.docx` ğŸ“ *(front-matter + DoD patterns)*
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf` ğŸ—ï¸ *(system design + governance + roadmap)*

> ğŸ§¾ Standards referenced by validation (expected paths):
> - `docs/standards/KFM_STAC_PROFILE.md`
> - `docs/standards/KFM_DCAT_PROFILE.md`
> - `docs/standards/KFM_PROV_PROFILE.md`

### Modeling, simulation, and math ğŸ§®

- `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf` ğŸš€
- `Generalized Topology Optimization for Structural Design.pdf` ğŸ§±
- `Spectral Geometry of Graphs.pdf` ğŸ§ 

### Statistics, experiment design, and ML ğŸ“ˆ

- `Understanding Statistics & Experimental Design.pdf` ğŸ§ª
- `regression-analysis-with-python.pdf` ğŸ“‰
- `Regression analysis using Python - slides-linear-regression.pdf` ğŸ“
- `think-bayes-bayesian-statistics-in-python.pdf` ğŸ²
- `graphical-data-analysis-with-r.pdf` ğŸ“Š
- `Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf` ğŸ¤– *(reference; availability may vary)*

### Geospatial, cartography, remote sensing, and 3D GIS ğŸŒ

- `python-geospatial-analysis-cookbook.pdf` ğŸŒ
- `making-maps-a-visual-guide-to-map-design-for-gis.pdf` ğŸ¨
- `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf` ğŸ“±
- `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf` ğŸ›°ï¸
- `Archaeological 3D GIS_26_01_12_17_53_09.pdf` ğŸº

### Data management and databases ğŸ—ƒï¸

- `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf` ğŸ˜
- `Database Performance at Scale.pdf` âš¡
- `Scalable Data Management for Future Hardware.pdf` ğŸ§±âš¡
- `Data Spaces.pdf` ğŸ§©

### Web, visualization, and media formats ğŸ–¥ï¸

- `responsive-web-design-with-html5-and-css3.pdf` ğŸ“±
- `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf` ğŸ®
- `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf` ğŸ–¼ï¸

### Concurrency, distributed systems, and software practice ğŸ§µ

- `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf` ğŸ§µ
- `A programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `B-C programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `D-E programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `F-H programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `I-L programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `M-N programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `O-R programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `S-T programming Books.pdf` ğŸ§° *(multi-book compendium)*
- `U-X programming Books.pdf` ğŸ§° *(multi-book compendium)*

### Governance, law, and human-centered constraints âš–ï¸

- `Introduction to Digital Humanism.pdf` ğŸ¤
- `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf` âš–ï¸
- `Principles of Biological Autonomy - book_9780262381833.pdf` ğŸ§¬

### Security references ğŸ”

- `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf` ğŸ›¡ï¸
- `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf` âš ï¸ *(defensive awareness only)*

---

<div align="center">

**KFM Validation Toolkit** Â· ğŸ§ª Evidence-driven Â· ğŸ›°ï¸ Catalog-first Â· ğŸ•¸ï¸ Graph-consistent Â· ğŸŒ Geo-correct Â· ğŸ” Defensive Â· âš–ï¸ Governed

</div>
