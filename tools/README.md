<!--
ğŸ“Œ tools/ is the repoâ€™s *governed toolchain surface* for building + validating KFM artifacts.
ğŸ—“ï¸ Last updated: 2026-01-20
ğŸ” Review cycle: 90 days (or anytime pipeline order / catalogs / policy changes)
ğŸ§­ Alignment: Master Guide v13 (contract-first + evidence-first + one canonical home per subsystem)
ğŸ§ª Scientific posture: Verification + Validation + Uncertainty Quantification (V&V&UQ) for anything â€œmodel-yâ€
-->

> According to a document set updated through **2026-01-20**, `tools/` is the **governed command surface** for building + validating KFM artifacts â€” and it must preserve the v13 pipeline order, provenance-first publishing, and citation-required Focus Mode. ğŸ§¾âœ…[^kfm_v13]

<div align="center">

# ğŸ› ï¸ `tools/` â€” Kansas Frontier Matrix (KFM) Toolchain

**Deterministic â€¢ Provenance-aware â€¢ CI-friendly**  
**Build it once â€¢ verify it forever â€¢ ship with a paper trail** ğŸ§¾âœ…

![Python](https://img.shields.io/badge/Python-3.11%2B-informational)
![Node](https://img.shields.io/badge/Node-18%2B-informational)
![Docker](https://img.shields.io/badge/Docker-optional%20%28dev%2FCI%29-informational)
![License](https://img.shields.io/badge/license-MIT-success)

![Contract-first](https://img.shields.io/badge/contract--first-schemas%20%2B%20API-blue)
![Evidence-first](https://img.shields.io/badge/evidence--first-catalogs%20%2B%20PROV-blueviolet)
![Provenance-first](https://img.shields.io/badge/provenance--first-no%20publish%20without%20PROV-red)
![Catalog-first](https://img.shields.io/badge/catalog--first-STAC%20%7C%20DCAT%20%7C%20PROV-blue)
![Policy-as-code](https://img.shields.io/badge/policy--as--code-OPA%20%2F%20Conftest-ff7a00)
![SBOM](https://img.shields.io/badge/SBOM-SPDX%20%7C%20CycloneDX-2ea043)
![SLSA-ish](https://img.shields.io/badge/SLSA-ish-attestations-8b5cf6)

![GeoParquet](https://img.shields.io/badge/GeoParquet-analytics-2ea043)
![COG](https://img.shields.io/badge/COG-rasters-1f6feb)
![PMTiles](https://img.shields.io/badge/PMTiles-vector%20tiles-8250df)
![OCI](https://img.shields.io/badge/OCI-artifact%20registry-8b5cf6)
![ORAS](https://img.shields.io/badge/ORAS-transfer-8b5cf6)
![Cosign](https://img.shields.io/badge/Cosign-signing-8b5cf6)

![STAC](https://img.shields.io/badge/STAC-catalogs-1f6feb)
![DCAT](https://img.shields.io/badge/DCAT-discovery-8250df)
![PROV](https://img.shields.io/badge/PROV-lineage-8250df)
![Neo4j](https://img.shields.io/badge/Neo4j-graph-00ba7c)
![PostGIS](https://img.shields.io/badge/PostGIS-spatial%20DB-2d6cdf)
![MapLibre](https://img.shields.io/badge/MapLibre-2D%20maps-1f6feb)
![Cesium](https://img.shields.io/badge/Cesium-optional%203D-6f42c1)

</div>

> **TL;DR:** `tools/` is the **governed toolchain** that builds, validates, and packages KFM artifacts **without bypassing governance**.  
> Tools are **CI-safe** by design: deterministic defaults, clear contracts, fast QA gates, provenance emission, and policy checks.

> [!IMPORTANT]
> **MCP** = **Methods, Controls & Processes** *(a.k.a. â€œMaster Coder Protocolâ€ â€” lab notebook + receipts)* ğŸ§ªğŸ§¾  
> `tools/` must support MCP workflows by producing **re-run-able** outputs and **linkable** provenance â€” without becoming â€œbusiness logic.â€[^mcp_receipts]

---

<details>
<summary><b>ğŸ§­ Table of contents</b></summary>

- [ğŸ§  Quick links](#quick-links)
- [ğŸ§­ Repo invariants](#repo-invariants)
- [ğŸ§± The non-negotiable ordering](#non-negotiable-ordering)
- [ğŸ¯ What belongs in tools](#what-belongs-in-tools)
- [ğŸ§­ Boundaries: tools vs scripts vs src vs mcp](#boundaries)
- [ğŸ¤– Agent toolchain: Watcherâ€“Plannerâ€“Executor](#agent-toolchain)
- [ğŸ§¾ Contracts & schemas](#contracts-and-schemas)
- [ğŸ“¦ Data staging + catalog locations](#data-staging)
- [ğŸ§© Dual-format packaging: GeoParquet + PMTiles](#dual-format-packaging)
- [ğŸ§± Tool contract](#tool-contract)
- [ğŸ§¾ Run manifests & JSON canonicalization](#run-manifests)
- [ğŸ² Determinism & reproducibility levels](#determinism)
- [ğŸ§ª Artifact QA matrix](#qa-matrix)
- [ğŸ“¡ Telemetry & observability](#telemetry)
- [ğŸ“ Expected folder layout](#expected-layout)
- [ğŸ” Common workflows](#common-workflows)
- [âœ… Validation & QA gates](#validation-gates)
- [ğŸ” Provenance, SBOM, attestations, releases](#provenance-sbom-attestations)
- [ğŸ“¦ OCI artifact registry distribution](#oci-distribution)
- [ğŸ“¦ Offline packs & field ops](#offline-packs)
- [ğŸ§µ Pulse Threads & Concept Nodes](#pulse-threads)
- [ğŸ—ºï¸ Geo & mapping utilities](#geo-mapping)
- [ğŸ›°ï¸ Remote sensing utilities](#remote-sensing)
- [ğŸ§Š Imaging & compression utilities](#imaging-compression)
- [ğŸ§± 3D / WebGL / scene utilities](#3d-visualization)
- [ğŸ©º Graph health checks](#graph-health)
- [ğŸ§  Graph & DB utilities](#graph-db)
- [ğŸ“Š Statistical evidence utilities](#stats-evidence)
- [ğŸ§ª Modeling/ML/simulation utilities](#modeling-ml-simulation)
- [ğŸ” Security posture](#security-posture)
- [âš¡ Performance & scaling notes](#performance-scaling)
- [ğŸŒ Federation & cross-matrix interoperability](#federation)
- [ğŸ§© Contributing a new tool](#contributing)
- [ğŸ“š Project reference library](#reference-library)
- [ğŸ§¾ Metadata](#metadata)
- [ğŸ•°ï¸ Version history](#version-history)

</details>

---

<a id="quick-links"></a>
## ğŸ§  Quick links

- ğŸ“˜ Canonical repo guide (v13) â†’ `docs/MASTER_GUIDE_v13.md`[^kfm_v13]
- ğŸ§¾ KFM STAC/DCAT/PROV alignment (v13) â†’ `docs/standards/` + `schemas/`[^stac_dcat_prov]
- ğŸ“– Glossary (shared language) â†’ `docs/glossary.md`
- ğŸ“ Schemas & contracts (source of truth) â†’ `schemas/`
- ğŸ§ª Research workflow + run receipts â†’ `mcp/README.md`[^mcp_receipts]
- ğŸ§ª Canonical pipelines (ETL code) â†’ `src/pipelines/`
- ğŸ•¸ï¸ Graph build & ontology bindings â†’ `src/graph/`
- ğŸ›¡ï¸ API boundary (contracts + redaction) â†’ `src/server/` (UI does **not** query graph directly)[^kfm_v13]
- ğŸŒ UI (React Â· MapLibre Â· optional Cesium) â†’ `web/`[^ui_provenance_exports]
- ğŸ—‚ï¸ Data lifecycle + catalogs â†’ `data/README.md` (and the staging layout below)[^data_layout]
- ğŸ§· Governance gates â†’ `docs/governance/REVIEW_GATES.md`
- ğŸ›¡ï¸ Policy pack (OPA / Conftest) â†’ `tools/validation/policy/*.rego`[^policy_pack]
- ğŸ” Releases (bundles, SBOMs, attestations) â†’ `releases/`
- ğŸ§¾ Citation metadata (software + snapshots) â†’ `CITATION.cff`
- âœ… Tests â†’ `tests/README.md`

---

<a id="repo-invariants"></a>
## ğŸ§­ Repo invariants

> [!IMPORTANT]
> These are **guardrails**, not preferences. If a tool would violate these, redesign the tool.

### âœ… One canonical home per subsystem ğŸ§±
No mystery duplicates. If logic belongs in:
- pipelines â†’ `src/pipelines/`
- graph â†’ `src/graph/`
- API boundary â†’ `src/server/`
- UI â†’ `web/`
- schemas â†’ `schemas/`
- governed narratives â†’ `docs/reports/story_nodes/`

### âœ… Contract-first ğŸ“
Schemas and API contracts are **first-class artifacts**:
- implementations must conform
- changes require versioning and compatibility checks
- tools should validate against contracts by default

### âœ… Evidence-first + provenance-first ğŸ§¾ğŸ§¬
No â€œpublished-lookingâ€ output without boundary artifacts:
- **STAC + DCAT + PROV** are required before:
  - graph ingest
  - API exposure
  - UI or Story Node usage[^stac_dcat_prov]
- **Raw data is immutable**; â€œworkâ€ is ephemeral; â€œprocessedâ€ is governed evidence.[^immutability]
- **Large artifacts may live outside Git** (OCI registry / DVC / artifact store) *only* if catalogs + PROV remain the canonical â€œtruth boundary.â€[^oci_registry][^dvc]

### âœ… Deterministic by default ğŸ²ğŸš«
Given the same inputs + config + seed, tools must produce the same outputs (ordering included).[^immutability]

### âœ… The ordering is a governance boundary ğŸ§±ğŸ”’
Pipeline order is **absolute** (tools must not provide shortcuts).[^kfm_v13]

### âœ… Focus Mode is citation-required (and advisory) ğŸ§ ğŸ§¾
Focus Mode must cite sources and can refuse if citations canâ€™t be produced.[^focus_mode]

### âœ… Human-centered + sovereignty-aware ğŸŒ¾ğŸ§‘â€ğŸ¤â€ğŸ§‘
Tools are not just â€œcode runnersâ€ â€” they shape **decision artifacts**:
- respect consent, agency, and auditability
- treat policy & classification as **data**, enforced by gates[^sensitivity]
- default to *least surprise* and *least privilege*

---

<a id="non-negotiable-ordering"></a>
## ğŸ§± The non-negotiable ordering

> [!IMPORTANT]
> This ordering is not â€œarchitecture style.â€ Itâ€™s a **governance boundary**.[^kfm_v13]

**Raw â†’ Work/ETL â†’ Processed â†’ Catalogs (STAC/DCAT/PROV + QA) â†’ Graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode**

```mermaid
flowchart LR
  A["ğŸ“¥ Raw (immutable)<br/>data/raw/<domain>/"] --> B["ğŸ§ª Work / ETL (scratch)<br/>data/work/<domain>/"]
  B --> C["ğŸ“¦ Processed (publishable artifacts)<br/>data/processed/<domain>/"]
  C --> D["ğŸ—‚ï¸ Catalog boundary artifacts<br/>data/stac + data/catalog/dcat + data/prov<br/>+ QA gates"]
  D --> E["ğŸ•¸ï¸ Graph ingest<br/>(Neo4j; references catalogs)"]
  E --> F["ğŸ›¡ï¸ APIs<br/>(contracts + redaction)"]
  F --> G["ğŸŒ UI<br/>(React Â· MapLibre Â· optional Cesium)"]
  G --> H["ğŸ“š Story Nodes<br/>(governed narratives)"]
  H --> I["ğŸ¯ Focus Mode<br/>(evidence-linked context)"]
```

**Practical implication:** `tools/` must never create **published-looking outputs** that skip **catalog + provenance**.

---

<a id="what-belongs-in-tools"></a>
## ğŸ¯ What belongs in tools

`tools/` is for **reusable, CI-friendly tooling** that builds/validates artifacts in the governed pipeline.

âœ… Good fits:
- **Catalog QA gates** (STAC/DCAT/PROV schema + link + required-field checks)
- **Deterministic ID/hashing utilities** (stable IDs, checksums, manifests)
- **Format and integrity tooling** (COG validation, GeoParquet schema checks, geometry validity)
- **Policy enforcement tooling** (OPA/Conftest policy pack; no-downgrade rules; â€œno publish without provenanceâ€)[^policy_pack]
- **Graph/DB loaders** that **ingest from catalogs** (not ad-hoc inserts)
- **Release packaging** (SBOM generation, signatures, attestations)
- **CI entrypoints** (non-interactive, stable exit codes)
- **Scientific integrity harnesses** (V&V, UQ smoke checks, regression tests)[^mcp_receipts]
- **Agent wrappers** that only operate via reviewable artifacts (Watcher/Planner/Executor that opens PRs, emits receipts, and never â€œhot-patchesâ€ main)[^wpe]
- **Library ingestion & extraction** (e.g., extract PDF Portfolios into a normal folder + manifest for indexing)[^pdf_portfolios]
- **Content artifact helpers** that remain governed:
  - Story Node evidence manifests + PROV stubs (citation â†” manifest consistency checks)[^story_manifest]
  - Pulse Threads + Concept Nodes generation/validation (draft-by-default, PR-based)[^pulse_threads][^concept_nodes]
- **Graph health checks** and weekly integrity reports (orphan scan, constraint check, drift summary)[^graph_health]
- **Artifact distribution helpers** for large binaries (OCI registry push/pull + signing; catalog pointers stay canonical)[^oci_registry]

ğŸš« Not a good fit:
- Long-lived services (APIs, daemons) â†’ runtime/app folders
- Core domain/business logic â†’ `src/` (importable, testable modules)
- One-off â€œforever scriptsâ€ that bypass provenance and approvals â†’ keep in sandbox until promoted
- Anything that canâ€™t run non-interactively (or canâ€™t be made CI-safe)

---

<a id="boundaries"></a>
## ğŸ§­ Boundaries: tools vs scripts vs src vs mcp

### `src/` = canonical behavior (the engine) ğŸ—ï¸
- ETL jobs (`src/pipelines/`), graph build (`src/graph/`), API logic (`src/server/`), reusable libs.

### `tools/` = governed toolchain (the verified command surface) ğŸ› ï¸
- Thin entrypoints that call canonical modules, run validators, emit provenance, and produce release-quality artifacts.

### `scripts/` = convenience orchestration (the buttons/levers) ğŸ§°
- Local ops, developer helpers, environment glue.
- Preferred pattern: **scripts call tools**, tools call src.

### `mcp/` = receipts & scientific record (the lab notebook) ğŸ§ªğŸ§¾
- Run receipts, experiment logs, model cards, governance checklists.[^mcp_receipts]

> [!TIP]
> If youâ€™re implementing core behavior inside `tools/`, thatâ€™s a smell.  
> Put the logic in `src/` and keep `tools/` as a predictable CLI + validator layer.

---

<a id="agent-toolchain"></a>
## ğŸ¤– Agent toolchain: Watcherâ€“Plannerâ€“Executor

KFM supports **agent-assisted workflows** â€” but only when they behave like **governed tools** (deterministic, reviewable, provenance-emitting). The recommended structure is **Watcherâ€“Plannerâ€“Executor**.[^wpe]

### ğŸ›°ï¸ Watcher (detect change â†’ propose)
- Scans a defined surface (e.g., new files in a drop folder, updated feeds, new imagery, changed catalog entries).
- Emits an **immutable event** / proposal artifact:
  - `event.json` (what changed, where, why it matters)
  - proposed `plan.json` inputs (but does **not** run destructive changes)
- Default: **no network** unless `--allow-network` is set.

### ğŸ§­ Planner (propose plan â†’ deterministic, diffable)
- Takes Watcher events and produces a **deterministic plan**:
  - exact tool invocations
  - expected inputs/outputs
  - policy gates to run
  - rollback / failure behavior
- Writes a plan artifact that is:
  - stable-sorted
  - hashed
  - human-readable & machine-readable
- Must incorporate governance rules (e.g., FAIR+CARE constraints, sensitivity labels, and â€œno publish without provenanceâ€).[^policy_pack][^sensitivity]

### ğŸ§¾ Executor (apply plan â†’ PR-based + attested)
- Executes the plan in a controlled environment.
- Produces:
  - updated artifacts (data + catalogs + prov)
  - structured reports
  - MCP run receipt
- **Opens a pull request** (or produces a patch) rather than mutating protected branches.
- Attaches **SBOMs + SLSA-ish attestations** for the automated output (especially if generated/packaged by the agent).[^wpe]

> [!IMPORTANT]
> â€œAutomationâ€ in KFM is not a bypass â€” itâ€™s a **more disciplined contributor**.  
> If a human would need to pass gates, an agent does too.

---

<a id="contracts-and-schemas"></a>
## ğŸ§¾ Contracts & schemas

> [!IMPORTANT]
> **Schemas live at repo root:** `schemas/` is the canonical source of truth.  
> Tools must validate against these contracts by default.

### âœ… What counts as a â€œcontract artifactâ€
- JSON Schema (STAC/DCAT/PROV, Story Nodes, UI configs, telemetry)
- API boundary contracts (OpenAPI, GraphQL SDL, typed request/response)
- Tool manifests (optional) describing inputs/outputs, gates, and network posture
- **Data contract metadata** describing dataset schema, units, provenance hooks, and sensitivity
- **Domain design packs** (recommended): small â€œspec packetsâ€ per domain (units, preprocessing, metrics, certainty budgets) that tools can validate and use consistently.[^concept_nodes]

### âœ… Where tools should look
- `schemas/` â†’ JSON schemas (STAC/DCAT/PROV/storynodes/ui/telemetry)
- `docs/standards/` â†’ KFM profiles and governance rules (STAC/DCAT/PROV profiles, repo structure standard)[^stac_dcat_prov]

### ğŸ§¾ Data contract metadata (dataset-level) ğŸ“¦
For any dataset that will become evidence, require a dataset metadata file that includes:
- schema/fields + units
- coordinate reference system expectations (where applicable)
- license + attribution
- sensitivity/classification tags[^sensitivity]
- expected spatial/temporal bounds (where applicable)
- pointers to where STAC/DCAT/PROV will be emitted

---

<a id="data-staging"></a>
## ğŸ“¦ Data staging + catalog locations

KFM data work is staged and traceable, with **one canonical home per dataset**.[^data_layout]

### âœ… Canonical staging pattern (v13)

```text
data/
â”œâ”€â”€ sources/                     # retrieval manifests + checksums + licenses (recommended)
â”œâ”€â”€ raw/
â”‚   â””â”€â”€ <domain>/                # immutable as-received data
â”œâ”€â”€ work/
â”‚   â””â”€â”€ <domain>/                # intermediates / scratch (rebuildable)
â”œâ”€â”€ processed/
â”‚   â””â”€â”€ <domain>/                # publishable evidence artifacts
â”œâ”€â”€ stac/
â”‚   â”œâ”€â”€ collections/
â”‚   â””â”€â”€ items/
â”œâ”€â”€ catalog/
â”‚   â””â”€â”€ dcat/                    # DCAT JSON-LD datasets/distributions
â””â”€â”€ prov/                        # PROV bundles (JSON-LD recommended)
```

> [!IMPORTANT]
> **Immutability & trust boundaries**:  
> `raw/` is never edited; `work/` is ephemeral; `processed/` is governed evidence.[^immutability]

### ğŸ“Œ Source manifests (recommended for every ingest)
Place a source manifest alongside incoming data to make ingestion repeatable:
- URL/source identifier
- retrieval timestamp
- method (API export, manual upload, scan, etc.)
- checksums
- license/attribution notes (or links)[^sources_manifest]

### Streaming / near-real-time inputs â±ï¸
For streaming datasets:
- treat each batch as **append-only**
- use windowing (daily/weekly/monthly)
- donâ€™t rewrite history silently â€” publish a new version + provenance trail[^streaming]

### ğŸ“¦ Where big binaries live (Git vs Registry vs DVC) ğŸ§³
KFM supports â€œsmall in Git, big in artifact storageâ€ patterns **only** when:
- catalogs still exist in-repo and remain the canonical boundary
- PROV links the exact digest/version of the external artifact
- policy gates run the same way (license/sensitivity/no-downgrade) before publish[^oci_registry][^dvc]

---

<a id="dual-format-packaging"></a>
## ğŸ§© Dual-format packaging: GeoParquet + PMTiles

KFMâ€™s roadmap explicitly supports **dual-purpose geospatial outputs**:
- **GeoParquet** for analytics & bulk queries
- **PMTiles** for fast web map delivery and offline packs (single-file vector tile archive)[^pmtiles_dual_pack]

Why this lives in `tools/`:
- building both outputs from one processed dataset must be deterministic
- catalogs must link both distributions (STAC assets + DCAT distributions)
- provenance must record the â€œtile buildâ€ activity and parameters (tiling, simplification, zoom range)[^pmtiles_dual_pack]

> [!TIP]
> Treat GeoParquet + PMTiles as a *pair*: the UI serves PMTiles; analysis runs on GeoParquet; both point back to the same `data/processed/<domain>/` â€œevidence root.â€

---

<a id="tool-contract"></a>
## ğŸ§± Tool contract

Every tool must behave predictably under automation.

### âœ… Required CLI features
- `--help` (purpose, inputs/outputs, side effects, env vars, examples â‰¥ 2)
- `--version` (git SHA or semver)
- **safe-by-default mode**
  - either `--dry-run` default, or explicit â€œno writes unless --applyâ€
- `--apply` (only when the tool mutates state)
- `--env {dev|staging|prod}` when environment matters
- `--run-id <id>` (or read `KFM_RUN_ID`) for provenance correlation
- `--seed <int>` (or read `KFM_SEED`) for deterministic randomness
- `--contracts <path>` optional override (defaults to `schemas/`)
- `--log-json` (emit JSONL logs, one record per line)
- `--report <path>` (write a machine-readable summary artifact, even on failure)

### ğŸ§¾ RunContext + RunManifest (recommended)
For anything that produces evidence artifacts, tools should emit:
- `run_context.json` (human-oriented â€œreceiptâ€)
- `run_manifest.json` (machine-oriented â€œexactly what happenedâ€, canonicalized & hashed)[^run_manifest]

This is the glue between **PROV**, **catalogs**, **MCP receipts**, and **idempotency**.

### âœ… Exit codes (recommended standard)
- `0` success
- `2` CLI usage error
- `3` validation/QA failure (schema invalid, missing required fields, link check fails)
- `4` policy failure (license missing, classification downgrade, prohibited field)
- `>=10` runtime failure (I/O, network, DB, unhandled exceptions)

### ğŸ” Network posture
- Default to **no network** unless explicitly required
- If a tool fetches remote inputs:
  - require `--allow-network`
  - block private IP ranges by default (SSRF defense)
  - log source URLs + checksums of downloaded artifacts

### ğŸ§¾ Provenance emission (minimum viable)
If a tool produces or promotes evidence artifacts, it must emit a PROV bundle containing:
- run_id, timestamps, tool name/version
- code identity (git SHA) + config hash
- inputs used (IDs + checksums where feasible)
- outputs generated (paths + checksums)
- pointers back to STAC/DCAT records

### ğŸ¤– AI-assisted behavior (allowed, but gated)
If a tool uses AI to suggest metadata / mappings:
- default mode must be **suggest-only** (no mutation)
- require `--apply` to write anything
- log model/version/config where permissible
- treat outputs as **draft** until validated + reviewed
- preserve user agency (human-in-the-loop by design)[^hilt]

---

<a id="run-manifests"></a>
## ğŸ§¾ Run manifests & JSON canonicalization

Run manifests solve a boring-but-critical problem: **stable identity for â€œa runâ€**.

### âœ… Why KFM cares
KFM explicitly proposes a `run_manifest.json` + canonical JSON hashing approach so:
- two runs can be compared deterministically
- artifacts can be referenced by digest (even across storage backends)
- â€œexactly-once ingestionâ€ patterns become feasible (idempotency keys)[^run_manifest]

### âœ… Recommended minimum fields (shape)
- `run_id`, timestamps, tool + version + git SHA
- normalized config + config hash
- input inventory (paths/URIs + sha256)
- output inventory (paths/URIs + sha256)
- â€œpolicy outcomesâ€ summary (pass/fail + policy bundle version)
- pointers to emitted STAC/DCAT/PROV objects (IDs/hrefs)

### âœ… Canonicalization rule
Use a JSON canonicalization scheme (e.g., RFC 8785/JCS) before hashing so:
- key ordering doesnâ€™t change the hash
- whitespace doesnâ€™t change the hash
- floats/ints are consistently serialized[^run_manifest]

> [!NOTE]
> This does **not** replace PROV; it makes PROV *more usable* by giving every run a stable, content-derived identity.

---

<a id="determinism"></a>
## ğŸ² Determinism & reproducibility levels

Not everything needs full hermetic builds â€” but everything needs **auditability**.

### ğŸ§© Repro levels (recommended)
| Level | Name | Promise | Typical use |
|---:|---|---|---|
| R0 | Deterministic | Same inputs+config+seed â‡’ same outputs | most tools |
| R1 | Provenance-complete | Deterministic + complete PROV + catalog pointers | publishable evidence |
| R1.5 | Idempotent-run | R1 + `run_manifest.json` canonical hash + replay guarantees | ingestion/promotion tooling |
| R2 | Rebuildable | R1 + pinned deps + machine spec captured | critical releases |
| R3 | Hermetic | R2 + no network + fully captured environment | highest assurance |

> [!TIP]
> If you donâ€™t know which level you need, default to **R1** for anything that touches `processed/`.

---

<a id="qa-matrix"></a>
## ğŸ§ª Artifact QA matrix

Use this matrix to decide which validators must run **before promotion** âœ…

| Artifact type | Minimum checks | Extra checks (recommended) |
|---|---|---|
| ğŸ“„ JSON/JSON-LD (STAC/DCAT/PROV) | schema + required fields + link resolution | URI normalization + SPDX license lint |
| ğŸ§¾ Run manifests | schema + canonicalization + stable hash recompute | cross-check inventories vs filesystem + policy bundle version |
| ğŸ§­ Vector (GeoParquet / FlatGeobuf / GeoJSON) | schema + CRS + geometry validity | topology rules + simplification policy + attribution propagation |
| ğŸ§± PMTiles | header validity + TileJSON/metadata present + bounds/zoom sanity | layer budgets + â€œno orphan attributionâ€ + signature verify if distributed |
| ğŸ›°ï¸ Raster (COG / GeoTIFF / NetCDF) | COG layout + CRS + bounds + nodata | overview completeness + histogram sanity + tiling alignment |
| ğŸ—„ï¸ Tabular (Parquet/CSV) | schema + types + missingness report | drift checks + range checks + sampling provenance |
| ğŸ“¦ Offline packs | manifest schema + checksums + policy gates | signature verification + size budgets + â€œno orphan assetsâ€ scan |
| ğŸ§¾ Story Nodes (Markdown + config) | schema + links + citations present | citation â†” manifest consistency checks[^story_manifest] |
| ğŸ§µ Pulse Threads / Concept Nodes | schema + citations/evidence refs + provenance pointers | cadence checks + â€œno unsourced assertionsâ€ lint |
| ğŸ¨ Map styles (MapLibre JSON) | JSON lint + sources valid + sprite/glyph refs | contrast/legibility budgets + scale tests |
| ğŸ§  ML artifacts (metrics/models) | metrics schema + dataset refs + seeds | calibration checks + fairness slices + uncertainty |
| ğŸ§® Simulation outputs | config+seed captured + deterministic rerun | V&V smoke tests + UQ summary + sensitivity |
| ğŸ§Š 3D assets (3D Tiles / glTF) | manifest + attribution + bounding volume | LOD validation + GPU budget checks + compression checks |
| ğŸ“¦ OCI artifacts | digest pinned + signature verified + SBOM attached | referrer integrity + policy tags enforced[^oci_registry] |

---

<a id="telemetry"></a>
## ğŸ“¡ Telemetry & observability

Telemetry is a **contracted surface** (schema-first) â€” used to measure UX safety signals, governance friction, and system health.

### âœ… Expectations
- event schemas live under `schemas/telemetry/`
- tools should validate telemetry payloads against schemas in CI
- logs should be JSONL (tool-friendly), with a minimal human-readable console summary

KFM also proposes tracking system sustainability signals (e.g., **energy consumption / carbon footprint**) as part of observability for long-running workflows.[^energy_telemetry]

> [!TIP]
> Treat telemetry as evidence about the system itself: version it, validate it, and keep it privacy-aware.

---

<a id="expected-layout"></a>
## ğŸ“ Expected folder layout

> If your repo differs, treat this as the target structure and document deltas in `tools/README.md`.

```text
ğŸ› ï¸ tools/
â”œâ”€â”€ ğŸ“˜ README.md
â”œâ”€â”€ ğŸ§° _lib/                      # shared helpers (logging, env validation, guardrails)
â”œâ”€â”€ ğŸ§¾ manifests/                 # optional tool.yaml manifests (one per tool)
â”œâ”€â”€ ğŸ›°ï¸ agents/                    # Watcherâ€“Plannerâ€“Executor entrypoints (PR-based automation)
â”œâ”€â”€ ğŸ§² ingest/                    # controlled ingest entrypoints (thin wrappers)
â”‚   â”œâ”€â”€ docs/                     # document/PDF ingestion â†’ text + metadata + graph links (gated)[^bulk_doc_ingest]
â”‚   â””â”€â”€ feeds/                    # scheduled fetchers (deny-by-default network)
â”œâ”€â”€ ğŸ·ï¸ catalogs/                  # STAC/DCAT emitters + catalog build helpers
â”œâ”€â”€ âœ… validation/                # fast QA gates (schema/link/prov/policy)
â”‚   â”œâ”€â”€ âš¡ catalog_qa/             # catalog QA gate (PR-friendly)
â”‚   â”œâ”€â”€ ğŸ›¡ï¸ policy/                # OPA/Conftest policies (license/classification/no-downgrade)[^policy_pack]
â”‚   â”œâ”€â”€ ğŸ§­ geo/                   # CRS/geom/raster validators
â”‚   â”œâ”€â”€ ğŸ“Š stats/                 # drift/residuals/effect-size reports
â”‚   â”œâ”€â”€ ğŸ” security/              # hostile-input checks (zip bombs, traversal, SSRF guards)
â”‚   â””â”€â”€ ğŸ“¡ telemetry/             # validate event schemas + payloads
â”œâ”€â”€ ğŸ†” id/                        # deterministic IDs, hashing, manifest tooling
â”œâ”€â”€ ğŸ§¬ prov/                      # provenance helpers (PROV JSON-LD emitters)
â”œâ”€â”€ ğŸ§¾ audit/                     # run manifests, JSON canonicalization, policy outcome receipts[^run_manifest]
â”œâ”€â”€ ğŸ“¦ artifacts/                 # OCI/registry helpers (oras/cosign wrappers, digest pinning)[^oci_registry]
â”œâ”€â”€ ğŸ“š library/                   # extract PDF portfolios + build doc manifests/indexes[^pdf_portfolios]
â”œâ”€â”€ ğŸ§µ content/                   # story manifests, pulse threads, concept nodes (governed content)[^pulse_threads]
â”œâ”€â”€ ğŸ§© dsl/                       # optional: schema/profile/policy DSL compilers (contract-first)
â”œâ”€â”€ ğŸ•¸ï¸ graph/                     # graph ingest helpers (must consume catalog roots)
â”‚   â””â”€â”€ ğŸ©º health/                # graph health checks (weekly, CI-friendly)[^graph_health]
â”œâ”€â”€ ğŸ—„ï¸ db/                        # PostGIS helpers, migrations, query packs
â”œâ”€â”€ ğŸ—ºï¸ geo/                       # GDAL wrappers, tiling, reprojection, COG/PMTiles utilities[^pmtiles_dual_pack]
â”œâ”€â”€ ğŸ›°ï¸ rs/                        # remote sensing helpers (GEE export, masking, compositing)
â”œâ”€â”€ ğŸ§Š 3d/                        # 3D Tiles / glTF tooling, mesh + point cloud validation
â”œâ”€â”€ ğŸŒ web/                       # map build helpers (styles, tiles packaging, offline packs)
â”œâ”€â”€ ğŸ¤– ml/                        # train/eval orchestration (must emit datasets + metrics refs)
â”œâ”€â”€ ğŸ§® simulation/                # scenario runners (must record configs + seeds)
â”œâ”€â”€ ğŸ” attest/                    # SBOM + signing helpers (cosign/sigstore patterns)
â”œâ”€â”€ âš¡ perf/                      # profiling harnesses + performance budgets
â””â”€â”€ ğŸ§ª ci/                        # deterministic entrypoints used by CI
```

> [!NOTE]
> Canonical schemas are in `schemas/` (repo root). Tools should **reference**, not duplicate, contracts.

---

<a id="common-workflows"></a>
## ğŸ” Common workflows

### ğŸ§­ â€œWhat do I run?â€ (at a glance)
| I want toâ€¦ | Runâ€¦ | Outputâ€¦ |
|---|---|---|
| âœ… Quick PR gate | `tools/validation/catalog_qa/...` | report + exit code |
| ğŸ—‚ï¸ Build catalogs | `tools/catalogs/...` | STAC/DCAT |
| ğŸ§¬ Emit provenance | `tools/prov/...` | PROV bundle |
| ğŸ§¾ Emit run manifest | `tools/audit/build_run_manifest.py` | `run_manifest.json` + hash[^run_manifest] |
| ğŸ§© Build GeoParquet+PMTiles | `tools/geo/package_dual.py` | `.parquet` + `.pmtiles` + catalogs[^pmtiles_dual_pack] |
| ğŸšš Promote/publish | `tools/catalogs/promote...` | atomic move + updated catalogs |
| ğŸ•¸ï¸ Load graph/DB | `tools/graph/...` / `tools/db/...` | ingest report |
| ğŸ©º Graph health check | `tools/graph/health/weekly_check.py` | health report + KPIs[^graph_health] |
| ğŸŒ Build UI assets | `tools/web/...` | tiles/styles/manifests |
| ğŸ“¦ Build offline pack | `tools/web/build_offline_pack.py` | signed pack + manifest |
| ğŸ“¦ Push big artifacts to OCI | `tools/artifacts/push_oci.py` | digest-pinned artifacts + signatures[^oci_registry] |
| ğŸ” Release bundle | `tools/attest/...` | SBOM + attestation in `releases/` |
| ğŸ¤– Run automation safely | `tools/agents/watcher.py â†’ planner.py â†’ executor.py` | PR + receipts |

---

### A) Build a dataset (stage â†’ validate â†’ catalog â†’ promote) âœ…

1) Ingest â†’ `data/raw/<domain>/...`  
2) Transform â†’ `data/work/<domain>/...`  
3) Validate (schema/CRS/geometry/license/bounds)  
4) Emit STAC/DCAT/PROV  
5) Promote to `data/processed/<domain>/...`  
6) (Optional) Ingest into graph/DB from catalogs  
7) Write MCP run receipt if it affects decisions or production  

Illustrative shape:
```bash
# ingest (examples)
python tools/ingest/ingest.py --help

# validate (fast fail)
python tools/validation/catalog_qa/run_catalog_qa.py --help

# emit catalogs + provenance
python tools/catalogs/build_catalogs.py --help
python tools/prov/emit_prov.py --help

# promote (atomic publish)
python tools/catalogs/promote.py --help
```

> [!TIP]
> If it changes `processed/`, it should also change **STAC/DCAT/PROV** and have a run receipt.[^stac_dcat_prov]

---

### B) PR gate: â€œCatalog QA quick checkâ€ âš¡

Designed to be fast enough to run on every PR:
- schema validity (STAC/DCAT/PROV + extensions)
- required fields (license, bbox, time, assets)
- link resolution (hrefs exist; assets reachable in repo layout)

```bash
python tools/validation/catalog_qa/run_catalog_qa.py --root data/stac
```

---

### C) Evidence artifacts (analysis / AI / simulation outputs) ğŸ§¾ğŸ¤–

KFM treats analysis outputs as first-class datasets:
- store under `data/processed/<domain>/...`
- create STAC/DCAT entries
- emit PROV capturing inputs + parameters + seeds + uncertainty/metrics
- do not expose directly in UI; go through API boundary[^kfm_v13]

```bash
python tools/ml/train.py --help
python tools/simulation/run_scenario.py --help
python tools/catalogs/build_catalogs.py --help
python tools/prov/emit_prov.py --help
python tools/validation/catalog_qa/run_catalog_qa.py --root data/stac
```

Simulation outputs should follow reproducible, deterministic patterns (config + seed + V&V + UQ summaries).[^kfm_sim]

---

### D) Policy enforcement (OPA / Conftest) ğŸ›¡ï¸

Use policy tests for hard rules:
- license must exist
- classification must not downgrade
- prohibited fields/paths
- â€œno publish without provenanceâ€
- â€œFocus Mode must cite evidence sourcesâ€[^focus_mode][^policy_pack]

```bash
conftest test -p tools/validation/policy data/stac data/catalog/dcat data/prov --all-namespaces
```

---

### E) Graph/DB ingest from catalogs (no ad-hoc writes) ğŸ•¸ï¸

Graph and DB loaders should:
- accept **catalog roots** as inputs (STAC/DCAT/PROV)
- refuse to load items missing provenance or license (unless explicitly allowed)
- emit an ingest report (counts, warnings, failures)

```bash
python tools/graph/ingest_from_stac.py --help
python tools/db/load_from_catalog.py --help
```

---

### F) Build web-friendly map artifacts (COG + PMTiles + styles) ğŸ—ºï¸

KFMâ€™s stack supports both PostGIS tile-serving and prepackaged tile archives (PMTiles/MBTiles) depending on deployment and offline needs.[^tile_postgis][^pmtiles_dual_pack]

```bash
python tools/geo/build_cog.py --help
python tools/geo/build_pmtiles.py --help
python tools/web/lint_style.py --help
python tools/3d/package_3dtiles.py --help
```

---

<a id="validation-gates"></a>
## âœ… Validation & QA gates

Think in rings (each ring blocks promotion if it fails):

### Ring 0: Structure ğŸ§±
- JSON parses
- schema validation (STAC/DCAT/PROV + extensions)
- required files exist

### Ring 1: Integrity ğŸ”—
- checksums/manifest inventory
- deterministic IDs present where required
- run manifest hash recompute + match[^run_manifest]
- atomic publish (no half-state)

### Ring 2: Semantics ğŸ§ 
- CRS correctness + axis order
- geometry validity (and any allowed repair policy)
- raster sanity (nodata, resolution, alignment)
- time/bounds sanity (Kansas bounds, plausible ranges)

### Ring 3: Statistical & scientific sanity ğŸ§ªğŸ“Š
- drift checks (schema + distributions)
- regression diagnostics (residuals, heteroscedasticity, multicollinearity flags)
- uncertainty summaries (where applicable)
- â€œsmell testsâ€ for simulation outputs (stability checks / invariants)[^kfm_sim]

### Ring 4: Governance & safety ğŸ”
- license required before publish
- classification propagation (no downgrade)
- sensitive fields redaction rules (including location generalization policies)[^sensitivity]
- policy tests (OPA/Conftest) where used[^policy_pack]
- secrets scans + dependency hygiene checks

### Ring 5: AI integrity ğŸ§ ğŸ§¾
- Focus Mode outputs must carry citations; otherwise refuse or return an explicit â€œinsufficient evidenceâ€ response.[^focus_mode]
- prompt-injection defenses and redaction validation (Prompt Gate)[^prompt_gate]

---

<a id="provenance-sbom-attestations"></a>
## ğŸ” Provenance, SBOM, attestations, releases

### Provenance (required for publish)
At minimum, each publish action should have:
- run_id
- code version (git SHA)
- config hash
- inputs used (IDs + checksums where feasible)
- outputs generated (paths + checksums)
- pointers to STAC/DCAT records
- (recommended) run manifest hash + location[^run_manifest]

### âœ… PR-to-PROV binding (recommended)
KFM explicitly proposes mapping GitHub PRs/commits/workflows to PROV so every code change that affects evidence can be traced to:
- PR number + commit SHAs
- workflow run ID
- SBOM + signatures + policy outcomes[^github_prov]

### SBOM + signing (recommended for releases)
For release bundles or promoted artifacts:
- generate SBOMs (tool deps and/or artifact deps)
- sign artifacts where feasible
- attach attestations (build provenance, policy checks, QA outcomes)[^wpe]

### ğŸ“¦ Release bundles live in `releases/`
Recommended structure:
```text
releases/
â””â”€â”€ 2026-01-20_v0.6.0/
    â”œâ”€â”€ sbom.spdx.json
    â”œâ”€â”€ attestations/
    â”œâ”€â”€ manifests/
    â””â”€â”€ notes.md
```

> [!TIP]
> Keep logs lightweight in-repo; store heavy logs as CI artifacts or in an artifact store.

---

<a id="oci-distribution"></a>
## ğŸ“¦ OCI artifact registry distribution

For large artifacts (PMTiles, GeoParquet, COGs), KFM proposes leveraging **OCI registries as storage**:
- use **ORAS** to push arbitrary artifacts with media types
- use **Cosign** (keyless) to sign and verify artifacts
- attach signatures/SBOMs as OCI â€œreferrersâ€
- reference artifacts by **digest** inside STAC/DCAT/PROV for immutability[^oci_registry]

> [!IMPORTANT]
> OCI storage is a distribution channel â€” not a governance bypass.  
> Catalogs + PROV remain the canonical boundary, and policy gates still apply.[^oci_registry]

---

<a id="offline-packs"></a>
## ğŸ“¦ Offline packs & field ops

KFMâ€™s UI roadmap includes **PWA support** and **offline data packs** so field researchers, educators, and rural communities can use KFM without connectivity.[^pwa_offline]

### âœ… What an offline pack should contain
- pre-rendered tiles (vector/raster) for a defined AOI
- slimmed catalogs (STAC/DCAT/PROV) scoped to the pack
- a signed manifest (checksums + versions + policy tags)
- â€œcredits bundleâ€ (attribution + licensing text for export/sharing)
- optional: a small on-device model for limited offline Focus Mode (if policy allows)[^offline_packs]

PMTiles/MBTiles are explicitly considered as offline-friendly tile packaging formats for KFMâ€™s UI and tooling.[^pmtiles_dual_pack]

### ğŸ§¾ Governance requirement
Offline packs are still â€œpublish-likeâ€ artifacts:
- must pass validation gates
- must include provenance + catalogs
- must carry policy labels (classification, sensitivity)

### ğŸ§­ UX alignment
The UI is designed to surface provenance (â€œthe map behind the mapâ€), and even exports/shared views should carry credits.[^ui_provenance_exports]

---

<a id="pulse-threads"></a>
## ğŸ§µ Pulse Threads & Concept Nodes

KFM proposes two â€œcontent artifactsâ€ that sit between datasets and narratives â€” and they belong in the governed toolchain:

### ğŸ§µ Pulse Threads (recurring evidence-linked updates)
Pulse Threads are designed as lightweight, recurring â€œwhatâ€™s new + why it mattersâ€ narratives, anchored in evidence and structured metadata.[^pulse_threads]

Toolchain implications:
- schema-first thread metadata (cadence, scope, evidence refs)
- citations are mandatory; â€œno unsourced assertionsâ€ lint
- PR-based workflow (draft â†’ review â†’ publish)
- PROV links thread statements back to datasets/records

### ğŸ§  Conceptual Attention Nodes (concept-as-entity)
Concept Nodes define shared â€œconcept anchorsâ€ (a place/event/phenomenon) that unify:
- domains
- synonyms / aliases
- policies / sensitivity constraints
- recommended datasets + story nodes[^concept_nodes]

Toolchain implications:
- concept schema + validation (IDs, aliases, links, policy tags)
- graph ingestion downstream of catalogs (concept nodes become graph entities with provenance)
- Focus Mode can cite concept nodes as stable, governed context

---

<a id="geo-mapping"></a>
## ğŸ—ºï¸ Geo & mapping utilities

### CRS & units are non-negotiable ğŸ“
Tools that touch geometry must:
- refuse unknown CRS by default
- log CRS for inputs and outputs
- document any reprojection and record it in provenance

KFMâ€™s internal standard is **WGS84 (EPSG:4326)** for web consistency; incoming data is reprojected on ingest and tracked in provenance.[^crs_wgs84]

### Web-serving friendliness ğŸŒ
When emitting UI-facing assets:
- prefer COG with overviews for rasters
- avoid huge GeoJSON blobs (tile/simplify)
- ensure attribution + license + legends travel with the output

### Tile serving strategies (both are valid) ğŸ§±
- **PostGIS tile endpoints** (e.g., `ST_AsMVT`), driven by API adapters[^tile_postgis]
- **Prepackaged tiles** (PMTiles/MBTiles) for fast static hosting and offline packs[^pmtiles_dual_pack]

---

<a id="remote-sensing"></a>
## ğŸ›°ï¸ Remote sensing utilities

Remote sensing tooling should prefer **derived products + provenance** over raw archive dumps:
- record AOI (bbox/geometry) + time window
- record compositing + masking logic (cloud/shadow, water, snow, etc.)
- record resolution/CRS
- export as COGs (and/or cloud-optimized NetCDF where relevant)
- emit STAC Items per logical unit (scene, tile, station-day, etc.)

> [!TIP]
> Donâ€™t let EO pipelines become â€œmystery rasters.â€ If you canâ€™t trace how it was made, itâ€™s not shippable.

---

<a id="imaging-compression"></a>
## ğŸ§Š Imaging & compression utilities

Images are evidence too â€” and compression choices change meaning ğŸ§¾

Recommended tool behaviors:
- detect format + bit depth + alpha channels
- warn when a lossy conversion could change interpretation (e.g., subtle gradients)
- emit a small report: chosen format, compression parameters, and rationale

Practical format hints (rule-of-thumb):
- **JPEG** â†’ photographs / continuous tone, lossy
- **PNG** â†’ screenshots / line art / sharp edges, lossless, supports alpha
- **GIF** â†’ limited palette, simple animations (avoid for scientific rasters)
- **BMP/XBM** â†’ legacy / rarely suitable in modern pipelines

---

<a id="3d-visualization"></a>
## ğŸ§± 3D / WebGL / scene utilities

When we ship 3D, we ship **performance budgets + provenance** ğŸ§Šâš¡

Tools in `tools/3d/` should support:
- validating glTF / 3D Tiles manifests
- generating LOD pyramids (and verifying completeness)
- embedding attribution + license + provenance pointers in manifests
- sanity-checking GPU budgets (triangle count, texture size, draw calls) for target devices

KFMâ€™s mapping/UI design explicitly considers MapLibre for 2D and Cesium for 3D (3D Tiles / CZML), with time-slider storytelling and optional 3D expansion.[^maplibre_cesium]

> [!NOTE]
> Archaeology and historical reconstruction workflows often require **explicit uncertainty labeling** in 3D (e.g., â€œmeasuredâ€ vs â€œinferredâ€). Treat uncertainty as metadata, not a footnote.

---

<a id="graph-health"></a>
## ğŸ©º Graph health checks

KFM explicitly proposes a **weekly graph health check** as a governance-friendly integrity practice:
- catch orphan nodes/edges and integrity drift early
- produce a publishable health report (counts, constraints, anomalies)
- wire into CI + maintainer review loops[^graph_health]

Recommended outputs:
- `reports/graph_health/<date>/report.json`
- `reports/graph_health/<date>/report.md`
- `run_manifest.json` pointer + hash
- suggested fixes (as a PR plan), not silent mutations

---

<a id="graph-db"></a>
## ğŸ§  Graph & DB utilities

### Neo4j / graph ğŸ•¸ï¸
Graph ingest should be downstream of catalogs:
- store references back to STAC/DCAT/PROV (donâ€™t duplicate bulky data)
- enforce invariants:
  - â€œevery dataset node links to provenanceâ€
  - â€œno orphan entitiesâ€
  - â€œstable pagination order for query surfacesâ€

### PostGIS / PostgreSQL ğŸ—„ï¸
- prefer database-side spatial ops when safe (joins, buffers, within, intersects)
- use staging tables + transactional swaps (load â†’ validate â†’ swap)
- avoid foot-guns in shared query packs:
  - prefer explicit column lists over `SELECT *`
  - validate query plans for large tables (indices, bounds, partitions)

KFMâ€™s PostGIS adapter pattern includes tile generation via `ST_AsMVT` and emphasizes the division:
**â€œPostGIS stores geo truth, catalogs describe assets, graph links context.â€**[^tile_postgis]

---

<a id="stats-evidence"></a>
## ğŸ“Š Statistical evidence utilities

KFM treats statistics as **evidence engineering**, not â€œextra mathâ€ ğŸ“ˆğŸ§¾

Tools should help prevent common failure modes:
- silent p-hacking / multiple comparisons
- â€œsignificant but tinyâ€ effects presented without context
- regression assumptions ignored (heteroscedasticity, multicollinearity, non-linearity)
- underpowered or non-replicable experimental setups

Recommended outputs:
- effect sizes + uncertainty (CI/credible intervals), not just p-values
- residual diagnostics (plots + stats)
- drift reports (training vs current distribution)
- declared priors (for Bayesian tools) + sensitivity summaries

Classification tooling should prefer reporting precision/recall and macro-averaged F1 where class imbalance exists.[^ml_metrics]

> [!TIP]
> If a statistical result is used to justify a decision or an operational rule, it belongs in `mcp/` as a run receipt (with links to catalogs + provenance).[^mcp_receipts]

---

<a id="modeling-ml-simulation"></a>
## ğŸ§ª Modeling/ML/simulation utilities

Modeling tools must behave like scientific instruments ğŸ§ªğŸ”¬:
- capture parameters + seeds
- emit evaluation artifacts (metrics + plots where relevant)
- record dataset IDs used (STAC/DCAT pointers)
- write run receipts for significant results (MCP alignment)
- support verification/validation hooks (golden tests, invariants, sanity checks)

Simulation-specific expectations (V&V & UQ mindset):
- verification: â€œdid we solve the equations right?â€
- validation: â€œare we solving the right equations for this phenomenon?â€
- uncertainty: quantify sensitivity to inputs, parameters, and model form[^kfm_sim]

> [!CAUTION]
> If a tool uses AI-assisted generation, label it and record the model/version/config where permissible.

---

<a id="security-posture"></a>
## ğŸ” Security posture

Treat `tools/` as part of the threat model:
- inputs are hostile (archives, rasters, PDFs, GeoJSON, model files)
- validate types with allowlists
- enforce size limits + decompression limits
- defend against SSRF for network fetchers
- sanitize paths and refuse traversal
- never print secrets; never require secrets in CLI args

### ğŸ§  Prompt security (â€œPrompt Gateâ€)
KFM explicitly calls out a **Prompt Gate** approach: guardrails against prompt injection, policy bypass, and unsafe tool execution â€” especially for AI-assisted workflows.[^prompt_gate]

### ğŸ§· Sensitivity / sovereignty posture
KFM explicitly discusses sensitivity controls such as **location generalization**, access control, and policy tags (including CARE-aligned governance expectations for indigenous/community-sensitive data).[^sensitivity]

> [!IMPORTANT]
> Security references in the library are for **defensive posture and awareness** only.  
> Tools must never provide â€œoffense automationâ€ â€” the goal is resilience, not exploitation.

---

<a id="performance-scaling"></a>
## âš¡ Performance & scaling notes

When tools grow:
- chunk work (tiles/partitions/morsels) for parallelism
- introduce â€œpipeline breakersâ€ at materialization boundaries
- keep caches explicit and provenance-aware
- profile first, then optimize (measure before guessing)
- prefer near-data execution for large scans (where architecture supports it)

Database performance reminders:
- stable query shapes + stable sort orders are part of determinism
- indexing strategy must be documented (and reproducible)
- treat query plans as artifacts for critical pipelines (store summaries in reports)

> The rule: speed is good â€” **but correctness and provenance come first**.

---

<a id="federation"></a>
## ğŸŒ Federation & cross-matrix interoperability

KFM is designed to be â€œfederation-readyâ€ ğŸŒ¾â¡ï¸ğŸŒ:
- schemas and APIs should be standardizable across regions
- export/import should operate at the catalog boundary (STAC/DCAT/PROV)
- avoid Kansas-specific assumptions in reusable tool logic (keep those in domain configs)[^streaming]

Federation is explicitly framed as â€œmulti-region discoveryâ€ driven by shared metadata protocols, where a central UI can query multiple regional KFMs via standard outputs (DCAT/STAC/PROV).[^streaming]

Ideas that fit naturally in `tools/`:
- `tools/catalogs/export_bundle.py` â†’ export STAC/DCAT/PROV + checksums
- `tools/catalogs/import_bundle.py` â†’ validate + ingest external catalogs (deny-by-default)
- `tools/contracts/package_schemas.py` â†’ publish a versioned schema pack for sister projects

> [!NOTE]
> Federation strengthens governance: shared contracts make audits and cross-region evidence easier to verify.

---

<a id="contributing"></a>
## ğŸ§© Contributing a new tool

### âœ… Definition of done
A tool is â€œrealâ€ when it has:
- entrypoint (`.py`, `.js`, `.sh`, etc.) with `--help` and 2 examples
- deterministic defaults (stable ordering; seeded randomness if applicable)
- structured logs + stable exit codes
- writes outputs to the correct data stage (raw/work/processed)
- emits/updates catalogs + provenance when producing publishable artifacts
- emits run manifest when it publishes/promotes evidence[^run_manifest]
- a CI target (smoke test at minimum)
- a clear home in the folder map above

### Suggested `tool.yaml` manifest (recommended)
```yaml
name: "catalog_qa"
entrypoint: "tools/validation/catalog_qa/run_catalog_qa.py"
owner: "@team-or-handle"
inputs:
  - "data/stac/**"
outputs:
  - "reports/catalog_qa/**"
modes:
  - dry_run: true
  - apply: false
network:
  default: "deny"
determinism:
  stable_sorting: true
  seeded: false
gates:
  - "stac_schema"
  - "link_check"
  - "license_required"
  - "prov_required_for_publish"
  - "run_manifest_required"
```

### ğŸªœ Promotion ladder (how scripts become tools)
1) prototype in `sandbox/` or local notebook  
2) extract core logic into `src/`  
3) add a thin `tools/` CLI wrapper  
4) add validators + provenance emission  
5) add run manifest + canonical hashing  
6) add CI target + docs + examples  
7) promote to â€œgoverned surfaceâ€ âœ…  

---

<a id="reference-library"></a>
## ğŸ“š Project reference library

These files inform how tools are designed (determinism, validation, governance, scaling, and UX constraints).  
Keep this list updated when the library changes.

### ğŸ§­ Canonical KFM system docs (architecture, AI, UI, intake)
- **KFM Master Guide / v13 contracts** â†’ `MARKDOWN_GUIDE_v13.md.gdoc`[^kfm_v13]
- **KFM system architecture & features** â†’ `Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf`[^wpe]
- **KFM technical documentation** â†’ `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf`[^sources_manifest]
- **KFM AI system overview** â†’ `Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf`[^focus_mode]
- **KFM UI system overview** â†’ `Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf`[^ui_provenance_exports]
- **KFM data intake guide** â†’ `ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf`[^immutability]
- **KFM latest ideas & proposals** â†’ `ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals.docx.pdf`[^pmtiles_dual_pack]
- **KFM innovation roadmap** â†’ `Innovative Concepts to Evolve the Kansas Frontier Matrix (KFM).pdf`[^cultural_protocols]
- **Additional ideas / add-ons** â†’ `Additional Project Ideas.pdf` (Pulse Threads, run manifests, OCI distribution, graph health checks)[^pulse_threads]

### ğŸ§ª Scientific method & MCP receipts
- `Scientific Method _ Research _ Master Coder Protocol Documentation.pdf` (hypotheses, methods, receipts, reproducibility)[^mcp_receipts]

### ğŸ—ºï¸ Geospatial + mapping hub design
- `Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf` (MapLibre/Cesium, time slider, data hosting, DVC hints)[^maplibre_cesium][^dvc]

### ğŸ§¾ Standards + writing conventions
- `Comprehensive Markdown Guide_ Syntax, Extensions, and Best Practices.docx` (advanced GitHub markdown patterns)[^markdown_guide]

### ğŸ“¦ Reference portfolios (PDF Portfolios)
Some â€œbookshelvesâ€ are packaged as **PDF Portfolios** (Acrobat-style bundles). Tools should support extracting them to a normal folder for indexing/search.[^pdf_portfolios]

- `AI Concepts & more.pdf` *(PDF Portfolio)*[^pdf_portfolios]
- `Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf` *(PDF Portfolio)*[^pdf_portfolios]
- `Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf` *(PDF Portfolio)*[^pdf_portfolios]
- `Various programming langurages & resources 1.pdf` *(PDF Portfolio)*[^pdf_portfolios]

> [!TIP]
> Add a governed extractor like `tools/library/extract_pdf_portfolio.py` that emits:
> - extracted PDFs
> - `manifest.json` (filename, sha256, source portfolio, extracted_at)
> - optional: a local search index for docs (dev-only)

---

<a id="metadata"></a>
## ğŸ§¾ Metadata

```yaml
title: "tools/ â€” Kansas Frontier Matrix Toolchain"
path: "tools/README.md"
version: "v0.6.0"
last_updated: "2026-01-20"
review_cycle: "90 days"
governance: "FAIR + CARE aligned; sovereignty-aware"
pipeline_order: "Raw â†’ Work/ETL â†’ Processed â†’ STAC/DCAT/PROV catalogs â†’ Neo4j graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode"
```

---

<a id="version-history"></a>
## ğŸ•°ï¸ Version history

| Version | Date | Summary | Author |
|---:|---|---|---|
| v0.6.0 | 2026-01-20 | Integrated the newest project ideas into the governed toolchain: added **run manifests + JSON canonicalization** (idempotent runs), **OCI artifact registry distribution** (ORAS + Cosign + digest pinning), **Pulse Threads + Concept Nodes** as governed content artifacts, **weekly graph health checks**, and the **GeoParquet + PMTiles dual-format packaging** pattern. Updated folder layout, QA matrix, and reference library to include all project files (including PDF portfolios). | KFM Engineering |
| v0.5.0 | 2026-01-19 | Updated `tools/` README to v13 staging (`data/raw|work|processed`), added Watcherâ€“Plannerâ€“Executor agent toolchain guidance, strengthened provenance-first + citation-required Focus Mode rules, added telemetry/observability contract notes, and expanded offline pack/field ops expectations; refreshed reference library. | KFM Engineering |
| v0.4.0 | 2026-01-13 | Expanded `tools/` README using project reference library: added determinism levels, artifact QA matrix, stats evidence tooling, 3D/WebGL guidance, remote sensing + compression notes, federation framing (data spaces), and a clearer promotion ladder; updated reference library and canonical data staging. | KFM Engineering |
| v0.3.0 | 2026-01-11 | Aligned `tools/` README with Master Guide v13: contract-first + evidence-first; clarified canonical paths (`schemas/`, `src/*`, `web/`, `releases/`); added contracts section + federation readiness notes. | KFM Engineering |
| v0.2.0 | 2026-01-09 | Aligned `tools/` with repo-wide boundaries (src/scripts/mcp), added tool contract + data staging rules + QA rings + security posture + richer folder map. | KFM Engineering |
| v0.1.0 | 2026-01-08 | Initial toolbox README draft. | KFM Engineering |

---

## ğŸ“ Evidence notes (footnotes)

[^kfm_v13]: v13 invariants and pipeline staging/canonical boundary artifacts (STAC/DCAT/PROV) + â€œno skipping stages.â€ [oai_citation:0â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU) [oai_citation:1â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
[^data_layout]: v13 data lifecycle layout and canonical folder paths for raw/work/processed plus catalogs/prov outputs. [oai_citation:2â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
[^stac_dcat_prov]: STAC/DCAT/PROV alignment and evidence-artifact treatment for derived/AI outputs; catalogs are required boundary artifacts before downstream stages. [oai_citation:3â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU) [oai_citation:4â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
[^focus_mode]: Focus Mode / AI outputs require citations and are constrained by governance/policy guardrails; prompts and answers are treated as governance-sensitive surfaces. [oai_citation:5â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU) [oai_citation:6â€¡Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf](file-service://file-Pv8eev6RWvCKrGCXyzY7zg)
[^immutability]: Raw input data is treated as immutable/read-only evidence; transformations occur downstream and must be deterministic/config-driven for reproducibility. [oai_citation:7â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
[^streaming]: Federation and multi-region interoperability rely on standard STAC/DCAT/PROV outputs and shared governance posture; offline packs can bundle slices across regions with careful collation/governance. [oai_citation:8â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj) [oai_citation:9â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
[^sources_manifest]: `data/sources/` manifests are used to capture external source URL/license/schema and support provenance-first ingestion (without Git-versioning huge raw inputs). [oai_citation:10â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
[^policy_pack]: Policy-as-code posture and OPA/Conftest gates are part of KFMâ€™s governance enforcement surface (license/classification/no-downgrade; deny-by-default where appropriate). [oai_citation:11â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU) [oai_citation:12â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
[^wpe]: Watcherâ€“Plannerâ€“Executor pattern, PR-based automation, and attested outputs align with the â€œtools enforce the pipelineâ€ governance intent. [oai_citation:13â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj) [oai_citation:14â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)
[^prompt_gate]: Prompt security layers/Prompt Gate are explicitly described as part of AI safety and tool misuse hardening. [oai_citation:15â€¡Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf](file-service://file-Pv8eev6RWvCKrGCXyzY7zg)
[^ui_provenance_exports]: UI surfaces provenance (â€œmap behind the mapâ€), is decoupled via APIs, and exports/shared views are intended to carry credits; supports reuse by other regions. [oai_citation:16â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt) [oai_citation:17â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt)
[^pwa_offline]: UI/mobile strategy includes offline data packs and field use; system supports offline-first usage patterns. [oai_citation:18â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt)
[^offline_packs]: Offline mode considerations include packaging limited Focus Mode behavior only if policy permits on-device models; offline packs remain governed artifacts. [oai_citation:19â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt)
[^crs_wgs84]: WGS84 (EPSG:4326) standard and vector tile tooling (e.g., Tippecanoe) are called out for scalable web delivery, with reprojection tracked in provenance. [oai_citation:20â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
[^maplibre_cesium]: MapLibre for 2D and optional Cesium for 3D (3D Tiles/CZML) with time-slider storytelling patterns are part of the mapping/UI architecture options. [oai_citation:21â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)
[^ar_mode]: AR guidance emphasizes filtering layers, avoiding clutter, and reusing existing endpoints with an AR client profile. [oai_citation:22â€¡KFM- python-geospatial-analysis-cookbook-over-60-recipes-to-work-with-topology-overlays-indoor-routing-and-web-application-analysis-with-python.pdf](file-service://file-2gpiGDZS8iw6EdxGswEdHp)
[^bulk_doc_ingest]: Bulk document ingestion roadmap includes OCR + metadata creation + linking into the graph (gated + provenance). [oai_citation:23â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)
[^telemetry]: Telemetry is treated as a schema-first contract surface; validate payloads and keep privacy-aware logs. [oai_citation:24â€¡Kansas Frontier Matrix â€“ Comprehensive UI System Overview.pdf](file-service://file-KcBQruYcoFVDEixzzRHTwt)
[^mcp_receipts]: MCP emphasizes QA in CI, deterministic outputs/seed recording, and structured receipts/checklists for reproducibility and governance traceability. [oai_citation:25â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32) [oai_citation:26â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)
[^hilt]: Human-in-the-loop expectations for AI-assisted metadata/story generation; AI suggests, humans approve for important outputs. [oai_citation:27â€¡Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf](file-service://file-Pv8eev6RWvCKrGCXyzY7zg)
[^cultural_protocols]: CARE-aligned and sovereignty-aware metadata (including cultural protocol labels such as TK labels) are proposed as governance practice areas. [oai_citation:28â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
[^sensitivity]: Sensitivity controls include location generalization, policy tags, and permission-based access; emphasizes consent and Indigenous data sovereignty expectations. [oai_citation:29â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
[^story_review]: Story validation / peer review concepts to reduce narrative drift and improve trust signals are proposed in KFMâ€™s innovation roadmap. [oai_citation:30â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)
[^kfm_sim]: Simulation outputs treated as evidence artifacts: config+seed captured, V&V and UQ summaries, and provenance/policy gates for publishability. [oai_citation:31â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)
[^pdf_portfolios]: Several reference bundles are PDF Portfolios that require extraction for normal indexing/search; governed tooling should extract + manifest them. [oai_citation:32â€¡AI Concepts & more.pdf](file-service://file-K6BctJjeUwvyCahLf9qdwr) [oai_citation:33â€¡Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf](file-service://file-RrXMFY7cP925exsQYermf2) [oai_citation:34â€¡Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf](file-service://file-RshcX5sNY2wpiNjRfoP6z6) [oai_citation:35â€¡Various programming langurages & resources 1.pdf](file-service://file-4wp3wSSZs7gk5qHWaJVudi)
[^run_manifest]: KFM proposes `run_manifest.json` + canonical JSON hashing (RFC 8785/JCS style) to support idempotency, exact run identity, and robust provenance linking. [oai_citation:36â€¡Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf](file-service://file-64djFYQUCmxN1h6L6X7KUw)
[^oci_registry]: ORAS + Cosign + OCI registry distribution is proposed for big artifacts (PMTiles, GeoParquet) with digest pinning and referrer-attached signatures/SBOMs; catalogs include OCI distribution metadata. [oai_citation:37â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T) [oai_citation:38â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)
[^pulse_threads]: Pulse Threads are proposed as a recurring, evidence-linked narrative artifact type with structured metadata and citation discipline. [oai_citation:39â€¡Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf](file-service://file-RrXMFY7cP925exsQYermf2)
[^concept_nodes]: Conceptual Attention Nodes are proposed as governed â€œconcept anchorsâ€ connecting domains, aliases, evidence, and policy constraints. [oai_citation:40â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-AkqwUuYPp5zePf7pv5SMxi)
[^graph_health]: Weekly graph health check is proposed as a recurring integrity and governance practice to catch drift/orphans and emit auditable reports. [oai_citation:41â€¡Comprehensive Markdown Guide_ Syntax, Extensions, and Best Practices.docx](file-service://file-J6rFRcp4ExCCeCdTevQjxz)
[^github_prov]: GitHub Actions reusable workflow is proposed to generate PROV from PRs/commits/workflow metadata, producing traceability artifacts for code-to-data provenance. [oai_citation:42â€¡ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals.docx.pdf](file-service://file-SQ3f7ve8SGiusT6ThZEuCe)
[^pmtiles_dual_pack]: KFM proposes dual geospatial packaging: GeoParquet for analytics and PMTiles for web/offline delivery, with STAC/DCAT records linking both distributions. [oai_citation:43â€¡ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals.docx.pdf](file-service://file-SQ3f7ve8SGiusT6ThZEuCe)
[^tile_postgis]: PostGIS adapter serves tiles via SQL templates like `ST_AsMVT`; emphasizes â€œPostGIS stores geo truth, catalogs describe assets, graph links context,â€ and mentions PMTiles/GeoParquet proposals in this ecosystem. [oai_citation:44â€¡ğŸ“š Kansas Frontier Matrix (KFM) Data Intake â€“ Technical & Design Guide.pdf](file-service://file-EbUCdsJMbu5KwpoKMrLrgj)
[^ml_metrics]: Macro-averaged precision/recall/F1 definitions are cited as useful for imbalanced classification reporting and governance-friendly evaluation summaries.
[^energy_telemetry]: KFM proposes tracking sustainability metrics (energy consumption / carbon footprint) as part of system observability and quality monitoring. [oai_citation:45â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf](file-service://file-4Umt1yHoGKicdmLWzFJ9sC)
[^markdown_guide]: Advanced GitHub Markdown patterns (callouts, Mermaid diagrams, tables) are referenced as writing conventions for consistent docs and run reports. [oai_citation:46â€¡Comprehensive Markdown Guide_ Syntax, Extensions, and Best Practices.docx](file-service://file-J6rFRcp4ExCCeCdTevQjxz)
[^dvc]: Mapping hub design proposes using DVC (or similar) to manage large data artifacts outside Git while maintaining reproducible pointers and workflow discipline. [oai_citation:47â€¡Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf](file-service://file-ShqHKgjxCS9UT9vbcxDNzA)
[^story_manifest]: Story Nodes are proposed to pair narrative text with structured evidence manifests and PROV links so CI can validate citation integrity and maintain auditability. [oai_citation:48â€¡Additional Project Ideas.pdf](file-service://file-Pc2GNivcrHBeKjBQksLC3T)