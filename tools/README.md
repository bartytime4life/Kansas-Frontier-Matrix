<div align="center">

# ğŸ› ï¸ Kansas Frontier Matrix â€” Tools (`/tools/`)

**Mission:** Provide **utility scripts and helper tools** that support  
data ingestion, processing, validation, and deployment workflows  
across the Kansas Frontier Matrix (KFM) project.  

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../.github/workflows/site.yml)  
[![Tests](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/tests.yml/badge.svg)](../.github/workflows/tests.yml)  
[![CodeQL](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/codeql.yml/badge.svg)](../.github/workflows/codeql.yml)  
[![Trivy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../.github/workflows/trivy.yml)  
[![Pre-Commit](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/pre-commit.yml/badge.svg)](../.github/workflows/pre-commit.yml)  
[![Docs Â· MCP](https://img.shields.io/badge/Docs-MCP-blue)](../docs/)  

</div>

---

## ğŸ¯ Purpose

The `/tools/` directory contains **scripts, utilities, and helper programs**  
that are not part of the deployed core system but are essential for:  

- ğŸ—‚ï¸ **Data management** â€” fetching, converting, and validating datasets.  
- ğŸ§ª **Testing & validation** â€” schema checks, STAC compliance, and CI helpers.  
- ğŸš€ **Automation** â€” build/deploy utilities and Makefile helpers.  
- ğŸ§­ **Exploration** â€” quick analysis, Jupyter notebooks, or migration helpers.  

All tools follow **Master Coder Protocol (MCP)**: documented, reproducible, and transparent.  

---

## ğŸ“š Structure

```text
tools/
â”œâ”€â”€ fetch_data.py         # Fetch raw datasets using source descriptors
â”œâ”€â”€ convert_gis.py        # Convert shapefiles/rasters â†’ GeoJSON/COG GeoTIFF
â”œâ”€â”€ validate_stac.py      # Validate STAC collections/items against schemas
â”œâ”€â”€ checksum.py           # Generate/verify SHA-256 provenance sidecars
â”œâ”€â”€ migrate_graph.py      # Load/update entities in Neo4j from ETL outputs
â”œâ”€â”€ build_config.py       # Regenerate app.config.json and layers.json
â”œâ”€â”€ notebooks/            # Jupyter notebooks for exploration / prototyping
â””â”€â”€ utils/                # Shared Python utilities (logging, config, helpers)


â¸»

âš™ï¸ Key Tools

fetch_data.py
	â€¢	Reads data/sources/*.json manifests.
	â€¢	Downloads referenced files (via HTTP, API, or ArcGIS REST).
	â€¢	Stores raw files in data/raw/.

convert_gis.py
	â€¢	Converts GIS datasets to open formats:
	â€¢	Vector â†’ GeoJSON
	â€¢	Raster â†’ Cloud-Optimized GeoTIFF (COG)
	â€¢	Reprojects to WGS84 (EPSG:4326) for consistency.

validate_stac.py
	â€¢	Runs JSON Schema + STAC 1.0.0 validation.
	â€¢	Ensures every item in data/stac/ is compliant before CI/CD passes.

checksum.py
	â€¢	Creates .sha256 files for all raw and processed data.
	â€¢	Verifies checksums to guarantee provenance integrity.

migrate_graph.py
	â€¢	Loads processed ETL outputs into the Neo4j knowledge graph.
	â€¢	Uses Cypher transactions for batch inserts.
	â€¢	Prevents duplicate entities by fuzzy-matching names/aliases.

build_config.py
	â€¢	Rebuilds frontend configs (app.config.json, layers.json).
	â€¢	Sources metadata from data/stac/ collections.
	â€¢	Ensures web UI stays synchronized with the latest datasets.

â¸»

ğŸš€ Usage

Typical workflows are orchestrated via Makefile targets.

# Fetch all external datasets
make fetch

# Convert raw GIS â†’ open formats
make convert

# Validate STAC catalog compliance
make stac-validate

# Verify checksums
make checksums

# Migrate data into Neo4j graph
make graph-migrate

# Rebuild web UI configs
make site-config

For ad-hoc usage, run tools directly:

python tools/fetch_data.py --source data/sources/usgs_topo.json
python tools/convert_gis.py input.shp output.json
python tools/validate_stac.py data/stac/items/*


â¸»

ğŸ§­ Guidelines
	â€¢	Every tool must:
	â€¢	Be documented with inline comments.
	â€¢	Support CLI help (-h/--help).
	â€¢	Log actions to stdout (and optionally to a provenance log).
	â€¢	Prefer open libraries (GDAL, rasterio, pyproj, pystac).
	â€¢	Small, reusable modules â†’ importable by other scripts.
	â€¢	Long-term or experimental workflows â†’ put in notebooks/ and migrate later.

â¸»


<div align="center">


ğŸ”— Tools are not throwaways â€” they are first-class,
documented, and reproducible under MCP standards.

</div>
```