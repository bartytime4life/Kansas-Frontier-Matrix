# ğŸ§° Tools (Dev + Ops Utilities)

![KFM](https://img.shields.io/badge/KFM-tools%20hub-1f6feb?style=for-the-badge)
![Scope](https://img.shields.io/badge/scope-dev%20%7C%20data%20ops%20%7C%20qa-0b7285?style=for-the-badge)
![Principle](https://img.shields.io/badge/principle-provenance--first-6f42c1?style=for-the-badge)

This folder contains **developer + operator tools** used to run, validate, and maintain the **Kansas Frontier Matrix (KFM)** platform in a **reproducible, provenance-first** way.

> ğŸ§  Guiding idea: tools should **help** the platformâ€”not bypass it.  
> Prefer **pipeline + catalog + API** workflows over direct DB edits whenever possible.

---

## ğŸ§­ Table of contents

- [ğŸ§© What belongs in `tools/`?](#-what-belongs-in-tools)
- [ğŸš€ Quickstart](#-quickstart)
- [ğŸ“ Tool index](#-tool-index)
- [ğŸƒ Running tools safely](#-running-tools-safely)
- [ğŸ”Œ Common API calls (useful for tools)](#-common-api-calls-useful-for-tools)
- [ğŸ§ª MCP standards for tool authors](#-mcp-standards-for-tool-authors)
- [ğŸ› ï¸ Troubleshooting](#ï¸-troubleshooting)
- [â• Adding a new tool](#-adding-a-new-tool)

---

## ğŸ§© What belongs in `tools/`

`tools/` is for **repeatable** utilities that support:

- ğŸ§± **Environment & stack management** (dev workflows, helper CLIs)
- ğŸ§¬ **Data operations** (ingest triggers, batch exports, format conversions)
- âœ… **Validation / QA** (schema checks, catalog integrity checks, spatial sanity tests)
- ğŸ“¦ **Packaging** (dataset bundles, release helpers, artifact stamping)
- ğŸ” **Diagnostics** (health checks, dependency verification, port checks)

What *doesnâ€™t* belong here:

- âŒ One-off experiments that arenâ€™t repeatable  
- âŒ Manual â€œhot fixesâ€ that bypass governance / provenance  
- âŒ Secret keys or sensitive datasets

---

## ğŸš€ Quickstart

### 1) Bring up the dev stack
From repo root (see main README for the canonical commands):

```bash
docker compose up -d
# or (older)
docker-compose up -d
```

### 2) Confirm the API is reachable
- Swagger UI: `http://localhost:8000/docs` ğŸ”

### 3) Run tools
Tools may run:
- **On your host** (shell/node/python scripts), or
- **Inside containers** via `docker compose exec` for consistent deps + mounted volumes.

---

## ğŸ“ Tool index

> Add new tools here as they are introduced. Keep this list current âœ…

### ğŸ§° Current tools

- **`tools/kfm/`** â€” KFM helper CLI / operational utilities  
  ğŸ‘‰ See: [`tools/kfm/README.md`](./kfm/README.md)

---

## ğŸƒ Running tools safely

### âœ… Preferred: run â€œin contextâ€ of the stack
Running inside the API container is often best because the environment already has:
- database connectivity (PostGIS / graph DB, etc.)
- mounted `data/` volumes
- any geospatial deps (GDAL/proj/etc.) installed in the image

Examples:

```bash
# open a shell inside the API container
docker compose exec api bash

# run a one-off pipeline script (example path)
docker compose exec api python pipelines/my_pipeline.py
```

### ğŸ§¯ Safety checklist
Before you run anything that changes data:

- [ ] Are you in the **correct environment** (dev vs prod)?
- [ ] Do you have a **dry-run** mode available?
- [ ] Are outputs versioned / logged?
- [ ] Are you preserving the **canonical pipeline order**?

---

## ğŸ” Canonical pipeline order

Tools should reinforce the platformâ€™s â€œsource â†’ proof â†’ productâ€ model:

```mermaid
flowchart LR
  raw[ğŸ“¥ Raw data] --> processed[âš™ï¸ Processed]
  processed --> prov[ğŸ§¾ Catalog & Provenance]
  prov --> db[ğŸ—„ï¸ Databases]
  db --> api[ğŸ§© API]
  api --> ui[ğŸ—ºï¸ UI]

  tools((ğŸ§° Tools))
  tools --> processed
  tools --> prov
  tools --> api
```

---

## ğŸ”Œ Common API calls (useful for tools)

These examples are handy when writing scripts that interact with KFM via the **backend API**.

> ğŸ§© Tip: If youâ€™re unsure which endpoints exist in your current build, use Swagger: `http://localhost:8000/docs`

### ğŸ—‚ï¸ Dataset metadata
```bash
curl -s "http://localhost:8000/api/v1/datasets/ks_hydrology_1880" | jq
```

### ğŸ” Catalog search
```bash
curl -s "http://localhost:8000/api/v1/catalog/search?q=railroad" | jq
```

### ğŸ§¾ Stream dataset data (GeoJSON example)
```bash
curl -s "http://localhost:8000/api/v1/datasets/ks_hydrology_1880/data?format=geojson&bbox=-102,36,-94,40" \
  | jq '.features[0]'
```

### ğŸ—ï¸ Trigger an ingest pipeline
```bash
curl -s -X POST "http://localhost:8000/api/v1/ingest/runPipeline" \
  -H "Content-Type: application/json" \
  -d '{
    "pipeline_id": "example_pipeline",
    "args": {"force": false}
  }' | jq
```

### ğŸ§  Focus Mode (AI-assisted query)
```bash
curl -s -X POST "http://localhost:8000/api/v1/ai/query" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "List major trails in Kansas and their purposes."
  }' | jq
```

### ğŸ•¸ï¸ GraphQL (if enabled)
```bash
curl -s -X POST "http://localhost:8000/graphql" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "query { storyNodes { id title yearRange } }"
  }' | jq
```

---

## ğŸ§ª MCP standards for tool authors

KFM is built around **reproducibility + rigor**. Tools should follow â€œMCPâ€ expectations:

### âœ… Tool quality bar
- **Reproducible:** same input â†’ same output (or explain nondeterminism)
- **Auditable:** logs include timestamps, versions, and key parameters
- **Traceable:** outputs link back to sources (dataset IDs, file paths, commit SHA, etc.)
- **Governed:** donâ€™t bypass catalog/provenance rules

### ğŸ”’ Minimum features (strongly recommended)
- `--help` with examples
- `--dry-run` (or â€œplanâ€ mode) for destructive actions
- deterministic output naming (include dataset IDs + timestamps)
- `--json` output option for machine-readable results
- exit codes (0 success, non-zero failure)

---

## ğŸ› ï¸ Troubleshooting

### ğŸ§± Containers wonâ€™t start / DB connection issues
```bash
docker compose logs api --tail=200
```

Common causes:
- **dependency timing:** DB not ready yet (restart stack)
- **port conflicts:** local Postgres on `5432`, Neo4j on `7474`, web/app on `3000/8000`
- **volume permissions:** container canâ€™t write to mounted `data/`

### ğŸ” Code changes not reflected
```bash
docker compose up -d --build
```

---

## â• Adding a new tool

Create a self-contained folder per tool:

```text
tools/
  my-tool/
    README.md
    bin/
      my-tool
    src/
    tests/
```

### ğŸ“Œ Expectations
- Include **purpose**, **inputs/outputs**, and **examples** in the toolâ€™s README
- Prefer container-executed workflows (`docker compose exec api ...`) when tools need DB/GDAL/etc.
- Update this index: [ğŸ“ Tool index](#-tool-index)

---

### âœ… Suggested conventions

| Item | Recommendation |
|------|----------------|
| Naming | short, verb-ish (`reindex`, `export`, `validate`) |
| Logging | always log inputs + output locations |
| Safety | add `--dry-run` + â€œdanger zoneâ€ callouts |
| Docs | include a â€œWhat it changesâ€ section |
| CI | add at least a smoke test if feasible |

---

> ğŸ§­ If youâ€™re unsure where something should live:  
> - â€œone time experimentâ€ â†’ `docs/` or `notebooks/` (if present)  
> - â€œrepeatable utilityâ€ â†’ `tools/` âœ…  
> - â€œcore platform featureâ€ â†’ backend/frontend modules