<!--
ğŸ§­ Governed Markdown (optional)
id: tools.web.readme
owner: Kansas-Matrix-System
status: draft
last_updated: 2026-01-14
-->

# ğŸŒ `tools/web` â€” Web Tooling (Provenance-First, Web-Ready Artifacts)

<p align="center">
  <img alt="Kansas-Matrix-System banner" src="https://img.shields.io/badge/Kansas--Matrix--System-Web%20Tooling-1f6feb?style=for-the-badge" />
</p>

<p align="center">
  <img alt="Provenance First" src="https://img.shields.io/badge/ğŸ§¾%20Provenance-First-success?style=flat-square" />
  <img alt="Contract First" src="https://img.shields.io/badge/ğŸ“œ%20Contracts-Validated-success?style=flat-square" />
  <img alt="Open Standards" src="https://img.shields.io/badge/ğŸŒ%20Standards-STAC%20%7C%20DCAT%20%7C%20PROV--O-blue?style=flat-square" />
  <img alt="Web Output" src="https://img.shields.io/badge/ğŸ—ºï¸%20Web-Static%20Viewer%20Ready-blueviolet?style=flat-square" />
  <img alt="Security Mindset" src="https://img.shields.io/badge/ğŸ”%20Security-Logs%20%26%20Guardrails-orange?style=flat-square" />
</p>

> **What this folder is:** the â€œbridgeâ€ between **cataloged sources â†’ validated metadata â†’ web-ready artifacts** (indexes, manifests, citations, attribution bundles, and optional static-site build helpers).  
> **What it is not:** a place for â€œmystery layersâ€ or untracked data. If it shows up in the UI/AI, it must be traceable and reproducible.

---

## âœ¨ Why `tools/web` exists

KFM/Kansas-Matrix-System is built on **contract-first** + **provenance-first** principles: every dataset/layer/story snippet must have **metadata and lineage** you can inspect, validate, and cite. `tools/web` operationalizes that philosophy by turning your *catalog + provenance* into *web-consumable* outputs.

This module specifically focuses on:

- âœ… **Validation**: fail fast if metadata contracts are incomplete (license, spatial/temporal extent, processing steps, source attribution).
- âœ… **Packaging**: generate deterministic web assets (manifests, indexes, attribution bundles).
- âœ… **Traceability**: connect UI/Focus Mode outputs back to cataloged sources with citation scaffolding.
- âœ… **Reproducibility**: make â€œbuild the site / build the indexâ€ deterministic (CI-friendly, DVC-friendly, cache-friendly).

---

## ğŸ§± Core design pillars

### 1) ğŸ§¾ Provenance-first or it doesnâ€™t ship
If a layer, story element, or AI answer appears anywhere, we must be able to answer:

- Where did it come from?
- Under what license can we use it?
- What transformations created it?
- What exact artifact/version is referenced?

### 2) ğŸ“œ Contract-first, validated by tooling
Metadata JSON is a **data contract**. `tools/web` assumes your pipeline enforces these contracts before data is accepted into the official catalog.

### 3) ğŸ§© Clean boundaries (ports/adapters mindset)
This folder should expose **stable interfaces** so that:
- the backend (FastAPI / services),
- pipelines (ETL),
- and the frontend viewer (web)
can evolve without breaking one another.

### 4) ğŸ§  Human-centered + ethical safeguards
The web surface is where trust is won or lost. We ship:
- transparent sourcing,
- clear AI labeling,
- and guardrails that prevent â€œsilent, untraceableâ€ outputs.

---

## ğŸ—‚ï¸ What belongs in here

Think of `tools/web` as a toolbox of **build-time** and **publish-time** tasks.

### âœ… Typical responsibilities
- Build/refresh a **dataset & story index** used by the web UI (search, timeline, filters)
- Build/refresh **attribution bundles** (credits, license summaries, source lists)
- Build/refresh **citation-ready evidence objects** (for Focus Mode panels)
- Validate catalog JSON + STAC/DCAT/provenance fragments
- Generate **web manifests** for layers (tiles, COGs, GeoJSON/GeoParquet pointers)

### ğŸš« What should *not* live here
- Business/domain logic (belongs in core services)
- One-off scripts with no logging, no tests, no deterministic outputs
- Anything that fetches remote data without storing provenance + license metadata

---

## ğŸ§­ Recommended folder layout

> Adjust to match your repo â€” the goal is clarity + separation. âœ‚ï¸

```text
ğŸ§° tools/
  ğŸŒ web/
    ğŸ“„ README.md
    ğŸ§ª tests/
    ğŸ§© src/
      ğŸ§± contracts/          # schemas + validators (JSONSchema/Pydantic/etc)
      ğŸ§¾ citations/          # evidence + citation builders
      ğŸ§­ index/              # search/timeline/catalog index builders
      ğŸ—ºï¸ manifests/          # layer manifests (tiles/COGs/vector endpoints)
      ğŸ§° build/              # web build helpers (optional)
      ğŸ” policy/             # safe defaults (rate limits, allowlists, robots, etc)
    ğŸ“¦ fixtures/             # tiny test fixtures (sample metadata, sample STAC items)
```

---

## ğŸš€ Quickstart

### 1) Run validations (contracts first)
```bash
# Example patterns (adapt to your runner)
python -m tools.web.contracts.validate data/catalog/**/*.json
```

### 2) Build the web indexes (deterministic output)
```bash
python -m tools.web.index.build \
  --catalog data/catalog \
  --out web/assets/index
```

### 3) Generate attribution + citations bundle
```bash
python -m tools.web.citations.build \
  --catalog data/catalog \
  --out web/assets/attribution
```

### 4) (Optional) Build/refresh the static web viewer
```bash
# If your repo uses a Makefile convention
make site
```

---

## ğŸ§© Interfaces & contracts (recommended)

> These are *suggested* stable interfaces so tooling stays modular.

### ğŸ§¾ `SourceRecord`
A minimal, web-friendly source record:

```json
{
  "id": "dataset:water_quality_1990s:v3",
  "title": "Water Quality Measurements (1990s)",
  "source": {
    "name": "Agency / Archive Name",
    "url": "https://example.org/dataset",
    "retrieved_at": "2026-01-14T00:00:00Z"
  },
  "license": {
    "name": "CC-BY 4.0",
    "url": "https://creativecommons.org/licenses/by/4.0/"
  },
  "spatial_extent": { "bbox": [-102.05, 36.99, -94.59, 40.00] },
  "temporal_extent": { "start": "1990-01-01", "end": "1999-12-31" },
  "processing": [
    { "step": "clean", "tool": "pipeline/water_quality_clean.py", "hash": "sha256:..." },
    { "step": "export", "format": "GeoParquet", "hash": "sha256:..." }
  ],
  "artifacts": [
    { "type": "geoparquet", "path": "data/processed/water_quality_1990s_v3.parquet" },
    { "type": "stac_item", "path": "data/stac/items/water_quality_1990s_v3.json" }
  ]
}
```

### ğŸ” `WebIndex`
A single merged index that your UI can load quickly:

- `datasets[]` (title, id, tags, extents, quick links, thumbnails)
- `stories[]` (title, id, chapter, linked dataset ids)
- `places[]` (optional: knowledge graph extract for map search)
- `build_info` (git sha, build time, schema version)

### ğŸ—ºï¸ `LayerManifest`
One manifest per layer (tiles + vector endpoints + legend):

- tile endpoints (XYZ, PMTiles, WMTS, etc.)
- COG pointers
- legend and symbology hints
- attribution and license snippet (pulled from contracts)

---

## ğŸ§  How this supports Focus Mode (Evidence Panels)

`tools/web` should make it easy for the UI (and AI) to show:

- **What the claim is**
- **What dataset(s) support it**
- **What the license is**
- **How the dataset was processed**
- **How to reproduce the artifact**

A practical pattern:

- Build a **citation bundle** once at publish time
- Ship it to `web/assets/attribution/`
- UI uses it for â€œSourcesâ€ popovers and AI evidence panels

---

## ğŸ›¡ï¸ Security & policy defaults

Even if this folder only does â€œbuild-time work,â€ itâ€™s part of a system that:

- ingests from external sources,
- exposes outputs to the public,
- and supports AI summaries.

So we ship strong defaults:

- ğŸ§¾ **Always** require license + attribution fields
- ğŸ§ª Validate schema in CI
- ğŸ§¯ Avoid embedding secrets in build artifacts
- ğŸ§µ Produce structured logs for auditability
- ğŸ§¼ Strip/escape untrusted HTML if any text is packaged for UI

> Bonus: align logs/alerts with the broader platformâ€™s audit mindset (misuse detection, anomalous behavior patterns, etc.).

---

## ğŸ§ª Testing philosophy

**Small, deterministic, fixture-driven.**

- âœ… unit tests for validators + builders
- âœ… â€œgolden fileâ€ tests for generated indexes/manifests
- âœ… schema regression tests (old catalogs must still validate or explicitly migrate)

---

## ğŸ—ºï¸ How this relates to the rest of the repo

Typical flow:

```mermaid
flowchart LR
  A[(data/sources)] --> B[pipelines: ingest/clean/transform]
  B --> C[(data/catalog + STAC/DCAT/PROV)]
  C --> D[tools/web: validate]
  D --> E[tools/web: build indexes + attribution + manifests]
  E --> F[(web/assets)]
  F --> G[web viewer / UI]
  C --> H[Focus Mode / Knowledge Graph]
```

---

## ğŸ§° Make targets (suggested convention)

| Target | What it should do | Output |
|---|---|---|
| `make validate` | validate metadata contracts + STAC/DCAT/PROV fragments | CI gate âœ… |
| `make index` | build dataset/story/place indexes | `web/assets/index/*` |
| `make attribution` | generate citations + attribution bundle | `web/assets/attribution/*` |
| `make site` | build/refresh the web viewer | `web/dist` or `web/` |

---

## ğŸ§­ Contribution checklist

Before a PR touching `tools/web` is â€œdoneâ€ âœ…:

- [ ] New/updated schema is versioned (no silent breaking changes)
- [ ] Tests include fixtures and deterministic expected outputs
- [ ] Generated artifacts include `build_info` (timestamp + git sha + schema version)
- [ ] Attribution fields are preserved end-to-end
- [ ] No new script bypasses provenance/contract rules

---

## ğŸ“š Project reference library (used to shape this module)

These project docs/books inform decisions in `tools/web` (architecture, governance, UI readiness, security posture, data pipelines, and statistical validation).

<details>
  <summary><strong>ğŸ“Œ Architecture, governance & system design</strong></summary>

- ğŸ“˜ Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation *(contracts, provenance, AI guardrails, scalable web architecture)*
- ğŸ§© Kansas-Frontier-Matrix â€” Open-Source Geospatial Historical Mapping Hub Design *(repo structure, Makefile conventions, DVC, static viewer build patterns)*
- ğŸ§  Introduction to Digital Humanism *(accountability, transparency, sociotechnical risks)*
- ğŸ—ƒï¸ Data Spaces *(systems integration + modular data exchange patterns)*

</details>

<details>
  <summary><strong>ğŸ—ºï¸ GIS, mapping, remote sensing & web delivery</strong></summary>

- â˜ï¸ Cloud-Based Remote Sensing with Google Earth Engine *(pipelines + external compute orchestration)*
- ğŸ§­ python-geospatial-analysis-cookbook *(GeoJSON, PostGIS workflows, practical export patterns)*
- ğŸ—ºï¸ Making Maps: A Visual Guide to Map Design for GIS *(cartographic communication for UI outputs)*
- ğŸ“± Mobile Mapping: Space, Cartography and the Digital *(mobile constraints + interaction patterns)*
- ğŸº Archaeological 3D GIS *(3D spatial storytelling use-cases)*

</details>

<details>
  <summary><strong>ğŸ¨ Web UI, rendering & front-end readiness</strong></summary>

- ğŸ“ Responsive Web Design with HTML5 and CSS3 *(layout, accessibility, responsive strategy)*
- ğŸ§Š WebGL Programming Guide *(3D rendering foundations for map/scene viewers)*

</details>

<details>
  <summary><strong>ğŸ—„ï¸ Databases, performance & scaling</strong></summary>

- ğŸ˜ PostgreSQL Notes for Professionals *(practical Postgres patterns)*
- âš¡ Database Performance at Scale *(I/O, infra, disk considerations)*
- ğŸ§¬ Scalable Data Management for Future Hardware *(parallelism + future-proof storage/compute thinking)*

</details>

<details>
  <summary><strong>ğŸ“Š Stats, ML, analysis quality & evaluation</strong></summary>

- ğŸ“‰ Understanding Statistics & Experimental Design *(A/B tests, measurement discipline for UX & extraction)*
- ğŸ“ˆ Regression Analysis with Python *(model evaluation + fit diagnostics for derived analytics)*
- ğŸ§® Regression analysis using Python â€” slides *(quick reference)*
- ğŸ² Think Bayes *(Bayesian reasoning for ranking/uncertainty in evidence)*
- ğŸ“Š Graphical Data Analysis with R *(exploratory analysis of pipeline + index quality metrics)*
- ğŸ§  Deep Learning for Coders with fastai & PyTorch *(optional: embeddings / ranking / semantic search)*

</details>

<details>
  <summary><strong>ğŸ” Security mindset & adversarial thinking</strong></summary>

- ğŸ›¡ï¸ Ethical Hacking & Countermeasures *(logging, monitoring, intrusion mindset)*
- ğŸ Gray Hat Python *(defensive awareness; do not misuseâ€”use for secure engineering context)*

</details>

<details>
  <summary><strong>ğŸ§© Additional math/engineering references used across the system</strong></summary>

- ğŸ§± Scientific Modeling and Simulation (NASA-grade guide) *(rigor + reproducibility mindset)*
- ğŸ§¬ Principles of Biological Autonomy *(systems thinking inspiration)*
- ğŸ§® Spectral Geometry of Graphs *(graph analytics foundations)*
- ğŸ—ï¸ Generalized Topology Optimization for Structural Design *(optimization mindset; not directly web, but informs pipeline discipline)*
- ğŸ–¼ï¸ Compressed Image File Formats (JPEG/PNG/GIF/â€¦) *(image handling for thumbnails/tiles/assets)*
- ğŸ“š A / B-C / D-E / F-H / I-L / M-N / O-R / S-T / U-X programming books *(broad engineering reference set)*

</details>

---

## ğŸ§­ Roadmap (optional, but recommended)

- [ ] Schema versioning + migration tool (`tools/web/contracts/migrate`)
- [ ] â€œEvidence packâ€ format for Focus Mode (claim â†’ sources â†’ artifacts)
- [ ] Robust license normalization + attribution formatter
- [ ] Optional `web/assets/search` builder for full-text or semantic index
- [ ] CI job that blocks publish if any artifact lacks provenance fields

---

## ğŸ§© Related docs

- ğŸ“„ `../../README.md` â€” project overview
- ğŸ§¾ `../../docs/` â€” architecture + governance docs
- ğŸ—ºï¸ `../../web/` â€” the viewer (if present)
- ğŸ§ª `../../pipelines/` or `../../scripts/` â€” ingestion & processing

---

**If youâ€™re unsure where to add something:**  
Ask â€œIs this about turning *cataloged + validated* data into *web-ready* outputs?â€  
If yes âœ… â†’ it likely belongs in `tools/web`.  
If no âŒ â†’ it belongs elsewhere (domain/service/pipeline/frontend).

