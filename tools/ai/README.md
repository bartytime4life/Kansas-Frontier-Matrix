# ğŸ§  tools/ai â€” Evidenceâ€‘Backed AI Toolbelt

![KFM](https://img.shields.io/badge/KFM-Kansas%20Frontier%20Matrix-1f6feb)
![AI](https://img.shields.io/badge/AI-Focus%20Mode%20%7C%20RAG-6f42c1)
![Policy](https://img.shields.io/badge/Policy-OPA%20(Policy%20as%20Code)-0b7285)
![Runtime](https://img.shields.io/badge/Runtime-Ollama%20(Local%20LLM)-f97316)
![Trust](https://img.shields.io/badge/Trust-Provenance%E2%80%91First%20%F0%9F%91%A3-2ea44f)
![Data](https://img.shields.io/badge/Data-STAC%20%2B%20DCAT%20%2B%20PROV-0ea5e9)

> [!IMPORTANT]
> **KFM AI is advisory-only and evidence-first.** Every answer must include citations, and any output is policy-checked before it reaches the UI.

---

## ğŸ¯ What this folder is for

`tools/ai/` is the **developer toolbelt + runbook** for KFMâ€™s AI features (especially **Focus Mode**), including:

- ğŸ§© **Local model runtime** guidance (Ollama) and deployment patterns  
- ğŸ” **Retrieval + indexing** helpers (hybrid: graph + spatial + text/vector)  
- ğŸ›¡ **Governance + safety** (Prompt Gate + OPA policy checks + allow/deny tool controls)  
- ğŸ§ª **Evaluation & reproducibility** workflows (golden sets, deterministic scenarios, audits)  
- ğŸ§¾ **Provenance enforcement** (â€œno citation, no answerâ€) and logging conventions

> [!NOTE]
> This README defines the **contract** for AI tooling in KFM. If your repo structure differs, keep the principles and update paths accordingly.

---

## ğŸ§­ North Star rules (nonâ€‘negotiables)

### âœ… Evidence-first (no black boxes)
- All AI answers must cite supporting KFM sources (footnote-style, e.g. `[1]`, `[2]`).
- Datasets are packaged with metadata + lineage via the **catalog triplet**: **STAC + DCAT + PROV**.
- If a claim canâ€™t be supported by retrieved evidence, the assistant must refuse or clearly express uncertainty.

### âœ… Least privilege by default
- Focus Modeâ€™s model runtime is **sandboxed**: no internet, no filesystem, no arbitrary tool execution.
- Any future tool use is gated via explicit **allowlists**.

### âœ… Policy as code (OPA)
- Inputs are filtered through a **Prompt Gate** (prompt injection + disallowed content).
- Outputs are checked by **OPA** rules that can **block, redact, or require safe fallbacks**.

### âœ… Reproducible by design
- Pipelines and modeling runs should be deterministic (seeded, frozen dependencies, controlled external calls).
- Scenario testing stays isolated until humans approve merges.

---

## ğŸ§  How Focus Mode works

### ğŸ§© High-level pipeline

```mermaid
flowchart LR
  U[ğŸ‘¤ User] --> UI[ğŸ–¥ï¸ Focus Mode UI Panel]
  UI --> PG[ğŸ§¼ Prompt Gate\nsanitize + normalize input]
  PG --> RET[ğŸ” Hybrid Retrieval\nNeo4j + PostGIS + Search/Vector]
  RET --> CTX[ğŸ“¦ Context Bundle\nsnippets + IDs + metadata]
  CTX --> LLM[ğŸ¤– LLM Runtime\n(Ollama / local)]
  LLM --> DRAFT[ğŸ“ Draft Answer\n+ citations]
  DRAFT --> OPA[ğŸ›¡ OPA Policy Check\nblock/redact/allow]
  OPA --> LEDGER[ğŸ§¾ PROV/AI Ledger\nhash + version metadata]
  OPA --> UI
```

### ğŸ” Hybrid retrieval (why it matters)
Focus Mode is designed to â€œgroundâ€ answers using:
- ğŸ§  **Knowledge graph** relationships (Neo4j)  
- ğŸ—º **Spatial queries** (PostGIS)  
- ğŸ§¾ **Full-text + vector similarity** (search index + embeddings)  

Then it packages evidence as a **context bundle** so the LLM answers from *KFM data*, not vibes.

---

## ğŸ—‚ï¸ Suggested layout inside `tools/ai/`

> [!TIP]
> If the repo already has a different layout, treat this as a **recommended standard**. The key is: prompts, policies, retrieval, evals are versioned and testable.

```text
tools/ai/
â”œâ”€â”€ ğŸ“„ README.md
â”œâ”€â”€ ğŸ“ ollama/                      # local LLM runtime helpers
â”‚   â”œâ”€â”€ ğŸ“„ docker-compose.ollama.yml
â”‚   â”œâ”€â”€ ğŸ“„ Modelfile                # optional: pinned settings / system prompt
â”‚   â””â”€â”€ ğŸ“„ models.md                # approved models list + pinning notes
â”œâ”€â”€ ğŸ“ prompts/                     # system prompts + templates (versioned)
â”‚   â”œâ”€â”€ ğŸ“„ focus_mode.system.md
â”‚   â”œâ”€â”€ ğŸ“„ focus_mode.user.md
â”‚   â””â”€â”€ ğŸ“„ citations.contract.md
â”œâ”€â”€ ğŸ“ policies/                    # governance as code
â”‚   â”œâ”€â”€ ğŸ“ opa/
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ ai_output.rego        # citation + safety rules
â”‚   â”‚   â”œâ”€â”€ ğŸ“„ sensitive_geo.rego    # redaction rules (sacred sites, etc.)
â”‚   â”‚   â””â”€â”€ ğŸ“„ pii.rego              # PII protections
â”‚   â””â”€â”€ ğŸ“ schemas/                 # JSON Schema / SHACL / validators
â”œâ”€â”€ ğŸ“ retrieval/                   # indexing + retrieval glue
â”‚   â”œâ”€â”€ ğŸ“„ build_index.py
â”‚   â”œâ”€â”€ ğŸ“„ embed_corpus.py
â”‚   â””â”€â”€ ğŸ“„ kg_query_templates.cypher
â”œâ”€â”€ ğŸ“ eval/                        # eval harness + golden sets
â”‚   â”œâ”€â”€ ğŸ“ golden/
â”‚   â”œâ”€â”€ ğŸ“ datasets/
â”‚   â””â”€â”€ ğŸ“„ run_eval.py
â””â”€â”€ ğŸ“ runbooks/                    # operational playbooks
    â”œâ”€â”€ ğŸ“„ incident_ai.md
    â”œâ”€â”€ ğŸ“„ model_upgrade.md
    â””â”€â”€ ğŸ“„ policy_changes.md
```

---

## ğŸš€ Quickstart (local)

### 1) Start an LLM runtime (Ollama)

You can run Ollama either as:
- ğŸ§‘â€ğŸ’» **Host service** (`ollama serve`)  
- ğŸ³ **Docker container** (recommended for consistent dev environments)

#### ğŸ³ Example `docker-compose` for Ollama

```yaml
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    environment:
      - OLLAMA_KEEP_ALIVE=24h
    deploy:
      resources:
        limits:
          memory: 16g
volumes:
  ollama_data:
```

> [!IMPORTANT]
> In production, prefer **pinning** images/models by digest + recording versions in provenance logs (model upgrades must be auditable).

---

### 2) Point KFM to the runtime

Typical env vars (names may differâ€”standardize them in your repo):

```bash
export OLLAMA_API_URL="http://localhost:11434"
export KFM_AI_MODEL="your-chat-model"
export KFM_EMBED_MODEL="your-embedding-model"
```

---

### 3) Smoke test (LLM reachable)

```bash
curl -s "$OLLAMA_API_URL/api/tags" | head
```

If that returns JSON, the runtime is up âœ…

---

## ğŸ§¾ Provenance & citations

### â€œNo citation, no answerâ€ enforcement

Focus Mode should always produce **footnote-style** citations:

- In text: `â€¦ drought conditions peaked in 1936 [1].`
- Then a footer list mapping `[1]` â†’ dataset record / STAC item / document ID.

> [!NOTE]
> This is intentionally strict: it reduces hallucinations and makes answers auditable.

### ğŸ›¡ OPA policy example: enforce citation markers

A simple rule pattern is: *if the answer contains factual claims, require at least one `[\d+]` marker.*

```rego
package kfm.ai.output

default allow = false

# naive example: require at least one [number] style citation
allow {
  regex.match("\\[[0-9]+\\]", input.answer)
}
```

> [!WARNING]
> This is only a starter. Real policies should also cover: sensitive locations, PII redaction, dataset permission checks, and â€œhallucinated entitiesâ€ constraints.

---

## ğŸ›¡ï¸ Security & governance checklist

### ğŸ§¼ Prompt Gate (input)
- Detect + neutralize prompt injection attempts
- Block disallowed requests (PII fishing, hate speech, etc.)
- Normalize the prompt before it hits the model

### ğŸ§° Tool allow/deny lists
- Default: **no tools** (text-only)
- Any future tool must be explicitly approved, reviewed, logged, and monitored

### ğŸ§¯ Output checks (OPA)
- Block unsafe content
- Redact sensitive geo coordinates (e.g., protected cultural sites)
- Require hedging for speculative content
- Require that referenced entities exist in the knowledge graph (anti-hallucination guardrail)

### ğŸ” Secrets & UI hardening
- Keep credentials inaccessible to the AI process
- Use CSP headers to reduce XSS risk
- Rate-limit AI endpoints

---

## ğŸ§ª Evaluation, reproducibility & â€œsafe experimentationâ€

### ğŸ§° Deterministic scenario testing (`kfm-sim-run`)
KFMâ€™s design includes a sandbox runner that:
- creates an isolated copy of the data environment
- freezes timestamps/seeds/external calls for repeatability
- can produce a **draft PR** including updated data + metadata + PROV  
- keeps simulated outputs separate until **human review & merge**

### ğŸŒ¬ Bias correction models (example: `kfm-air-correct`)
Domain modules can â€œimprove data qualityâ€ using transparent, documented methods (e.g., quantile mapping + extreme handling) and publish outputs as new datasets with full provenance.

---

## ğŸŒ Federation-ready AI (long-term)

KFMâ€™s roadmap anticipates a network of interoperable â€œFrontier Matrixâ€ instances:
- Standard schemas + APIs so regions can interoperate
- Potential **GraphQL federation** to query across multiple instances
- Shared artifact practices (OCI-style packaging, signed attestations) so datasets/models remain verifiable across deployments

---

## ğŸ“š Project docs & reference library (used to shape this README)

> [!TIP]
> Keep authoritative PDFs under something like `docs/pdfs/` (or `docs/_sources/`) and link them here for discoverability.

### ğŸ§­ Core KFM architecture & AI governance
- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Platform Overview and Roadmap**  
- **Kansas Frontier Matrix (KFM) â€“ Comprehensive UI System Overview (Technical Architecture Guide)**  
- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design**  
- **Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–**  
- **ğŸ“š Kansas Frontier Matrix (KFM) â€“ Expanded Technical & Design Guide**  
- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation**  
- **KFM AI Infrastructure â€“ Ollama Integration Overview**

### ğŸ§ª Engineering rigor & documentation standards
- **Scientific Method / Research / Master Coder Protocol Documentation** (testing, CI, deterministic outputs, experiment tracking)
- **Markdown guide / repo layout guidance** (recommended structure for docs/data/schemas/tools)

### ğŸ§  AI + data science reading binders (PDF portfolios)
- **AI Concepts & more** (AI/ML concepts + reference materials)
- **Data Management / Theories / Architectures / Data Science / Bayesian Methods** (data architecture + probabilistic modeling references)
- **Various programming languages & resources** (polyglot skill-up binder)
- **Mapping/Modeling/Python/Git/HTTP/CSS/Docker/GraphQL/Data Compression/Linux/Security** (full-stack + infra references)
- **Geographic Information/Security/Git/R/SciPy/MATLAB/ArcGIS/Spark/TypeScript/Web Apps** (geo + compute + app references)
- **Maps/GoogleMaps/VirtualWorlds/Archaeological Computer Graphics/Geospatial/WebGL** (3D/immersive geovis + webgl references)

---

## ğŸ¤ Contributing to AI tooling

### âœ… Pull-request expectations
- ğŸ§ª Tests included (unit + integration where relevant)
- ğŸ§¾ Policies updated alongside new behaviors (OPA + prompts)
- ğŸ§  Prompts treated as versioned artifacts (reviewed like code)
- â™»ï¸ Determinism where possible (seed, pinned deps, controlled externals)
- ğŸ““ Logs + provenance updates included (so outputs remain auditable)

### ğŸ§· A practical PR checklist
- [ ] Does the change preserve **â€œno citation, no answerâ€**?
- [ ] Are any new data sources represented as **STAC/DCAT/PROV**?
- [ ] Did we update **OPA** rules for new edge cases?
- [ ] Are we leaking anything sensitive (PII / protected locations)?
- [ ] Did we pin model/runtime versions and record them?

---

## ğŸ†˜ Troubleshooting quick hits

- **Model answers without citations** â†’ treat as failure; block or refuse by policy  
- **OPA blocks too aggressively** â†’ revise policy + add regression tests (donâ€™t bypass)  
- **Slow answers** â†’ check retrieval scope, context size, and caching (donâ€™t remove guardrails)  
- **Weird hallucinated entities** â†’ enforce â€œentity must exist in KGâ€ policy + tighten retrieval

---

### ğŸ§© Related areas
- `src/pipelines/` âš™ï¸ ETL + model runs (deterministic, provenance tracked)  
- `src/graph/` ğŸ§  ontology + graph build + constraints  
- `src/server/` ğŸŒ FastAPI/GraphQL boundary  
- `web/` ğŸ—º React + MapLibre/Cesium UI (Focus Mode panel lives here)  
- `schemas/` ğŸ“ JSON Schema / SHACL contracts (telemetry, story nodes, catalogs)  

---