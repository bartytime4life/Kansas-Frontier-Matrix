# ğŸ¤– `tools/ml` â€” Machine Learning Toolkit (Kansas Frontier Matrix)

![Status](https://img.shields.io/badge/status-WIP-orange) ![Focus](https://img.shields.io/badge/focus-provenance--first-blue) ![Scope](https://img.shields.io/badge/scope-geospatial%20%2B%20timeseries%20%2B%20imagery-green)  
![Stack](https://img.shields.io/badge/stack-Python%20%7C%20PostGIS%20%7C%20GEE%20%7C%20WebGL-informational) ![Ethos](https://img.shields.io/badge/ethos-digital%20humanism-purple)

> ğŸ§­ **North Star:** ML inside KFM must be **searchable, mappable, auditable, and modelable** â€” with **sources + processing steps** treated as firstâ€‘class citizens. :contentReference[oaicite:0]{index=0}

---

## ğŸ¯ What this folder is

`tools/ml/` is the **ML workbench** for KFM: training, evaluation, and deployment helpers for models that operate on **Kansasâ€™s spatial truth** â€” from scanned archival maps to sensor streams and satellite imagery.

It is designed for:
- ğŸ—ºï¸ **Geospatial ML** (vector + raster + spatiotemporal)
- ğŸ“¡ **Remote sensing** (GEE + local pipelines)
- ğŸ§ª **Reproducible experiments** (statsâ€‘correct, leakageâ€‘resistant)
- ğŸ§¾ **Provenance-first artifacts** (dataset manifests + model cards)
- ğŸ§° **Practical baselines first** (regression/classification before deep nets)
- ğŸ§© **Clean architecture integration** (ports/adapters, not spaghetti) :contentReference[oaicite:1]{index=1}

---

## ğŸ§± Nonâ€‘negotiable principles

### 1) ğŸ§¾ Provenance-first
Every dataset, feature set, trained model, and prediction must be traceable to:
- source datasets (IDs/URLs/archives)
- transformations (parameters + code version)
- evaluation protocol (split strategy, metrics)
- assumptions + limitations

KFM treats citations/metadata as â€œfirst-class data,â€ avoiding black boxes. :contentReference[oaicite:2]{index=2}

### 2) ğŸ§  Advisory AI only
KFM AI is **assistive** and **evidence-backed**.  
No autonomous decision-making, no silent policy recommendations. :contentReference[oaicite:3]{index=3}

### 3) ğŸ§ª Statistics-correct evaluation
We prioritize:
- spatial/temporal cross-validation (not random splits by default)
- uncertainty + error bars (not just point metrics)
- experiment design discipline (avoid â€œdashboard scienceâ€)

### 4) â™»ï¸ Reproducible by default
If you canâ€™t rerun it, you canâ€™t ship it:
- pinned env + deterministic seeds (where feasible)
- manifests for datasets and models
- machine-readable run logs

### 5) ğŸ§° Baselines before â€œSOTAâ€
Start with interpretable baselines:
- linear/logistic regression
- tree ensembles
- generalized linear models
- Bayesian baselines when uncertainty matters

(ML theory + practical algorithms foundations) :contentReference[oaicite:4]{index=4} :contentReference[oaicite:5]{index=5}

---

## ğŸ—ï¸ How `tools/ml` fits into KFM

KFM follows a modular / clean architecture approach (core domain â†” use cases â†” adapters). ML tooling should **plug in**, not sprawl. :contentReference[oaicite:6]{index=6}

```mermaid
flowchart TB
  subgraph KFM["Kansas Frontier Matrix ğŸ§­"]
    A["Domain Entities ğŸ§©\n(parcels, maps, sensors, events)"]
    B["Use Cases / Services âš™ï¸\n(query, compare, simulate, report)"]
    C["Ports & Adapters ğŸ”Œ\n(DB, GEE, file stores, UI)"]
  end

  subgraph ML["tools/ml ğŸ¤–"]
    D["Dataset Builder ğŸ§¾\n(manifests + feature specs)"]
    E["Training + Tuning ğŸ§ª\n(baselines â†’ advanced)"]
    F["Evaluation ğŸ§­\n(spatial/temporal splits)"]
    G["Registry + Model Cards ğŸ“¦\n(versioned artifacts)"]
    H["Inference ğŸ±\n(batch + realtime)"]
  end

  A --> B --> C
  D --> E --> F --> G --> H
  ML --> C
  B --> ML
```

---

## ğŸ“ Suggested layout (inside `tools/ml/`)

> âœ… Treat this as a **contract** for what belongs here (and what doesnâ€™t).

```text
tools/ml/ ğŸ¤–
â”œâ”€ ğŸ§¾ manifests/                  # dataset + model manifests (YAML/JSON)
â”œâ”€ ğŸ§º datasets/                   # dataset builders + validators
â”œâ”€ ğŸ§± features/                   # feature engineering (geo, time, text, imagery)
â”œâ”€ ğŸ§  models/                     # model definitions (baseline â†’ advanced)
â”œâ”€ ğŸ§ª training/                   # train loops, tuning, tracking
â”œâ”€ ğŸ§­ eval/                       # metrics, spatial CV, error analysis
â”œâ”€ ğŸ“¦ registry/                   # model cards, artifact metadata, promotion gates
â”œâ”€ ğŸ± serving/                    # inference adapters (batch, streaming, API)
â”œâ”€ ğŸ—ºï¸ viz/                        # mapping helpers + tiles/overlays + WebGL hooks
â”œâ”€ ğŸ““ notebooks/                  # exploration (kept disposable + documented)
â”œâ”€ ğŸ› ï¸ scripts/                    # CLI entrypoints (build/train/eval/pack)
â”œâ”€ âœ… tests/                      # unit + data-contract + leakage tests
â””â”€ ğŸ“˜ README.md                   # you are here
```

---

## ğŸš€ Quickstart (workflow contract)

Even before code exists, we standardize *the shape* of workflows.

### 0) Decide the *problem class* ğŸ¯
- **Tabular regression/classification** (sensor + parcel features)
- **Raster/imagery** (classification, segmentation, change detection)
- **Spatiotemporal forecasting** (moisture, drought indicators, anomalies)
- **Graph ML** (networks: roads, rivers, ownership, citations)

### 1) Build a dataset manifest ğŸ§¾
Create a manifest that defines:
- sources (with IDs + citations)
- spatial/temporal bounds
- transforms
- label definitions
- split strategy

Example (skeletal):

```yaml
dataset_id: "kfm_soil_moisture_v1"
task: "regression"
label:
  name: "soil_moisture"
  unit: "volumetric_water_content"
sources:
  - id: "usda_soil_survey"
    type: "vector"
    provenance: { citation: "..." }
  - id: "sentinel_2_ndvi"
    type: "raster"
    provenance: { citation: "..." }
splits:
  strategy: "spatial_block_cv"
  folds: 5
transforms:
  - name: "reproject"
    crs: "EPSG:XXXX"
  - name: "normalize"
    method: "zscore"
```

### 2) Train a baseline first ğŸ§°
Start simple:
- linear regression / ridge / lasso
- random forest / gradient boosting
- calibrated uncertainty estimates (when needed)

(Practical + theory) :contentReference[oaicite:7]{index=7} :contentReference[oaicite:8]{index=8}

### 3) Evaluate like itâ€™s geospatial ğŸ—ºï¸
Default evaluation should assume **spatial autocorrelation** and **time dependence**:
- spatial blocking
- temporal forward-chaining
- â€œleave-region-outâ€ tests for generalization

### 4) Package artifacts with a model card ğŸ“¦
A â€œship-readyâ€ model includes:
- model card (what it does + what it *canâ€™t* do)
- dataset manifest(s)
- metrics by slice (region/time)
- known failure modes
- calibration notes + uncertainty approach

### 5) Serve predictions as map-ready outputs ğŸ§©
Predictions should be exportable as:
- vector attributes (GeoJSON/Parquet)
- raster tiles / COGs
- time-indexed series
â€¦and always include provenance metadata.

---

## ğŸ—ºï¸ Geospatial ML guardrails (KFM defaults)

### CRS + units are part of your model âœ…
- Every feature set must declare CRS, resolution, and units.
- Reprojection is a **logged transform**, not a hidden step.

### Spatial leakage is sneaky ğŸ•µï¸
Random splits can inflate metrics because nearby points are similar.
Prefer:
- spatial blocks
- grouped splits by watershed/county/grid cell
- temporal splits for forecasting

### Raster + vector alignment is a first-class problem ğŸ§ 
Document:
- resampling method
- pixel size
- window/patch extraction logic
- nodata handling

(Map design and GIS visualization expectations matter for trust)  
ğŸ“Œ *Cartographic clarity is part of â€œmodel quality.â€*  
(Helpful GIS visualization references) :contentReference[oaicite:9]{index=9}

---

## ğŸ§ª Experimental discipline checklist

Use this before you brag about an RÂ² ğŸ˜„

- [ ] Split strategy matches the deployment scenario (space/time)
- [ ] Baseline beats naive heuristics (mean, last-value, seasonal)
- [ ] Metrics include uncertainty / confidence intervals where relevant
- [ ] Error analysis includes map views (where does it fail?)
- [ ] Model card includes limitations + assumptions
- [ ] Data + model provenance recorded and queryable
- [ ] Performance tested at scale (DB + pipeline throughput) :contentReference[oaicite:10]{index=10}

---

## ğŸ“¦ Data + model registries (what we store)

### Dataset record (minimum viable)
- dataset_id, version, created_at
- sources + citations
- spatial/temporal bounds
- transforms + parameters
- schema (features + dtypes + units)
- split strategy
- checksums for files / partitions

### Model record (minimum viable)
- model_id, version, task
- dataset_id(s) used
- training config hash
- metrics + slices
- calibration + uncertainty notes
- intended use + prohibited use
- fairness/coverage notes (when applicable)
- runtime constraints (latency, memory)

(When storing these in a DB, treat performance as a design requirement, not a â€œlaterâ€ problem.) :contentReference[oaicite:11]{index=11}

---

## ğŸ§° Tooling patterns we encourage

### ğŸ§® Numerical + scientific computing
Lean on well-tested scientific Python workflows when possible. :contentReference[oaicite:12]{index=12}

### ğŸ§¾ Theory + algorithmic grounding
When in doubt, return to fundamentals (PAC, ERM/SRM, optimization framing). :contentReference[oaicite:13]{index=13}

### ğŸ“ Linear algebra literacy
If you canâ€™t reason about matrices, youâ€™ll struggle to debug ML pipelines. :contentReference[oaicite:14]{index=14}

### ğŸ§© Flexible, maintainable system design
ML tooling should stay modular and adaptable as requirements change. :contentReference[oaicite:15]{index=15}

### ğŸ§µ Concurrency for streaming/near-real-time
Sensor data + inference pipelines need safe concurrency patterns (avoid race conditions and â€œphantomâ€ bugs).

---

## ğŸ—ºï¸ Visualization & UI hooks

Model outputs must be **human-inspectable**:
- map overlays (confidence, error, anomalies)
- time sliders
- interactive 3D where appropriate (archaeology / terrain / volumes)

If youâ€™re feeding a WebGL-based viewer, export formats should be designed intentionally (tile pyramids, lightweight vector payloads, etc.).  

---

## ğŸ” Security, governance, and â€œdo no harmâ€

Even â€œjust a modelâ€ is part of the systemâ€™s attack surface:
- protect dataset credentials / API keys
- validate inputs (donâ€™t trust external feeds)
- treat model artifacts as supply-chain items (hash + provenance)
- log access for sensitive datasets

Also: model outputs can be socially consequential. KFMâ€™s posture is **transparent, accountable, and community-oriented** (digital humanism lens).

---

## ğŸ“š Project source library (used to shape `tools/ml`) ğŸ“š

> The following project PDFs inform the design, guardrails, and recommended techniques in this folder.  
> Some are deep references; others are practical cookbooks. Together they form the â€œKFM ML stack brain.â€ ğŸ§ âœ¨

<details>
<summary><strong>ğŸ§  ML fundamentals & math</strong></summary>

- **Understanding Machine Learning: From Theory to Algorithms** â€” learning theory, PAC/ERM, algorithmic paradigms. :contentReference[oaicite:16]{index=16}  
- **Basics of Linear Algebra for Machine Learning** â€” matrices, decompositions, least squares intuition. :contentReference[oaicite:17]{index=17}  
- **regression-analysis-with-python.pdf** â€” applied regression patterns for baseline modeling.  
- **Regression analysis using Python - slides-linear-regression.pdf** â€” quick regression refreshers & visuals.  
- **think-bayes-bayesian-statistics-in-python.pdf** â€” Bayesian framing for uncertainty & decision support.  

</details>

<details>
<summary><strong>ğŸ§ª Statistics, experimental design, EDA</strong></summary>

- **Understanding Statistics & Experimental Design.pdf** â€” experimental discipline, inference, avoiding misleading conclusions.  
- **graphical-data-analysis-with-r.pdf** â€” fast EDA patterns (plots, residuals, diagnostics).  

</details>

<details>
<summary><strong>ğŸ›°ï¸ Geospatial, mapping, remote sensing</strong></summary>

- **Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation** â€” provenance-first + clean architecture + evidence-backed AI ethos. :contentReference[oaicite:18]{index=18}  
- **Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf** â€” scalable remote sensing workflows.  
- **python-geospatial-analysis-cookbook.pdf** â€” Python recipes for GIS operations and spatial data handling.  
- **making-maps-a-visual-guide-to-map-design-for-gis.pdf** â€” cartographic clarity (critical for trustworthy ML outputs).  
- **Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf** â€” mapping in lived contexts (useful for UX & field tools).  
- **Archaeological 3D GIS_26_01_12_17_53_09.pdf** â€” 3D spatial reasoning, volumes, visibility analysis, interpretive layers. :contentReference[oaicite:19]{index=19}  

</details>

<details>
<summary><strong>ğŸ—„ï¸ Data engineering, storage, scale</strong></summary>

- **Database Performance at Scale.pdf** â€” practical tuning mindset; performance is a product feature. :contentReference[oaicite:20]{index=20}  
- **PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf** â€” SQL competence for registries/features.  
- **Scalable Data Management for Future Hardware.pdf** â€” thinking about storage/compute trends and system layout.  
- **Data Spaces.pdf** â€” interoperability + governance patterns for multi-source data ecosystems.  

</details>

<details>
<summary><strong>ğŸ§© Systems, architecture, language/tooling</strong></summary>

- **Flexible Software Design** â€” designing for changing requirements (perfect match for evolving ML tooling). :contentReference[oaicite:21]{index=21}  
- **Implementing Programming Languages** â€” useful when we introduce DSLs for pipelines/queries. :contentReference[oaicite:22]{index=22}  
- **concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf** â€” concurrency lessons for real-time ingestion & serving.  
- **A programming Books.pdf / Bâ€‘C / Dâ€‘E / Fâ€‘H / Iâ€‘L / Mâ€‘N / Oâ€‘R / Sâ€‘T / Uâ€‘X programming Books.pdf** â€” broad language/tool references (the â€œshelfâ€).  
- **MATLAB Notes for Professionals** â€” numerical/prototyping quick reference. :contentReference[oaicite:23]{index=23}  
- **Bash Notes for Professionals** â€” pipeline scripting + ops glue. :contentReference[oaicite:24]{index=24}  
- **Objectiveâ€‘C Notes for Professionals** â€” legacy/mobile integrations where relevant. :contentReference[oaicite:25]{index=25}  

</details>

<details>
<summary><strong>ğŸ§  Simulation, graphs, optimization, complex systems</strong></summary>

- **Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf** â€” verification/validation mindset, modeling rigor.  
- **Spectral Geometry of Graphs.pdf** â€” spectral methods for graph analytics & embeddings.  
- **Generalized Topology Optimization for Structural Design.pdf** â€” optimization patterns and constraint thinking (useful beyond structures).  
- **Principles of Biological Autonomy - book_9780262381833.pdf** â€” systems thinking for ecological/agent-like modeling.  

</details>

<details>
<summary><strong>ğŸ–¥ï¸ Visualization, formats, web</strong></summary>

- **webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf** â€” 3D visualization pipelines for model outputs.  
- **responsive-web-design-with-html5-and-css3.pdf** â€” dashboards and map UIs that work on real devices.  
- **compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf** â€” image format pitfalls (critical for raster provenance).  

</details>

<details>
<summary><strong>âš–ï¸ Ethics, law, security</strong></summary>

- **Introduction to Digital Humanism.pdf** â€” human-centered tech constraints for KFMâ€™s AI layer.  
- **On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf** â€” governance + legal framing.  
- **ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf** â€” security awareness for pipelines & infra.  
- **Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf** â€” defensive understanding and hardening mindset (use responsibly).  

</details>

<details>
<summary><strong>ğŸ”¥ Deep learning (optional / when warranted)</strong></summary>

- **Deep Learning for Coders with fastai and PyTorch** â€” deep learning workflow reference for imagery or large-scale tasks.  
  *(Use after baselines, with clear evaluation + provenance.)*

</details>

---

## âœ… â€œReady to mergeâ€ criteria for any ML tool added here

- [ ] Has a manifest schema (dataset or model) ğŸ§¾  
- [ ] Has at least one baseline implementation ğŸ§°  
- [ ] Has tests for data contracts + leakage âœ…  
- [ ] Produces map-ready outputs ğŸ—ºï¸  
- [ ] Writes provenance metadata ğŸ§¾  
- [ ] Documents limits + failure modes ğŸ§   
- [ ] Plays nicely with KFMâ€™s clean architecture ğŸ”Œ :contentReference[oaicite:26]{index=26}

---

## ğŸ§­ Next milestones (roadmap)

- ğŸ§¾ Implement dataset manifest validation + checksums
- ğŸ§ª Add spatial CV utilities + leakage tests
- ğŸ“¦ Add model card templates + registry schema (Postgres/PostGIS)
- ğŸ± Add serving adapters for batch + streaming inference
- ğŸ—ºï¸ Add â€œprediction â†’ map overlayâ€ exporters (vector + raster + tiles)

---

> ğŸ§  If youâ€™re about to add a model without a dataset manifest and a spatially-aware evaluation planâ€¦  
> **please donâ€™t** ğŸ˜„ â€” start with provenance and splits, then model.

