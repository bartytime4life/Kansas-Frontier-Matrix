# ğŸ§° tools/ci â€” Continuous Integration Runbook ğŸš¦

[![CI](https://img.shields.io/badge/CI-GitHub%20Actions-2088FF?logo=githubactions&logoColor=white)](#-where-ci-runs)
[![Quality Gates](https://img.shields.io/badge/Quality-Gates%20ON-6f42c1)](#-minimum-ci-gates-v13)
[![Data Contracts](https://img.shields.io/badge/Data-STAC%20%7C%20DCAT%20%7C%20PROV-2ea44f)](#-data--metadata-gates)
[![Security](https://img.shields.io/badge/Security-Scans%20Enabled-critical?logo=securityscorecard&logoColor=white)](#-security--governance-gates)

> **Rule of thumb ğŸ§ :** If it canâ€™t be validated, it canâ€™t be merged.  
> KFM/Kansas-Matrix work is *evidence-first* and *contract-first* â€” CI is the enforcement layer.

---

## ğŸ—ºï¸ Contents

- [ğŸ¯ Purpose](#-purpose)
- [ğŸ“¦ What lives in `tools/ci/`](#-what-lives-in-toolsc i)
- [ğŸ§¬ Canonical pipeline (why CI is strict)](#-canonical-pipeline-why-ci-is-strict)
- [âœ… Minimum CI gates (v13)](#-minimum-ci-gates-v13)
- [ğŸ§ª Gate matrix](#-gate-matrix)
- [ğŸƒ Run CI locally](#-run-ci-locally)
- [ğŸ§± Adding a new gate](#-adding-a-new-gate)
- [ğŸ§¾ Data & metadata gates](#-data--metadata-gates)
- [ğŸ•¸ï¸ Graph + API contract gates](#ï¸-graph--api-contract-gates)
- [ğŸ” Security & governance gates](#-security--governance-gates)
- [âš¡ Performance & cost control](#-performance--cost-control)
- [ğŸ†˜ Troubleshooting](#-troubleshooting)
- [ğŸ“š Project Library Index](#-project-library-index)

---

## ğŸ¯ Purpose

`tools/ci/` is the **single home** for CI utilities that:

- run in **GitHub Actions** (or your CI runner of choice),
- run **locally** the same way (no â€œworks on my machineâ€),
- enforce KFMâ€™s **contract-first** and **evidence-first** standards,
- protect the repo from **broken metadata**, **broken links**, **schema drift**, **unsafe content**, and **silent regressions**.

> [!IMPORTANT]
> CI is not â€œjust tests.â€ For this project, CI is the *governance engine* that keeps the pipeline order intact and keeps the catalog trustworthy.

---

## ğŸ“¦ What lives in `tools/ci/`

This directory should contain small, composable building blocks (scripts + configs) that can be wired into workflows.

**Recommended structure (adapt as needed):**
```text
ğŸ“ tools/ci/
â”œâ”€â”€ ğŸ“„ README.md                # (this file) runbook + gate contract
â”œâ”€â”€ ğŸ“ bin/                     # tiny entrypoints (bash / python)
â”‚   â”œâ”€â”€ ğŸ§ª run_unit_tests.*
â”‚   â”œâ”€â”€ ğŸ§¾ validate_markdown.*
â”‚   â”œâ”€â”€ ğŸ§¬ validate_catalog.*
â”‚   â”œâ”€â”€ ğŸ§© validate_schemas.*
â”‚   â”œâ”€â”€ ğŸ•¸ï¸ graph_smoke_test.*
â”‚   â””â”€â”€ ğŸ” security_scans.*
â”œâ”€â”€ ğŸ“ fixtures/                # small test datasets + sample graph fixtures
â”œâ”€â”€ ğŸ“ reports/                 # CI artifacts (json summaries, junit, coverage, etc.)
â””â”€â”€ ğŸ“ workflows/               # reusable workflow snippets (optional)
```

**Design constraints (non-negotiable):**
- âœ… deterministic output (seeded randomness, stable ordering)
- âœ… clear exit codes (`0` pass, nonâ€‘zero fail)
- âœ… CI-friendly logs (no interactive prompts)
- âœ… *fast by default* â€” heavy checks go to nightly/scheduled lanes

---

## ğŸ§¬ Canonical pipeline (why CI is strict)

KFMâ€™s â€œcanonical pipelineâ€ ordering is enforced culturally **and** mechanically:

```mermaid
flowchart LR
  A[ETL] --> B[STAC/DCAT/PROV Catalogs]
  B --> C[Neo4j Graph]
  C --> D[APIs]
  D --> E[React/Map UI]
  E --> F[Story Nodes]
  F --> G[Focus Mode]
```

> [!NOTE]
> CI gates are aligned to this ordering: you donâ€™t get to publish a Story Node if the catalogs, graph, and contracts arenâ€™t valid.

---

## âœ… Minimum CI gates (v13)

These are the **baseline** gates expected for v13 contributions (docs + data + code):

### ğŸ§¾ Documentation gates
- **Markdown protocol & frontâ€‘matter checks** (YAML front-matter, required sections, governed templates)
- **Link/reference validation** (no broken internal references, unresolved citations)

### ğŸ§© Schema gates
- **JSON Schema validation** for:
  - STAC Items/Collections
  - DCAT Datasets
  - PROV JSONâ€‘LD
  - Story Node schemas
  - UI/telemetry config schemas (when present)

### ğŸ•¸ï¸ Graph + API gates
- **Graph integrity tests** (fixture graph constraints, ontology invariants)
- **API contract tests** (OpenAPI/GraphQL linting + contract tests against known inputs)

### ğŸ” Security + governance gates
- **Secret scanning**
- **PII / sensitive content scanning**
- **Sensitive location checks**
- **Classification consistency checks** (prevent â€œdowngradingâ€ restricted â†’ public without approved deâ€‘identification)

> [!TIP]
> Treat metadata like code: it must â€œcompileâ€ before it merges. Aim for a **zeroâ€‘defect** policy for catalogs and dataset metadata.

---

## ğŸ§ª Gate matrix

A practical way to keep CI fast *and* strict is to split gates into lanes:

| Gate ğŸ§· | PR (required) | `main` (required) | Nightly/Scheduled | Notes |
|---|:---:|:---:|:---:|---|
| Format + lint (Py/JS) ğŸ¨ | âœ… | âœ… | â€” | Fast feedback |
| Unit tests ğŸ§ª | âœ… | âœ… | âœ… | Full matrix runs at night |
| Markdown/front-matter ğŸ§¾ | âœ… | âœ… | âœ… | Must never be flaky |
| Link validation ğŸ”— | âœ… | âœ… | âœ… | Prevent doc rot |
| STAC/DCAT/PROV schema ğŸ§© | âœ… | âœ… | âœ… | â€œMetadata compileâ€ gate |
| Catalog QA (geo sanity) ğŸ—ºï¸ | âœ… | âœ… | âœ… | geometry/CRS/extents |
| Graph smoke + constraints ğŸ•¸ï¸ | âœ…* | âœ… | âœ… | `*` can be PR-only on graph-touch changes |
| API contract tests ğŸ“œ | âœ… | âœ… | âœ… | OpenAPI/GraphQL + mocks |
| Security scans ğŸ” | âœ… | âœ… | âœ… | also on dependency updates |
| Performance smoke âš¡ | â€” | âœ…* | âœ… | `*` keep PR fast |

---

## ğŸƒ Run CI locally

CI is most effective when contributors can reproduce failures locally.

> [!NOTE]
> Command names below are **recommended conventions**. If your repo already has scripts, mirror them here and update this README.

### 1) Environment setup (Python + Node + containers)
```bash
# Python (recommended: venv)
python -m venv .venv
source .venv/bin/activate
python -m pip install -U pip

# Node (if web UI exists)
# npm ci

# Optional: bring up integration dependencies (PostGIS/Neo4j/etc.)
# docker compose up -d
```

### 2) Run the â€œPR laneâ€
```bash
# Format/lint/test/doc checks (example)
# pre-commit run --all-files
# python -m pytest -q
# python -m mypy src/
# npm run lint && npm test
```

### 3) Run the â€œcatalog laneâ€
```bash
# Validate schemas + catalog QA (example)
# python tools/ci/bin/validate_schemas.py
# python tools/ci/bin/validate_catalog.py
```

### 4) Run the â€œintegration laneâ€
```bash
# Graph + API contract tests (example)
# python tools/ci/bin/graph_smoke_test.py
# python tools/ci/bin/api_contract_test.py
```

> [!TIP]
> Keep fixtures **tiny**. CI should validate correctness, not reprocess the whole world.

---

## ğŸ§± Adding a new gate

When you add a gate, aim for **clarity, determinism, and speed**.

### âœ… Gate contract
Every gate should:
- accept `--help`
- return nonâ€‘zero on failure
- print a **human summary** + optionally emit a **machine artifact** (JSON/JUnit)
- have a clear owner + â€œwhy it existsâ€ documented

### ğŸ§© Typical workflow
1. Add script to `tools/ci/bin/â€¦`
2. Add local entrypoint (Makefile task or `./tools/ci/bin/...`)
3. Add/adjust pre-commit hook (if relevant)
4. Wire into GitHub Actions workflow
5. Add a short section to this README:
   - what it checks
   - where it runs (PR/main/nightly)
   - how to reproduce locally
   - common failure reasons

---

## ğŸ§¾ Data & metadata gates

This projectâ€™s â€œdata qualityâ€ is not optional â€” CI is expected to validate:

### ğŸ§© Schema compliance (STAC/DCAT/PROV + extensions)
- validate all catalog JSON against schemas
- enforce required fields (license, spatial/temporal extents, links, etc.)
- prevent schema drift (profiles change only via deliberate PR)

### ğŸ—ºï¸ Geospatial sanity (Catalog QA)
Examples of â€œbasic but essentialâ€ checks:
- geometry validity (e.g., no selfâ€‘intersections)
- CRS consistency (no accidental reprojection drift)
- spatial extents plausibility (bounds match Kansas + domain constraints)
- attribute ranges (e.g., non-negative values where required)
- file/link integrity (no broken artifact references)

> [!IMPORTANT]
> Data changes should trigger CI lanes the same way code changes do. If a dataset update breaks validation, the PR should be blocked.

### ğŸ“¦ Reproducible ETL runs
For heavier pipelines:
- containerize (GDAL/OGR/geospatial deps are painful to install repeatedly)
- isolate dependencies (donâ€™t rely on runner global state)
- store artifacts with run IDs / timestamps
- avoid â€œsilent overwritesâ€ unless explicitly versioned

---

## ğŸ•¸ï¸ Graph + API contract gates

### ğŸ•¸ï¸ Graph integrity tests
Use a small fixture dataset to ensure:
- required labels exist
- relationships follow ontology rules
- unique IDs and required properties are enforced
- â€œcontract invariantsâ€ remain true across refactors

### ğŸ“œ API contract tests
CI should:
- lint OpenAPI/GraphQL definitions
- run contract tests against known requests/responses
- require backward compatibility **or** explicit contract migration

> [!TIP]
> If you change the API, change the contract + tests in the same PR. No exceptions.

---

## ğŸ” Security & governance gates

CI must act like a **tripwire** for:
- secrets (keys/tokens/passwords)
- accidental PII inclusion
- sensitive location disclosures
- classification downgrades without approved transformations

**Practical additions that pay off quickly:**
- dependency vulnerability scanning (incl. transitive deps)
- container image scanning (if images are built)
- permission hardening in workflow YAML (principle of least privilege)

> [!CAUTION]
> If you ever use self-hosted runners: treat them as a high-trust environment. Lock down permissions, secrets exposure, and workflow write access aggressively.

---

## âš¡ Performance & cost control

CI should keep a tight feedback loop **without** becoming expensive or slow.

### ğŸ§¯ Keep PR checks fast
- default to unit/smoke tests on PRs
- move â€œfull dataset rebuildâ€ and â€œfull integration matrixâ€ to nightly

### ğŸ“ˆ Profile the pipeline
- measure per-step duration
- treat slowdowns as regressions (especially for data pipelines)

### ğŸ§  Performance gates (optional but recommended)
- simple budgets: build time, test duration, memory
- DB query plan regression checks for critical endpoints
- â€œhot pathâ€ benchmarks in nightly lane

---

## ğŸ†˜ Troubleshooting

### â€œSchema validation failedâ€
- The file is structurally invalid (missing fields / wrong types)
- The profile changed but schema wasnâ€™t updated
- A link points to a moved/renamed artifact

âœ… Fix: validate locally, then update schema/profiles deliberately.

### â€œCatalog QA failedâ€
Common causes:
- invalid geometry
- CRS mismatch
- missing license
- broken links
- out-of-range values

âœ… Fix: correct data or metadata; donâ€™t bypass the gate.

### â€œGraph integrity failedâ€
Common causes:
- missing required node properties
- changed label/relationship naming
- fixture data doesnâ€™t satisfy new constraints

âœ… Fix: update migration + fixture + constraints together.

### â€œContract test failedâ€
Common causes:
- response shape changed
- new required field without versioning
- endpoint behavior changed unexpectedly

âœ… Fix: update API + contract + tests in one PR, or add a versioned endpoint.

---

## ğŸ“š Project Library Index

This repo carries a **large embedded library** of PDFs/books that inform CI policy, testing strategy, data quality, security, modeling rigor, and geospatial correctness.

<details>
<summary><b>ğŸ“¦ Core KFM/Kansas-Matrix governance & architecture</b></summary>

- ğŸ“„ **Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf**
- ğŸ“„ **MARKDOWN_GUIDE_v13.md.gdoc** (Master Guide / repo structure / validation & CI gates)
- ğŸ“„ **Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf**
- ğŸ“„ **Scientific Method _ Research _ Master Coder Protocol Documentation.pdf**
- ğŸ“„ **Comprehensive Markdown Guide.docx**
</details>

<details>
<summary><b>ğŸ§ª Scientific computing, stats, experiments, ML</b></summary>

- ğŸ“„ Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf
- ğŸ“„ Understanding Statistics & Experimental Design.pdf
- ğŸ“„ regression-analysis-with-python.pdf
- ğŸ“„ Regression analysis using Python - slides-linear-regression.pdf
- ğŸ“„ graphical-data-analysis-with-r.pdf
- ğŸ“„ think-bayes-bayesian-statistics-in-python.pdf
- ğŸ“„ Data Mining Concepts & applications.pdf
- ğŸ“„ Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf
- ğŸ“„ S-T programming Books.pdf (supervised learning / bias-variance concepts)
- ğŸ“„ I-L programming Books.pdf (ML implementation patterns)
</details>

<details>
<summary><b>ğŸ—ºï¸ Geospatial, remote sensing, mapping & media</b></summary>

- ğŸ“„ python-geospatial-analysis-cookbook.pdf
- ğŸ“„ KFM- python-geospatial-analysis-cookbook-over-60-recipes-to-work-with-topology-overlays-indoor-routing-and-web-application-analysis-with-python.pdf
- ğŸ“„ Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf
- ğŸ“„ making-maps-a-visual-guide-to-map-design-for-gis.pdf
- ğŸ“„ Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf
- ğŸ“„ Archaeological 3D GIS_26_01_12_17_53_09.pdf
- ğŸ“„ compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf (tile/image outputs)
</details>

<details>
<summary><b>ğŸŒ Web/UI engineering</b></summary>

- ğŸ“„ responsive-web-design-with-html5-and-css3.pdf
- ğŸ“„ webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf
</details>

<details>
<summary><b>ğŸ—„ï¸ Databases, scaling, performance</b></summary>

- ğŸ“„ PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf
- ğŸ“„ Database Performance at Scale.pdf
- ğŸ“„ Scalable Data Management for Future Hardware.pdf
- ğŸ“„ concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf
- ğŸ“„ Spectral Geometry of Graphs.pdf (graph reasoning foundations)
</details>

<details>
<summary><b>ğŸ” Security, governance, ethics & law</b></summary>

- ğŸ“„ ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf
- ğŸ“„ Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf
- ğŸ“„ Data Spaces.pdf (classification/access-control concepts)
- ğŸ“„ Introduction to Digital Humanism.pdf
- ğŸ“„ On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf
- ğŸ“„ Principles of Biological Autonomy - book_9780262381833.pdf
</details>

<details>
<summary><b>ğŸ§‘â€ğŸ’» Programming reference bundles (multi-book PDFs)</b></summary>

These are â€œmegaâ€ references used across the project (languages, tooling, protocols, DevOps patterns):

- ğŸ“„ A programming Books.pdf
- ğŸ“„ B-C programming Books.pdf
- ğŸ“„ D-E programming Books.pdf
- ğŸ“„ F-H programming Books.pdf
- ğŸ“„ I-L programming Books.pdf
- ğŸ“„ M-N programming Books.pdf
- ğŸ“„ O-R programming Books.pdf
- ğŸ“„ S-T programming Books.pdf
- ğŸ“„ U-X programming Books.pdf
</details>

---

### ğŸ”­ CI roadmap ideas (good next increments)
- ğŸ§¬ Make the â€œCatalog QAâ€ CLI the single authoritative entrypoint (local + CI)
- ğŸ§ª Add fixture-based **round-trip** tests for critical ETL â†’ catalog outputs
- ğŸ•¸ï¸ Add graph migrations + constraint regression fixtures
- ğŸ“œ Add API schema diff gate (break detection)
- ğŸ§¯ Add performance budgets (build/test/query) with nightly trend reporting
- ğŸ§¾ Add docs link checker + reference resolver for Story Nodes

> [!NOTE]
> Keep CI strict, but keep it kind: error messages should tell contributors **exactly** how to fix the issue.

