# ğŸ§° my-tool â€” Evidenceâ€‘First Utility for Kansasâ€‘Matrix-System

<p align="center">
  <b>Small, sharp tooling that respects the KFM â€œtruth pathâ€</b><br/>
  Raw âœ Processed âœ Catalog/Provenance âœ Databases âœ API âœ UI/AI âœ…
</p>

<p align="center">
  <!-- âœ¨ Replace <OWNER>/<REPO> + workflow names with your real ones -->
  <img alt="build" src="https://img.shields.io/github/actions/workflow/status/<OWNER>/<REPO>/ci.yml?branch=main" />
  <img alt="license" src="https://img.shields.io/github/license/<OWNER>/<REPO>" />
  <img alt="python" src="https://img.shields.io/badge/python-%3E%3D3.10-blue" />
  <img alt="docker" src="https://img.shields.io/badge/docker-compose-blue" />
  <img alt="status" src="https://img.shields.io/badge/status-alpha-orange" />
</p>

---

## âœ¨ What is this?

**`my-tool`** is a **tooling module** (CLI-first) for the **Kansasâ€‘Matrix-System / KFM stack**, built to help you:
- ğŸ” **Inspect** the system (health checks, config checks, connectivity checks)
- ğŸ§ª **Validate** inputs/outputs (schemas, geospatial sanity, provenance rules)
- ğŸ—‚ï¸ **Interact** with governed APIs (dataset lookup, catalog search, safe queries)
- ğŸ§¾ **Enforce evidence** (â€œNo Source, No Answerâ€ âœ…) when generating or verifying derived outputs

> ğŸ§  Design goal: empower fast iteration **without** bypassing provenance, metadata, or governance.

---

## ğŸ§­ Design Principles (Nonâ€‘Negotiables)

- ğŸ§¾ **Evidence-first outputs**  
  If a report/map/answer canâ€™t be traced to sources + metadata, itâ€™s not â€œdoneâ€.

- ğŸ›¤ï¸ **No bypass of the truth path**  
  Tools should **never** â€œshortcutâ€ ingestion/canonical processing/catlogging to make something â€œappearâ€ in the UI.  
  If you need a value in the UI, it must pass through **Catalog/Provenance âœ DB âœ API**.

- ğŸ”Œ **Loose coupling**  
  `my-tool` talks to services via their **APIs/contracts**, not internal DB hacks.

- ğŸ“¦ **Container-friendly**  
  Prefer running inside `docker compose` so your results match CI/production behavior.

---

## ğŸš€ Quickstart

### Option A (Recommended): Run inside Docker Compose ğŸ³

From repo root:

```bash
docker compose up -d
```

Then:

```bash
docker compose exec api my-tool --help
docker compose exec api my-tool doctor
```

> âœ… Why this is recommended: you get the same service wiring (API + DB + catalog + AI) used by the platform.

---

### Option B: Run locally (fast iteration) âš¡

```bash
cd tools/my-tool

python -m venv .venv
source .venv/bin/activate

pip install -U pip
pip install -e ".[dev]"

my-tool --help
my-tool doctor
```

---

## ğŸ§© Commands (CLI)

> All commands should be **safe by default**: read-only unless explicitly told otherwise.

### ğŸ” System Checks

```bash
my-tool doctor
my-tool doctor --verbose
```

Typical checks:
- âœ… environment variables present
- âœ… API reachable
- âœ… auth configured (if enabled)
- âœ… storage paths readable
- âœ… optional AI backend reachable (e.g., local model or external provider)

---

### ğŸ—‚ï¸ Catalog & Dataset Discovery

Examples use KFM-style endpoints like:
- `GET /api/v1/datasets/{id}`
- `GET /api/v1/catalog/search`

```bash
my-tool api ping
my-tool datasets get ks_hydrology_1880
my-tool catalog search --q "river" --bbox "-102,36,-94,40" --time "1880..1900"
```

---

### ğŸ§¾ Provenance Guards

```bash
my-tool validate dataset ./data/processed/ks_hydrology_1880.geojson
my-tool validate catalog ./data/catalog/dcat/datasets/ks_hydrology_1880.json
my-tool validate prov ./data/catalog/prov/ks_hydrology_1880.prov.json
```

What â€œvalidateâ€ should cover:
- ğŸ§¬ schema checks (required fields)
- ğŸ—ºï¸ geospatial sanity (bbox, CRS expectations, geometry validity)
- ğŸ§¾ provenance links exist (W3C PROV-style relationships)
- ğŸ·ï¸ metadata present (STAC/DCAT summaries + links to assets)

---

### ğŸ§  Focus Mode / AI Safety Tests (Optional)

If your stack exposes a â€œFocus Modeâ€ endpoint (example: `POST /focus-mode/query`) and you want regression tests:

```bash
my-tool focus ask "List major trails in Kansas and cite sources."
my-tool focus regression --suite ./tests/focus/*.yaml
```

Suggested assertions:
- âœ… answer includes citations/refs
- âœ… tool does not hallucinate dataset IDs
- âœ… â€œno evidence foundâ€ is returned when appropriate

---

## ğŸ”§ Configuration

`my-tool` reads configuration from:
- âœ… environment variables
- âœ… `.env` files (if you use them)
- âœ… docker-compose environment wiring

Create `tools/my-tool/.env` (never commit secrets):

```bash
# API
KFM_API_BASE_URL=http://localhost:8000
KFM_AUTH_TOKEN=  # optional if auth disabled

# Data paths (adjust to your repo conventions)
KFM_DATA_ROOT=../../data
KFM_LOG_LEVEL=info

# Optional AI
AI_BACKEND=ollama        # or openai / none
AI_BACKEND_URL=http://localhost:11434
OLLAMA_MODEL=llama2:7b
```

> ğŸ” Tip: mirror the repoâ€™s `.env.example` naming where possible.

---

## ğŸ—‚ï¸ Repo Layout (Suggested)

```text
tools/my-tool/
â”œâ”€ ğŸ“„ README.md
â”œâ”€ ğŸ“¦ pyproject.toml            # or package.json if JS/TS tool
â”œâ”€ ğŸ” .env.example
â”œâ”€ ğŸ§  my_tool/
â”‚  â”œâ”€ __init__.py
â”‚  â”œâ”€ cli.py                    # entrypoint
â”‚  â”œâ”€ config.py                 # env parsing + defaults
â”‚  â”œâ”€ api_client.py             # governed API calls only
â”‚  â”œâ”€ validators/
â”‚  â”‚  â”œâ”€ dataset.py
â”‚  â”‚  â”œâ”€ catalog.py
â”‚  â”‚  â””â”€ prov.py
â”‚  â””â”€ utils/
â”‚     â”œâ”€ logging.py
â”‚     â””â”€ io.py
â”œâ”€ ğŸ§ª tests/
â”‚  â”œâ”€ test_doctor.py
â”‚  â”œâ”€ test_validators.py
â”‚  â””â”€ focus/                    # optional regression suites
â””â”€ ğŸ› ï¸ scripts/
   â””â”€ dev.sh
```

---

## ğŸ§± Architecture Fit

`my-tool` is intentionally positioned as a **helper** and **guardrail** around the platform:

```mermaid
flowchart LR
  A[ğŸ§± Raw Sources] --> B[ğŸ§¼ Processed]
  B --> C[ğŸ—‚ï¸ Catalog + Provenance]
  C --> D[ğŸ—„ï¸ Databases]
  D --> E[ğŸ§© API]
  E --> F[ğŸ—ºï¸ UI / ğŸ¤– AI]
  G[ğŸ§° my-tool] -.read/validate.-> B
  G -.read/validate.-> C
  G -.governed calls.-> E
  G -.never direct.-> D
```

âœ… **Allowed:** validate processed outputs, validate catalog/prov records, query the API  
ğŸš« **Not allowed:** writing directly into DBs â€œto save timeâ€, bypassing metadata, shipping untraceable artifacts

---

## ğŸ§ª Dev Workflow

### Lint / Format

```bash
# examples (adjust to your stack)
ruff check .
ruff format .
```

### Type checks

```bash
mypy my_tool
```

### Tests

```bash
pytest -q
```

### Pre-commit (recommended)

```bash
pre-commit install
pre-commit run --all-files
```

---

## ğŸ” Security & Data Governance Notes

- ğŸ§¯ **Secrets**: never commit `.env` (use `.env.example`)
- ğŸ§¾ **Provenance**: if you generate/transform data, emit a PROV record + link it in catalog metadata
- ğŸ§­ **Access controls**: if OAuth2/role access exists, donâ€™t â€œwork around itâ€ â€” make the tool respect it
- ğŸ§¼ **Safe defaults**: prefer read-only commands unless `--write` or `--apply` is explicitly set

---

## ğŸ§¯ Troubleshooting

<details>
  <summary><b>â€œAPI not reachableâ€</b></summary>

- Check Docker: `docker compose ps`
- Check ports: `docker compose logs api --tail 200`
- If using local run, confirm `KFM_API_BASE_URL` matches the running service.
</details>

<details>
  <summary><b>â€œAI backend not reachableâ€ (Ollama / local model)</b></summary>

- Confirm the service is running and the URL/port is correct.
- If API is in Docker and model runs on host, you may need `host.docker.internal` (platform-dependent).
</details>

<details>
  <summary><b>Validation fails on geometry</b></summary>

- Common causes: invalid polygons, mixed CRS assumptions, broken bbox metadata.
- Run with `--verbose` and output a small failing sample for debugging.
</details>

---

## ğŸ—ºï¸ Roadmap (Suggested)

- [ ] `my-tool doctor --json` for CI consumption
- [ ] `my-tool validate --fix` (safe, deterministic fixes only)
- [ ] `my-tool catalog diff` (compare catalog vs DB vs storage)
- [ ] `my-tool focus regression` with golden citations
- [ ] Add SOPs under `mcp/sops/` for repeatable workflows ğŸ“š

---

## ğŸ¤ Contributing

1. âœ… Keep changes small and testable  
2. âœ… Add/adjust validators when introducing new dataset shapes  
3. âœ… Document behavior changes in this README  
4. âœ… If you add a new command, add `--help` examples + at least one test

---

## ğŸ“„ License

See the repository root `LICENSE` file.

---

### ğŸ§  Mini Philosophy Reminder

> If it canâ€™t be traced, it canâ€™t be trusted.  
> If it bypasses the path, it doesnâ€™t ship.
