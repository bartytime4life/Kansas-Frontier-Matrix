# ğŸ§° my-tool Â· `src/`

> Internal source package for **my-tool** â€” a developer utility that helps you interact with the **Kansas Frontier Matrix (KFM)** stack in a **contract-first** + **evidence-first** way. ğŸ§­ğŸ“Œ

---

## ğŸ¯ What this folder is for

This `src/` directory is the **implementation layer** for the tool:

- ğŸ§© CLI command implementations (routing, args, help text)
- ğŸ”Œ API client wrappers (REST + GraphQL)
- ğŸ§¾ â€œEvidence-firstâ€ helpers (attach provenance pointers to output)
- ğŸ§° Utilities (logging, config, formatting, error handling)

> ğŸ’¡ If youâ€™re looking for user-facing install/usage docs, check for a higher-level README at `tools/my-tool/README.md` (if present). This file is intentionally **developer-oriented**.

---

## ğŸ§  Principles (nonâ€‘negotiable)

KFMâ€™s philosophy is **traceable output** and **repeatable workflows** â€” this tool should mirror that.

1. **Evidence-first output ğŸ§¾**
   - Every emitted artifact (JSON, markdown, reports) should be traceable to **dataset IDs**, **STAC items/assets**, **DCAT metadata**, and/or **PROV lineage**.
2. **No pipeline leapfrogging ğŸš¦**
   - Canonical ordering (donâ€™t bypass stages):  
     `ETL â†’ STAC/DCAT/PROV â†’ Neo4j Graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode`
3. **Safe-by-default ğŸ”’**
   - Validate inputs, use allow-lists, avoid dangerous shell execution patterns, and prefer parameterized queries.
4. **Automation-ready ğŸ¤–**
   - Must run cleanly in **local dev** and **CI** with deterministic outputs.

---

## ğŸ§­ Architecture at a glance

```mermaid
flowchart LR
  A[ğŸ§° my-tool CLI / lib] --> B[ğŸŒ KFM REST API]
  A --> C[ğŸ§  KFM GraphQL API]
  B --> D[(ğŸ—ºï¸ PostGIS)]
  B --> E[(ğŸ§¬ Neo4j)]
  B --> F[âœ¨ Focus Mode AI (RAG)]
  F --> G[ğŸ¦™ Ollama (local LLM) / external provider]
```

---

## ğŸ”Œ KFM surfaces youâ€™ll likely touch

Below are **common** API surfaces youâ€™ll see referenced across commands and clients:

### ğŸ—ƒï¸ Catalog & datasets
- `GET /api/v1/datasets/{id}`
- `GET /api/v1/catalog/search`
- `GET /api/v1/datasets/{id}/data?format=geojson&bbox=...`

### ğŸ§ª Safe adâ€‘hoc querying
- `GET /api/v1/query?table=...&select=...&where=...&bbox=...`

### ğŸ§± Map tiles
- `GET /tiles/{layer}/{z}/{x}/{y}.pbf` (vector tiles)
- `GET /tiles/{layer}/{z}/{x}/{y}.png` (raster tiles)

### ğŸ§  Focus Mode AI
- `POST /api/v1/ai/query` (answer + citations)
- `/api/v1/ai/stream` (streaming; experimental)
- `GET /api/v1/ai/suggestions`

### ğŸ—ï¸ Ingestion / pipeline control (restricted)
- `POST /api/v1/ingest/runPipeline`

> âš ï¸ Some endpoints are role-gated. Keep tokens out of logs and never print secrets.

---

## ğŸƒ Local dev quickstart

### 1) Run the KFM stack ğŸ³
From the repo root (or wherever your `docker-compose.yml` lives):

```bash
docker-compose up
```

Verify:
- âœ… Swagger UI: `http://localhost:8000/docs`
- âœ… GraphQL (if enabled): `http://localhost:8000/graphql`

### 2) Install my-tool deps ğŸ“¦
From `tools/my-tool/`:

```bash
npm install
```

### 3) Run dev mode âš¡
Choose the command that matches your implementation:

```bash
# Common (TypeScript / watcher)
npm run dev

# Or run compiled output (if you build to dist/)
node ./dist/cli.js --help
```

---

## âš™ï¸ Configuration

Create `tools/my-tool/.env` (or use your repo-standard config loader).

| Variable | Example | Purpose |
|---|---|---|
| `KFM_API_BASE_URL` | `http://localhost:8000` | Base URL for REST/GraphQL |
| `KFM_API_TOKEN` | `...` | Auth token for restricted endpoints |
| `KFM_PROFILE` | `dev` | Switches behavior per env |
| `KFM_OUTPUT_DIR` | `./out` | Output path for generated artifacts |

âœ… Tip: prefer **explicit configuration** over â€œmagic defaultsâ€ for reproducibility.

---

## ğŸ—‚ï¸ Module map (suggested layout)

Keep modules small, composable, and **contract-shaped**:

```text
ğŸ“ src/
  ğŸ“ cli/                # arg parsing + command routing
  ğŸ“ commands/            # one folder per command
  ğŸ“ clients/             # REST/GraphQL wrappers
  ğŸ“ contracts/           # STAC/DCAT/PROV validation helpers
  ğŸ“ io/                  # filesystem + output formatting
  ğŸ“ logging/             # structured logs + verbosity
  ğŸ“ errors/              # typed errors + exit codes
  ğŸ“„ index.ts             # library entry (optional)
```

---

## â• Add a new command

1. ğŸ“ Create: `src/commands/<name>/`
2. Add â€œthe trioâ€:
   - ğŸ“„ `schema.ts` â€” input validation
   - ğŸ“„ `handler.ts` â€” business logic (side-effect disciplined)
   - ğŸ“„ `examples.md` â€” copy/paste examples + expected output
3. ğŸ”— Wire it into `src/cli/` routing.
4. ğŸ§ª Add tests + fixtures (â€œgolden outputsâ€ if generating artifacts).
5. ğŸ§¾ Ensure outputs include evidence pointers (dataset IDs, STAC/DCAT/PROV references).

---

## ğŸ§ª Testing & quality gates

Recommended scripts:

```bash
npm run lint
npm run typecheck
npm test
```

### âœ… Definition of Done (DoD)
- âœ… Tests passing
- âœ… Docs updated (README + examples)
- âœ… Outputs trace to evidence
- âœ… No secret leakage (tokens never printed)
- âœ… Error paths return consistent exit codes

---

## ğŸ“¦ Build & publish notes (if this becomes an npm package)

If you publish, generate a backwards-compatible build and automate it:

```json
{
  "scripts": {
    "build": "babel ./lib --out-dir ./dist-modules",
    "prepublish": "npm run build"
  }
}
```

Also consider ignoring build output in git:

```gitignore
dist-modules/
```

---

## ğŸ§¯ Troubleshooting

<details>
  <summary>Common issues (click to expand)</summary>

- **Port conflicts** ğŸ”  
  If `5432` / `8000` / `7474` are taken, update `docker-compose` port mappings.

- **Docker memory too low ğŸ§ **  
  Large datasets/models need more RAM. Increase Dockerâ€™s memory allocation.

- **Auth failures ğŸ”**  
  Confirm `KFM_API_TOKEN` is set and that your role is permitted for ingest/pipeline endpoints.

- **Slow AI responses ğŸ¢**  
  Verify your local LLM runtime (e.g., Ollama) is reachable and the model is pulled.

</details>

---

## ğŸ”— Related docs (within the repo)

- ğŸ“ `docs/architecture/` â€” system design, AI integration, roadmap
- ğŸ“ `docs/standards/` â€” contracts + documentation conventions
- ğŸ“ `src/server/api/` â€” API docs (REST + GraphQL)
- ğŸ“ `pipelines/` â€” ETL + reproducibility

---
