<!--
ğŸ“Œ This README defines the *canonical pipeline boundary* for KFM (Kansas Frontier Matrix).
ğŸ—“ï¸ Last updated: 2026-01-09
-->

<div align="center">

# ğŸ§¬ KFM Pipelines  
`pipelines/README.md`

**Deterministic ETL â†’ governed catalogs â†’ graph ingestion â†’ APIs â†’ UI**  
The operational spine of **Kansas Frontier Matrix (KFM)**. ğŸ§ ğŸ—ºï¸

![Status](https://img.shields.io/badge/status-active-brightgreen)
![Docs-first](https://img.shields.io/badge/docs-documentation--first-1f6feb)
![Contract-first](https://img.shields.io/badge/contracts-contract--first-0aa3a3)
![Evidence-first](https://img.shields.io/badge/evidence-catalog--before--graph-8957e5)
![PDC](https://img.shields.io/badge/pipeline%20contract-KFM--PDC%20v11-blue)
![STAC](https://img.shields.io/badge/metadata-STAC%20v11-7b42f6)
![DCAT](https://img.shields.io/badge/metadata-DCAT%20v11-7b42f6)
![PROV](https://img.shields.io/badge/provenance-PROV%20v11-7b42f6)
![Graph](https://img.shields.io/badge/graph-Neo4j-00c853)
![Security](https://img.shields.io/badge/security-hostile--inputs%20%2B%20deny--by--default-red)
![Governance](https://img.shields.io/badge/governance-FAIR%20%2B%20CARE%20%2B%20Sovereignty-2ea043)

</div>

---

## ğŸ”— Quick links (start here)
- ğŸ§­ Repo overview: `../README.md`
- ğŸ§© Executable boundary: `../src/README.md`
- ğŸ“¦ Data + metadata boundary: `../data/README.md`
- ğŸ§ª MCP (runs, experiments, model cards): `../mcp/README.md`
- ğŸ›ï¸ Master architecture guide: `../docs/MASTER_GUIDE_v13.md` *(canonical intent + paths)*
- ğŸ§± Architecture & ADRs: `../docs/architecture/`
- ğŸ“œ Schemas + profiles: `../schemas/` *(STAC/DCAT/PROV, telemetry, story nodes, etc.)*
- ğŸ§° Validators & tools: `../tools/` *(incl. catalog QA)*
- ğŸ¤ CI/CD: `../.github/` *(workflows, security policy, automation)*
- ğŸŒ Web UI boundary: `../web/` *(React Â· MapLibre Â· optional Cesium)*

> [!NOTE]
> This `pipelines/` folder is a **portal + contract** ğŸ“  
> The **executable** pipeline code lives in `src/pipelines/`.  
> Evidence outputs live in `data/` (and must be cataloged).

---

## ğŸ§­ Quick navigation
- [ğŸš¦ Nonâ€‘negotiables](#-non-negotiables)
- [ğŸ§¬ What a â€œpipelineâ€ means in KFM](#-what-a-pipeline-means-in-kfm)
- [ğŸ§± The canonical ordering](#-the-canonical-ordering)
- [ğŸ“¦ Data & metadata lifecycle](#-data--metadata-lifecycle)
- [ğŸ“ Where things live](#-where-things-live)
- [âš™ï¸ Running pipelines](#ï¸-running-pipelines)
- [âœ… Quality gates](#-quality-gates)
- [ğŸ” Governance & sovereignty](#-governance--sovereignty)
- [ğŸ›¡ï¸ Security & hostile inputs](#ï¸-security--hostile-inputs)
- [ğŸ”­ Performance & scaling](#-performance--scaling)
- [ğŸŒ¾ Example pipeline archetypes](#-example-pipeline-archetypes)
- [ğŸ§© Adding a new pipeline](#-adding-a-new-pipeline)
- [ğŸ“š Project reference library influence map](#-project-reference-library-influence-map)
- [ğŸ•°ï¸ Version history](#ï¸-version-history)

---

## ğŸ§¾ Doc metadata

| Field | Value |
|---|---|
| Doc | `pipelines/README.md` |
| Status | Active âœ… |
| Last updated | **2026-01-09** |
| Audience | Contributors implementing ETL jobs, validators, catalog writers, graph ingest exports |
| Prime directive | **No catalog â†’ no graph â†’ no API â†’ no UI.** Catalogs are the interface. |

---

## ğŸš¦ Nonâ€‘negotiables

1) **Pipelines are deterministic builders** ğŸ§ª  
   Same inputs + config + code = same outputs (IDs, hashes, metadata).

2) **Declared inputs / declared outputs** ğŸ“¥â¡ï¸ğŸ“¤  
   Every pipeline must state what it reads and what it publishes (with paths + IDs).

3) **Catalogs are not optional** ğŸ—‚ï¸  
   Data is not â€œrealâ€ in KFM until it has:
   - STAC (spatial/temporal assets)
   - DCAT (dataset discovery)
   - PROV (lineage + run identity)

4) **Atomic publish** ğŸ§¾  
   Stage first â†’ validate â†’ publish **all-or-nothing** (no halfâ€‘written datasets in `data/processed/` or catalogs).

5) **Governance travels with the data** ğŸª¶  
   Classification, sensitivity, and redaction are enforced endâ€‘toâ€‘end. No downstream â€œloosening.â€

6) **KFM ordering is sacred** ğŸ§±  
   **ETL â†’ STAC/DCAT/PROV â†’ Neo4j Graph â†’ APIs â†’ Web UI â†’ Story Nodes â†’ Focus Mode**

> [!TIP]
> If your pipeline canâ€™t produce a clean paper trail (inputs â†’ transforms â†’ outputs â†’ catalogs â†’ lineage), itâ€™s not ready to merge. âœ…

---

## ğŸ§¬ What a pipeline means in KFM

A KFM pipeline is a **replayable builder** that produces:

- ğŸ“¦ **Evidence artifacts** in `data/processed/**` *(COG, Parquet, GeoJSON, CSV, tiles, etc.)*
- ğŸ—‚ï¸ **Catalog artifacts** in canonical locations *(STAC/DCAT)*
- ğŸ§¬ **Lineage artifacts** *(W3C PROV bundles: inputs â†’ activity â†’ outputs)*
- ğŸ§· **Integrity artifacts** *(hash manifests; inventories; deterministic IDs)*
- ğŸ“ˆ **Telemetry artifacts** *(run summaries, timings, gate outcomes)*

> [!IMPORTANT]
> Pipelines do **not** â€œsecretly update the graph.â€  
> The graph ingests **from catalogs** (and/or graph export artifacts) via controlled paths.

---

## ğŸ§± The canonical ordering

> [!IMPORTANT]
> This is a governance boundary, not a preference.

```mermaid
flowchart LR
  A["ğŸ§ª ETL + Normalization"] --> B["ğŸ—‚ï¸ STAC/DCAT/PROV Catalogs"]
  B --> C["ğŸ•¸ï¸ Neo4j Graph (references back to catalogs)"]
  C --> D["ğŸ›¡ï¸ APIs (contracts + redaction)"]
  D --> E["ğŸ—ºï¸ Web UI (React Â· MapLibre Â· optional Cesium)"]
  E --> F["ğŸ“š Story Nodes (governed narratives)"]
  F --> G["ğŸ¯ Focus Mode (context + provenance bundle)"]
```

> ğŸ§­ Legend (kept outside Mermaid to avoid renderer issues):  
> ğŸ§ª ETL â†’ ğŸ—‚ï¸ Catalogs â†’ ğŸ•¸ï¸ Graph â†’ ğŸ›¡ï¸ APIs â†’ ğŸ—ºï¸ UI â†’ ğŸ“š Story â†’ ğŸ¯ Focus

---

## ğŸ“¦ Data & metadata lifecycle

KFM uses a **required staging lifecycle** so everyone can tell â€œwhat stage is this file in?â€ at a glance:

- `data/raw/<domain>/...` â†’ raw source drops (read-only mindset)
- `data/work/<domain>/...` â†’ intermediate transforms (ok to delete/regenerate)
- `data/processed/<domain>/...` â†’ final evidence artifacts (publishable)

At publish time, pipelines must also write catalogs & lineage:

- `data/stac/collections/` + `data/stac/items/` â†’ STAC
- `data/catalog/dcat/` â†’ DCAT (JSONâ€‘LD dataset catalog)
- `data/prov/` â†’ PROV bundles (run + dataset lineage)

> [!NOTE]
> Some older notes may say `data/provenance/`.  
> **v13 canonical path is `data/prov/`.** Keep new work aligned.

---

## ğŸ“ Where things live

### ğŸ§­ Repo context (target shape)
```text
ğŸ“ pipelines/                 # ğŸ“ this folder (portal + conventions; not executable code)
ğŸ“ src/                       # ğŸ§© executable source code
â”‚  â””â”€â”€ ğŸ“ pipelines/          # ğŸ§ª ETL jobs + catalog writers + validators
ğŸ“ data/                      # ğŸ“¦ raw â†’ work â†’ processed + STAC/DCAT/PROV
ğŸ“ schemas/                   # ğŸ“ JSON Schemas (STAC/DCAT/PROV, telemetry, story nodes, etc.)
ğŸ“ tools/                     # ğŸ§° validators, QA tools, devops helpers
ğŸ“ web/                       # ğŸŒ UI (React + MapLibre + optional Cesium)
ğŸ“ mcp/                       # ğŸ““ methods + experiments + run receipts
ğŸ“ tests/                     # âœ… automated tests (unit/integration)
ğŸ“ releases/                  # ğŸ“¦ packaged release artifacts (manifest + SBOM)
ğŸ“ .github/                   # ğŸ¤ CI/CD, policies, automation
```

### ğŸ§ª Pipeline code lives here (canonical)
```text
ğŸ“ src/pipelines/
â”œâ”€â”€ ğŸ“ _shared/                  # ğŸ§© shared IO helpers, catalog emitters, validators
â””â”€â”€ ğŸ“ <domain>/
   â””â”€â”€ ğŸ“ <pipeline_name>/
      â”œâ”€â”€ run.py                 # entrypoint
      â”œâ”€â”€ pipeline.yml           # declarative config (recommended)
      â”œâ”€â”€ config/                # env-specific configs (dev/stage/prod)
      â”œâ”€â”€ schemas/               # domain schemas (if needed)
      â”œâ”€â”€ validators/            # QA gates (schema, bounds, link checks, etc.)
      â”œâ”€â”€ tests/                 # pipeline tests (fixtures + mini-run)
      â””â”€â”€ README.md              # developer-facing notes (short)
```

### ğŸ§¾ Pipeline docs live here (runbooks)
```text
ğŸ“ docs/pipelines/
â””â”€â”€ ğŸ“ <domain>/
   â””â”€â”€ ğŸ“ <pipeline_name>/
      â””â”€â”€ README.md              # purpose, inputs, outputs, SLA cadence, gates, failure modes
```

---

## âš™ï¸ Running pipelines

> [!NOTE]
> Prefer the repoâ€™s `Makefile` command surface when available.  
> If your local repo doesnâ€™t have these targets yet, treat this section as the **intended ergonomics**.

### âœ… Recommended: `make` entrypoints
```bash
# list pipelines (example)
make pipelines-list

# run a pipeline (example)
make pipeline RUN=hydrology/watersheds ENV=dev

# validate catalogs (example)
make catalog-qa

# build graph exports from catalogs (example)
make graph-export
```

### ğŸ Direct execution (module style)
```bash
python -m src.pipelines.hydrology.watersheds.run --env dev --config config/dev.yml
python -m src.pipelines.hazards.refresh.run --env dev --since "2026-01-01T00:00:00Z"
```

### ğŸ§± Typical environment variables
| Variable | Purpose |
|---|---|
| `KFM_ENV` | `dev|stage|prod` |
| `KFM_DATA_ROOT` | data root (if not repo-relative) |
| `KFM_STAC_ROOT` | STAC output root |
| `KFM_DCAT_ROOT` | DCAT output root |
| `KFM_PROV_ROOT` | PROV output root |
| `KFM_GRAPH_EXPORT_ROOT` | graph export root (CSV/Cypher) |
| `KFM_TELEMETRY_ROOT` | telemetry output root |
| `KFM_NEO4J_URI` | graph ingest endpoint *(if enabled)* |

> [!TIP]
> For complex geospatial dependencies (GDAL, PROJ, etc.), **Docker is your friend** ğŸ³  
> Containerize pipeline environments to reduce â€œworks on my machineâ€ drift.

---

## âœ… Quality gates

A pipeline is â€œdoneâ€ only when all of these pass:

### 1) âœ… Schema & bounds validation
- Input schema checks (columns/types; required fields)
- Spatial bounds checks (Kansas extent, expected CRS, sane coordinate ranges)
- Unit sanity checks (meters vs feet, mm vs inches, etc.)

### 2) ğŸ—‚ï¸ Catalog correctness
- STAC validity (Collections + Items)
- DCAT dataset/distributions are complete
- PROV bundles exist and link inputs/outputs

> [!NOTE]
> KFM treats metadata like code â€” it must pass tests.

### 3) ğŸ”— Link integrity
- Asset URLs/paths resolve
- STAC links are not broken
- Catalog IDs resolve downstream (graph ingest expects them)

### 4) ğŸ§· Integrity & determinism
- Checksums recorded (manifest inventories)
- Stable IDs for Items/datasets across reruns (when inputs unchanged)

### 5) ğŸ§° Catalog QA tooling
KFM uses a **Catalog QA gate** in CI/pre-release:
- expected tool location: `tools/validation/catalog_qa/`

> [!TIP]
> Make it easy for reviewers: `make catalog-qa` should be boring. ğŸ˜Œâœ…

---

## ğŸ” Governance & sovereignty

KFM is FAIR + CARE + sovereignty-aware by design.

### ğŸª¶ Classification propagation (deny-by-default)
- If an input is restricted, outputs **must not** be less restricted unless an explicit redaction/generalization step exists.
- Treat unknown sensitivity as restricted until reviewed.

### âœ‚ï¸ Redaction & generalization is multi-layer
If redaction is required, it must be applied consistently:
- `data/processed/**` (redacted evidence artifact)
- STAC/DCAT metadata (flags and documentation)
- API (enforces access & redaction)
- UI (additional checks / disclosure UX)

### ğŸ§¾ Audit trails
- Pipelines should emit telemetry signals when redaction/generalization occurs.
- Governance reviews are required for classification or sensitivity changes.

---

## ğŸ›¡ï¸ Security & hostile inputs

Pipelines ingest â€œfiles from the world.â€ Assume inputs are hostile by default. ğŸ§¯

### âœ… Required defensive posture
- Validate file types & magic bytes (donâ€™t trust extensions)
- Prevent path traversal (archives/extractors)
- Defend against decompression bombs (archives/images)
- Avoid unsafe shelling-out; sanitize args when calling GDAL/other tools
- Parameterize SQL; never string-concatenate untrusted values
- Never log secrets or sensitive raw content

> [!CAUTION]
> If someone malicious controls this input, whatâ€™s the maximum harm?  
> If the answer includes â€œrun code / exfiltrate / crash,â€ add guards **before** merging.

---

## ğŸ”­ Performance & scaling

KFM scales by staying **metadata-driven** and **chunk-friendly**:

- ğŸ“¦ Chunk work into partitions (tiles, counties, time windows)
- ğŸ§± Add pipeline breakers where materialization is necessary (write Parquet/COGs, then continue)
- ğŸ” Favor replay safety (idempotent keys, stable output paths, deterministic ordering)
- ğŸ›°ï¸ Bring compute to the data when possible (cloud processing + ingest the result)

> [!NOTE]
> For future streaming/near-real-time pipelines, the architecture can extend toward event/stream processors, parallel task pools, and adaptive execution models â€” without breaking the governed ETLâ†’catalog boundary.

---

## ğŸŒ¾ Example pipeline archetypes

These are canonical *shapes* KFM supports. Match one before inventing a new one. ğŸ§©

### 1) ğŸŒŠ Time-series & sensor ingestion
**Use when:** climate records, IoT readings, socio-economic time series  
**Outputs:** Parquet tables + temporal catalog coverage; supports timeline visualizations and analysis.

**Example intent:** ingest long-range NOAA monthly climate data into a single time-indexed Parquet dataset with spatial tags (FIPS/lat-long), then publish catalogs for discovery.

### 2) ğŸ›°ï¸ Remote sensing â€œcompute-to-dataâ€ ingest
**Use when:** imagery is too large to download/process locally  
**Pattern:** compute in a cloud environment (e.g., GEE-like workflows), then ingest the final product into `data/processed/**` with full PROV pointers to scripts, params, and date ranges.

### 3) ğŸ’§ Hydrology terrain processing
**Use when:** DEM-derived hydrology (flow direction/accumulation, watersheds, streams)  
**Typical tools:** GDAL + WhiteboxTools  
**Outputs:** COG rasters + vector GeoJSON + STAC metadata for map-ready layers.

### 4) ğŸŒªï¸ Hazards refresh pipeline (continuous ingest)
**Use when:** multi-source hazard chronicles (tornadoes, floods, fires, droughts, etc.)  
**Pattern:** automated ETL on a schedule (e.g., daily) that fetches, normalizes, catalogs, and produces higher-level summaries.  
**Downstream:** hazard events become graph nodes linked to provenance and related domains.

> [!TIP]
> â€œValue-addedâ€ derived layers (summaries, clustering, indices) are still **evidence artifacts**: store in `data/processed/**` + STAC/DCAT + PROV.

---

## ğŸ§© Adding a new pipeline

### âœ… Checklist (minimum bar)
- [ ] Choose a domain folder: `src/pipelines/<domain>/`
- [ ] Define the pipelineâ€™s inputs/outputs **before** coding (contract-first)
- [ ] Implement deterministic ETL (config-driven; stable IDs)
- [ ] Write outputs to `data/processed/<domain>/...`
- [ ] Emit STAC + DCAT + PROV
- [ ] Add validators (schema, bounds, link checks, classification propagation)
- [ ] Add tests (unit + at least one mini end-to-end run)
- [ ] Add docs: `docs/pipelines/<domain>/<pipeline_name>/README.md`
- [ ] Ensure graph ingest/export is driven from catalogs (no ad-hoc inserts)

### ğŸ§¾ Pipeline doc contract (what every pipeline doc must include)
Under `docs/pipelines/<domain>/<pipeline_name>/README.md`:

- ğŸ¯ Purpose + scope + SLA cadence
- ğŸ§º Inputs (sources, access requirements, licenses)
- ğŸ§ª Validation gates (what fails fast; what warns)
- ğŸ§· Integrity model (hashing, manifests, idempotency)
- ğŸ—‚ï¸ STAC/DCAT mapping (collections/items/datasets)
- ğŸ§¬ PROV mapping (entities/activities/agents)
- ğŸ’¥ Failure modes + replay rules + kill switch
- ğŸª¶ Governance notes (classification, redaction/generalization, restrictions)

### ğŸ§ª Run receipts (MCP link)
If this pipeline run is used to justify decisions or publish evidence:
- add a run receipt: `mcp/runs/RUN-YYYY-MM-DD-.../`
- link the evidence outputs (paths + catalog IDs)

---

## ğŸ“š Project reference library influence map

> [!NOTE]
> These project library files inform **pipeline design + review standards**: determinism, validation, scaling, governance, security posture, and map-readiness.

<details>
<summary><strong>ğŸ“¦ Expand: Project files â†’ what they influence in pipelines</strong></summary>

| Project file | Primary lens | Pipeline-level impact |
|---|---|---|
| `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.docx` | ğŸ§­ System blueprint | Defines deterministic pipeline contracts, provenance emission, schema/bounds validation, and atomic publish expectations. |
| `MARKDOWN_GUIDE_v13.md.gdoc` | ğŸ§± Repo canon | Canonical directory layout, evidence-first ordering, and where catalogs/lineage must be written. |
| `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf` | ğŸ›°ï¸ RS workflows | Cloud-first compute patterns; export discipline; treating derived indices as datasets with provenance. |
| `python-geospatial-analysis-cookbook.pdf` | ğŸ—ºï¸ GIS engineering | PostGIS + geospatial IO patterns; boundary transforms; web mapping-friendly outputs. |
| `making-maps-a-visual-guide-to-map-design-for-gis.pdf` | ğŸ¨ Cartography | â€œMap honestyâ€ constraints that should influence aggregation, classification, and derived layer publishing. |
| `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf` | ğŸ“± Offline/mobile | Asset sizing, tiling, caching, and â€œlow bandwidth firstâ€ constraints upstream. |
| `responsive-web-design-with-html5-and-css3.pdf` | ğŸŒ Frontend constraints | Pipeline outputs should respect payload budgets and progressive loading needs. |
| `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf` | ğŸ§Š 3D/GPU | LOD/tiling needs; coordinate convention clarity; performance-aware asset preparation. |
| `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf` | ğŸ–¼ï¸ Imagery | Compression/thumbnail strategy; preventing bloated repos; QA screenshot conventions. |
| `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf` | ğŸ˜ Data store | Postgres conventions; migrations; indexing; safe import/export practices for derived tables. |
| `Scalable Data Management for Future Hardware.pdf` | âš™ï¸ Performance | Chunking + task pools + pipeline breaker thinking; future streaming/parallel execution models. |
| `Data Spaces.pdf` | ğŸ”— Interop | Catalogs as interfaces; roles/access rights; monitoring mindset for data platforms. |
| `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf` | ğŸ§ª V&V discipline | Verification/validation mindset for simulation outputs and analytical pipelines. |
| `Understanding Statistics & Experimental Design.pdf` | ğŸ“Š Rigor | Bias/confounding awareness; pipeline QA checks that prevent misleading derived products. |
| `regression-analysis-with-python.pdf` | ğŸ“ˆ Diagnostics | Baselines + residual checks as â€œquality gatesâ€ for modeled evidence artifacts. |
| `Regression analysis using Python - slides-linear-regression.pdf` | ğŸ“ˆ Quick ref | Handy reminders for assumptions and evaluation discipline. |
| `graphical-data-analysis-with-r.pdf` | ğŸ“‰ EDA instincts | Early anomaly detection; QC plots as pipeline artifacts (small, linked). |
| `think-bayes-bayesian-statistics-in-python.pdf` | ğŸ² Uncertainty | Uncertainty reporting as a first-class output (intervals, posteriors) when relevant. |
| `Spectral Geometry of Graphs.pdf` | ğŸ•¸ï¸ Graph analytics | Caution for graph-derived features; treat metrics as signals, not facts. |
| `Generalized Topology Optimization for Structural Design.pdf` | ğŸ§® Optimization | Structuring optimization as reproducible workflows with explicit constraints/objectives. |
| `Principles of Biological Autonomy - book_9780262381833.pdf` | ğŸ§  Systems thinking | Feedback loops, stability, resilience in pipeline+governance design. |
| `Introduction to Digital Humanism.pdf` | â¤ï¸ Human-centered | Accountability and transparency in how pipelines publish evidence and affect narratives. |
| `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf` | âš–ï¸ AI governance | Label AI involvement; provenance; risk framing for decision-support outputs. |
| `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf` | ğŸ§¯ Threat modeling | Pipeline and service hardening mindset; privilege boundaries; defensive defaults. |
| `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf` | ğŸ›¡ï¸ Security mindset | Hostile-input awareness for parsers, extractors, and automation glue code. |
| `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf` | ğŸ§µ Concurrency | Careful orchestration; race condition avoidance; safe worker/job design. |
| `A programming Books.pdf` | ğŸ§° Polyglot reference | General engineering reference; choose tools without breaking boundaries. |
| `B-C programming Books.pdf` | ğŸ§° DevOps & CI patterns | CI scheduling, validation-after-ETL, containerization for reproducibility. |
| `D-E programming Books.pdf` | ğŸ§° ML implementation patterns | End-to-end preprocessing consistency; reproducible model export patterns. |
| `F-H programming Books.pdf` | ğŸ§° GIS/RS/ML mixed ref | Data processing patterns spanning geo + ML use cases. |
| `I-L programming Books.pdf` | ğŸ§° Maintainability | Practical patterns for robust, maintainable systems. |
| `M-N programming Books.pdf` | ğŸ§° Systems reference | Systems + networking awareness where needed. |
| `O-R programming Books.pdf` | ğŸ§° Engineering reference | Pragmatic engineering patterns across stacks. |
| `S-T programming Books.pdf` | ğŸ§° Security & testing | Secure coding posture; data store attack awareness; test discipline. |
| `U-X programming Books.pdf` | ğŸ§° Cross-discipline | Long-term maintainability and integration thinking. |
| `Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf` | ğŸ¤– ML practice | Pragmatic baselines + data-centric iteration (treat model outputs as governed evidence). |

</details>

---

## ğŸ•°ï¸ Version history

| Version | Date | Summary | Author |
|---:|---|---|---|
| v1.3.0 | 2026-01-09 | Removed placeholder citation markers; aligned repo paths to v13 canonical structure (`web/`, `data/catalog/dcat/`, `data/prov/`); strengthened pipeline contract essentials (declared IO, PROV, schema/bounds, atomic publish); added governance, security, scaling, and archetype guidance; expanded reference library influence map. | KFM Engineering |
| v1.2.0 | 2026-01-07 | Prior iteration with v11 contract badges and pipeline ordering statement. | KFM Engineering |

---

<div align="center">

**Â© 2026 Kansas Frontier Matrix** Â· CCâ€‘BY 4.0 (project docs)  
ğŸ§¬ FAIR+CARE Â· ğŸª¶ Sovereignty-aware Â· ğŸ›¡ï¸ Policy-gated builds

</div>
