<!--
ğŸ“Œ This README defines the *canonical pipeline boundary* for KFM (Kansas Frontier Matrix) / Kansasâ€‘Matrixâ€‘System.
ğŸ—“ï¸ Last updated: 2026-01-11
ğŸ” Review cycle: 90 days (or anytime pipeline order / catalogs / policy changes)
-->

<div align="center">

# ğŸ§¬ KFM Pipelines  
`pipelines/README.md`

**Deterministic ETL â†’ governed catalogs â†’ graph ingestion â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode**  
The operational spine of **Kansas Frontier Matrix (KFM)**. ğŸ§ ğŸ—ºï¸ğŸ§¾

![Status](https://img.shields.io/badge/status-active-brightgreen)
![Master Guide](https://img.shields.io/badge/Master%20Guide-v13%20(draft)-1f6feb)
![Contract-first](https://img.shields.io/badge/contracts-contract--first-0aa3a3)
![Evidence-first](https://img.shields.io/badge/evidence-catalog--before--graph-8957e5)
![Determinism](https://img.shields.io/badge/determinism-idempotent%20ETL-success)
![KFM Profiles](https://img.shields.io/badge/profiles-STAC%20%7C%20DCAT%20%7C%20PROV%20(v11)-7b42f6)
![Graph](https://img.shields.io/badge/graph-Neo4j-00c853)
![API Boundary](https://img.shields.io/badge/UI%20access-API%20only%20(no%20graph%20direct)-ff6b6b)
![Security](https://img.shields.io/badge/security-hostile--inputs%20%2B%20deny--by--default-red)
![Governance](https://img.shields.io/badge/governance-FAIR%20%2B%20CARE%20%2B%20Sovereignty-2ea043)

</div>

> **TL;DR:** `pipelines/` is the **portal + contract** for how KFM builds evidence.  
> The **executable pipeline code** lives in `src/pipelines/`.  
> The **publishable artifacts** live in `data/processed/**` and are not â€œrealâ€ until theyâ€™re **cataloged (STAC/DCAT)** and **traceable (PROV)**.

> [!IMPORTANT]
> **Prime directive:** **No catalog â†’ no graph â†’ no API â†’ no UI.**  
> Catalogs are the interface. Provenance is the receipt. ğŸ§¾âœ…

---

## ğŸ”— Quick links (start here) ğŸ§­
- ğŸ  Repo overview: `../README.md`
- ğŸ§© Executable boundary: `../src/README.md` *(if present)*
- ğŸ“¦ Data + metadata boundary: `../data/README.md` *(required reading)*
- ğŸ§ª Tests & QA gates: `../tests/README.md`
- ğŸ§° Governed toolchain surface: `../tools/README.md`
- ğŸ§° Automation wrappers: `../scripts/README.md`
- ğŸ““ MCP (runs, experiments, receipts): `../mcp/README.md` *(or `../mcp/MCP-README.md` if thatâ€™s the canonical name)*
- ğŸ“˜ Master Guide (canonical intent + paths): `../docs/MASTER_GUIDE_v13.md` *(if present)*
- ğŸ§± Architecture & ADRs: `../docs/architecture/`
- ğŸ§¾ Governance: `../docs/governance/`
- ğŸ“ Schemas + profiles: `../schemas/` **and** `../docs/standards/`
- ğŸ§© Templates: `../docs/templates/`
- ğŸ“š Story Nodes (narrative content): `../docs/reports/story_nodes/` *(draft/published workflow)*
- ğŸŒ Web UI boundary: `../web/` *(React Â· MapLibre Â· optional Cesium)*

---

<details>
<summary><b>ğŸ§­ Table of contents</b></summary>

- [ğŸ§¾ Doc metadata](#-doc-metadata)
- [ğŸš¦ Nonâ€‘negotiables](#-non-negotiables)
- [ğŸ§  What a â€œpipelineâ€ means in KFM](#-what-a-pipeline-means-in-kfm)
- [ğŸ§± The canonical ordering](#-the-canonical-ordering)
- [ğŸ§© Pipeline taxonomy](#-pipeline-taxonomy)
- [ğŸ“¦ Data & metadata lifecycle](#-data--metadata-lifecycle)
- [ğŸ“ Where things live](#-where-things-live)
- [ğŸ“œ KFM Pipeline Definition Contract](#-kfm-pipeline-definition-contract)
- [âš™ï¸ Running pipelines](#ï¸-running-pipelines)
- [âœ… Quality gates](#-quality-gates)
- [ğŸ§¾ Receipts, telemetry, and replay](#-receipts-telemetry-and-replay)
- [ğŸ” Governance & sovereignty](#-governance--sovereignty)
- [ğŸ›¡ï¸ Security & hostile inputs](#ï¸-security--hostile-inputs)
- [ğŸ”­ Performance & scaling](#-performance--scaling)
- [ğŸŒ¾ Example pipeline archetypes](#-example-pipeline-archetypes)
- [ğŸ§© Adding a new pipeline](#-adding-a-new-pipeline)
- [ğŸ“š Project reference library influence map](#-project-reference-library-influence-map)
- [ğŸ§¾ Metadata](#-metadata)
- [ğŸ•°ï¸ Version history](#ï¸-version-history)

</details>

---

## ğŸ§¾ Doc metadata

| Field | Value |
|---|---|
| Doc | `pipelines/README.md` |
| Status | Active âœ… |
| Last updated | **2026-01-11** |
| Review cycle | 90 days ğŸ” |
| Audience | Contributors implementing ETL jobs, validators, catalog writers, graph exports/ingest bridges |
| Prime directive | **No catalog â†’ no graph â†’ no API â†’ no UI.** Catalogs are the interface. |

---

## ğŸš¦ Nonâ€‘negotiables

1) **Deterministic, idempotent ETL** ğŸ§ª  
   Same inputs + same config + same code â‡’ same outputs (stable IDs/hashes) and reruns do not corrupt or duplicate.

2) **Contract-first** ğŸ“œ  
   Pipelines are driven by declared contracts (schemas, profiles, OpenAPI) and contract changes trigger compatibility checks.

3) **Catalogs are not optional** ğŸ—‚ï¸  
   Data is not â€œrealâ€ in KFM until it has:
   - **STAC** (assets + spatial/temporal metadata)
   - **DCAT** (dataset discovery & distributions)
   - **PROV** (lineage + run identity)

4) **Evidence-first narrative** ğŸ“š  
   Story Nodes / Focus Mode must cite **cataloged evidence**. No unsourced narrative content.  
   If AI helps generate text: label it, attach provenance, and include confidence/uncertainty where applicable.

5) **API boundary rule** ğŸ›¡ï¸  
   The UI must **never** query Neo4j/DB directly; all access goes through governed APIs (contracts + redaction).

6) **Governed ordering is sacred** ğŸ§±  
   **ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**

> [!TIP]
> If your pipeline canâ€™t produce a clean paper trail (inputs â†’ transforms â†’ outputs â†’ catalogs â†’ lineage), itâ€™s not ready to merge. âœ…ğŸ§¾

---

## ğŸ§  What a â€œpipelineâ€ means in KFM

A KFM pipeline is a **replayable builder** that produces:

- ğŸ“¦ **Evidence artifacts** â†’ `data/processed/**` *(COG, GeoParquet, CSV, tiles, thumbnails, reports, model artifacts, etc.)*
- ğŸ—‚ï¸ **Catalog artifacts** â†’ `data/stac/**` + `data/catalog/dcat/**`
- ğŸ§¬ **Lineage artifacts** â†’ `data/prov/**` *(W3C PROV JSONâ€‘LD recommended)*
- ğŸ§· **Integrity artifacts** â†’ manifests, checksums, inventories
- ğŸ“ˆ **Telemetry artifacts** â†’ run summaries, gate outcomes, timings *(location is configurable; keep it deterministic and linkable)*

> [!IMPORTANT]
> Pipelines do **not** â€œsecretly update the graph.â€  
> The graph ingests **from catalogs** (and/or explicit graph export artifacts) via controlled paths.

---

## ğŸ§± The canonical ordering

> [!IMPORTANT]
> This is a governance boundary, not a preference.

```mermaid
flowchart LR
  A["ğŸ§ª ETL + Normalization"] --> B["ğŸ—‚ï¸ STAC/DCAT/PROV Catalogs"]
  B --> C["ğŸ•¸ï¸ Graph (references catalogs)"]
  C --> D["ğŸ›¡ï¸ APIs (contracts + redaction)"]
  D --> E["ğŸ—ºï¸ Web UI (React Â· MapLibre Â· optional Cesium)"]
  E --> F["ğŸ“š Story Nodes (draft/published)"]
  F --> G["ğŸ¯ Focus Mode (context + evidence bundle)"]
```

---

## ğŸ§© Pipeline taxonomy

Not all pipelines look the same. KFM supports a few **governed shapes**:

| Type | When to use | Key rule ğŸ”‘ |
|---|---|---|
| ğŸ§± **Build (batch)** | One-time or periodic creation of a dataset | Must be deterministic + cataloged + provâ€™d before use |
| ğŸ” **Refresh (scheduled)** | Regular updates (daily/weekly/monthly) | Must be idempotent; versioned outputs; diffs are inspectable |
| ğŸ‘€ **Watcher (nearâ€‘realâ€‘time)** | Polling/streaming feeds (e.g., GTFSâ€‘RT) | Each window produces catalogable â€œunitsâ€ + receipts; no mystery updates |
| ğŸ”Œ **Adapter (import bridge)** | Bring in external exports (partner datasets, agency drops) | Must validate schema/license/classification before promotion |
| ğŸ§ª **Analysis/Model** | Derived indicators, regression outputs, simulation runs | Record params/seeds; treat results as evidence artifacts |
| ğŸ“„ **Document ingest** | PDFs/scans â†’ extracted text/entities | Must store raw doc + derived text; provenance + redaction rules required |

> [!NOTE]
> Watchers are still bound by ordering: **they produce cataloged outputs first**, then (optionally) graph/API consumption follows.

---

## ğŸ“¦ Data & metadata lifecycle

KFM uses a required staging lifecycle so everyone can tell â€œwhat stage is this file in?â€ at a glance:

### ğŸ“¥ Data stages
- `data/raw/<domain>/...` â†’ raw source drops *(read-only mindset)*
- `data/work/<domain>/...` â†’ intermediate transforms *(ok to delete/regenerate)*
- `data/processed/<domain>/...` â†’ final evidence artifacts *(publishable)*

### ğŸ—‚ï¸ Catalog + provenance stages (required before downstream use)
- `data/stac/` â†’ STAC collections/items (assets + metadata)
- `data/catalog/dcat/` â†’ DCAT datasets/distributions (discovery)
- `data/prov/` â†’ PROV bundles (run + dataset lineage)

> [!NOTE]
> Some older notes may say `data/provenance/`.  
> **Canonical path is `data/prov/`.** Keep new work aligned.

---

## ğŸ“ Where things live

### ğŸ§­ Repo context (target shape)
```text
ğŸ“ pipelines/                 # ğŸ“ this folder (portal + conventions; not executable code)
ğŸ“ src/                       # ğŸ§© executable source code
â”‚  â”œâ”€â”€ ğŸ“ pipelines/          # ğŸ§ª ETL jobs + catalog writers + validators
â”‚  â”œâ”€â”€ ğŸ“ graph/              # ğŸ•¸ï¸ graph construction + queries (from catalogs)
â”‚  â””â”€â”€ ğŸ“ server/             # ğŸ›¡ï¸ APIs (contracts + redaction enforcement)
ğŸ“ data/                      # ğŸ“¦ raw â†’ work â†’ processed + STAC/DCAT/PROV
ğŸ“ schemas/                   # ğŸ“ JSON Schemas (contracts)
ğŸ“ docs/                      # ğŸ“˜ governed documentation (templates, standards, governance)
ğŸ“ tools/                     # ğŸ§° validators, QA tools, deterministic entrypoints
ğŸ“ scripts/                   # ğŸ§° orchestration wrappers (call tools/src)
ğŸ“ tests/                     # âœ… automated tests (unit/integration/e2e)
ğŸ“ web/                       # ğŸŒ UI (React + MapLibre + optional Cesium)
ğŸ“ releases/                  # ğŸ“¦ packaged releases (manifest + SBOM + attestations)
ğŸ“ .github/                   # ğŸ¤ CI/CD, policies, automation
```

### ğŸ§ª Pipeline code (canonical)
```text
ğŸ“ src/pipelines/
â””â”€â”€ ğŸ“ <domain>/
    â””â”€â”€ ğŸ“ <pipeline_name>/
        â”œâ”€â”€ run.py                     # entrypoint (CLI)
        â”œâ”€â”€ pipeline.yml               # ğŸ“œ pipeline contract (required / strongly recommended)
        â”œâ”€â”€ README.md                  # short notes + examples (dev-facing)
        â”œâ”€â”€ config/                    # env configs (dev/stage/prod)
        â”œâ”€â”€ schemas/                   # domain schemas (if needed)
        â”œâ”€â”€ validators/                # QA gates (schema, bounds, link checks, etc.)
        â”œâ”€â”€ tests/                     # mini-run tests + fixtures
        â””â”€â”€ _shared/                   # optional submodules (keep DRY; prefer src/pipelines/_shared)
```

### ğŸ“˜ Domain module docs (recommended)
A domain should document its pipelines + governance posture here:

```text
ğŸ“ docs/data/
â””â”€â”€ ğŸ“ <domain>/
    â”œâ”€â”€ README.md                      # domain overview + pipeline list + access notes
    â””â”€â”€ ğŸ“ pipelines/
        â””â”€â”€ ğŸ“ <pipeline_name>/
            â””â”€â”€ README.md              # runbook: IO, cadence, gates, failure modes, replay rules
```

### ğŸ“š Story Node content (governed narrative)
```text
ğŸ“ docs/reports/story_nodes/
â”œâ”€â”€ ğŸ“ draft/
â””â”€â”€ ğŸ“ published/
```

> [!TIP]
> If you add a new domain pipeline, add a domain module README under `docs/data/<domain>/README.md` so reviewers can find the â€œwhat/why/howâ€ quickly. ğŸ§­âœ…

---

## ğŸ“œ KFM Pipeline Definition Contract

KFM pipelines are contract-first. A pipeline should have a machine-readable contract file (recommended name: `pipeline.yml`) that explains **what it reads, what it writes, and what it guarantees**.

### âœ… Minimum contract fields (recommended)
- `id` (stable, versioned; do not encode secrets)
- `name`, `description`, `owner`
- `inputs` (sources, paths, licenses, checksums when feasible)
- `outputs` (paths + formats + dataset IDs)
- `catalogs` (STAC/DCAT targets; collections/items/datasets)
- `provenance` (how run_id/config hash is captured)
- `gates` (schema/bounds/link/license/classification checks)
- `determinism` (stable sorting, seed strategy, idempotency key)
- `network` posture (deny-by-default; allowlist & logging if enabled)
- `resources` (optional: memory/CPU hints; chunking strategy)

### ğŸ§© Example `pipeline.yml` (starter template)
```yaml
id: "kfm.hydrology.watersheds.v1"
name: "Hydrology Watersheds Builder"
owner: "@kfm-engineering"
description: "Derives watershed boundaries + flow products from DEM inputs and publishes map-ready layers."

envs: ["dev", "stage", "prod"]

inputs:
  - id: "kfm.elevation.dem.3dep.v1"
    stage: "raw"
    paths:
      - "data/raw/elevation/3dep/**"
    license: "public-domain-or-provider-license"
    notes: "Record exact source + version in PROV."

outputs:
  stage: "processed"
  datasets:
    - id: "kfm.hydrology.watersheds.v1"
      paths:
        - "data/processed/hydrology/watersheds/**"
      formats: ["COG", "GeoParquet", "GeoJSON (small only)"]

catalogs:
  stac_root: "data/stac"
  dcat_root: "data/catalog/dcat"
  collections:
    - "kfm.hydrology"
  items:
    strategy: "one item per logical unit (tile/county/basin)"
  dcat:
    dataset_id: "kfm.hydrology.watersheds.v1"

provenance:
  prov_root: "data/prov"
  run_id_env: "KFM_RUN_ID"
  config_hash: "sha256(pipeline.yml + config/<env>.yml)"
  record_git_sha: true
  record_seeds: true

gates:
  - "schema_required"
  - "crs_required"
  - "geometry_valid"
  - "bounds_sane"
  - "license_required"
  - "classification_no_downgrade"
  - "stac_schema"
  - "dcat_schema"
  - "prov_bundle_present"
  - "link_check"

determinism:
  stable_sorting: true
  seeded: true
  seed_source: "KFM_SEED or derived from run_id"
  idempotency_key: "(dataset_id, input_checksums, config_hash)"

network:
  default: "deny"
  allow_with_flag: "--allow-network"
  ssrf_protection: true
  log_urls_and_checksums: true
```

> [!IMPORTANT]
> The contract does not replace docs; it makes the docs **enforceable**.  
> CI can validate `pipeline.yml` shape and cross-check it against produced artifacts.

---

## âš™ï¸ Running pipelines

> [!NOTE]
> Prefer the repoâ€™s **make/CI entrypoints** when available.  
> If your repo doesnâ€™t have these targets yet, treat this section as intended ergonomics.

### âœ… Recommended: `make` entrypoints (examples)
```bash
# list pipelines (example)
make pipelines-list

# run a pipeline (example)
make pipeline RUN=hydrology/watersheds ENV=dev

# validate catalogs (example)
make catalog-qa

# graph ingest/export (example)
make graph-export
make graph-ingest
```

### ğŸ Direct execution (module style)
```bash
python -m src.pipelines.hydrology.watersheds.run --env dev --config config/dev.yml --run-id "RUN-2026-01-11-demo"
python -m src.pipelines.hazards.refresh.run --env dev --since "2026-01-01T00:00:00Z" --run-id "RUN-2026-01-11-hazards"
```

### ğŸ§± Expected flags (strongly recommended)
- `--help` (must include â‰¥2 runnable examples)
- `--env {dev|stage|prod}`
- `--config <path>`
- `--run-id <id>` (or `KFM_RUN_ID`)
- `--dry-run` default OR â€œno writes unless `--apply`â€
- `--apply` for state mutation
- `--allow-network` for any remote fetching (deny-by-default)

### ğŸ§± Typical environment variables
| Variable | Purpose |
|---|---|
| `KFM_ENV` | `dev|stage|prod` |
| `KFM_RUN_ID` | provenance correlation across logs/catalogs/PROV |
| `KFM_DATA_ROOT` | data root (if not repo-relative) |
| `KFM_STAC_ROOT` | STAC output root |
| `KFM_DCAT_ROOT` | DCAT output root |
| `KFM_PROV_ROOT` | PROV output root |
| `KFM_GRAPH_EXPORT_ROOT` | graph export root (CSV/Cypher/JSON) |
| `KFM_TELEMETRY_ROOT` | telemetry output root |
| `KFM_SEED` | RNG seed for stochastic pipelines |
| `KFM_NEO4J_URI` | graph endpoint *(only for controlled ingest steps)* |

> [!TIP]
> For heavy geo deps (GDAL/PROJ), **Docker is your friend** ğŸ³  
> Containerize pipeline environments to reduce â€œworks on my machineâ€ drift.

---

## âœ… Quality gates

A pipeline is â€œdoneâ€ only when these pass (prefer â€œfail closedâ€ ğŸ”’):

### Ring 0 â€” Structure ğŸ§±
- JSON/YAML parses
- schema validation for outputs + catalogs
- required files exist (pipeline.yml, configs, outputs present)

### Ring 1 â€” Integrity ğŸ§·
- checksums/manifests recorded
- deterministic IDs stable when inputs unchanged
- atomic publish (no half-written processed outputs)

### Ring 2 â€” Semantics ğŸ§ 
- CRS correctness + axis order
- geometry validity (and any repair policy is explicit + logged)
- raster sanity (nodata, resolution, overviews for COG)
- bounds/time sanity (Kansas extent, plausible ranges, monotonic windows where required)

### Ring 3 â€” Governance & safety ğŸ”ğŸ›¡ï¸
- license required before publish
- classification/sensitivity propagation (no downgrade)
- redaction/generalization audited
- hostile input guards (archives, rasters, PDFs, GeoJSON, etc.)
- secrets/sensitive patterns not leaked to logs

### ğŸ§° Catalog QA tooling (standard)
KFM uses a **Catalog QA gate** in CI/pre-release:
- expected home: `tools/validation/catalog_qa/`

> [!TIP]
> Make it easy for reviewers: `make catalog-qa` should be boring. ğŸ˜Œâœ…

---

## ğŸ§¾ Receipts, telemetry, and replay

KFM is evidence-first: pipelines should emit â€œreceiptsâ€ that let someone reproduce the run.

### âœ… Minimum receipt set (recommended for any publish)
- ğŸ§¾ `data/prov/<RUN-ID>.jsonld` (or a bundle directory)
- ğŸ§· checksums manifest for produced outputs
- ğŸ—‚ï¸ STAC + DCAT references for all published artifacts
- ğŸªµ structured logs (human + optional JSONL)

### â­ Recommended: MCP run receipt (when used for decisions or publish)
- `mcp/runs/<RUN-ID>/MANIFEST.md` (human narrative of â€œwhat happenedâ€)
- links to the relevant catalogs + outputs + gates

> [!NOTE]
> Telemetry should help answer: **what ran, what changed, what gates passed, what was withheld/redacted, and why**.  
> Example event concept: `focus_mode_redaction_notice_shown` when sensitive data is withheld/generalized in downstream experiences.

---

## ğŸ” Governance & sovereignty

KFM is FAIR + CARE + sovereignty-aware by design ğŸª¶

### ğŸªª Classification propagation (deny-by-default)
- Outputs cannot be **less restricted** than inputs unless an explicit redaction/generalization step exists and is reviewed.
- If classification cannot be determined, default to **restricted**.

### âœ‚ï¸ Redaction/generalization is multi-layer
If redaction is required, it must be applied consistently:
- `data/processed/**` (redacted evidence artifact)
- STAC/DCAT metadata (flags + documentation)
- API layer (access control + redaction enforcement)
- UI layer (additional disclosure/UX checks)

### ğŸ§¾ Audit trails
- Pipelines should emit telemetry and provenance notes when redaction/generalization occurs.
- Governance reviews are required for classification/sensitivity changes.

---

## ğŸ›¡ï¸ Security & hostile inputs

Pipelines ingest â€œfiles from the world.â€ Assume inputs are hostile by default. ğŸ§¯

### âœ… Required defensive posture
- validate file types & magic bytes (donâ€™t trust extensions)
- prevent path traversal (archives/extractors)
- defend against decompression bombs (archives/images)
- sanitize subprocess args when calling GDAL/other tooling
- parameterize SQL (never string-concat untrusted values)
- **never log secrets**; never print sensitive raw content

### ğŸŒ Network posture
- default: **no network**
- if a pipeline fetches remote inputs:
  - require `--allow-network`
  - block private IP ranges by default (SSRF defense)
  - log URLs + checksums of downloaded artifacts

> [!CAUTION]
> If someone malicious controls this input, whatâ€™s the maximum harm?  
> If the answer includes â€œrun code / exfiltrate / crash,â€ add guards **before** merging. ğŸš«ğŸ§¨âœ…

---

## ğŸ”­ Performance & scaling

KFM scales by staying **metadata-driven** and **chunk-friendly**:

- ğŸ“¦ partition work (tiles, counties, watersheds, time windows)
- ğŸ§± pipeline breakers at materialization boundaries (COG/Parquet outputs)
- ğŸ” replay safety (idempotency keys + deterministic ordering)
- â™»ï¸ avoid reprocessing unchanged inputs (checksums + manifests)
- ğŸ—„ï¸ push heavy spatial ops into PostGIS when safe (joins, intersects, buffers)
- ğŸ›°ï¸ compute-to-data for imagery-heavy domains

> [!TIP]
> Prefer â€œboring performance winsâ€: stable chunking + caching + deterministic manifests.  
> Speed is good â€” **but correctness and provenance come first**. ğŸ§¾âœ…

---

## ğŸŒ¾ Example pipeline archetypes

Match an archetype before inventing a new one ğŸ§©

### 1) ğŸŒŠ Time-series & sensor ingestion (batch/refresh)
**Use when:** climate records, stream gauges, socio-economic time series  
**Outputs:** Parquet + temporal coverage metadata + catalog entries  
**Key gates:** schema, time window sanity, missingness checks, license, provenance.

### 2) ğŸ›°ï¸ Remote sensing compute-to-data ingest (batch/refresh)
**Use when:** imagery too large for local processing  
**Pattern:** compute externally (e.g., cloud workflows) â†’ ingest derived product â†’ publish COG + STAC + DCAT + PROV  
**Key gates:** band/range sanity (e.g., NDVI âˆˆ [-1,1]), cloud mask logic recorded, export params captured.

### 3) ğŸ’§ Hydrology terrain processing (batch)
**Use when:** DEM-derived flow direction/accumulation, watersheds, streams  
**Outputs:** COG rasters + web-ready vectors + STAC Items for each logical unit  
**Key gates:** CRS, nodata, alignment, geometry validity, Kansas bounds.

### 4) ğŸŒªï¸ Hazards refresh (scheduled refresh)
**Use when:** multi-source hazard chronicles (tornado, flood, drought, fire)  
**Pattern:** scheduled ETL â†’ normalized event records â†’ cataloged evidence + summaries  
**Downstream:** events become graph nodes linked to provenance + sources.

### 5) ğŸš GTFSâ€‘RT watcher (nearâ€‘realâ€‘time)
**Use when:** live transit telemetry (vehicle positions, trip updates)  
**Pattern:** watcher polls/streams â†’ writes time-windowed artifacts â†’ emits STAC Items per window/day â†’ DCAT dataset distribution â†’ PROV per run/window  
**Key gates:** strict timestamp handling, dedupe, retention policy, governance classification.

### 6) ğŸ“„ Bulk document ingest (evidence-first)
**Use when:** PDFs/scans (reports, notices, historical docs) must become searchable evidence  
**Pattern:** store raw doc â†’ extract text (and optional entities) â†’ catalog as evidence with provenance + redaction rules  
**Key gates:** hostile PDF handling, PII policy checks, attribution/license capture.

> [!TIP]
> â€œValue-addedâ€ derived layers (summaries, clustering, indices) are still **evidence artifacts**: store in `data/processed/**` + STAC/DCAT + PROV. âœ…ğŸ—‚ï¸ğŸ§¬

---

## ğŸ§© Adding a new pipeline

### âœ… Checklist (minimum bar)
- [ ] Choose a domain: `src/pipelines/<domain>/`
- [ ] Define inputs/outputs **before** coding (contract-first)
- [ ] Implement deterministic ETL (config-driven; stable IDs)
- [ ] Write to `data/raw â†’ data/work â†’ data/processed` *(stage appropriately)*
- [ ] Emit STAC + DCAT + PROV (before downstream use)
- [ ] Add validators (schema, bounds, links, license, classification propagation)
- [ ] Add tests (unit + at least one mini end-to-end run)
- [ ] Add docs: `docs/data/<domain>/pipelines/<pipeline_name>/README.md`
- [ ] Ensure graph ingest/export is driven from catalogs (no ad-hoc inserts)

### ğŸ§¾ Pipeline runbook contract (what every pipeline doc must include)
Under `docs/data/<domain>/pipelines/<pipeline_name>/README.md`:

- ğŸ¯ Purpose + scope + SLA cadence
- ğŸ§º Inputs (sources, access requirements, licenses)
- âœ… Validation gates (what fails fast; what warns)
- ğŸ§· Integrity model (hashing, manifests, idempotency)
- ğŸ—‚ï¸ STAC/DCAT mapping (collections/items/datasets)
- ğŸ§¬ PROV mapping (entities/activities/agents)
- ğŸ’¥ Failure modes + replay rules + kill switch
- ğŸª¶ Governance notes (classification, redaction/generalization, restrictions)

### ğŸ§ª Run receipts (MCP alignment)
If this run is used to justify decisions or publish evidence:
- add a run receipt: `mcp/runs/RUN-YYYY-MM-DD-.../`
- link evidence outputs (paths + catalog IDs)
- include gate outcomes + any redactions applied

---

## ğŸ“š Project reference library influence map

These library files shape pipeline design + review standards: determinism, validation, scaling, governance, security posture, and map readiness. ğŸ§ ğŸ§¾

<details>
<summary><strong>ğŸ“¦ Expand: Project files â†’ what they influence in pipelines</strong></summary>

| Project file | Primary lens | Pipeline-level impact |
|---|---|---|
| `MARKDOWN_GUIDE_v13.md.gdoc` | ğŸ§± Repo canon | Canonical ordering, subsystem boundaries, evidence-first narrative, API boundary rule, and v13 directory + standards expectations. |
| `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.docx` | ğŸ§­ System blueprint | End-to-end architecture intent; how evidence supports maps, analysis, APIs, and decision support UX. |
| `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf` | ğŸ›°ï¸ RS workflows | Export discipline; record AOI/time/method; derived products as first-class datasets with provenance. |
| `python-geospatial-analysis-cookbook.pdf` | ğŸ—ºï¸ GIS engineering | Practical geospatial IO patterns; PostGIS-centric operations; safer spatial joins/filters; web mapping friendly outputs. |
| `making-maps-a-visual-guide-to-map-design-for-gis.pdf` | ğŸ¨ Cartography | â€œMap honestyâ€ constraints: classification/aggregation choices, legends, and style implications should be audited. |
| `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf` | ğŸ“± Offline/mobile | Payload budgets, tiling, caching, and progressive loading constraints upstream of UI. |
| `responsive-web-design-with-html5-and-css3.pdf` | ğŸŒ Frontend constraints | Pipeline artifacts should respect responsive payload budgets and progressive loading needs. |
| `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf` | ğŸ§Š 3D/GPU | Coordinate conventions; LOD/tiling needs; GPU-friendly asset preparation and validation. |
| `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf` | ğŸ–¼ï¸ Imagery | Compression/thumbnail strategy; preventing bloated repos; QA artifact conventions. |
| `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf` | ğŸ˜ Data store | Transactional safety, migrations, indexing, stagingâ†’swap patterns for reproducible ingest. |
| `Scalable Data Management for Future Hardware.pdf` | âš™ï¸ Performance | Chunking, locality, concurrency-safe execution; pipeline breakers; future streaming/parallel models. |
| `Data Spaces.pdf` | ğŸ”— Interop | Catalogs as interfaces; rights/access awareness; monitoring mindset for data platforms. |
| `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf` | ğŸ§ª V&V discipline | Verification/validation patterns; scientific reproducibility posture; run receipts + parameter capture. |
| `Understanding Statistics & Experimental Design.pdf` | ğŸ“Š Rigor | Bias/confounding awareness; acceptance gates that prevent misleading â€œderived truths.â€ |
| `regression-analysis-with-python.pdf` | ğŸ“ˆ Diagnostics | Baselines + residual checks as pipeline quality gates for modeled artifacts. |
| `Regression analysis using Python - slides-linear-regression.pdf` | ğŸ“ˆ Quick ref | Reminders for assumptions, diagnostics, and evaluation discipline. |
| `graphical-data-analysis-with-r.pdf` | ğŸ“‰ EDA instincts | QC plots as pipeline artifacts (small, linked, and deterministic). |
| `think-bayes-bayesian-statistics-in-python.pdf` | ğŸ² Uncertainty | Uncertainty as a first-class output (intervals/posteriors) for decision support. |
| `Spectral Geometry of Graphs.pdf` | ğŸ•¸ï¸ Graph analytics | Caution: graph-derived metrics are signals; validate integrity & meaning; donâ€™t overclaim. |
| `Generalized Topology Optimization for Structural Design.pdf` | ğŸ§® Optimization | Optimization runs must record objectives/constraints; determinism and replay rules matter. |
| `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf` | ğŸ§¯ Threat modeling | Defensive posture for networked ingestion; SSRF, logging, privilege boundaries. |
| `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf` | ğŸ›¡ï¸ Security mindset | Hostile-input awareness for parsers/extractors; hardening glue code and tooling. |
| `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf` | ğŸ§µ Concurrency | Deterministic concurrency patterns; avoid races; safe orchestration for scheduled/real-time pipelines. |
| `Introduction to Digital Humanism.pdf` | â¤ï¸ Human-centered | Transparency + accountability defaults; explainability and community trust. |
| `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf` | âš–ï¸ AI governance | Label AI involvement; provenance + risk framing for decision-support outputs. |
| `A programming Books.pdf` â€¦ `U-X programming Books.pdf` | ğŸ§° Polyglot shelf | Broad implementation reference; pick tooling without breaking contracts/boundaries. |

</details>

---

## ğŸ§¾ Metadata

```yaml
title: "KFM Pipelines â€” canonical pipeline boundary"
path: "pipelines/README.md"
version: "v1.4.0"
last_updated: "2026-01-11"
review_cycle: "90 days"
prime_directive: "No catalog â†’ no graph â†’ no API â†’ no UI"
pipeline_order: "ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ APIs â†’ UI â†’ Story Nodes â†’ Focus Mode"
principles:
  - "contract-first"
  - "evidence-first"
  - "determinism-by-default"
  - "deny-by-default security"
  - "FAIR+CARE + sovereignty-aware"
```

---

## ğŸ•°ï¸ Version history

| Version | Date | Summary | Author |
|---:|---|---|---|
| v1.4.0 | 2026-01-11 | Aligned pipeline README with Master Guide v13 invariants (API boundary, evidence-first narrative); added pipeline taxonomy + PDC contract template; expanded receipts/telemetry; added watcher/document-ingest archetypes; clarified docs paths for domains/pipelines/story nodes. | KFM Engineering |
| v1.3.0 | 2026-01-09 | Strengthened pipeline contract essentials (declared IO, PROV, schema/bounds, atomic publish); expanded governance, security, scaling, and archetype guidance. | KFM Engineering |

---

<div align="center">

**Â© 2026 Kansas Frontier Matrix** Â· CCâ€‘BY 4.0 (project docs)  
ğŸ§¬ FAIR+CARE Â· ğŸª¶ Sovereignty-aware Â· ğŸ›¡ï¸ Policy-gated builds Â· ğŸ§¾ Evidence-first

</div>

<!--
ğŸ“ Evidence anchors (project docs used to update this README)
- Master Guide v13 invariants (ordering, API boundary, evidence-first narrative, determinism): :contentReference[oaicite:0]{index=0} :contentReference[oaicite:1]{index=1} :contentReference[oaicite:2]{index=2}
- KFM system blueprint + decision-support framing: :contentReference[oaicite:3]{index=3}
- Future pipeline extensions (watchers, document ingest, OpenLineage/attestation concepts): 
-->
