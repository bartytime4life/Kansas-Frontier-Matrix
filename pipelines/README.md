<!-- According to a document refresh from 2026-01-26: this README was updated using the full KFM project doc set (core PDFs + AI infra + UI architecture + Master Guide v13 + reference bundles). -->
<!--
ğŸ“Œ This README defines the *canonical pipeline boundary* for KFM (Kansas Frontier Matrix) / Kansasâ€‘Matrixâ€‘System.
ğŸ—“ï¸ Last updated: 2026-01-26
ğŸ” Review cycle: 90 days (or anytime pipeline order / catalogs / policy / distribution / narrative rules change)
-->

<div align="center">

# ğŸ§¬ KFM Pipelines  
`pipelines/README.md`

**Deterministic ETL â†’ source manifests â†’ governed catalogs â†’ derived stores (Neo4j + PostGIS + Search Index) â†’ APIs â†’ UI â†’ Story Nodes + Pulse Threads â†’ Focus Mode**  
The operational spine of **Kansas Frontier Matrix (KFM)**. ğŸ§ ğŸ—ºï¸ğŸ§¾

![Status](https://img.shields.io/badge/status-active-brightgreen)
![Master Guide](https://img.shields.io/badge/Master%20Guide-v13-1f6feb)
![Contract-first](https://img.shields.io/badge/contracts-contract--first-0aa3a3)
![Policy Pack](https://img.shields.io/badge/policy-OPA%20%7C%20Conftest-7c3aed)
![Evidence-first](https://img.shields.io/badge/evidence-catalog--before--stores-8957e5)
![Determinism](https://img.shields.io/badge/determinism-idempotent%20ETL-success)
![Run Manifests](https://img.shields.io/badge/audit-run__manifest%20%2B%20gate__reports-4b5563)
![OCI Artifacts](https://img.shields.io/badge/artifacts-OCI%20%7C%20ORAS%20optional-2563eb)
![Signing](https://img.shields.io/badge/signing-cosign%20%7C%20attestations-ffb703)
![Supply Chain](https://img.shields.io/badge/supply%20chain-SBOM%20%7C%20SLSA%20%7C%20signing-111827)
![Telemetry](https://img.shields.io/badge/telemetry-append--only%20NDJSON-0f766e)
![KFM Profiles](https://img.shields.io/badge/profiles-STAC%20%7C%20DCAT%20%7C%20PROV-7b42f6)
![Graph](https://img.shields.io/badge/graph-Neo4j-00c853)
![Spatial DB](https://img.shields.io/badge/spatial-PostGIS-336791)
![Search Index](https://img.shields.io/badge/search-full--text%20index%20%2B%20optional%20vectors-2563eb)
![API Stack](https://img.shields.io/badge/api-FastAPI%20%7C%20REST%20%2B%20GraphQL-0ea5e9)
![API Boundary](https://img.shields.io/badge/UI%20access-API%20only%20(no%20direct%20stores)-ff6b6b)
![UI](https://img.shields.io/badge/ui-React%20%7C%20MapLibre%20%7C%20Cesium(optional)-0ea5e9)
![LLM Runtime](https://img.shields.io/badge/llm-Ollama%20(local)-111827)
![Narrative](https://img.shields.io/badge/narrative-Story%20Nodes%20%2B%20Pulse%20Threads-f97316)
![Security](https://img.shields.io/badge/security-hostile--inputs%20%2B%20deny--by--default-red)
![Governance](https://img.shields.io/badge/governance-FAIR%20%2B%20CARE%20%2B%20Sovereignty-2ea043)

</div>

> **TL;DR:** `pipelines/` is the **portal + contract** for how KFM builds evidence.  
> The **executable pipeline code** lives in `src/pipelines/`.  
> The **publishable evidence** lives in `data/processed/**` and is not â€œrealâ€ until itâ€™s **cataloged (STAC/DCAT)** and **traceable (PROV)** â€” *then* it can power derived stores (graph / PostGIS / search index) behind the governed API boundary. ğŸ§¾âœ…

> [!IMPORTANT]
> **Prime directive:** **No catalog â†’ no derived stores (graph/index) â†’ no API â†’ no UI.**  
> Catalogs are the interface. Provenance is the receipt. ğŸ§¾âœ…

> [!IMPORTANT]
> **Second directive:** **No policy pass â†’ no merge â†’ no publish.**  
> Governance is enforced (automated + human review), not â€œbest-effort.â€ âš–ï¸ğŸ”’

> [!IMPORTANT]
> **Narrative directive:** **No narrative without evidence.**  
> Story Nodes & Pulse Threads must ship with an **evidence manifest** that points to **cataloged evidence** (STAC/DCAT/PROV) and/or stable graph IDs (that resolve back to catalogs). ğŸ—‚ï¸ğŸ“š

---

## ğŸ”— Quick links (start here) ğŸ§­
- ğŸ  Repo overview: `../README.md`
- ğŸ§© Executable boundary: `../src/README.md` *(if present)*
- ğŸ§ª Pipeline implementations: `../src/pipelines/README.md` *(if present)*
- ğŸ•¸ï¸ Graph tooling (exports/ingest): `../src/graph/README.md` *(if present)*
- ğŸšª API boundary (governed trust edge): `../src/server/README.md` *(if present)*
- ğŸ“œ API contracts (OpenAPI + GraphQL SDL): `../src/server/contracts/` *(if present)*
- âš–ï¸ Policy Pack (OPA/Rego): `../tools/validation/policy/` *(and/or `../src/server/policy/` if present)*
- ğŸ¤– AI boundary (Focus Mode service): `../src/ai/README.md` *(if present)*
- ğŸ“¦ Data + metadata boundary: `../data/README.md` *(required reading)*
- ğŸ§¾ Audits (run manifests + gate reports): `../data/audits/README.md` *(if present)*
- ğŸ“ˆ Telemetry (append-only NDJSON): `../data/telemetry/README.md` *(if present)*
- ğŸ§ª Tests & QA gates: `../tests/README.md`
- ğŸ§° Governed toolchain surface: `../tools/README.md`
- ğŸ§° Automation wrappers: `../scripts/README.md`
- ğŸ““ MCP (runs, experiments, receipts): `../mcp/README.md` *(or `../mcp/MCP-README.md` if thatâ€™s canonical)*
- ğŸ“˜ Master Guide (canonical intent + paths): `../docs/MASTER_GUIDE_v13.md` *(if present)*
- ğŸ§± Architecture & ADRs: `../docs/architecture/`
- ğŸ§¾ Governance: `../docs/governance/`
- ğŸ“ Schemas + profiles: `../schemas/` **and** `../docs/standards/`
- ğŸ§© Templates: `../docs/templates/`
- ğŸ“š Story Nodes (narrative content): `../docs/reports/story_nodes/` *(draft/published workflow)*
- ğŸ“£ Pulse Threads (rapid narrative updates): `../docs/reports/pulse_threads/` *(if present)*
- ğŸ§© Design Packs (domain blueprints): `../docs/design_packs/` *(if present)*
- ğŸŒ Web UI boundary: `../web/` *(React Â· MapLibre Â· optional Cesium)*

---

<details>
<summary><b>ğŸ§­ Table of contents</b></summary>

- [ğŸ§¾ Doc metadata](#-doc-metadata)
- [ğŸš¦ Nonâ€‘negotiables](#-non-negotiables)
- [ğŸ§  What a â€œpipelineâ€ means in KFM](#-what-a-pipeline-means-in-kfm)
- [ğŸ§­ Canonical paths & aliases](#-canonical-paths--aliases)
- [ğŸ§± The canonical ordering](#-the-canonical-ordering)
- [ğŸ” Derived stores & indexing (Neo4j + PostGIS + search)](#-derived-stores--indexing-neo4j--postgis--search)
- [ğŸ§  Pipelines as â€œcompilersâ€](#-pipelines-as-compilers)
- [ğŸ§© Pipeline taxonomy](#-pipeline-taxonomy)
- [ğŸ¤– Focus Mode & AI infrastructure (Ollama + policy gates)](#-focus-mode--ai-infrastructure-ollama--policy-gates)
- [ğŸ“£ Narrative layer: Story Nodes + Pulse Threads](#-narrative-layer-story-nodes--pulse-threads)
- [ğŸ“¦ Data & metadata lifecycle](#-data--metadata-lifecycle)
- [ğŸš€ Promotion workflow](#-promotion-workflow)
- [ğŸ§° GitOps publish boundary](#-gitops-publish-boundary)
- [ğŸ“¦ Artifact distribution: Filesystem + OCI registries](#-artifact-distribution-filesystem--oci-registries)
- [âš–ï¸ Policy-as-code](#ï¸-policy-as-code-opa--conftest)
- [ğŸ§‘â€ğŸ¤â€ğŸ§‘ Wâ€‘Pâ€‘E automation](#-wpe-automation-watcher--planner--executor)
- [ğŸ“ Where things live](#-where-things-live)
- [ğŸ§¾ Standard artifacts](#-standard-artifacts)
- [ğŸ§¾ Manifests: run_manifest + evidence_manifest](#-manifests-run_manifest--evidence_manifest)
- [ğŸ©º Derived store health checks](#-derived-store-health-checks)
- [ğŸ“œ KFM Pipeline Definition Contract](#-kfm-pipeline-definition-contract)
- [âš™ï¸ Running pipelines](#ï¸-running-pipelines)
- [âœ… Quality gates](#-quality-gates)
- [ğŸ§¾ Receipts, telemetry, and replay](#-receipts-telemetry-and-replay)
- [ğŸ” Governance & sovereignty](#-governance--sovereignty)
- [ğŸ›¡ï¸ Security & hostile inputs](#ï¸-security--hostile-inputs)
- [ğŸ”­ Performance & scaling](#-performance--scaling)
- [ğŸŒ¾ Example pipeline archetypes](#-example-pipeline-archetypes)
- [ğŸ§© Adding a new pipeline](#-adding-a-new-pipeline)
- [ğŸ§© Design Packs](#-design-packs)
- [ğŸ“š Project reference library influence map](#-project-reference-library-influence-map)
- [ğŸ§¾ Metadata](#-metadata)
- [ğŸ•°ï¸ Version history](#ï¸-version-history)
- [ğŸ“ Evidence anchors](#-evidence-anchors)

</details>

---

## ğŸ§¾ Doc metadata

| Field | Value |
|---|---|
| Doc | `pipelines/README.md` |
| Status | Active âœ… |
| Last updated | **2026-01-26** |
| Review cycle | 90 days ğŸ” |
| Audience | Contributors implementing ETL jobs, validators, catalog writers, store/index builders, graph exports/ingest bridges, narrative builders |
| Prime directive | **No catalog â†’ no derived stores (graph/index) â†’ no API â†’ no UI.** Catalogs are the interface. |
| Second directive | **No policy pass â†’ no merge â†’ no publish.** |
| Narrative directive | **No narrative without evidence** (Story Nodes + Pulse Threads require evidence manifests). |
| System mission fit | Make Kansas spatial truth **searchable, mappable, auditable, modelable** (provenance-first; AI is advisory; no black boxes) ğŸ§ ğŸ§¾ |

---

## ğŸš¦ Nonâ€‘negotiables

1) **Deterministic, idempotent ETL** ğŸ§ª  
   Same inputs + same config + same code â‡’ same outputs (stable IDs/hashes) and reruns do not corrupt or duplicate.

2) **Immutable raw is the first trust boundary** ğŸ§Š  
   `data/raw/**` is treated as **read-only evidence**. Any byte changes occur downstream in `data/work/**` or `data/processed/**` (and must be traceable).  
   *If you â€œfixed it by editing raw,â€ you broke auditability.* ğŸ§¾

3) **Contract-first** ğŸ“œ  
   Pipelines are driven by declared contracts (schemas, profiles, OpenAPI/GraphQL). Contract changes trigger compatibility checks.

4) **Catalogs are not optional** ğŸ—‚ï¸  
   Evidence is not â€œrealâ€ in KFM until it has:
   - **STAC** (assets + spatial/temporal metadata) â€” `data/stac/collections/` + `data/stac/items/`
   - **DCAT** (dataset discovery & distributions) â€” `data/catalog/dcat/`
   - **PROV** (lineage + run identity) â€” `data/prov/`

5) **Derived stores are rebuildable (never hand-edit)** ğŸ§±  
   Neo4j, PostGIS loads, and the search index are **derived** layers. They must be rebuilt from **cataloged artifacts** (and bounded ingest/export files), not manually patched.

6) **Evidence-first narrative** ğŸ“š  
   Story Nodes / Pulse Threads / Focus Mode must cite **cataloged evidence** (or stable graph IDs that resolve to cataloged evidence).  
   If AI helps generate text: label it, attach provenance, and include confidence/uncertainty where applicable.

7) **API boundary rule** ğŸ›¡ï¸  
   The UI must **never** query Neo4j/PostGIS/index directly; all access goes through governed APIs (contracts + redaction).

8) **Governed ordering is sacred** ğŸ§±  
   **ETL â†’ STAC/DCAT/PROV â†’ Derived stores â†’ API â†’ UI â†’ Story Nodes + Pulse Threads â†’ Focus Mode**

9) **Stable identifiers (no semantic IDs)** ğŸ§·  
   IDs must be **information-free** and invariant over time (donâ€™t encode meaning that will drift). Prefer UUID/ULID + metadata.  
   *If it â€œneeds renaming,â€ it wasnâ€™t a stable ID.* ğŸ§ 

10) **Policy-as-code gating (fail closed)** âš–ï¸ğŸ”’  
   Governance rules are enforced automatically (OPA/Rego + Conftest is the default posture). If a policy canâ€™t be evaluated, default is **deny**.

11) **Run manifests are required for publish** ğŸ§¾  
   Every publish produces a machine-readable **run manifest** (what ran, what changed, what passed/failed, what got signed, where it got distributed).

12) **GitOps & auditable publishing** ğŸ§¾ğŸ”  
   â€œPublishedâ€ means: validated artifacts + catalogs + provenance + policy report + review trail (PR/approvals).  
   *If it didnâ€™t go through review, itâ€™s not production evidence.*

> [!TIP]
> If your pipeline canâ€™t produce a clean paper trail (inputs â†’ transforms â†’ outputs â†’ catalogs â†’ lineage â†’ gates â†’ signatures), itâ€™s not ready to merge. âœ…ğŸ§¾

---

## ğŸ§  What a â€œpipelineâ€ means in KFM

A KFM pipeline is a **replayable builder** that produces (at minimum):

- ğŸ“ **Source manifests** â†’ `data/sources/**` *(where the data came from, rights, sensitivity; pointer-over-payload)*
- ğŸ“¦ **Evidence artifacts** â†’ `data/processed/**` *(COG, GeoParquet, CSV, tiles, thumbnails, reports, model artifacts, etc.)*
- ğŸ—‚ï¸ **Catalog artifacts** â†’ `data/stac/**` + `data/catalog/dcat/**`
- ğŸ§¬ **Lineage artifacts** â†’ `data/prov/**` *(W3C PROV JSONâ€‘LD recommended)*
- ğŸ§¾ **Audit artifacts** â†’ `data/audits/**` *(run manifests + deterministic gate reports)*
- ğŸ§· **Integrity artifacts** â†’ manifests, checksums, inventories
- ğŸ§ª **Gate artifacts** â†’ schema reports, policy reports, link-check reports *(deterministic + storable)*
- ğŸ“ˆ **Telemetry artifacts** â†’ append-only NDJSON summaries *(location configurable; linkable to run_id)*

Optionally (but commonly), a pipeline also emits **bounded ingest payloads** for derived stores:

- ğŸ•¸ï¸ **Graph exchange artifacts** â†’ `data/graph/csv/**` *(or `data/graph/cypher/**` optional)*
- ğŸ—„ï¸ **PostGIS load artifacts** â†’ `data/db/postgis/**` *(recommended pattern; repo may vary)*
- ğŸ” **Search index docs + mappings** â†’ `data/index/search/**` *(recommended pattern; repo may vary)*

> [!IMPORTANT]
> Pipelines do **not** â€œsecretly update the stores.â€  
> Derived stores ingest **from catalogs** (and/or explicit bounded ingest artifacts) via controlled paths.

---

## ğŸ§­ Canonical paths & aliases

KFM has a few â€œnames youâ€™ll see in old notes.â€ Hereâ€™s the **current canonical set**:

| Concept | Canonical path âœ… | Common aliases you may see âš ï¸ |
|---|---|---|
| Source manifests | `data/sources/**` | *(varies)* |
| Raw drops | `data/raw/**` | *(same)* |
| Work / intermediate | `data/work/**` | *(same)* |
| Processed evidence | `data/processed/**` | *(same)* |
| STAC catalogs | `data/stac/collections/**` + `data/stac/items/**` | `data/stac/**` *(loose)*, `data/catalog/**` *(older drafts)* |
| DCAT catalogs | `data/catalog/dcat/**` | `data/catalogs/**`, `data/catalog/**` |
| Provenance | `data/prov/**` | `data/provenance/**` |
| Audit run manifests | `data/audits/**` | `data/runs/**`, `mcp/runs/**` *(context-dependent)* |
| Telemetry logs | `data/telemetry/**` | `logs/**`, `observability/**` |
| Graph exchange | `data/graph/csv/**` | `data/neo4j/**` *(older notes)* |
| Index exchange (recommended) | `data/index/**` | `data/search/**`, `data/indexes/**` |
| API implementation | `src/server/**` | `api/**` *(sometimes only docs/gateway)* |
| UI implementation | `web/**` | `frontend/**` |

> [!NOTE]
> When in doubt: follow **Master Guide v13** canonical paths. Older spellings should be treated as legacy aliases.

---

## ğŸ§± The canonical ordering

> [!IMPORTANT]
> This is a governance boundary, not a preference.

```mermaid
flowchart LR
  A["ğŸ§ª ETL + Normalization"] --> B["ğŸ—‚ï¸ STAC/DCAT/PROV Catalogs"]
  B --> C["ğŸ§© Derived stores (bounded ingest)\nNeo4j + PostGIS + Search Index"]
  C --> D["ğŸ›¡ï¸ APIs (contracts + redaction)"]
  D --> E["ğŸ—ºï¸ Web UI (React Â· MapLibre Â· optional Cesium)"]
  E --> F["ğŸ“š Story Nodes + ğŸ“£ Pulse Threads"]
  F --> G["ğŸ¯ Focus Mode (context + evidence bundle)"]
```

> [!NOTE]
> The Master Guide often shorthandâ€™s â€œDerived storesâ€ as â€œNeo4j graph,â€ but the **API may also query PostGIS and the search index**.  
> The invariant is: **catalogs are produced first** and **all stores are built from cataloged truth**, not raw guesses. ğŸ§¾

---

## ğŸ” Derived stores & indexing (Neo4j + PostGIS + search)

KFM uses a **â€œstorage trioâ€** pattern behind the API boundary:

### ğŸ—„ï¸ PostGIS (spatial-first)
- Efficient spatial queries, joins, aggregations, and raster/vector operations
- Good for â€œmap features by bbox/time,â€ â€œbuffer/intersect,â€ â€œgroup-by,â€ and analytics that are safer in SQL
- Pipelines should treat PostGIS loads as **rebuildable** and record:
  - table/schema targets
  - load method (COPY/ogr2ogr/etc.)
  - row counts + spatial bounds + indexes created
  - provenance pointer back to STAC/DCAT/PROV

### ğŸ•¸ï¸ Neo4j (relationship-first)
- Represents **entities, events, documents, places, and their relationships**
- Should store **references/pointers** to catalogs (STAC/DCAT IDs, PROV activity IDs), not bulky payloads
- Ontology posture: stable labels/relationships; migrations required for breaking changes  
  *(CIDOCâ€‘CRM mappings are encouraged for cultural heritage entities when relevant.)* ğŸ›ï¸

### ğŸ” Search index (discovery-first)
- Full-text search over:
  - DCAT dataset metadata (title, keywords, themes)
  - extracted text corpora (documents, OCR outputs, transcripts)
  - optional embedding/vector retrieval for Focus Mode
- Pipelines should build search docs **from cataloged artifacts** and emit:
  - index mappings (schema)
  - an index build manifest (counts, hashes, run_id)
  - a policy-sanitized â€œpublic vs restrictedâ€ split (never index forbidden fields)

> [!IMPORTANT]
> The stores are **implementation details** behind the API boundary.  
> The **catalog triplet (STAC/DCAT/PROV)** remains the contract surface and the audit anchor. ğŸ§¾âœ…

---

## ğŸ§  Pipelines as â€œcompilersâ€

A helpful mental model: **pipelines behave like compilers** â€” inputs go through phases, and each phase has gates.  
This keeps the system honest: â€œbuild stepsâ€ are explicit, testable, and replayable. ğŸ§±

| Compiler concept ğŸ§© | Pipeline analogue ğŸ§¬ | What we enforce âœ… |
|---|---|---|
| Lexing/parsing | ingest + schema parse | reject malformed inputs early |
| Type checking | semantic validation | CRS, geometry validity, ranges, licensing |
| IR transforms | normalization | canonical encodings + stable sort order |
| Linking | catalog linkage | STAC â†” DCAT â†” PROV cross-refs present |
| Linting | policy checks | OPA/Rego denies block publish |
| Codegen | artifacts + catalogs | COG/Parquet + STAC/DCAT + PROV receipts |
| Packaging | distribution | file paths **and/or** OCI artifact packaging + signing |
| Indexing | derived stores | Neo4j/PostGIS/search builds are reproducible + bounded |
| Optimization | scaling tactics | tiling, partitioning, caching, indexing |
| Error reporting | receipts & logs | actionable failures + correlation IDs |

> [!NOTE]
> A pipeline that â€œkind of worksâ€ but canâ€™t explain itself is a governance bug, not a feature. ğŸ§¾

---

## ğŸ§© Pipeline taxonomy

Not all pipelines look the same. KFM supports a few **governed shapes**:

| Type | When to use | Key rule ğŸ”‘ |
|---|---|---|
| ğŸ§± **Build (batch)** | One-time or periodic creation of a dataset | Deterministic + cataloged + provâ€™d before use |
| ğŸ” **Refresh (scheduled)** | Regular updates (daily/weekly/monthly) | Idempotent; versioned outputs; diffs inspectable |
| ğŸ‘€ **Watcher (nearâ€‘realâ€‘time)** | Polling/streaming feeds (e.g., GTFSâ€‘RT) | Each window produces catalogable â€œunitsâ€ + receipts |
| ğŸ”Œ **Adapter (import bridge)** | External exports (partner datasets, agency drops) | Validate schema/license/classification before promotion |
| ğŸ§ª **Analysis/Model** | Derived indicators, Bayesian inference, simulation runs | Record params/seeds; output uncertainty + diagnostics |
| ğŸ§® **Optimization** | Multi-constraint optimization runs | Record objective/constraints; deterministic run IDs |
| ğŸ•¸ï¸ **Graph build/export** | Build bounded graph exports from catalogs | Edges reference catalog IDs + provenance IDs |
| ğŸ—„ï¸ **PostGIS loader** | Populate PostGIS from cataloged evidence | Load is reproducible; never a â€œmanual hotfixâ€ |
| ğŸ” **Search index builder** | Publish metadata + doc corpora into search | Public/restricted indexing is policy-gated |
| ğŸ“„ **Document ingest** | PDFs/scans â†’ extracted text/entities | Store raw + derived; provenance + redaction rules required |
| ğŸ§Š **3D/volumetric** | 3D meshes, point clouds, 3D tiles | Coordinate conventions + LOD/tiling + validation gates |
| ğŸ§³ **Offline pack builder** | Field/classroom bundles | Packs embed manifests + catalog pointers + license bundle |
| ğŸ“£ **Pulse Thread generator** | Rapid narrative updates from evidence | Must ship evidence_manifest; review path required |
| ğŸ§  **Pattern detector** | Detects narrative-worthy shifts (EWMA/CUSUM/threshold) | Produces alert artifacts; never â€œpublishes silentlyâ€ |
| ğŸ©º **Derived-store health check** | Integrity + drift checks (graph/DB/index) | Emits reports; triggers Wâ€‘Pâ€‘E (PR) on anomalies |
| ğŸ§© **Design Pack builder** | Create repeatable domain blueprints | Packs are versioned specs; used to scaffold pipelines |

> [!NOTE]
> Watchers (and narrative generators) are still bound by ordering: **they produce cataloged outputs first**, then store/API/UI consumption follows.

---

## ğŸ¤– Focus Mode & AI infrastructure (Ollama + policy gates)

KFM AI is **advisory-only** and **evidence-bound**. Focus Mode does not â€œinventâ€ truth â€” it composes answers **from governed evidence**. ğŸ§­ğŸ¤–

### ğŸ§© Architecture snapshot (high level)
- UI captures: question + map context (location, layers, time)
- Backend AI service performs retrieval:
  - Neo4j (relationships)
  - Search index (documents/full-text; optionally embeddings)
  - Catalog lookups (STAC/DCAT/PROV metadata)
- LLM composes answer **with citations**
- Output is policy-validated (OPA) **before** returning to UI
- All Q&A emits receipts (audit + provenance pointers)

### ğŸ›¡ï¸ â€œPrompt gatewayâ€ posture (deny-by-default)
- sanitize incoming prompts (treat user text as hostile input)
- strip or quarantine instructions that attempt to override policy (â€œignore system rulesâ€¦â€, etc.)
- enforce:
  - tool allowlists (if any tool calling exists)
  - model allowlists + pinned versions/digests
  - output schema (structured response preferred)
  - cite-or-refuse rule (no citations â†’ deny)

### ğŸ§¾ AI answer receipts (required for anything user-visible)
At minimum, a Focus Mode answer should be linkable to:
- `run_id` (or `answer_id`)
- model name + version/digest
- retrieval set (catalog IDs + graph IDs + doc IDs)
- OPA decision ID + policy bundle hash/version
- rendered answer + citations (machine-readable list)

> [!IMPORTANT]
> Focus Mode answers are treated like â€œevidence outputsâ€ when persisted: they must be **traceable**, **policy-gated**, and **clearly labeled** as AI-assisted.

---

## ğŸ“£ Narrative layer: Story Nodes + Pulse Threads

KFM treats narrative as **governed content**, not â€œfreeform text.â€ ğŸ“šğŸ”’

### ğŸ“š Story Nodes (curated narrative)
- Long-form, structured narrative tied to map state (layers + camera + timeline)
- Must include citations to cataloged evidence (and/or stable graph IDs that resolve to evidence)
- Has draft/published workflow; Focus Mode shows **published** only

**Recommended Story Node folder shape (v13-style):**
```text
docs/reports/story_nodes/
  â”œâ”€ draft/
  â”‚   â””â”€ <story_id>/
  â”‚      â”œâ”€ story.md                # governed narrative markdown (template-based)
  â”‚      â”œâ”€ story.json              # map/timeline script (camera, layers, steps)
  â”‚      â”œâ”€ evidence_manifest.yml   # machine-checkable claimâ†’evidence map
  â”‚      â””â”€ assets/                 # images, figures (with captions/alt text)
  â””â”€ published/
      â””â”€ <story_id>/...
```

### ğŸ“£ Pulse Threads (rapid narrative updates)
Pulse Threads are short, time-aware narrative updates linked to place/time + evidence.  
They are ideal for â€œwhat changed?â€ moments (new dataset drop, anomaly detection, model update, hazard refresh).

**Key rules:**
- Must include an **evidence manifest** (see below) pointing to catalog IDs
- Must be labeled **human-authored** vs **AI-suggested** (opt-in for AI content)
- Must respect sovereignty + sensitivity (no location side-channels)

### ğŸ§  Conceptual Attention Nodes (concept taxonomy)
Concept nodes (e.g., â€œdroughtâ€, â€œrailroad expansionâ€, â€œbiodiversityâ€) provide:
- consistent tagging across datasets, graph entities, Story Nodes, Pulse Threads
- transparent â€œwhy did the AI show this?â€ anchors (Focus Mode auditability)
- federation-friendly mapping across jurisdictions (shared concept IDs)

### â™¿ Accessibility & UX (non-optional for published narrative)
- captions/alt text for assets
- readable map symbology + legends
- keyboard navigation + focus states in UI where applicable
- avoid color-only encoding for critical meaning

> [!TIP]
> Narrative is *also data* in KFM: it must be searchable, auditable, and cross-referenced. ğŸ§¾âœ…

---

## ğŸ“¦ Data & metadata lifecycle

KFM uses a required staging lifecycle so everyone can tell â€œwhat stage is this file in?â€ at a glance:

### ğŸ“ Source manifests (pointer-over-payload)
- `data/sources/<domain>/<dataset>/source.json` â†’ where it came from, license, sensitivity, checksums/URLs *(best-effort)*  
  Think: **intent + rights + risk**.

### ğŸ“¥ Data stages
- `data/raw/<domain>/...` â†’ raw source drops *(read-only mindset)*
- `data/work/<domain>/...` â†’ intermediate transforms *(ok to delete/regenerate)*
- `data/processed/<domain>/...` â†’ final evidence artifacts *(publishable)*

### ğŸ—‚ï¸ Catalog + provenance stages (required before downstream use)
- `data/stac/collections/` + `data/stac/items/` â†’ STAC collections/items (assets + metadata)
- `data/catalog/dcat/` â†’ DCAT datasets/distributions (discovery)
- `data/prov/` â†’ PROV bundles (run + dataset lineage)

### ğŸ§¾ Audit + telemetry stages (required for publish)
- `data/audits/<run_id>/run_manifest.json` â†’ canonical run record (what ran, inputs, outputs, digests)
- `data/audits/<run_id>/gates/**` â†’ deterministic gate artifacts (schema/policy/link checks)
- `data/telemetry/**` â†’ append-only NDJSON summaries keyed by run_id *(location/configurable)*

### ğŸ§© Derived store exchange stages (recommended; bounded)
- `data/graph/csv/` â†’ bounded import/export CSVs (bulk ingest friendly)
- `data/graph/cypher/` *(optional)* â†’ bounded Cypher scripts for controlled ingest
- `data/db/postgis/` *(recommended)* â†’ load scripts/manifests (COPY/DDL + checks)
- `data/index/search/` *(recommended)* â†’ mappings + doc exports + build manifests

### ğŸ§³ Offline pack stages (optional, but governed)
- `data/packs/<pack_id>/` â†’ a self-contained â€œevidence bundleâ€ *(tiles + indexes + manifests + README + licenses)*

---

## ğŸš€ Promotion workflow

A pipeline output is either **not yet trustworthy**, or **published as governed evidence**.

### âœ… Promotion states (recommended)

| State | Location | Who can use it? | Required artifacts |
|---|---|---|---|
| ğŸŸ¡ `candidate` | `data/work/**` | pipeline devs only | none (but logs helpful) |
| ğŸŸ  `staged` | `data/processed/**` | reviewers + QA | checksums + basic gates |
| ğŸŸ¢ `published` | `data/processed/**` + catalogs + audits | everyone downstream | **STAC + DCAT + PROV + run_manifest + policy pass** |

### ğŸ” Promotion rules (fail closed ğŸ”’)
- **No publish without license + classification.**
- **No publish without PROV lineage** (inputs + run config + output IDs).
- **No publish without STAC/DCAT** for anything user-visible.
- **No publish without run manifest + gate reports** (schema + policy).
- **No publish if classification would downgrade** (unless audited redaction step exists).
- **No publish if policy checks cannot run** (missing policies/inputs = deny).
- **No derived-store â€œproduction ingestâ€ from non-published evidence** *(dev/stage exceptions must be explicit and labeled)*.

```mermaid
flowchart TB
  C["ğŸŸ¡ candidate\n(data/work)"] -->|gates pass| S["ğŸŸ  staged\n(data/processed)"]
  S -->|catalog+prov+audit+policy emitted| P["ğŸŸ¢ published\n(STAC/DCAT/PROV + run_manifest + policy pass)"]
  P -->|bounded ingest| D["ğŸ§© derived stores\n(Neo4j/PostGIS/Search)"]
  S -->|gates fail| F["ğŸ›‘ fail closed\n(receipt + fixes)"]
```

> [!TIP]
> Think â€œ**atomic publish**â€: write new outputs to a run-scoped directory â†’ validate â†’ promote/swap pointer â†’ emit catalogs â†’ emit audits â†’ declare published. âœ…

---

## ğŸ§° GitOps publish boundary

KFM treats the repo + CI as part of the pipeline boundary:

- PRs are the default â€œchange envelopeâ€ for **datasets, catalogs, policies, narrative, and pipeline code**
- CI runs **data QA + schema validation + policy pack + narrative lint + doc protocol checks**
- Merge (or signed release) is what *turns a candidate into published evidence*

```mermaid
flowchart LR
  A["PR opened ğŸ§¾\n(dataset/code/catalog/narrative)"] --> B["CI: Detect â†’ Validate âš™ï¸"]
  B -->|policy deny| X["âŒ Block\n(fail closed)"]
  B -->|all pass| C["Review âœ…\n(human + council as needed)"]
  C --> D["Merge/Release ğŸŸ¢\n(Publish)"]
  D --> E["Deploy/Sync ğŸ”\n(services + catalogs + store ingests)"]
```

> [!NOTE]
> GitOps becomes provenance: run manifests and PROV bundles should record git SHA and (when available) PR/review references. ğŸ§¾ğŸ”

---

## ğŸ“¦ Artifact distribution: Filesystem + OCI registries

KFMâ€™s default posture is **pointer-over-payload**: catalogs point to evidence assets wherever they live. ğŸ”—ğŸ—‚ï¸

### âœ… Distribution modes
1) **Filesystem / object storage paths (default)**  
   - STAC assets reference `href` paths (local, S3, HTTPS, etc.)
   - DCAT distributions reference download/service endpoints

2) **OCI registry distribution (optional, advanced)** ğŸ“¦ğŸ³  
   For reproducible distribution and strong supply-chain posture, datasets can be packaged as OCI artifacts:
   - push evidence + catalogs + provenance as an OCI artifact
   - sign with cosign / attach attestations (SBOM, provenance, gate reports)
   - reference the OCI artifact from DCAT `distribution` (and/or STAC links)

3) **Citable release identifiers (optional, roadmap-friendly)** ğŸ”–  
   For externally referenced â€œeditionsâ€ of datasets:
   - include stable identifiers (e.g., DOI/URN) in DCAT `identifier`
   - ensure identifier resolves to the signed release manifest (and catalogs)

```mermaid
flowchart LR
  A["ğŸ“¦ data/processed"] --> B["ğŸ—‚ï¸ STAC/DCAT/PROV"]
  B --> C["ğŸ§¾ run_manifest + gate reports"]
  C --> D["ğŸ” sign + attest (optional)"]
  D --> E["ğŸ“¦ OCI registry (optional)"]
  B --> F["ğŸ§© bounded ingests\n(Neo4j/PostGIS/Search)"]
  F --> G["ğŸ›¡ï¸ API â†’ ğŸ—ºï¸ UI â†’ ğŸ“š narrative â†’ ğŸ¯ Focus Mode"]
```

> [!IMPORTANT]
> OCI is a *distribution enhancement*, not a bypass.  
> **The ordering stays the same:** evidence â†’ catalogs/prov â†’ audits â†’ (optional packaging/signing) â†’ derived stores â†’ downstream.

---

## âš–ï¸ Policy-as-code (OPA + Conftest)

KFM governance rules should be executable:

- **OPA/Rego** encodes rules (license required, classification propagation, cite-or-refuse for AI outputs, no direct-store UI access, etc.)
- **Conftest** runs those rules in CI and produces actionable failures (rule IDs + messages)
- Policy checks are just another ring in the quality gates (and must be replayable)

**Recommended homes (common patterns):**
- `tools/validation/policy/*.rego` *(policy source)*
- `src/server/policy/` *(runtime policy bundles / adapters, if used)*
- `src/server/contracts/` *(OpenAPI + GraphQL schemas as contracts)*

### ğŸ§© Example policy (pattern): â€œAI responses must include citationsâ€
```rego
package kfm.ai

default allow = false

allow {
  input.response.citations
  count(input.response.citations) > 0
}
```

> [!TIP]
> Treat policy failures like compiler errors: fix the input until it compiles. ğŸ§©âš–ï¸

---

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Wâ€‘Pâ€‘E automation (Watcher Â· Planner Â· Executor)

Some KFM maintenance can be automated â€” but only with guardrails:

- ğŸ‘€ **Watcher** detects events (new upstream data drop, broken link, schema drift, policy warning, derived-store drift, graph/index health anomaly)
- ğŸ§  **Planner** drafts a plan **under policy constraints**
- ğŸ› ï¸ **Executor** performs the work by opening a PR (and never bypasses CI/policy)

**Rule of thumb:** automation must still produce **the same artifacts humans do**  
(manifests â†’ processed â†’ catalogs â†’ provenance â†’ audits â†’ policy pass â†’ PR trail). ğŸ§¾âœ…

---

## ğŸ“ Where things live

### ğŸ§­ Repo context (target shape)
```text
ğŸ“ pipelines/                 # ğŸ“ this folder (portal + conventions; not executable code)
ğŸ“ src/                       # ğŸ§© executable source code
â”‚  â”œâ”€â”€ ğŸ“ pipelines/          # ğŸ§ª ETL jobs + catalog writers + validators
â”‚  â”œâ”€â”€ ğŸ“ graph/              # ğŸ•¸ï¸ graph export/ingest tooling (from catalogs)
â”‚  â”œâ”€â”€ ğŸ“ server/             # ğŸ›¡ï¸ APIs (FastAPI; REST + GraphQL; contracts + redaction)
â”‚  â”‚   â””â”€â”€ ğŸ“ contracts/      # ğŸ“œ OpenAPI + GraphQL SDL (contract-first)
â”‚  â””â”€â”€ ğŸ“ ai/                 # ğŸ¤– AI services (Focus Mode; advisory-only; citation gates)
ğŸ“ data/                      # ğŸ“¦ sources â†’ raw â†’ work â†’ processed + catalogs + audits + exchange payloads
â”‚  â”œâ”€â”€ ğŸ“ sources/            # ğŸ“ source manifests (rights + sensitivity + pointers)
â”‚  â”œâ”€â”€ ğŸ“ raw/                # ğŸ“¥ raw drops (immutable evidence)
â”‚  â”œâ”€â”€ ğŸ“ work/               # ğŸ§ª intermediates
â”‚  â”œâ”€â”€ ğŸ“ processed/          # ğŸ“¦ publishable evidence artifacts
â”‚  â”œâ”€â”€ ğŸ“ stac/               # ğŸ—‚ï¸ STAC catalogs (collections/ + items/)
â”‚  â”œâ”€â”€ ğŸ“ catalog/dcat/       # ğŸ—‚ï¸ DCAT catalogs
â”‚  â”œâ”€â”€ ğŸ“ prov/               # ğŸ§¬ provenance
â”‚  â”œâ”€â”€ ğŸ“ audits/             # ğŸ§¾ run_manifest + deterministic gate reports
â”‚  â”œâ”€â”€ ğŸ“ telemetry/          # ğŸ“ˆ append-only NDJSON summaries (optional)
â”‚  â”œâ”€â”€ ğŸ“ graph/csv/          # ğŸ•¸ï¸ bounded CSV exports/imports
â”‚  â”œâ”€â”€ ğŸ“ index/search/       # ğŸ” search docs/mappings/manifests (recommended)
â”‚  â””â”€â”€ ğŸ“ packs/              # ğŸ§³ offline packs (optional)
ğŸ“ schemas/                   # ğŸ“ JSON Schemas (contracts)
ğŸ“ docs/                      # ğŸ“˜ governed documentation (templates, standards, governance)
â”‚  â”œâ”€â”€ ğŸ“ reports/story_nodes/   # ğŸ“š curated narrative (draft/published)
â”‚  â”œâ”€â”€ ğŸ“ reports/pulse_threads/ # ğŸ“£ rapid narrative updates (optional)
â”‚  â””â”€â”€ ğŸ“ design_packs/          # ğŸ§© domain blueprints (optional)
ğŸ“ tools/                     # ğŸ§° validators, QA tools, deterministic entrypoints
ğŸ“ scripts/                   # ğŸ§° orchestration wrappers (call tools/src)
ğŸ“ tests/                     # âœ… automated tests (unit/integration/e2e)
ğŸ“ web/                       # ğŸŒ UI (React + MapLibre + optional Cesium)
ğŸ“ releases/                  # ğŸ“¦ packaged releases (manifest + SBOM + attestations)
ğŸ“ .github/                   # ğŸ¤ CI/CD, policies, automation
```

### ğŸ§± Clean architecture lens (conceptual)
Even if folders donâ€™t literally match these names, the **layering concept** matters:

- **Domain**: schemas + core entities (contracts, invariants)
- **Application**: use-cases (pipelines, validators, ingestion orchestration)
- **Infrastructure**: storage drivers (PostGIS/Neo4j/search adapters), external APIs
- **Interfaces**: API controllers/resolvers, CLI entrypoints, UI

> [!NOTE]
> Keep â€œgoverned boundariesâ€ clean: catalogs/prov/audits sit between raw computation and user-facing surfaces. ğŸ§¾âœ…

---

## ğŸ§¾ Standard artifacts

KFM evidence is **pointer-over-payload** whenever possible: catalogs + IDs + signed URLs/paths  
(instead of dumping giant blobs into API/UI). ğŸ”—ğŸ—‚ï¸

### âœ… Minimum publishable artifact set (KFM standard)
For any dataset intended for search/map/story/focus:

1) **Source manifests** in `data/sources/**`
   - origin, license, sensitivity/classification, access pointers
   - (optional) checksums for remote sources

2) **Evidence artifacts** in `data/processed/**`
   - preferred geo formats: **COG**, **GeoParquet**, **PMTiles** *(as needed)*
   - optional: thumbnails/quicklooks (small, cacheable)
   - optional: 3D Tiles / glTF assets (for 3D domains)

3) **Catalog artifacts**
   - **STAC** items/collections that reference the evidence assets
   - **DCAT** dataset + distributions for discovery

4) **Lineage artifacts**
   - **PROV** bundle: inputs â†’ activities â†’ outputs
   - includes run identity, config hash, git SHA *(where available)*

5) **Audit + gate artifacts**
   - **run_manifest.json** (canonical run record)
   - checksums manifest (sha256 preferred)
   - schema validation reports (machine-readable)
   - policy report (OPA/Conftest output, machine-readable)
   - optional: inventory (file sizes + media types)
   - optional: energy/sustainability report for heavy runs ğŸŒ±

6) **Derived-store exchange artifacts (only when needed)**
   - Neo4j: bounded CSV export/import in `data/graph/csv/**`
   - PostGIS: bounded load scripts + manifests in `data/db/postgis/**` *(recommended)*
   - Search: docs + mappings + build manifest in `data/index/search/**` *(recommended)*

7) **Narrative artifacts (when producing Story Nodes / Pulse Threads)**
   - `story.md` / `pulse.md` plus `evidence_manifest.yml` *(see below)*
   - map-state config (Story Nodes): `story.json` *(recommended)*
   - stable IDs / concept tags / sensitivity flags

8) **AI receipts (when Focus Mode content is persisted or used operationally)**
   - answer ID + model version/digest
   - retrieval set (catalog IDs + graph IDs + doc IDs)
   - policy decision logs (OPA decision IDs + bundle hash)
   - classification/sensitivity posture for the output (labels)

9) **Safety artifacts (when shipping containers/releases)**
   - SBOM (software bill of materials)
   - signed images/artifacts + attestations *(SLSA-like posture)*

> [!NOTE]
> Quicklooks are UX helpers. The authoritative truth is the evidence artifact + catalog metadata. ğŸ—‚ï¸âœ…

---

## ğŸ§¾ Manifests: run_manifest + evidence_manifest

Manifests are the â€œreceipts you can compile.â€ ğŸ§¾ğŸ§©  
Theyâ€™re designed to let CI, reviewers, and future-you answer:

- **What ran?**
- **With what inputs/config?**
- **What outputs were produced, cataloged, indexed, and signed?**
- **What gates passed/failed?**
- **What narrative content was generated and what evidence supports it?**

### ğŸ§¾ `run_manifest.json` (required for publish)
**Recommended home:** `data/audits/<RUN-ID>/run_manifest.json`

**Recommended contents (minimum):**
- `run_id`, `pipeline_id`, `env`, `git_sha`
- `config_hash`, `idempotency_key`
- `inputs[]` (source refs + checksums/ETags when feasible)
- `outputs[]` (paths + hashes + dataset IDs)
- `catalog_refs` (STAC/DCAT/PROV IDs/paths)
- `gate_reports[]` (schema/policy/link checks)
- `policy_bundle` *(recommended)*: bundle version/hash, decision IDs
- `store_ingests[]` *(recommended when used)*: graph/postgis/search build summaries
- `signatures[]` *(optional)* (cosign refs, attestations, SBOM)
- `distribution[]` *(optional)* (OCI refs, object store URLs, DOI/URN identifiers)

> [!TIP]
> Keep it deterministic: if the pipeline is replayed with identical inputs/config, the manifest should be materially identical (except for timestamps). â±ï¸âœ…

### ğŸ“š `evidence_manifest.yml` (required for Story Nodes & Pulse Threads)
**Recommended homes:**
- Story Nodes: `docs/reports/story_nodes/<draft|published>/<story_id>/evidence_manifest.yml`
- Pulse Threads: `docs/reports/pulse_threads/<draft|published>/<pulse_id>/evidence_manifest.yml`

**Recommended contents (minimum):**
- `content_id`, `type: story_node|pulse_thread`, `version`
- `claims[]` (each claim has at least one evidence reference)
- `evidence[]` (STAC/DCAT/PROV IDs, graph IDs, external sources that are themselves cataloged)
- `concept_tags[]` (Conceptual Attention Node IDs)
- `sensitivity` (flags and redaction/generalization notes)
- `ai_assistance` (true/false + model/run refs + confidence)

> [!IMPORTANT]
> Evidence manifests do **not** replace citationsâ€”they make them enforceable and machine-checkable. ğŸ§¾âœ…

---

## ğŸ©º Derived store health checks

The stores are derived layers. They must stay healthy. ğŸ§©ğŸ©º

### âœ… Weekly (recommended) health check job
A scheduled â€œstore healthâ€ pipeline should emit:
- Neo4j: constraints/index status, node/edge deltas, orphan detection (missing catalog/prov refs)
- PostGIS: schema drift, table row deltas, spatial index checks, bounds sanity
- Search index: mapping drift, doc count deltas, forbidden-field detection, stale doc cleanup
- lag detection (catalog published but store not updated)
- policy posture drift (new denies, missing rules, failing checks)

**Recommended outputs:**
- `data/audits/store-health/<YYYY-MM-DD>/report.json`
- `data/audits/store-health/<YYYY-MM-DD>/report.md` *(review-friendly summary)*

**Recommended behavior:**
- health check failures open a PR (Wâ€‘Pâ€‘E Executor) with:
  - the report artifacts
  - proposed fixes (ingest rerun, reindex, migrations, etc.)
  - explicit human review requirements when sensitive

---

## ğŸ“œ KFM Pipeline Definition Contract

KFM pipelines are contract-first. A pipeline should have a machine-readable contract file (recommended: `pipeline.yml`)
that explains **what it reads, what it writes, and what it guarantees**.

### âœ… Minimum contract fields (recommended)
- `id` (stable, versioned; do not encode secrets)
- `name`, `description`, `owner`
- `sources` (source manifest refs; rights + sensitivity posture)
- `inputs` (sources, paths, checksums/ETags when feasible)
- `outputs` (paths + formats + dataset IDs)
- `catalogs` (STAC/DCAT targets; collections/items/datasets)
- `provenance` (how run_id/config hash is captured)
- `audits` (run_manifest location; gate report locations)
- `gates` (schema/bounds/link/license/classification/policy checks)
- `determinism` (stable sorting, seed strategy, idempotency key)
- `classification` + `license` rules (deny-by-default on unknowns)
- `policy` (which bundles/rulesets must pass)
- `stores` *(recommended)*: how derived stores are built (Neo4j/PostGIS/search), bounded artifact paths
- `network` posture (deny-by-default; allowlist & logging if enabled)
- `distribution` *(optional)* (OCI registry packaging + signing requirements)
- `identifiers` *(optional)* (DOI/URN/content-addressed digests)
- `narrative` *(optional)* (Story Node/Pulse Thread outputs + evidence manifest rules)
- `ai` *(optional)* (model allowlist, prompt gateway rules, cite-or-refuse gates)
- `concept_tags` *(optional)* (Conceptual Attention Node IDs used)
- `resources` *(optional)* (memory/CPU hints; chunking strategy)
- `retention` *(optional)* (how long intermediate artifacts persist)
- `privacy` *(optional)* (PII checks; redaction/generalization rules)
- `offline_packs` *(optional)* (pack output + manifest rules)

### ğŸ§© Example `pipeline.yml` (starter template)
```yaml
id: "kfm.hydrology.watersheds.v1"
name: "Hydrology Watersheds Builder"
owner: "@kfm-engineering"
description: "Derives watershed boundaries + flow products from DEM inputs and publishes map-ready layers."

envs: ["dev", "stage", "prod"]

sources:
  - ref: "data/sources/elevation/3dep/source.json"
    notes: "Rights + sensitivity are enforced from source.json into catalogs and APIs."

inputs:
  - id: "kfm.elevation.dem.3dep.v1"
    stage: "raw"
    paths:
      - "data/raw/elevation/3dep/**"
    license: "public-domain-or-provider-license"
    classification: "public"

outputs:
  stage: "processed"
  datasets:
    - id: "kfm.hydrology.watersheds.v1"
      paths:
        - "data/processed/hydrology/watersheds/**"
      formats: ["COG", "GeoParquet", "PMTiles"]
      classification: "public"
      license: "CC-BY-4.0"

catalogs:
  stac_root: "data/stac"
  stac_collections: "data/stac/collections"
  stac_items: "data/stac/items"
  dcat_root: "data/catalog/dcat"
  collections:
    - "kfm.hydrology"
  items:
    strategy: "one item per logical unit (tile/county/basin)"
  dcat:
    dataset_id: "kfm.hydrology.watersheds.v1"

provenance:
  prov_root: "data/prov"
  run_id_env: "KFM_RUN_ID"
  config_hash: "sha256(pipeline.yml + config/<env>.yml)"
  record_git_sha: true
  record_seeds: true

audits:
  audits_root: "data/audits"
  run_manifest: "data/audits/${KFM_RUN_ID}/run_manifest.json"
  gate_reports_root: "data/audits/${KFM_RUN_ID}/gates"

gates:
  - "schema_required"
  - "crs_required"
  - "geometry_valid"
  - "bounds_sane"
  - "license_required"
  - "classification_no_downgrade"
  - "stac_schema"
  - "dcat_schema"
  - "prov_bundle_present"
  - "run_manifest_present"
  - "policy_pack_pass"
  - "link_check"

determinism:
  stable_sorting: true
  seeded: true
  seed_source: "KFM_SEED or derived from run_id"
  idempotency_key: "(dataset_id, input_checksums, config_hash)"

stores:
  neo4j:
    enabled: true
    export_csv_root: "data/graph/csv/${KFM_RUN_ID}"
    constraints_profile: "kfm-v13"
  postgis:
    enabled: false
    load_root: "data/db/postgis/${KFM_RUN_ID}"
  search:
    enabled: false
    index_docs_root: "data/index/search/${KFM_RUN_ID}"

policy:
  required_rulesets:
    - "tools/validation/policy"
  conftest_profile: "kfm-v13"

network:
  default: "deny"
  allow_with_flag: "--allow-network"
  ssrf_protection: true
  log_urls_and_checksums: true

distribution:
  mode: "filesystem"   # or "oci"
  oci:
    enabled: false
    ref: "oci://registry.example/kfm/${dataset_id}:${version}"
    sign_with_cosign: true
    attach_sbom: true
    attach_prov: true

ai:
  enabled: false
  llm_runtime: "ollama"
  model_allowlist:
    - "llama3.1"
  cite_or_refuse: true

offline_packs:
  enabled: false
  packs_root: "data/packs"

retention:
  work_dir_ttl_days: 14
  keep_failed_runs: true
```

> [!IMPORTANT]
> The contract does not replace docs; it makes the docs **enforceable**.  
> CI can validate `pipeline.yml` shape and cross-check it against produced artifacts.

---

## âš™ï¸ Running pipelines

> [!NOTE]
> Prefer the repoâ€™s **make/CI entrypoints** when available.  
> If your repo doesnâ€™t have these targets yet, treat this section as intended ergonomics.

### âœ… Recommended: `make` entrypoints (examples)
```bash
# list pipelines (example)
make pipelines-list

# run a pipeline (example)
make pipeline RUN=hydrology/watersheds ENV=dev

# validate catalogs + policy (example)
make catalog-qa
make policy-qa

# derived store ingests (examples)
make graph-export
make graph-ingest
make postgis-load
make search-index-build

# health checks (example)
make store-health
```

### ğŸ Direct execution (module style)
```bash
python -m src.pipelines.hydrology.watersheds.run --env dev --config config/dev.yml --run-id "RUN-2026-01-26-demo"
python -m src.pipelines.hazards.refresh.run --env dev --since "2026-01-01T00:00:00Z" --run-id "RUN-2026-01-26-hazards"
```

### ğŸ§± Expected flags (strongly recommended)
- `--help` (must include â‰¥2 runnable examples)
- `--env {dev|stage|prod}`
- `--config <path>`
- `--run-id <id>` (or `KFM_RUN_ID`)
- `--dry-run` default OR â€œno writes unless `--apply`â€
- `--apply` for state mutation
- `--allow-network` for any remote fetching (deny-by-default)
- `--telemetry-root <path>` *(optional but recommended)*
- `--log-level {DEBUG|INFO|WARNING|ERROR}` *(optional)*

### ğŸ§± Typical environment variables
| Variable | Purpose |
|---|---|
| `KFM_ENV` | `dev|stage|prod` |
| `KFM_RUN_ID` | provenance correlation across logs/catalogs/PROV/audits |
| `KFM_DATA_ROOT` | data root (if not repo-relative) |
| `KFM_SOURCES_ROOT` | source manifests root |
| `KFM_STAC_ROOT` | STAC output root |
| `KFM_DCAT_ROOT` | DCAT output root |
| `KFM_PROV_ROOT` | PROV output root |
| `KFM_AUDITS_ROOT` | audits output root (run manifests + gate reports) |
| `KFM_TELEMETRY_ROOT` | telemetry output root |
| `KFM_POLICY_ROOT` | policy pack root (OPA/Rego) |
| `KFM_SEED` | RNG seed for stochastic pipelines |
| `KFM_NEO4J_URI` | graph endpoint *(only for controlled ingest steps)* |
| `KFM_POSTGIS_DSN` | PostGIS connection *(only for controlled ingest steps)* |
| `KFM_SEARCH_URI` | search/index endpoint *(only for controlled ingest steps)* |
| `KFM_OLLAMA_URL` | Ollama runtime URL *(Focus Mode / AI service)* |
| `KFM_LLM_MODEL` | model name allowlisted by policy |
| `KFM_POLICY_BUNDLE_SHA` | record which policy bundle was applied |

> [!TIP]
> For heavy geo deps (GDAL/PROJ), **Docker is your friend** ğŸ³  
> Containerize pipeline environments to reduce â€œworks on my machineâ€ drift.

---

## âœ… Quality gates

A pipeline is â€œdoneâ€ only when these pass (prefer â€œfail closedâ€ ğŸ”’):

### Ring 0 â€” Structure ğŸ§±
- JSON/YAML parses
- schema validation for outputs + catalogs + manifests
- required files exist (`pipeline.yml`, configs, outputs present)
- docs protocol checks (where applicable): YAML front-matter, required sections, link validity

### Ring 1 â€” Integrity ğŸ§·
- checksums/manifests recorded
- deterministic IDs stable when inputs unchanged
- atomic publish (no half-written processed outputs)
- run_manifest emitted for staged/published

### Ring 2 â€” Semantics ğŸ§ 
- CRS correctness + axis order
- geometry validity (and any repair policy is explicit + logged)
- raster sanity (nodata, resolution, overviews for COG)
- bounds/time sanity (Kansas extent, plausible ranges, monotonic windows where required)

### Ring 3 â€” Governance & safety ğŸ”ğŸ›¡ï¸
- license required before publish
- classification/sensitivity propagation (no downgrade)
- redaction/generalization audited (when required)
- hostile input guards (archives, rasters, PDFs, GeoJSON, etc.)
- secrets/sensitive patterns not leaked to logs

### Ring 4 â€” Policy pack (OPA/Rego) âš–ï¸
- policy checks run and produce a deterministic report artifact
- deny rules block merge/publish (missing policies = deny)
- AI outputs: cite-or-refuse gates (uncited assertions are denied)

### Ring 5 â€” Derived store integrity (when building stores) ğŸ§©
- Neo4j: referential integrity across CSVs, constraints/profile checks, no orphan edges
- PostGIS: schema drift checks, index creation verified, bounds sanity
- Search: mapping/schema pinned, forbidden-field scanning, doc count sanity

### Ring 6 â€” Narrative integrity (Story Nodes + Pulse Threads) ğŸ“šğŸ§¾
- evidence_manifest present and machine-checkable
- all cited evidence resolves to STAC/DCAT/PROV or stable graph IDs
- fact vs interpretation clearly signaled (AI-labeled, confidence provided when applicable)
- no sensitive location leaks (sovereignty rules enforced)
- accessibility basics satisfied for published narrative assets â™¿

### Ring 7 â€” Modeling credibility (when doing inference/simulation) ğŸ§ªğŸ“Š
If a pipeline produces analytical/model outputs, it must emit diagnostics artifacts:
- EDA/QC summaries (missingness, distribution checks)
- regression diagnostics (residual checks, assumptions, baselines)
- Bayesian outputs (priors, posterior summaries, credible intervals)
- simulation V&V posture (verification/validation notes, sensitivity metadata)
- uncertainty is first-class (intervals, confidence/credible bounds, caveats)
- model cards (recommended) for AI/ML artifacts ğŸ“‡

> [!TIP]
> Make it easy for reviewers: `make catalog-qa` and `make store-health` should be boring. ğŸ˜Œâœ…

---

## ğŸ§¾ Receipts, telemetry, and replay

KFM is evidence-first: pipelines should emit â€œreceiptsâ€ that let someone reproduce the run.

### âœ… Minimum receipt set (recommended for any publish)
- ğŸ§¬ `data/prov/<RUN-ID>.jsonld` (or a bundle directory)
- ğŸ§¾ `data/audits/<RUN-ID>/run_manifest.json`
- ğŸ§· checksums manifest for produced outputs
- ğŸ—‚ï¸ STAC + DCAT references for all published artifacts
- âš–ï¸ policy report artifact (Conftest output; machine-readable)
- ğŸªµ structured logs (human + optional JSONL)
- ğŸ”— PR/review reference *(recommended)*: publish trail is part of provenance

### ğŸ“ˆ Telemetry (append-only, linkable)
- Keep telemetry append-only and keyed by `run_id`
- Prefer NDJSON summaries that can be indexed by tooling
- Do not log secrets or restricted raw content
- Recommended signals (governance-friendly):
  - policy deny events
  - redaction/generalization events
  - sensitive access flags
  - derived-store ingest counts + drift deltas

### â­ Recommended: MCP run receipt (when used for decisions or publish)
- `mcp/runs/<RUN-ID>/MANIFEST.md` (human narrative of â€œwhat happenedâ€)
- links to the relevant catalogs + outputs + gates
- any redactions/generalizations applied + rationale

> [!NOTE]
> Telemetry should help answer: **what ran, what changed, what gates passed, what was withheld/redacted, and why**.  
> In KFM, governance/AI can also produce an **append-only ledger** of significant outputs (especially AI answers).

---

## ğŸ” Governance & sovereignty

KFM is FAIR + CARE + sovereignty-aware by design ğŸª¶

### ğŸªª Classification propagation (deny-by-default)
- Outputs cannot be **less restricted** than inputs unless an explicit redaction/generalization step exists and is reviewed.
- If classification cannot be determined, default to **restricted**.

### ğŸ§· Stable IDs (information-free)
- Donâ€™t embed meaning (names, years, sequence, geography) into identifiers.
- Treat IDs as stable pointers; store meaning in metadata where it can evolve safely.

### ğŸª¶ Sovereignty & cultural protocols (first-class)
Some datasets require extra governance and/or special handling:
- culturally sensitive locations (coordinate fuzzing / aggregation)
- restricted heritage knowledge (access controls + disclosure UX)
- council/community approvals recorded as part of provenance

### âœ‚ï¸ Redaction/generalization is multi-layer
If redaction is required, it must be applied consistently:
- `data/processed/**` (redacted evidence artifact)
- STAC/DCAT metadata (flags + documentation)
- API layer (access control + redaction enforcement)
- UI layer (additional disclosure/UX checks)

### ğŸ§® Statistical disclosure control (when needed)
When â€œaggregation can still revealâ€ (small counts, unique patterns, linkage risk), consider:
- k-anonymity / l-diversity / t-closeness style protections
- differential privacy for published aggregates (where appropriate)
- query auditing / inference control for sensitive analytics endpoints
- â€œdeny-by-defaultâ€ on derived indexes that might leak protected fields

### ğŸ§¾ Audit trails
- Pipelines should emit telemetry and provenance notes when redaction/generalization occurs.
- Governance reviews are required for classification/sensitivity changes.

### ğŸŒ Federation-ready posture (planned)
KFM is designed to scale into a multi-region â€œFrontier Matrixâ€ federation:
- prefer global/URN-like dataset identifiers
- allow cross-instance catalog references (donâ€™t duplicate what can be cited)
- permit policy pack tuning per jurisdiction (while sharing a baseline)

---

## ğŸ›¡ï¸ Security & hostile inputs

Pipelines ingest â€œfiles from the world.â€ Assume inputs are hostile by default. ğŸ§¯

### âœ… Required defensive posture
- validate file types & magic bytes (donâ€™t trust extensions)
- prevent path traversal (archives/extractors)
- defend against decompression bombs (archives/images)
- sanitize subprocess args when calling GDAL/other tooling
- parameterize SQL (never string-concat untrusted values)
- **never log secrets**; never print sensitive raw content
- treat prompt inputs (for AI) as hostile too (prompt-injection posture)
- enforce allowlists for any outbound network fetch

### ğŸš Shell scripting standards (when using Bash wrappers)
- default to strict mode: `set -euo pipefail`
- quote variables *always*
- never `eval` user-controlled inputs
- prefer explicit allowlists for arguments and file patterns

### ğŸŒ Network posture
- default: **no network**
- if a pipeline fetches remote inputs:
  - require `--allow-network`
  - block private IP ranges by default (SSRF defense)
  - log URLs + checksums/ETags of downloaded artifacts

> [!CAUTION]
> If someone malicious controls this input, whatâ€™s the maximum harm?  
> If the answer includes â€œrun code / exfiltrate / crash,â€ add guards **before** merging. ğŸš«ğŸ§¨âœ…

---

## ğŸ”­ Performance & scaling

KFM scales by staying **metadata-driven** and **chunk-friendly**:

- ğŸ“¦ partition work (tiles, counties, watersheds, time windows)
- ğŸ§± pipeline breakers at materialization boundaries (COG/Parquet outputs)
- ğŸ” replay safety (idempotency keys + deterministic ordering)
- â™»ï¸ avoid reprocessing unchanged inputs (checksums + manifests + ETags)
- ğŸ—„ï¸ push heavy spatial ops into PostGIS when safe (joins, intersects, buffers)
- âš¡ scale batch jobs with Spark/cluster tooling when domains demand it *(only with strong provenance + determinism posture)*
- âš–ï¸ acknowledge workload mix (real-time vs batch; read-heavy vs write-heavy) and isolate where needed
- ğŸ›°ï¸ compute-to-data for imagery-heavy domains
- ğŸ§³ offline packs (PMTiles + compact indexes) for field/classroom modes

> [!TIP]
> Prefer â€œboring performance winsâ€: stable chunking + caching + deterministic manifests.  
> Speed is good â€” **but correctness and provenance come first**. ğŸ§¾âœ…

---

## ğŸŒ¾ Example pipeline archetypes

Match an archetype before inventing a new one ğŸ§©

### 1) ğŸŒŠ Time-series & sensor ingestion (batch/refresh)
**Use when:** climate records, stream gauges, socio-economic time series  
**Outputs:** Parquet + temporal coverage metadata + catalog entries  
**Key gates:** schema, time window sanity, missingness checks, license, provenance.

### 2) ğŸ›°ï¸ Remote sensing compute-to-data ingest (batch/refresh)
**Use when:** imagery too large for local processing  
**Pattern:** compute externally â†’ ingest derived product â†’ publish COG + STAC + DCAT + PROV  
**Key gates:** range sanity, export params captured, uncertainty metadata.

### 3) ğŸ’§ Hydrology terrain processing (batch)
**Use when:** DEM-derived flow direction/accumulation, watersheds, streams  
**Outputs:** COG rasters + vectors + STAC Items per logical unit  
**Key gates:** CRS, nodata, alignment, geometry validity, Kansas bounds.

### 4) ğŸŒªï¸ Hazards refresh (scheduled refresh)
**Use when:** multi-source hazard chronicles (tornado, flood, drought, fire)  
**Pattern:** scheduled ETL â†’ normalized event records â†’ cataloged evidence + summaries  
**Downstream:** events become graph nodes linked to provenance + sources.

### 5) ğŸš GTFSâ€‘RT watcher (nearâ€‘realâ€‘time)
**Use when:** live transit telemetry (vehicle positions, trip updates)  
**Pattern:** watcher polls/streams â†’ time-window artifacts â†’ STAC Items per window/day â†’ DCAT distributions â†’ PROV per run/window  
**Key gates:** strict timestamp handling, dedupe, retention policy, governance classification.

### 6) ğŸ“„ Bulk document ingest (evidence-first)
**Use when:** PDFs/scans (reports, notices, historical docs) must become searchable evidence  
**Pattern:** store raw doc â†’ extract text (and optional entities) â†’ catalog as evidence with provenance + redaction rules  
**Key gates:** hostile PDF handling, PII policy checks, attribution/license capture.

### 7) ğŸ§® Simulation + optimization runs (job-style)
**Use when:** scenario runs matter for decision support  
**Pattern:** parameterized run â†’ outputs + uncertainty + diagnostics â†’ STAC/DCAT + PROV run bundle  
**Key gates:** V&V posture, sensitivity metadata, deterministic seeds, reproducible configs.

### 8) ğŸ§Š 3D GIS / volumetric artifacts (optional advanced)
**Use when:** 3D trenches, volumes, meshes, point clouds, LOD needs  
**Pattern:** ingest â†’ validate CRS/scale â†’ generate LOD/tiles â†’ catalog assets + provenance  
**Key gates:** coordinate sanity, metadata completeness, LOD budgets.

### 9) ğŸ§³ Offline pack builder (field/classroom)
**Use when:** no-network mode, demos, outreach, field research  
**Pattern:** compile PMTiles + small GeoParquet slices + indexes + README + license bundle  
**Key gates:** pack manifest present, license bundle present, size budgets, reproducible build.

### 10) ğŸ” Search index build (discovery + Focus Mode retrieval)
**Use when:** datasets/docs must be discoverable by keyword and/or embeddings  
**Pattern:** build index docs from DCAT/STAC/PROV + approved corpora â†’ policy-sanitized index publish â†’ audit manifest  
**Key gates:** forbidden-field scan, mapping pinned, doc count sanity, replayable build.

### 11) ğŸ—„ï¸ PostGIS load + derived views (optional but common)
**Use when:** map/API queries need spatial joins/aggregations fast  
**Pattern:** load cataloged evidence â†’ create materialized views â†’ index â†’ emit load manifest  
**Key gates:** schema drift checks, bounds sanity, reproducible SQL/DDL, provenance refs.

### 12) ğŸ“£ Pulse Thread generator + ğŸ§  pattern detector
**Use when:** â€œwhat changed?â€ updates should be generated from evidence and alerts  
**Pattern:** detector emits alert artifacts â†’ curator/agent drafts Pulse Thread â†’ evidence_manifest â†’ review â†’ publish  
**Key gates:** evidence_manifest completeness, cite coverage, sensitivity/sovereignty checks, opt-in AI labeling.

### 13) ğŸ©º Store health check pipeline (maintenance)
**Use when:** long-lived integrity requires scheduled checks  
**Outputs:** health report artifacts + remediation PRs  
**Key gates:** fail-closed remediation workflow, auditability, no silent fixes.

> [!TIP]
> â€œValue-addedâ€ derived layers (summaries, clustering, indices) are still **evidence artifacts**: store in `data/processed/**` + STAC/DCAT + PROV + audits. âœ…ğŸ—‚ï¸ğŸ§¬

---

## ğŸ§© Adding a new pipeline

### âœ… Checklist (minimum bar)
- [ ] Choose a domain: `src/pipelines/<domain>/`
- [ ] Define inputs/outputs **before** coding (contract-first)
- [ ] Add/confirm `data/sources/**/source.json` (rights + sensitivity + pointers)
- [ ] Implement deterministic ETL (config-driven; stable IDs)
- [ ] Write to `data/raw â†’ data/work â†’ data/processed` *(stage appropriately; raw is immutable)*
- [ ] Emit STAC + DCAT + PROV (before downstream use)
- [ ] Emit audits: `run_manifest.json` + deterministic gate reports
- [ ] Produce a policy report (OPA/Conftest) and ensure it passes
- [ ] Add validators (schema, bounds, links, license, classification propagation)
- [ ] Add tests (unit + at least one mini end-to-end run)
- [ ] Add docs: `docs/data/<domain>/pipelines/<pipeline_name>/README.md`
- [ ] If needed, add bounded ingest artifacts for Neo4j/PostGIS/search (never manual edits)
- [ ] Ensure UI access stays API-only; catalogs remain the interface

### ğŸ§¾ Pipeline runbook contract (what every pipeline doc must include)
Under `docs/data/<domain>/pipelines/<pipeline_name>/README.md`:

- ğŸ¯ Purpose + scope + SLA cadence
- ğŸ§º Inputs (sources, access requirements, licenses)
- ğŸ“ Source manifest notes (rights + sensitivity + access pointers)
- âœ… Validation gates (what fails fast; what warns)
- âš–ï¸ Policy gates (which denies could block publish)
- ğŸ§· Integrity model (hashing, manifests, idempotency)
- ğŸ—‚ï¸ STAC/DCAT mapping (collections/items/datasets)
- ğŸ§¬ PROV mapping (entities/activities/agents)
- ğŸ§¾ Audit mapping (run_manifest + gate reports)
- ğŸ§© Derived store mapping (graph/postgis/search) if applicable
- ğŸ’¥ Failure modes + replay rules + kill switch
- ğŸª¶ Governance notes (classification, redaction/generalization, restrictions)
- ğŸ“£ Narrative outputs (if any): evidence_manifest rules + review path
- ğŸ§  Concept tags (if any): conceptual attention nodes used

---

## ğŸ§© Design Packs

Design Packs are **domain blueprints** that compress â€œhow to build this kind of pipelineâ€ into a repeatable spec. ğŸ§©ğŸ“¦  
Theyâ€™re especially useful for fast expansion (new domains, new indicators, new narrative templates) without rewriting governance from scratch.

### âœ… Typical Design Pack contents (recommended)
- `design_pack.yml` (domain goals, dataset IDs, ontologies, gates, UI expectations)
- `schemas/` (domain schemas)
- `examples/` (example evidence_manifest + run_manifest patterns)
- `mockups/` (optional UI expectations: layer names, symbology hints, story node templates)
- `budgets/` (size + latency targets, offline pack budgets)

> [!TIP]
> Design Packs should be versioned and reviewed like code. If a design pack changes, pipelines generated from it must re-run compatibility checks. âœ…ğŸ§¾

---

## ğŸ“š Project reference library influence map

These project files shape pipeline design + review standards: determinism, validation, scaling, governance, security posture, map readiness, and human-centered constraints. ğŸ§ ğŸ§¾

<details>
<summary><strong>ğŸ“¦ Expand: Project files â†’ what they influence in pipelines</strong></summary>

### ğŸ§­ Core KFM design docs (direct pipeline influence)
| Project file | Primary lens | Pipeline-level impact |
|---|---|---|
| `Kansas Frontier Matrix (KFM) â€“ Comprehensive Platform Overview and Roadmap.pdf` | ğŸ§­ Roadmap + distribution | OCI/ORAS packaging, signing/attestations posture, federation + identifiers, long-horizon expansion constraints. |
| `Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf` | ğŸ§± Architecture | Storage trio (PostGIS + Neo4j + search index), clean architecture lens, API stack (FastAPI; REST + GraphQL), governance boundaries. |
| `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf` | ğŸ§­ System blueprint | Standards posture, data stores, performance/offline constraints, evidence-first rules. |
| `ğŸ“š Kansas Frontier Matrix (KFM) â€“ Expanded Technical & Design Guide.pdf` | ğŸ“¥ Intake + deep tech | Raw immutability boundary, deterministic ETL, catalog triplet linkage, bounded CSV graph ingest posture, ontology mapping patterns. |
| `Kansas Frontier Matrix (KFM) â€“ Comprehensive UI System Overview (Technical Architecture Guide).pdf` | ğŸ—ºï¸ UI constraints | Provenance UX (â€œlayer provenanceâ€), Story Node + Focus Mode integration, map/timeline workflows, accessibility posture. |
| `Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf` | ğŸ¤– AI governance | Cite-or-refuse, explainable AI panel posture, governance ledger, drift monitoring, prompt security. |
| `KFM AI Infrastructure â€“ Ollama Integration Overview.pdf` | ğŸ¤– Runtime AI infra | Local LLM runtime integration, prompt gateway, policy gates for citations, auditing AI answers, resource constraints. |
| `MARKDOWN_GUIDE_v13.md.gdoc` | âœï¸ Canonical ordering + doc protocol | v13 invariants, canonical paths, STAC/DCAT/PROV alignment, Story Node governance, CI gates (schemas/links/security scans). |

### ğŸ“š Reference library bundles (PDF portfolios)
These are **shelf bundles** containing many embedded PDFs used as implementation references.

| Bundle file | Primary lens | Pipeline-level impact |
|---|---|---|
| `AI Concepts & more.pdf` | ğŸ¤– ML/AI foundations | Credibility gates (diagnostics, uncertainty), evaluation discipline, advisory-only posture for AI. |
| `Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf` | ğŸ—„ï¸ Data architecture + Bayesian methods | Provenance-first data management patterns, reproducibility discipline, uncertainty reporting standards. |
| `Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf` | ğŸ§Š GIS/3D/WebGL | Projection hygiene, LOD/tiling discipline, WebGL storytelling + 3D readiness (Cesium optional). |
| `Various programming langurages & resources 1.pdf` | ğŸ§° Implementation shelf | Polyglot tooling references, deterministic builds, secure scripting, CI discipline. |
| `Mapping-Modeling-Python-Git-HTTP-CSS-Docker-GraphQL-Data Compression-Linux-Security.pdf` | ğŸ§° DevOps + security | Dockerized pipelines, GraphQL contracts, compression + storage efficiency, Linux/security posture. |
| `Geographic Information-Security-Git-R coding-SciPy-MATLAB-ArcGIS-Apache Spark-Type Script-Web Applications.pdf` | ğŸ—ºï¸ GIS + compute ecosystem | ArcGIS/Spark/TypeScript and applied GIS patterns; informs scale-out options and interoperability considerations. |

</details>

---

## ğŸ§¾ Metadata

```yaml
title: "KFM Pipelines â€” canonical pipeline boundary"
path: "pipelines/README.md"
version: "v1.8.0"
last_updated: "2026-01-26"
review_cycle: "90 days"
prime_directive: "No catalog â†’ no derived stores (graph/index) â†’ no API â†’ no UI"
second_directive: "No policy pass â†’ no merge â†’ no publish"
narrative_directive: "No narrative without evidence manifests"
pipeline_order: "ETL â†’ STAC/DCAT/PROV â†’ Derived stores (Neo4j/PostGIS/Search) â†’ APIs â†’ UI â†’ Story Nodes + Pulse Threads â†’ Focus Mode"
principles:
  - "contract-first"
  - "evidence-first"
  - "raw-is-immutable trust-boundary"
  - "determinism-by-default"
  - "stable-identifiers (information-free)"
  - "deny-by-default security"
  - "policy-as-code (OPA/Rego) fail-closed"
  - "GitOps publish trail (PR/review as provenance)"
  - "run_manifest + gate reports required for publish"
  - "narrative evidence_manifest required (Story Nodes + Pulse Threads)"
  - "FAIR+CARE + sovereignty-aware"
  - "privacy + disclosure control when needed"
  - "modeling credibility (V&V + uncertainty artifacts)"
  - "artifact distribution is pointer-first (OCI optional; signing/attestations optional)"
  - "derived stores are rebuildable from catalogs"
  - "federation-ready (cross-instance references)"
```

---

## ğŸ•°ï¸ Version history

| Version | Date | Summary | Author |
|---:|---|---|---|
| v1.8.0 | 2026-01-26 | Aligned canonical STAC subpaths (`collections/` + `items/`) and `src/server/` API home (v13); formalized â€œderived storesâ€ stage (Neo4j + PostGIS + search index) behind API boundary; added Focus Mode AI infra gates (Ollama + prompt gateway + cite-or-refuse policy); expanded artifacts and gates for index/store builds; strengthened doc protocol + CI gate notes (links/schemas/security scans); added disclosure-control methods to governance section; refreshed influence map to include all current project files. | KFM Engineering |
| v1.7.0 | 2026-01-20 | Added narrative layer formalization (Pulse Threads + evidence_manifest); added run_manifest + audits directory; added OCI distribution concept (optional) and signing/attestation posture; added graph health check pipeline guidance; added Design Packs concept; strengthened raw-immutability as first trust boundary; updated influence map with Additional Project Ideas + Markdown Guide v13. | KFM Engineering |
| v1.6.0 | 2026-01-19 | Added manifest-first intake (`data/sources/**`); clarified canonical path aliases (catalog/prov); added GitOps publish boundary; formalized policy-as-code ring (OPA/Rego + Conftest); added Wâ€‘Pâ€‘E automation section; expanded standard artifacts (policy report, graph exchange, offline packs); refreshed influence map to the current project docs + portfolio bundles. | KFM Engineering |
| v1.5.0 | 2026-01-13 | Tightened â€œpipelines as compilersâ€ phase model; formalized promotion workflow (candidateâ†’stagedâ†’published); added standard artifact set incl. integrity + supply-chain notes; expanded credibility gates for inference/simulation; updated influence map. | KFM Engineering |
| v1.4.0 | 2026-01-11 | Aligned pipeline README with Master Guide v13 invariants (API boundary, evidence-first narrative); added pipeline taxonomy + PDC contract template; expanded receipts/telemetry; clarified docs paths. | KFM Engineering |
| v1.3.0 | 2026-01-09 | Strengthened pipeline contract essentials (declared IO, PROV, schema/bounds, atomic publish); expanded governance, security, scaling, and archetype guidance. | KFM Engineering |

---

## ğŸ“ Evidence anchors

> These are the project files directly used while updating this README.

### ğŸ§­ Core KFM docs
- `MARKDOWN_GUIDE_v13.md.gdoc`
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Platform Overview and Roadmap.pdf`
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Architecture, Features, and Design.pdf`
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf`
- `ğŸ“š Kansas Frontier Matrix (KFM) â€“ Expanded Technical & Design Guide.pdf`
- `Kansas Frontier Matrix (KFM) â€“ Comprehensive UI System Overview (Technical Architecture Guide).pdf`
- `Kansas Frontier Matrix (KFM) â€“ AI System Overview ğŸ§­ğŸ¤–.pdf`
- `KFM AI Infrastructure â€“ Ollama Integration Overview.pdf`

### ğŸ“š Reference bundles (PDF portfolios)
- `AI Concepts & more.pdf`
- `Data Managment-Theories-Architures-Data Science-Baysian Methods-Some Programming Ideas.pdf`
- `Maps-GoogleMaps-VirtualWorlds-Archaeological-Computer Graphics-Geospatial-webgl.pdf`
- `Various programming langurages & resources 1.pdf`
- `Mapping-Modeling-Python-Git-HTTP-CSS-Docker-GraphQL-Data Compression-Linux-Security.pdf`
- `Geographic Information-Security-Git-R coding-SciPy-MATLAB-ArcGIS-Apache Spark-Type Script-Web Applications.pdf`

---

<div align="center">

**Â© 2026 Kansas Frontier Matrix** Â· CCâ€‘BY 4.0 (project docs)  
ğŸ§¬ FAIR+CARE Â· ğŸª¶ Sovereignty-aware Â· ğŸ›¡ï¸ Policy-gated builds Â· ğŸ§¾ Evidence-first

</div>