# ğŸ§ªğŸ—ºï¸ Census Mapping QA

`ğŸ§ª QA: gated` `ğŸ—ºï¸ Domain: census mappings` `ğŸ“¦ Stage: external intake` `ğŸ”— Join key: GEOID` `ğŸ§¾ Metadata: STAC/DCAT/PROV`

> [!IMPORTANT]
> This folder is the **QA gate** for external Census boundary + crosswalk assets used by **Kansas Frontier Matrix (KFM)**.
> If it doesnâ€™t pass here, it **doesnâ€™t** get promoted into the canonical data lifecycle.

---

<details>
<summary><strong>ğŸ“Œ Table of Contents</strong></summary>

- [ğŸ¯ What this QA gate protects](#-what-this-qa-gate-protects)
- [ğŸ§­ Where this fits in KFM](#-where-this-fits-in-kfm)
- [ğŸ—‚ï¸ Directory layout](#ï¸-directory-layout)
- [ğŸ“¥ What belongs here](#-what-belongs-here)
- [âœ… QA gates](#-qa-gates)
- [ğŸ§ª Running QA](#-running-qa)
- [ğŸš¦Promotion workflow](#-promotion-workflow)
- [ğŸ§¾ QA reports](#-qa-reports)
- [ğŸ§· Definition of done](#-definition-of-done)
- [ğŸ§° Contributing new checks](#-contributing-new-checks)
- [ğŸ§¯ Common failures](#-common-failures)
- [ğŸ”— Related docs](#-related-docs)

</details>

---

## ğŸ¯ What this QA gate protects

Census boundary layers are **foundational** for joins, aggregations, and maps. A single failure (wrong CRS, broken geometry, bad GEOID field) can silently poison everything downstream.

This QA gate exists to:

- ğŸ§© Ensure boundary geometries are **valid + usable**
- ğŸ§­ Ensure CRS/datum are **present, consistent, and convertible**
- ğŸ”— Ensure join keys (e.g., GEOID) are **unique, complete, and stable**
- ğŸ§¾ Ensure every ingest has **traceable metadata + provenance**
- ğŸ›¡ï¸ Prevent accidental inclusion of **PII / sensitive locations** in publishable layers

---

## ğŸ§­ Where this fits in KFM

```mermaid
flowchart LR
  A[â¬‡ï¸ External download<br/>ZIP / GDB / SHP] --> B[ğŸ§ª QA gate<br/>data/external/mappings/census/qa]
  B -->|PASS âœ…| C[ğŸ“¦ data/raw/census/...]
  C --> D[ğŸ› ï¸ data/work/census/...]
  D --> E[âœ… data/processed/census/...]
  E --> F[ğŸ§¾ STAC + DCAT + PROV]
  F --> G[ğŸ§  Graph / API / UI]
  B -->|FAIL âŒ| X[ğŸ§¯ Fix + re-run QA]
```

> [!NOTE]
> The QA gate is **not** a replacement for ETL validation â€” itâ€™s the *first* line of defense that stops bad/unsafe assets before they become â€œofficial raw evidence.â€

---

## ğŸ—‚ï¸ Directory layout

Recommended contents for this folder (you can scaffold as needed):

```text
data/external/mappings/census/qa/
â”œâ”€ README.md                  # ğŸ‘ˆ you are here
â”œâ”€ ğŸ“ schemas/                 # JSON Schema / frictionless specs / column contracts
â”œâ”€ âœ… expectations/            # Great Expectations / custom rules (YAML/JSON)
â”œâ”€ ğŸ§ª tests/                   # pytest-based QA checks (fast, deterministic)
â”œâ”€ ğŸ§© fixtures/                # tiny sample datasets for regression tests (small!)
â”œâ”€ ğŸ“Š reports/                 # generated QA outputs (MD/JSON), per dataset run
â””â”€ ğŸ› ï¸ scripts/                 # helpers (checksums, validators, report builders)
```

---

## ğŸ“¥ What belongs here

âœ… **Belongs here**
- QA rules & contracts (schemas, expectations)
- Deterministic tests (CI-friendly)
- Small fixtures for regression tests
- QA reports (human-readable + machine-readable)

ğŸš« **Does NOT belong here**
- Full external source archives (unless your repo policy allows it)
- Large binaries without pointers/checksums
- â€œFinalâ€ published datasets (those belong in `data/processed/...`)

> [!TIP]
> Treat large source downloads as **referenced evidence**: store a pointer (source URL, version/vintage, checksum) and keep the rest reproducible.

---

## âœ… QA gates

### âœ… Must-pass gates

**1) ğŸ“¦ Intake integrity**
- Source archive is readable (ZIP/GDB/etc.)
- For shapefiles: required sidecars exist (`.shp/.shx/.dbf` and *ideally* `.prj`)
- Files are non-empty; counts are non-zero where expected

**2) ğŸ” Reproducibility**
- Record and verify a checksum (sha256) for every source artifact
- Verify â€œsame inputs â‡’ same outputsâ€ for any normalization step (idempotent)

**3) ğŸ§­ CRS + datum sanity**
- CRS is present and recognizable
- Coordinates fall in plausible bounds for the intended geography (Kansas / US / etc.)
- If CRS conversion is required, the target CRS is documented and consistent

**4) ğŸ§© Geometry validity**
- No empty geometries
- Geometry validity checks pass (self-intersections, ring closure, etc.)
- Multipolygon vs polygon types are consistent with the layer definition

**5) ğŸ·ï¸ Schema + identifiers**
- Required ID fields exist (e.g., `GEOID` or a documented alternative)
- IDs are **non-null**, **unique**, and **type-stable** (string vs int issues)
- Field naming is consistent for the intended vintage (document if it isnâ€™t)

**6) ğŸ”— Joinability**
- Join keys match the expected grain (tract vs block vs county, etc.)
- Crosswalk tables cover all expected features (no silent drop of areas)

**7) ğŸ›¡ï¸ Safety + governance**
- No direct PII fields (names, emails, addresses, phone numbers)
- No â€œsensitive locationâ€ layer is accidentally marked publishable without governance review
- Classification does not get downgraded through processing without an approved de-identification step

---

### âš ï¸ Tracked warnings

These should be **reported** (and ideally fixed) but may not always block (depending on policy):

- ğŸ•³ï¸ Minor slivers / small holes
- ğŸ§µ Small multipart artifacts below area threshold
- ğŸ“‰ Unexpected attribute sparsity (too many nulls in non-key fields)
- ğŸ“ Highly suspicious area/perimeter outliers (flag for review)

---

## ğŸ§ª Running QA

> [!NOTE]
> Command names vary by repo â€” treat these as **patterns**. The goal is: *fast deterministic checks that CI can run.*

### Local pattern

- Run QA in the same environment as CI (often the API container):

```bash
# Example pattern (adjust to your repo)
docker-compose exec api pytest -k census_mappings -q
```

### Dataset-targeted pattern

```bash
# Example pattern (adjust paths + module names)
python -m pipelines.qa.census_mappings \
  --input "data/external/mappings/census/sources/<source>/<vintage>/" \
  --report-out "data/external/mappings/census/qa/reports/<source>_<vintage>/"
```

---

## ğŸš¦ Promotion workflow

When QA passes, promote the asset into KFMâ€™s canonical lifecycle:

1) **ğŸ“Œ Register the external source**
   - Record: source name, vintage, license, checksum, and where it came from

2) **ğŸ“¦ Stage as raw evidence**
   - Place/point the raw evidence under `data/raw/<domain>/...`

3) **ğŸ› ï¸ Transform deterministically**
   - Write intermediate artifacts to `data/work/<domain>/...`
   - Produce curated outputs to `data/processed/<domain>/...`

4) **ğŸ§¾ Publish boundary artifacts**
   - Generate STAC (items/collections), DCAT entry, and PROV lineage bundle

5) **âœ… CI gate**
   - CI should validate: tests pass, metadata present, policies satisfied

---

## ğŸ§¾ QA reports

QA should output **both**:

- ğŸ§  `report.json` (machine-readable; can be enforced by CI)
- ğŸ§‘â€ğŸ« `report.md` (human-readable; reviewer-friendly)

Recommended report sections:

- Dataset identity (source, vintage, geography level)
- Checks executed (pass/warn/fail)
- CRS + bbox summary
- Feature counts + attribute completeness summary
- Join key integrity summary
- Geometry validity & repair notes (if any)
- Safety scan results (PII/sensitive indicators)
- Next actions (what to fix)

> [!IMPORTANT]
> If a QA report is going to be treated as an â€œevidence artifactâ€ (shared, used downstream, or shown in UI),
> store it like a first-class output with provenance â€” donâ€™t leave it as an untracked log blob.

---

## ğŸ§· Definition of done

Before merging a new census mapping source:

- [ ] âœ… Source identified + versioned (vintage clearly stated)
- [ ] ğŸ” Checksum recorded (sha256)
- [ ] âš–ï¸ License captured and compatible
- [ ] ğŸ§ª QA gates pass (no red failures)
- [ ] ğŸ§¾ Metadata produced (STAC/DCAT/PROV) for publishable outputs
- [ ] ğŸ›¡ï¸ Safety scans clean (or governance review completed)
- [ ] ğŸ‘€ Reviewer can reproduce the pipeline + QA deterministically

---

## ğŸ§° Contributing new checks

Guidelines:

- ğŸ§Š **Deterministic**: no manual prompts, no interactive steps
- ğŸ§ª **Fast**: keep QA cheap enough for CI
- ğŸ§¾ **Actionable**: every failure message must tell the dev what to fix
- ğŸ§© **Contract-first**: schemas/expectations are first-class and versioned

Suggested pattern:
- Add/adjust schema in `ğŸ“ schemas/`
- Add expectation in `âœ… expectations/`
- Add a small regression fixture in `ğŸ§© fixtures/`
- Add a test in `ğŸ§ª tests/`
- Ensure the report format stays stable (CI-friendly)

---

## ğŸ§¯ Common failures

- âŒ **Missing license** in metadata (often a CI policy hard-fail)
- âŒ **Missing CRS / missing `.prj`**
- âŒ **Geometry invalid** (self-intersections; mixed geometry types)
- âŒ **GEOID duplicates / nulls**
- âŒ **Wrong join grain** (tract key used for block layer, etc.)
- âŒ **Classification downgrade** (confidential â†’ public) without approved redaction
- âŒ **External source changes** without checksum update (breaks reproducibility)

---

## ğŸ”— Related docs

- ğŸ“˜ KFM Master guide + repo invariants  
  - `/docs/MASTER_GUIDE_v13.md`
- ğŸŒ Metadata standards  
  - `/docs/standards/KFM_STAC_PROFILE.md`  
  - `/docs/standards/KFM_DCAT_PROFILE.md`  
  - `/docs/standards/KFM_PROV_PROFILE.md`
- âš–ï¸ Governance + ethics + sovereignty  
  - `/docs/governance/ROOT_GOVERNANCE.md`  
  - `/docs/governance/ETHICS.md`  
  - `/docs/governance/SOVEREIGNTY.md`
- ğŸ› ï¸ Pipelines  
  - `/pipelines/` (deterministic ETL + validations)

