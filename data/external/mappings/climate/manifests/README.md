# ğŸŒ¦ï¸ Climate Manifests (External Mappings)

![KFM](https://img.shields.io/badge/KFM-pipeline-blue)
![Contract-first](https://img.shields.io/badge/contract--first-%E2%9C%85-success)
![Deterministic](https://img.shields.io/badge/ETL-deterministic%20%26%20logged-success)
![Metadata](https://img.shields.io/badge/metadata-STAC%20%7C%20DCAT%20%7C%20PROV-informational)

> **Purpose:** This folder holds **machine-readable manifests** that describe **external climate datasets** (sources, governance, transformation rules, and publication metadata).  
> Pipelines consume these manifests to ingest data **the KFM way**: Raw â†’ Processed â†’ Catalog/PROV â†’ Graph â†’ API â†’ UI. ğŸ§­

---

## ğŸ“ You are here

```text
data/
â””â”€â”€ external/
    â””â”€â”€ mappings/
        â””â”€â”€ climate/
            â””â”€â”€ manifests/
                â””â”€â”€ README.md   ğŸ‘ˆ you are here
```

âœ… **This directory is config + mapping metadata** (manifests).  
ğŸš« **No raw rasters, tables, or large binaries** should live here.

---

## ğŸ§¾ What is a â€œmanifestâ€ in KFM?

A **manifest** is a **contract artifact** that defines *everything needed* to bring an external climate dataset into KFM **repeatably**:

- ğŸ›°ï¸ **Source**: who provides the dataset, how itâ€™s accessed, licensing/attribution
- ğŸ§Š **Pinning**: how the source is versioned (release tag, timestamp, checksum strategy)
- ğŸ§ª **Transform**: normalization steps (reproject, clip, resample, convert, aggregate)
- ğŸ—‚ï¸ **Publish**: where outputs land (raw/work/processed) and how catalogs are generated
- ğŸ§¬ **Provenance**: how runs are recorded (inputs â†’ activities â†’ outputs)
- ğŸ” **Governance**: classification, redistribution rules, sensitivity tags, review gates

Think of manifests as **dataset â€œrecipesâ€** + **metadata truth** + **governance boundary**.

---

## ğŸ§­ How manifests fit the pipeline

```mermaid
flowchart LR
  M["Manifest (this folder) ğŸ§¾"] --> R["data/&lt;domain&gt;/raw ğŸ“¥"]
  R --> W["data/&lt;domain&gt;/work ğŸ› ï¸"]
  W --> P["data/&lt;domain&gt;/processed âœ…"]

  P --> S["STAC (collections/items) ğŸ›°ï¸"]
  P --> D["DCAT (catalog entry) ğŸ—ƒï¸"]
  P --> V["PROV (lineage bundle) ğŸ§¬"]

  S --> G["Graph (Neo4j) ğŸ•¸ï¸"]
  G --> A["API (contracts + redaction) ğŸ”’"]
  A --> U["UI (MapLibre/Cesium) ğŸ—ºï¸"]
```

**Key rule:** a manifest must never enable a shortcut that bypasses catalogs/provenance.  
If it canâ€™t be cataloged + provenanced, it isnâ€™t â€œpublishedâ€ in KFM.

---

## ğŸ“¦ What belongs in this folder

### âœ… Yes
- `*.manifest.yml` / `*.manifest.yaml` / `*.manifest.json`
- manifest templates & examples
- supporting mapping notes specific to *climate ingestion* (variable mappings, units, CRS rules)

### ğŸš« No
- downloaded files (NetCDF/GeoTIFF/CSV)
- secrets (API keys, tokens)
- generated catalogs (STAC/DCAT/PROV) â€” those belong in canonical catalog locations

---

## ğŸ·ï¸ Naming conventions

Use filenames that are stable, grep-able, and version-aware:

**Recommended**
- `provider__dataset__v<sourceVersion>.manifest.yml`
- `noaa__ghcn_daily__v2025-01.manifest.yml`
- `ecmwf__era5_land__v2024-12.manifest.yml`

**Avoid**
- `manifest.yml` (too generic)
- `final_final_v3.yml` (no ğŸ”¥)

> Tip: if source versioning is messy, version **your packaging** (e.g., `v1`, `v2`) and store **pin details inside** the manifest.

---

## ğŸ§© Manifest structure (recommended)

YAML is preferred for readability, JSON is allowed.

### Top-level shape

| Section | Required | What itâ€™s for |
|---|---:|---|
| `apiVersion`, `kind` | âœ… | Contract identity |
| `metadata` | âœ… | Dataset ID, title, description, tags, owners |
| `source` | âœ… | Provider + access method + license + citation |
| `coverage` | âœ… | Temporal + spatial extent + resolution |
| `variables` | âœ… | Variable dictionary (names, units, nodata, semantics) |
| `processing` | âœ… | Normalize recipe (clip/reproject/resample/aggregate/format) |
| `publishing` | âœ… | Target domain + output paths + STAC/DCAT/PROV IDs |
| `governance` | âœ… | Classification, redistribution, sensitivity, review flags |
| `validation` | â›³ | Expectations + QA checks that must pass |

---

## ğŸ§ª Example manifest (starter)

> Copy, rename, and fill in for a real dataset. Keep it *boring and deterministic*.

```yaml
apiVersion: kfm/v1
kind: ClimateDatasetManifest

metadata:
  id: ecmwf__era5_land__t2m_monthly
  title: "ERA5-Land Monthly Mean 2m Air Temperature"
  version: "v1" # your packaging version (not necessarily the provider's)
  description: >
    Monthly mean 2m air temperature, subset and normalized for KFM climate usage.
  tags: ["climate", "temperature", "raster", "timeseries"]
  owners:
    - name: "KFM Data Maintainers"
      role: "steward"

source:
  provider: "ECMWF / Copernicus Climate Data Store"
  homepage: "REPLACE_WITH_PROVIDER_URL"
  license: "REPLACE_WITH_LICENSE_ID_OR_URL"
  citation: "REPLACE_WITH_CITATION_TEXT_OR_DOI"

  access:
    method: "api"     # examples: http | api | gee | s3 | ftp
    adapter: "cdsapi" # the pipeline adapter name (implementation-specific)
    request:
      dataset: "reanalysis-era5-land-monthly-means"
      variables: ["2m_temperature"]
      format: "netcdf"

  pinning:
    strategy: "request-payload+hash"
    notes: >
      Pin the request payload used to download the file(s) and record sha256 after download.
      Re-running with the same payload must reproduce identical outputs.

coverage:
  spatial:
    crs: "EPSG:4326"
    # Use either bbox OR aoi_ref (AOI defined elsewhere in the repo)
    bbox: [-104.1, 36.9, -94.6, 40.1] # example Kansas-ish bbox
  temporal:
    start: "1981-01-01"
    end: null
    cadence: "monthly"

variables:
  - key: "t2m"
    standard_name: "air_temperature"
    units: "K"
    nodata: null
    description: "2 meter air temperature (monthly mean)"

processing:
  steps:
    - op: "clip"
      mode: "bbox"       # bbox | aoi_ref
      bbox_from: "coverage.spatial.bbox"
    - op: "reproject"
      to_crs: "EPSG:4326"
    - op: "convert"
      to: "COG"          # Cloud-Optimized GeoTIFF (or other project standard)
    - op: "tile"
      scheme: "wmts"     # optional
      notes: "Only if the downstream UI requires tiles; otherwise keep as COG."

publishing:
  target_domain: "climate"

  # Canonical staging (donâ€™t invent new stages)
  raw_path: "data/climate/raw/ecmwf__era5_land__t2m_monthly/v1/"
  work_path: "data/climate/work/ecmwf__era5_land__t2m_monthly/v1/"
  processed_path: "data/climate/processed/ecmwf__era5_land__t2m_monthly/v1/"

  stac:
    collection_id: "climate-ecmwf-era5land-t2m-monthly"
    item_id_template: "climate-ecmwf-era5land-t2m-monthly-{yyyy}-{mm}"
    asset_roles: ["data"]

  dcat:
    dataset_id: "climate-ecmwf-era5land-t2m-monthly"

  prov:
    activity_id: "etl:climate:ecmwf__era5_land__t2m_monthly"

governance:
  classification: "public"         # public | internal | restricted
  redistribution: "allowed"        # allowed | restricted | prohibited
  sensitivity: "none"              # none | cultural | endangered | site-protected | etc
  review_required: false
  notes: >
    If inputs are restricted, outputs must be >= restricted (never less restricted).

validation:
  expectations:
    output_formats: ["tif"]
    crs: "EPSG:4326"
  checks:
    - "schema"
    - "checksums_present"
    - "stac_generated"
    - "dcat_generated"
    - "prov_generated"
```

---

## âœ… â€œDefinition of Doneâ€ for a new manifest

Before a manifest is considered **merge-ready**:

- ğŸ“› **Identity is stable**: `metadata.id` wonâ€™t change later
- ğŸ§¾ **License + citation included** (no ambiguous reuse)
- ğŸ§· **Pinning strategy is explicit** (how we reproduce the exact source)
- ğŸ› ï¸ **Processing is deterministic** (same inputs + same config â‡’ same outputs)
- ğŸ—‚ï¸ **Publishing IDs exist** (STAC collection/item pattern, DCAT dataset id, PROV activity id)
- ğŸ” **Governance is declared** (classification + redistribution + any review flags)
- ğŸ§ª **Validation expectations are defined** (at least format + CRS + checksums policy)

---

## ğŸ” Governance & safety rules (climate isnâ€™t always â€œlow riskâ€)

Climate layers can still become sensitive when combined with:
- protected site locations ğŸº
- Indigenous/sovereign datasets ğŸª¶
- private property constraints ğŸ 
- endangered habitats ğŸ¾

So manifests must:
- declare **classification + redistribution**
- require review when needed
- never allow â€œquiet publishingâ€ to UI bypassing API controls

---

## ğŸ”— Related docs (start here)

- ğŸ“˜ `/docs/MASTER_GUIDE_v13.md`
- ğŸ§© `/docs/standards/` (STAC/DCAT/PROV profiles)
- ğŸ§ª `/src/pipelines/` (domain ETL jobs)
- ğŸ•¸ï¸ `/src/graph/` (graph build + constraints)
- ğŸ”’ `/src/server/` (API + redaction/contract enforcement)

---

## ğŸ§  FAQ

**Q: Where do I put the actual downloaded NetCDF/GeoTIFFs?**  
A: In the canonical staging paths under `data/<domain>/raw|work|processed`. Manifests only describe *how* to get and transform them.

**Q: Can I add a new metadata field ad-hoc?**  
A: Prefer extending the project profiles (STAC/DCAT/PROV) rather than inventing one-off fields. If you must, namespace it (e.g., `kfm:`) and document why.

**Q: What if the dataset is huge?**  
A: Use pointer-based storage patterns (hash + external location) and keep the manifest as the authoritative â€œreceiptâ€ for reproducibility.

---

ğŸ§Š **Keep it deterministic. Keep it governed. Keep it discoverable.** ğŸ—ºï¸

