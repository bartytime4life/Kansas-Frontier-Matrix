# ğŸ—ºï¸ USGS Mapping Pack (External) â€” `data/external/mappings/usgs/`

![USGS](https://img.shields.io/badge/source-USGS-0B3D91?style=for-the-badge)
![Mappings](https://img.shields.io/badge/type-mappings-222?style=for-the-badge)
![STAC/DCAT/PROV](https://img.shields.io/badge/metadata-STAC%20%7C%20DCAT%20%7C%20PROV-444?style=for-the-badge)
![Reproducible](https://img.shields.io/badge/principle-provenance--first-1f6feb?style=for-the-badge)

> ğŸ“ **Path:** `data/external/mappings/usgs/`  
> ğŸ¯ **Purpose:** Keep **USGS-sourced datasets** (and USGS-adjacent services) **machine-mappable, reproducible, and provenance-rich** before/while they flow into domain ETL, catalogs, graph, API, and UI.

---

## ğŸ§­ What this folder is

This directory is a **runbook + spec pack** for mapping **USGS products** (The National Map, 3DEP, hydrography, topo maps, etc.) into the projectâ€™s standardized metadata & ingestion patterns:

- âœ… **Dataset descriptors** (what it is, where it came from, how to fetch it)
- âœ… **Field/attribute crosswalks** (source fields â†’ canonical fields)
- âœ… **Spatial assumptions** (CRS, resolution, tiling/indexing strategy)
- âœ… **â€œBoundary artifactsâ€ hooks** (STAC/DCAT/PROV generation inputs/templates)

> **Not the data itself:** avoid committing large USGS binaries here (LiDAR, DEM mosaics, etc.). This folder is for **mapping + metadata** (and small helper configs).

---

## ğŸ—‚ï¸ Suggested layout

> Adjust to match your pipeline tooling â€” the point is consistency and discoverability. ğŸ’¡

```
ğŸ“ data/
â””â”€ ğŸ“ external/
   â””â”€ ğŸ“ mappings/
      â””â”€ ğŸ“¦ usgs/                                           ğŸ›°ï¸ USGS mapping packs + dataset blueprints
         â”œâ”€ ğŸ“„ README.md                                     ğŸ“˜ overview, conventions, and how to add a new USGS dataset
         â”œâ”€ ğŸ“ datasets/                                     ğŸ§© per-dataset mapping bundles (one folder per source program)
         â”‚  â”œâ”€ ğŸ“ 3dep_dem/                                  ğŸ”ï¸ 3DEP DEM: elevation rasters â†’ KFM elevation schema
         â”‚  â”‚  â”œâ”€ ğŸ“„ dataset.yaml                             âœ… dataset descriptor (scope, inputs, versions, outputs)
         â”‚  â”‚  â”œâ”€ ğŸ§© field_map.yml                             âœ… source fields/bands â†’ KFM canonical fields mapping
         â”‚  â”‚  â”œâ”€ ğŸ“„ stac.collection.template.json             ğŸ›°ï¸ STAC Collection template (program-level semantics)
         â”‚  â”‚  â”œâ”€ ğŸ“„ dcat.dataset.template.jsonld              ğŸ—‚ï¸ DCAT dataset template (discovery + governance)
         â”‚  â”‚  â””â”€ ğŸ“„ prov.template.json                        ğŸ§¬ PROV template (inputs â†’ transforms â†’ outputs)
         â”‚  â”œâ”€ ğŸ“ 3dep_lidar/                                 ğŸ›°ï¸ 3DEP LiDAR: point clouds/derivatives â†’ KFM lidar schema
         â”‚  â”œâ”€ ğŸ“ 3dhp_hydrography/                            ğŸŒŠ 3DHP: modern hydrography products â†’ KFM hydro schema
         â”‚  â”œâ”€ ğŸ“ nhd_legacy/                                 ğŸ§¾ Legacy NHD: historical hydro layers â†’ compatibility mappings
         â”‚  â”œâ”€ ğŸ“ wbd/                                        ğŸ—ºï¸ Watershed Boundary Dataset â†’ KFM watershed schema
         â”‚  â””â”€ ğŸ“ us_topo_historical/                         ğŸ—» US Topo (historical) â†’ KFM topo/map-sheet schema
         â””â”€ ğŸ“ shared/                                       ğŸ§° shared building blocks used across USGS datasets
            â”œâ”€ ğŸ“ crs/                                       ğŸ§­ CRS definitions + transforms + EPSG notes
            â”œâ”€ ğŸ“ templates/                                  ğŸ§± reusable templates (STAC/DCAT/PROV/mapping skeletons)
            â””â”€ ğŸ“„ qa_checks.md                                ğŸ§ª common QA checks (geometry, CRS, ranges, completeness)
```

---

## ğŸ§± Mapping philosophy (short + strict)

### âœ… Treat mappings like code
- PR-reviewed
- versioned
- tested (at least â€œschema + sanity checksâ€)

### âœ… Keep a *single source of truth*
- Each dataset has a **stable ID**
- Each dataset has a **fetch story** (where/how obtained)
- Each dataset has **provenance expectations** (inputs â†’ activities â†’ outputs)

### âœ… Prefer â€œsource-preservingâ€ transforms
- Preserve original attributes in a namespaced area (e.g., `source:*`)
- Add canonical/derived fields in a separate area (e.g., `kfm:*` or `canon:*`)
- Never lose the original CRS/units without recording them ğŸ”

---

## ğŸ†” Canonical dataset IDs

Use IDs that survive refactors and file moves.

**Recommended pattern:**
```
usgs::<program_or_product>::<dataset>::<variant_or_resolution>
```

Examples:
- `usgs::3dep::dem::1m`
- `usgs::3dep::lidar::ql2`
- `usgs::3dhp::edh::service`
- `usgs::tnm::ustopo::historical_scans`

---

## ğŸ§¬ Minimum metadata fields (for every dataset mapping)

Even if your pipeline uses a different schema, ensure you can answer these:

- **identity**
  - `id`, `title`, `description`, `keywords/tags`
- **source**
  - `source_org` (`USGS`)
  - `program/product` (TNM / 3DEP / 3DHP / etc.)
  - `landing_page`
  - `distribution` (download URL / API / service URL)
  - `retrieval_method` (manual, API, bulk, service)
  - `retrieved_at` (or â€œplanned/rollingâ€)
- **license & attribution**
  - `license_summary` (e.g., public domain in US; verify per asset)
  - `attribution_text` (credit line)
- **spatial**
  - `crs_source`, `crs_target` (if reprojected)
  - `extent_bbox` (or how computed)
  - `resolution` (meters/arc-seconds)
  - `nodata` rules (rasters)
- **update cadence**
  - `update_frequency` (annual, quarterly, irregular, legacy)
  - `last_known_update` (if available)
- **quality**
  - `qa_checks` (what we validate)
  - `known_issues` (if any)

---

## ğŸ“¦ STAC / DCAT / PROV â€œboundary artifactsâ€ (how these mappings plug in)

This project treats metadata as **first-class build outputs**:

- ğŸ›°ï¸ **STAC** â†’ collections + items for geospatial cataloging
- ğŸ—ƒï¸ **DCAT** â†’ discovery + data-catalog views (JSON-LD)
- ğŸ§¾ **PROV** â†’ lineage bundles (inputs, activities, agents)

A helpful mental model:

```mermaid
flowchart LR
  M["ğŸ§© USGS mappings (this folder)"] --> P["âš™ï¸ ETL / ingest pipelines"]
  P --> S["ğŸ›°ï¸ STAC (collections/items)"]
  P --> D["ğŸ—ƒï¸ DCAT (dataset entries)"]
  P --> V["ğŸ§¾ PROV (lineage bundles)"]
  S --> G["ğŸ§  Graph build"]
  G --> A["ğŸ”Œ API boundary"]
  A --> U["ğŸ—ºï¸ Map UI + Story Nodes"]
```

---

## ğŸ›°ï¸ USGS access points we commonly map

### ğŸ—ºï¸ The National Map (TNM)
Use TNM for foundational layers (elevation, hydrography, names, structures, boundaries, etc.).

- TNM program page: https://www.usgs.gov/programs/national-geospatial-program/national-map
- TNM tools hub (Downloader, API, viewers): https://www.usgs.gov/tools/download-data-maps-national-map

### ğŸ”Œ TNMAccess (API) + Web Services
If your pipeline fetches programmatically, document:
- endpoint
- query parameters
- paging rules
- rate-limits (if any)
- stable product identifiers (if available)

Helpful references:
- TNMAccess API is the â€œone APIâ€ used to reach TNM downloadable products (per USGS FAQ): https://www.usgs.gov/faqs/there-api-accessing-national-map-data
- Web services URL directory (REST/WMS/WMTS/WFS/WCS) reference: https://www.usgs.gov/faqs/where-can-i-find-a-list-urls-national-map-services

### ğŸŒ„ 3DEP (Elevation: LiDAR + DEM)
3DEP is usually the backbone for:
- high-res DEMs (1m/3m where available)
- LiDAR point clouds (huge)
- elevation-derived products

Key reference:
- 3DEP products & services overview: https://www.usgs.gov/3d-elevation-program/about-3dep-products-services

### ğŸŒŠ Hydrography (3DHP, NHD legacy, WBD)
Hydrography is in transition. Keep mappings explicit about **status**:

- âœ… **3DHP (current focus)**
- ğŸŸ¨ **NHD/NHDPlus HR + WBD as legacy/bridge** (still available, not maintained the same way)

References:
- 3DHP overview: https://www.usgs.gov/3d-hydrography-program
- 3DHP access/products cadence: https://www.usgs.gov/3d-hydrography-program/access-3dhp-data-products
- NHD info (legacy status notes live here): https://www.usgs.gov/national-hydrography/national-hydrography-dataset
- WBD overview: https://www.usgs.gov/national-hydrography/watershed-boundary-dataset

---

## ğŸ§¾ Licensing + attribution (donâ€™t skip this) ğŸ§ 

Even when datasets are broadly open, the mapping spec must clearly record:
- what we believe the license/usage terms are
- what credit line we will show in UI/story nodes
- any exceptions or special cases

**USGS credit guidance:**
- https://www.usgs.gov/information-policies-and-instructions/acknowledging-or-crediting-usgs

**Suggested credit lines (pick one and standardize):**
- `Credit: U.S. Geological Survey`
- `Source: U.S. Geological Survey`
- `(Dataset name) courtesy of the U.S. Geological Survey`

> ğŸ·ï¸ **Note:** The USGS identifier/logo is trademarked; donâ€™t embed it in a way that implies endorsement. When in doubt, stick to text attribution.

---

## âœ… QA checklist (recommended per dataset)

**Spatial sanity**
- [ ] CRS recorded (source + target)
- [ ] Bounds reasonable (bbox intersects expected region)
- [ ] Geometry validity (vectors)
- [ ] NODATA and units documented (rasters)
- [ ] Feature counts stable across runs (within expected delta)

**Metadata completeness**
- [ ] license + attribution present
- [ ] fetch method documented
- [ ] update cadence documented
- [ ] STAC/DCAT/PROV hooks present (or explicitly â€œnot applicableâ€)

**Reproducibility**
- [ ] inputs referenced by URL/ID + checksum (when downloaded)
- [ ] deterministic transforms (same inputs â†’ same outputs)
- [ ] processing toolchain versions recorded (GDAL, PDAL, etc.)

---

## â• Adding a new USGS dataset mapping (happy path)

1. **Create a dataset folder** under `datasets/<slug>/`
2. Add a `dataset.yaml` with:
   - ID, title, description
   - source URLs (landing + distribution)
   - license + attribution
   - spatial metadata assumptions
3. Add `field_map.yml` (if vector/tabular) or `raster_profile.yml` (if raster)
4. Add templates or references that let pipelines generate:
   - STAC collection/item
   - DCAT dataset entry
   - PROV bundle
5. Run validators / unit checks
6. Open a PR with:
   - mapping diff
   - example â€œexpected outputsâ€ (metadata + a tiny sample if appropriate)

---

## ğŸ”— Handy â€œofficialâ€ USGS links (bookmark these) ğŸ”–

- The National Map (TNM): https://www.usgs.gov/programs/national-geospatial-program/national-map
- Download tools hub: https://www.usgs.gov/tools/download-data-maps-national-map
- GIS Data Download (advanced methods incl. cloud + services): https://www.usgs.gov/the-national-map-data-delivery/gis-data-download
- Copyrights & credits: https://www.usgs.gov/information-policies-and-instructions/copyrights-and-credits
- Data licensing (background): https://www.usgs.gov/data-management/data-licensing
- TNM services URLs help: https://www.usgs.gov/faqs/where-can-i-find-a-list-urls-national-map-services

---

## ğŸ§© Related internal docs (project)

- ğŸ“˜ `docs/MASTER_GUIDE_v13.md` (repo structure + pipeline standards)
- ğŸ§ª `src/pipelines/` (ETL jobs consuming these mappings)
- ğŸ›°ï¸ `data/stac/` + ğŸ—ƒï¸ `data/catalog/dcat/` + ğŸ§¾ `data/prov/` (boundary artifacts)

---

### ğŸ§¯ Quick â€œgotchasâ€ (USGS-specific)

- ğŸ”ï¸ **LiDAR is huge** â†’ treat downloads as external artifacts; store checksums + retrieval metadata.
- ğŸŒŠ **Hydrography is evolving** â†’ label legacy datasets clearly; prefer 3DHP where possible.
- ğŸ—ºï¸ **Service endpoints can change** â†’ link to USGS â€œservices listâ€ pages and avoid hardcoding where possible.

---

