# ğŸ—ºï¸ External Dataset Mapping â€” `<dataset_slug>`

![Status](https://img.shields.io/badge/status-draft-lightgrey)
![Domain](https://img.shields.io/badge/domain-external-blue)
![STAC](https://img.shields.io/badge/STAC-required-success)
![DCAT](https://img.shields.io/badge/DCAT-required-success)
![PROV](https://img.shields.io/badge/PROV-required-success)
![License](https://img.shields.io/badge/license-TODO-orange)
![Governance](https://img.shields.io/badge/governance-review%20gated-purple)

> ğŸ¯ **Goal:** this folder documents *how* the external source dataset maps into KFMâ€™s governed boundary artifacts (ğŸ“¦ STAC + ğŸ“š DCAT + ğŸ§¾ PROV) and where its raw/processed assets live.  
> Treat this as the **human-readable contract** that keeps ETL, catalogs, graph ingest, and UI in sync.

---

## ğŸ§­ Quick Nav

- [ğŸ“¦ What lives here](#-what-lives-here)
- [ğŸ”– Dataset identity](#-dataset-identity)
- [ğŸŒ Source + access](#-source--access)
- [ğŸ§± Canonical pipeline placement](#-canonical-pipeline-placement)
- [ğŸŒ STAC mapping](#-stac-mapping)
- [ğŸ“š DCAT mapping](#-dcat-mapping)
- [ğŸ§¾ PROV mapping](#-prov-mapping)
- [ğŸ”— Cross-layer linkage checklist](#-cross-layer-linkage-checklist)
- [ğŸ§ª Validation](#-validation)
- [âš–ï¸ Governance, FAIR+CARE, sovereignty](#-governance-faircare-sovereignty)
- [ğŸ•°ï¸ Change log](#-change-log)
- [âœ… Definition of done](#-definition-of-done)
- [ğŸ”— Related KFM docs](#-related-kfm-docs)

---

## ğŸ“¦ What lives here

This directory is the **mapping/runbook** for a single dataset:

```text
ğŸ“ data/external/mappings/<dataset_slug>/
â”œâ”€â”€ ğŸ“„ README.md                ğŸ‘ˆ you are here (authoritative mapping notes)
â”œâ”€â”€ ğŸ“„ decisions.md             (optional) ADR-style mapping decisions + rationale
â”œâ”€â”€ ğŸ“„ field_map.csv            (optional) sourceâ†’canonical field mapping table
â”œâ”€â”€ ğŸ“„ stac_mapping.md          (optional) STAC-specific notes + asset rules
â”œâ”€â”€ ğŸ“„ dcat_mapping.md          (optional) DCAT-specific notes + distribution rules
â”œâ”€â”€ ğŸ“„ prov_mapping.md          (optional) PROV-specific notes + lineage graph shape
â””â”€â”€ ğŸ“ attachments/             (optional) screenshots, sample rows, schemas, etc.
```

### ğŸ—‚ï¸ Expected sibling locations (domain staging)

> These are **recommended** KFM â€œhomesâ€ for the datasetâ€™s staged assets:

- ğŸ§Š Raw snapshot (read-only): `../../raw/<dataset_slug>/`
- ğŸ§ª Work/intermediate outputs: `../../work/<dataset_slug>/`
- âœ… Processed outputs (stable): `../../processed/<dataset_slug>/`
- ğŸŒ STAC outputs: `../../../stac/collections/â€¦` + `../../../stac/items/â€¦`
- ğŸ“š DCAT outputs: `../../../catalog/dcat/â€¦`
- ğŸ§¾ PROV bundles: `../../../prov/â€¦`

---

## ğŸ”– Dataset identity

| Field | Value |
|---|---|
| Dataset name | `<human_friendly_name>` |
| Dataset slug | `<dataset_slug>` |
| Domain | `external` |
| Dataset ID (canonical) | `<uuid-or-urn>` |
| Source provider | `<provider_name>` |
| Source system/type | `<api|file|registry|archive|tbd>` |
| Primary spatial type | `<raster|vector|table|none>` |
| Temporal coverage | `<YYYYâ€“YYYY>` / `<event-based>` |
| Update cadence | `<one-off|monthly|annual|unknown>` |
| License | `<SPDX-ID-or-TBD>` |
| Citation / attribution text | `<paste required citation here>` |

âœ… **ID rule of thumb:** pick one canonical dataset_id and reuse it consistently in STAC, DCAT, and PROV.

---

## ğŸŒ Source + access

### ğŸ”— Source links

- Homepage: `<https://â€¦>`
- Direct download/API base: `<https://â€¦>`
- Terms / license: `<https://â€¦>`
- Upstream docs: `<https://â€¦>`

### ğŸ“¥ Acquisition notes

- Access method: `<download|api|scrape|manual>`
- Auth: `<none|api-key|oauth|â€¦>` (ğŸš« **never** commit secrets; use `.env` / secret store)
- Snapshot strategy:
  - âœ… Prefer immutable releases (tag/version/DOI)  
  - âœ… If â€œlatestâ€, record retrieval date + ETag/hash + pagination parameters

### ğŸ”’ Integrity + immutability

- Snapshot identifier: `<etag|release|doi|timestamp>`
- Checksums recorded: `<sha256:â€¦>` (recommended)
- Known upstream quirks: `<rate limits, missing fields, etc.>`

<details>
<summary>ğŸ“„ Suggested <code>source_manifest.yml</code> template (optional)</summary>

```yaml
dataset_slug: "<dataset_slug>"
retrieved_at: "<YYYY-MM-DD>"
source:
  provider: "<provider_name>"
  url: "<https://â€¦>"
  terms_url: "<https://â€¦>"
snapshot:
  id: "<etag|release|doi|timestamp>"
  files:
    - path: "data/external/raw/<dataset_slug>/<file>"
      sha256: "<sha256>"
      size_bytes: <int>
```
</details>

---

## ğŸ§± Canonical pipeline placement

KFMâ€™s non-negotiable ordering (donâ€™t leapfrog stages):

```mermaid
flowchart LR
  A[ğŸ“¥ External Source] --> B[ğŸ§Š Raw Snapshot<br/>data/external/raw/<dataset_slug>/]
  B --> C[ğŸ§ª ETL / Normalize<br/>src/pipelines/...]
  C --> D[âœ… Processed Outputs<br/>data/external/processed/<dataset_slug>/]
  D --> E[ğŸŒ STAC<br/>data/stac/...]
  D --> F[ğŸ“š DCAT<br/>data/catalog/dcat/...]
  D --> G[ğŸ§¾ PROV<br/>data/prov/...]
  E --> H[ğŸ§  Graph Ingest<br/>src/graph/...]
  F --> H
  G --> H
  H --> I[ğŸ”Œ APIs<br/>src/server/...]
  I --> J[ğŸ—ºï¸ UI<br/>web/...]
```

### ğŸ›ï¸ ETL contract (what the pipeline must guarantee)

- Deterministic / idempotent outputs (same inputs â‡’ same outputs) âœ…
- Raw files are read-only snapshots âœ…
- All transforms are documented here (units, CRS, cleaning rules, joins) âœ…
- Outputs are cataloged (STAC/DCAT) + traced (PROV) âœ…

---

## ğŸŒ STAC mapping

> STAC is the **geospatial indexing layer**. Even â€œmostly non-spatialâ€ datasets often still get a Collection for consistency.

### ğŸ“Œ STAC targets

- Collection JSON: `../../../stac/collections/<stac_collection_id>.json`
- Item JSONs: `../../../stac/items/<stac_collection_id>/â€¦` *(or your projectâ€™s convention)*

### ğŸ§© Collection-level decisions

- `id`: `<stac_collection_id>`
- `title`: `<human_friendly_name>`
- `description`: `<what it is + why it matters>`
- `extent.spatial.bbox`: `<minx,miny,maxx,maxy>`
- `extent.temporal.interval`: `<start/end>`
- `license`: `<SPDX or "proprietary">`
- Providers/attribution: `<who created it, who hosts it, who processed it>`

### ğŸ“ Asset rules (what gets linked)

| Output asset | Location | STAC `assets` key | Media type | Roles | Notes |
|---|---|---|---|---|---|
| `<file>` | `../../processed/<dataset_slug>/â€¦` | `<asset_key>` | `<type>` | `<data|metadata|thumbnail>` | `<notes>` |

### ğŸ§¬ Field mapping (geometry + properties)

| Source field | Source type | Canonical meaning | STAC field/property | Transform | Notes |
|---|---|---|---|---|---|
| `<src_col>` | `<type>` | `<meaning>` | `properties.<name>` | `<rule>` | `<edge cases>` |

âœ… **Spatial normalization:** document CRS assumptions and any reprojection here.  
âœ… **Temporal normalization:** document time parsing rules + timezone assumptions here.

---

## ğŸ“š DCAT mapping

> DCAT is the **discovery layer** (catalog of datasets). Keep it high-level, with clean distribution links.

### ğŸ“Œ DCAT targets

- Dataset JSON-LD: `../../../catalog/dcat/<dataset_slug>.jsonld` *(or your convention)*

### ğŸ§© Dataset-level fields

- Title: `<title>`
- Description: `<description>`
- Keywords/themes: `<keywords>`
- Publisher: `<publisher>`
- Contact point: `<email or url>`
- License: `<license>`
- Spatial/temporal coverage: `<summary>`

### ğŸ“¦ Distributions (links out)

| Distribution | URL / Path | Format | Points to | Notes |
|---|---|---|---|---|
| STAC Collection | `data/stac/collections/<stac_collection_id>.json` | `application/json` | STAC | âœ… preferred |
| Direct download | `<https://â€¦>` | `<csv|geotiff|â€¦>` | Source/processed | include access notes |

---

## ğŸ§¾ PROV mapping

> PROV is the **lineage layer**: raw inputs â†’ activities â†’ outputs, with agents + parameters.

### ğŸ“Œ PROV targets

- Bundle location: `../../../prov/<dataset_slug>/â€¦` *(or per-run convention)*

### ğŸ§  Required lineage shape (minimum)

- **Entities**
  - `raw:<file-or-snapshot>` â€” raw input(s)
  - `proc:<output>` â€” processed outputs
  - `cfg:<config>` â€” pipeline config used
- **Activity**
  - `act:<run_id>` â€” the ETL run (with start/end time)
- **Agents**
  - `agent:person:<name>` (optional)
  - `agent:software:<pipeline_name>` (recommended)

### ğŸ§ª Run identity

| Field | Value |
|---|---|
| Run ID | `<run_id>` |
| Pipeline path | `src/pipelines/<â€¦>` |
| Commit hash | `<git_sha>` |
| Parameters/config | `<path or embedded json>` |
| Runtime environment | `<docker image tag, python env, etc.>` |

### ğŸ§© Transformation notes (human-readable)

- Inputs used: `<list>`
- Steps performed: `<cleaning, joins, reprojection, OCR, etc.>`
- Known limitations / uncertainty: `<missing fields, geocoding confidence, etc.>`

---

## ğŸ”— Cross-layer linkage checklist

- [ ] ğŸŒ STAC Items link to **real assets** in `data/**/processed/**` (or stable storage)
- [ ] ğŸ“š DCAT distributions link to **STAC and/or downloads**
- [ ] ğŸ§¾ PROV links **raw â†’ work â†’ processed** and references run/config/commit
- [ ] ğŸ§  Graph nodes reference catalog IDs (STAC/DCAT/DOI) instead of duplicating payloads
- [ ] ğŸ·ï¸ License + attribution are present at *every* relevant layer (STAC/DCAT + assets)

---

## ğŸ§ª Validation

### âœ… Minimum local sanity checks

- [ ] Raw snapshot exists and is immutable (no edits after ingest)
- [ ] Processed outputs are reproducible from raw + config
- [ ] STAC JSON validates against KFM STAC profile (and base STAC)
- [ ] DCAT JSON-LD validates against KFM DCAT profile (and DCAT)
- [ ] PROV bundle validates against KFM PROV profile (and PROV)

> ğŸ” Tip: check `tools/` + CI workflows for the canonical validators used in this repo.

### ğŸ§¯ Common failure modes

- Missing license / unclear terms
- STAC assets point to nonexistent paths
- DCAT distributions stale or broken
- PROV missing run identifiers or raw inputs
- Sensitive coordinates exposed without review/redaction

---

## âš–ï¸ Governance, FAIR+CARE, sovereignty

### ğŸ§· Classification + access

- Classification: `<public|internal|restricted>`
- Release constraints: `<none|redact|aggregate|delay|approval_required>`
- Review gate required? `<yes/no>` (explain trigger)

### ğŸª¶ CARE / sovereignty notes (if applicable)

- Community/tribal relevance: `<tbd>`
- Data handling constraints: `<tbd>`
- Redaction/generalization rules: `<tbd>`

### ğŸ§­ Ethical flags

- Sensitive locations? `<yes/no>`
- Personally identifying info (PII)? `<yes/no>`
- Dual-use risk? `<yes/no>`
- Mitigations applied: `<tbd>`

---

## ğŸ•°ï¸ Change log

| Date | Version | Change | Author |
|---|---:|---|---|
| 2026-01-29 | 0.1.0 | Initial mapping scaffold | `<name>` |
| `<YYYY-MM-DD>` | `<x.y.z>` | `<what changed>` | `<name>` |

---

## âœ… Definition of done

- [ ] Source links + terms/licensing captured
- [ ] Raw snapshot strategy documented (version/etag/hash + retrieval date)
- [ ] Field mapping documented (units/CRS/time parsing)
- [ ] âœ… Processed outputs exist in `data/external/processed/<dataset_slug>/`
- [ ] ğŸŒ STAC Collection + Items produced and validate
- [ ] ğŸ“š DCAT dataset produced and validate
- [ ] ğŸ§¾ PROV bundle produced and traces rawâ†’processed with run/config/commit
- [ ] Cross-links verified (STACâ†”DCATâ†”PROV)
- [ ] Governance section complete (classification + CARE/sovereignty + redaction rules)
- [ ] Change log updated
- [ ] Optional: `decisions.md` captures any non-obvious choices

---

## ğŸ”— Related KFM docs

- ğŸ“˜ Master pipeline + structure: `docs/MASTER_GUIDE_v13.md`
- ğŸ§± Repository structure standard: `docs/standards/KFM_REPO_STRUCTURE_STANDARD.md`
- ğŸ“ Markdown protocol: `docs/standards/KFM_MARKDOWN_WORK_PROTOCOL.md`
- ğŸŒ STAC profile: `docs/standards/KFM_STAC_PROFILE.md`
- ğŸ“š DCAT profile: `docs/standards/KFM_DCAT_PROFILE.md`
- ğŸ§¾ PROV profile: `docs/standards/KFM_PROV_PROFILE.md`
- âš–ï¸ Governance root: `docs/governance/ROOT_GOVERNANCE.md`
- ğŸª¶ Sovereignty: `docs/governance/SOVEREIGNTY.md`

---

### ğŸ™‹ Contacts

- Domain steward: `<name>`
- Data pipeline owner: `<name>`
- Governance reviewer: `<name or team>`

