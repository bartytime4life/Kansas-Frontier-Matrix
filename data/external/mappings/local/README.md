# ğŸŒ External Data â€” Local Mappings (ğŸ“ `data/external/mappings/local/`)

![domain](https://img.shields.io/badge/domain-external-2b6cb0?style=flat-square)
![scope](https://img.shields.io/badge/scope-local--only-orange?style=flat-square)
![artifacts](https://img.shields.io/badge/artifacts-mapping%20specs%20%2B%20examples-7b2cbf?style=flat-square)
![governance](https://img.shields.io/badge/requirement-provenance--first-success?style=flat-square)

> ğŸ“Œ **TL;DR**: This folder holds **developer/local mapping specs** for turning *external providers + APIs* (Earth Engine, OpenTopography, USDA soils, etc.) into **KFM-shaped outputs** â€” with **STAC/DCAT/PROV-ready metadata intent** and reproducible parameters.  
> âœ… Useful for experiments, adapters, edge/offline runs, and â€œprove the mappingâ€ work before promotion to governed/shared mappings.

---

## ğŸ§­ Why this exists

KFM treats **metadata + provenance as boundary artifacts** â€” required to move data forward in the pipeline.  
This directory is where we keep **local-only mapping documents** that describe:

- **What external source is being used** (provider / dataset / API endpoint / version)
- **How it maps into KFM expectations** (fields, CRS, units, identifiers, time semantics)
- **What â€œpublishedâ€ outputs should look like** (STAC/DCAT/PROV targets, attribution, license notes)
- **How to reproduce the fetch or query** (parameters + caching strategy + checksums)

> ğŸ§  Think of these mappings as **â€œrecipes for determinismâ€** when the upstream system is dynamic.

---

## ğŸ§± How it fits the KFM pipeline

```mermaid
flowchart LR
  A[ğŸŒ External Provider / API] --> B[ğŸ§¾ Mapping Spec<br/>THIS FOLDER]
  B --> C[ğŸ“¥ Fetch / Ingest<br/>raw/work or on-demand]
  C --> D[ğŸ§¹ Normalize + Transform<br/>data/processed/...]
  D --> E[ğŸ—‚ï¸ Publish Boundary Artifacts<br/>STAC + DCAT + PROV]
  E --> F[ğŸ§  Graph / DB]
  F --> G[ğŸ”Œ API Layer]
  G --> H[ğŸ—ºï¸ UI / Story Nodes]
```

**Non-negotiable concept**: *No shortcuts.* External data still must flow through the KFM ordering (even if the â€œrawâ€ step is an API request record).

---

## âœ… What belongs here

Store **local mapping artifacts** that help you reliably translate external data into KFM conventions:

- ğŸ§¾ **Mapping specs** (YAML/JSON) for field transforms, canonical IDs, CRS rules, units, normalization, join keys
- ğŸ§ª **Example requests** (saved params, bounding boxes, filters)
- ğŸ§¬ **Example responses** (small sanitized payloads) for regression tests
- ğŸ§  **Attribution + licensing notes** (what must show up in STAC/DCAT/labels)
- ğŸ—ºï¸ **Projection / CRS decisions** (and how to transform into KFMâ€™s chosen CRS)
- ğŸ” **Caching strategy notes** (what gets persisted into `data/processed/...` for reproducibility)

---

## ğŸš« What does *not* belong here

Keep this folder clean and safe:

- âŒ **Secrets / API keys / tokens** (use `.env`, secret manager, or local untracked config)
- âŒ **Large binaries** (rasters, huge GeoJSON) â€” those belong in `data/processed/...` or external storage with checksums
- âŒ **Narratives / Story content** (that belongs in `docs/reports/story_nodes/...`)
- âŒ **Ad-hoc fields that violate profiles** (extend profiles upstream instead of inventing new metadata keys)

---

## ğŸ—‚ï¸ Recommended local layout

You can structure these mappings in a provider-first way:

```text
ğŸ“ data/
â””â”€ ğŸ“ external/
   â””â”€ ğŸ“ mappings/
      â””â”€ ğŸ“¦ local/                                   ğŸ›ï¸ local/partner/API-driven mappings + examples
         â”œâ”€ ğŸ“„ README.md                              ğŸ“˜ overview + conventions for local mapping packs
         â”œâ”€ ğŸ“ opentopography/                        ğŸ—» OpenTopography workflows + request/response examples
         â”‚  â””â”€ ğŸ“ dem_county_fetch/                   ğŸ§­ county DEM pull + normalization contract
         â”‚     â”œâ”€ ğŸ§¾ mapping.yaml                     âœ… mapping pack (fields, params, outputs, validation)
         â”‚     â”œâ”€ ğŸ§ª example_request.json             ğŸ§ª example request payload (redact tokens/keys)
         â”‚     â”œâ”€ ğŸ§ª example_response.json            ğŸ§ª example response payload (trimmed/sanitized)
         â”‚     â””â”€ ğŸ“„ notes.md                         ğŸ“ caveats, rate limits, edge cases, troubleshooting
         â”œâ”€ ğŸ“ earth_engine/                          ğŸ›°ï¸ Google Earth Engine workflows (scripts/queries as mappings)
         â”‚  â””â”€ ğŸ“ ndvi_kansas_yearly/                 ğŸŒ¿ NDVI yearly aggregation for Kansas
         â”‚     â”œâ”€ ğŸ§¾ mapping.yaml                     âœ… mapping pack (collections, bands, reducers, exports)
         â”‚     â”œâ”€ ğŸ§ª example_request.json             ğŸ§ª example request/config (no credentials)
         â”‚     â””â”€ ğŸ“„ notes.md                         ğŸ“ assumptions, QA checks, export formats
         â””â”€ ğŸ“ usda_soils/                            ğŸŒ¾ USDA soils (SDA) query mappings + crosswalk notes
            â””â”€ ğŸ“ sda_component_query/                ğŸ§± soils component query â†’ KFM soils schema
               â”œâ”€ ğŸ§¾ mapping.yaml                     âœ… mapping pack (query, fields, types, domains)
               â”œâ”€ ğŸ§ª example_request.json             ğŸ§ª example query/request body (sanitized)
               â””â”€ ğŸ“„ notes.md                         ğŸ“ interpretation notes + known issues + validation tips
```

### ğŸ·ï¸ Naming conventions

Pick names that are stable and grep-friendly:

- **provider**: `opentopography`, `earth_engine`, `usda_soils`, `noaa`, `usgs`, etc.
- **mapping slug**: `product_or_query__region__timegrain` (or similar)
- **versioning**: add `v1`, `v2` in folder or inside mapping metadata (preferred: inside the mapping file)

---

## ğŸ§¾ Mapping spec checklist

When creating a new mapping spec, aim to cover these categories:

### 1) Source identity (who/what)
- Provider name + API/endpoint or dataset identifier
- Version / collection ID (if upstream provides one)
- Terms / license / attribution text requirements

### 2) Spatial semantics (where)
- Input CRS + output CRS
- Geometry type expectations (point/line/polygon/raster)
- Bounding rules (clipping, dissolve, simplification thresholds)
- Precision rules (rounding / coordinate tolerance)

### 3) Temporal semantics (when)
- Source time field(s), format, timezone assumptions
- â€œObservation timeâ€ vs â€œpublication timeâ€ vs â€œprocessing timeâ€
- Time granularity (daily/monthly/yearly/etc.)

### 4) Attribute mapping (what)
- Field rename mapping (source â†’ canonical)
- Units conversion rules
- Null handling + value standardization
- Join keys (if enriching from multiple external calls)

### 5) KFM publication intent (how it becomes â€œrealâ€)
- Target processed output type + path intent (`data/processed/...`)
- STAC item/collection expectations
- DCAT dataset/distribution expectations
- PROV activity + entities + agents expectations

---

## ğŸ§© Minimal mapping template (suggested)

> This is a *recommended* shape; adapt to your pipeline tooling, but keep it deterministic and auditable.

```yaml
# ğŸ§¾ mapping.yaml (local-only)
mapping_id: "earth_engine.ndvi_kansas_yearly.v1"
status: "local"         # local | shared | governed
owner: "@you"
created: "YYYY-MM-DD"

source:
  provider: "Google Earth Engine"
  kind: "api"
  dataset_or_product: "NDVI"
  endpoint_or_collection: "COPERNICUS/S2_SR"   # example
  notes: "Yearly NDVI composite for Kansas"

repro:
  request_template: "example_request.json"
  cache_policy:
    mode: "persist"     # persist | temp | none
    target_dir: "data/processed/external_cache/earth_engine/ndvi_kansas_yearly/"
  integrity:
    checksum: "sha256"  # what your pipeline should compute

spatial:
  input_crs: "EPSG:4326"
  output_crs: "EPSG:4326"
  clip_to: "Kansas"
  geometry: "raster"

attributes:
  id_fields:
    stable_id: "kfm_id"
    source_id: "gee_asset_id"
  fields:
    - source: "NDVI"
      target: "ndvi"
      type: "float"
      units: "unitless"
      null_policy: "drop"

publish_intent:
  stac:
    collection_id: "external_gee_ndvi"
    item_id_pattern: "external_gee_ndvi_{year}"
  dcat:
    dataset_id: "external-gee-ndvi-kansas"
  prov:
    activity_type: "external_api_fetch_and_transform"
    agent: "EarthEngineAdapter"
    record_request_params: true

governance:
  attribution_required: true
  license: "CHECK_SOURCE_TERMS"
  sensitive: false
```

---

## ğŸ” Secrets & credentials (do this, not that)

âœ… **Do**
- Put API keys in `.env` (or local secret tooling)  
- Keep credentials **out of git history**
- Log *non-secret* request parameters for reproducibility (bbox, dates, filters)

âŒ **Donâ€™t**
- Commit keys in mapping YAML/JSON
- Store tokens in example request files

---

## ğŸ§ª Promotion path: local â†’ shared/governed

Local mappings are where we iterate fast.  
But once a mapping powers official pipelines or UI features, promote it:

1. âœ… Ensure outputs can be reproduced (or cached deterministically)
2. âœ… Ensure STAC/DCAT/PROV fields align with project profiles
3. âœ… Add validations/tests (even lightweight fixture checks)
4. âœ… Move/duplicate into the governed/shared mapping location (project convention)
5. âœ… Update any domain runbook docs under `docs/data/...` as needed

> ğŸ§  Rule of thumb: if the UI or API depends on it, it shouldnâ€™t remain â€œlocal.â€

---

## ğŸ”— Related docs & standards

- ğŸ“„ `docs/MASTER_GUIDE_v13.md` â€” canonical repo structure + data lifecycle
- ğŸ“„ `docs/standards/KFM_STAC_PROFILE.md` â€” STAC profile expectations
- ğŸ“„ `docs/standards/KFM_DCAT_PROFILE.md` â€” DCAT profile expectations
- ğŸ“„ `docs/standards/KFM_PROV_PROFILE.md` â€” provenance model expectations
- ğŸ§· `schemas/` â€” validation schemas (STAC/DCAT/PROV/storynodes/etc.)
- ğŸ§­ `src/pipelines/` â€” ingestion + transformation pipelines (mapping consumers)
- ğŸ”Œ Integration/adapters layer â€” where external providers should be wrapped (e.g., `*Adapter` patterns)

---

## ğŸ§° Quick â€œnew mappingâ€ checklist

- [ ] Create provider folder (if missing) ğŸ“
- [ ] Create mapping slug folder ğŸ“
- [ ] Add `mapping.yaml` ğŸ§¾
- [ ] Add `example_request.json` ğŸ§ª
- [ ] Add small `example_response.json` (optional, sanitized) ğŸ§ª
- [ ] Write `notes.md` with edge cases + CRS + attribution ğŸ“„
- [ ] Confirm downstream intent: where processed output should live, and what metadata artifacts will be generated âœ…

---

## ğŸ§  Keep it boring (boring = reproducible)

If itâ€™s reproducible, itâ€™s governable.  
If itâ€™s governable, it can be shipped. ğŸš€

