# ğŸ§± USDA NRCS Soils (SSURGO / gSSURGO) â€” Local Mapping Runbook

`Source: USDA NRCS` `Dataset-family: SSURGO + gSSURGO` `Mode: ğŸŒ API-first` `Offline: ğŸ’¾ optional` `Domain: data/external`

> [!IMPORTANT]
> **KFM is â€œAPI-firstâ€ for soils.** Prefer querying SSURGO via Soil Data Access (SDA) by point/polygon and caching results, instead of committing/hauling massive shapefiles. Keep a local snapshot only when you truly need offline access or ultra-fast repeat queries.

---

## ğŸ¯ What this folder is

This folder holds **local mapping notes + conventions** for integrating USDA soils into the project (Kansas Frontier Matrix / KFM).

- âœ… Good fits here:
  - ETL/runbook docs, conventions, naming standards, caching rules
  - Local-only helper configs (not secrets), sample queries, schema notes
  - â€œHow we ingest/publish this datasetâ€ instructions

- ğŸš« Not ideal to store here:
  - Huge raw SSURGO packages / statewide gSSURGO databases (put those in `raw/` and/or external storage; keep Git lean)

---

## ğŸ§­ Canonical pipeline (KFM standard)

```mermaid
flowchart LR
  A[ğŸ“¥ raw] --> B[ğŸ§ª work]
  B --> C[âœ… processed]
  C --> D[ğŸ—‚ï¸ catalog + provenance]
  D --> E[ğŸ—„ï¸ database / tiles]
  E --> F[ğŸ”Œ API]
  F --> G[ğŸ—ºï¸ UI]
```

**Rule of thumb:** If you canâ€™t explain *where the soil layer came from* and *how it was transformed*, itâ€™s not ready to ship.

---

## ğŸ“¦ Recommended directory layout

This repo uses a â€œdata-domainâ€ pattern. For this dataset, the domain is `external`.

```text
ğŸ“ data/
â””â”€ ğŸŒ external/
   â”œâ”€ ğŸ—‚ï¸ raw/                                 ğŸ§¾ immutable source drops (read-only / never overwrite)
   â”‚  â””â”€ ğŸ§± usda_soils/                         ğŸ“¦ downloads (zip/fgdb/gpkg) â€” do not hand-edit
   â”œâ”€ ğŸ§ª work/                                ğŸ§° staging workspace (scratch + rebuildable)
   â”‚  â””â”€ ğŸ§± usda_soils/                         ğŸ§ª scratch/intermediates
   â”œâ”€ âœ… processed/                            âœ… curated outputs (downstream-ready)
   â”‚  â””â”€ ğŸ§± usda_soils/                         ğŸ§¼ cleaned/standardized outputs (GeoPackage/Parquet/etc.)
   â””â”€ ğŸ§­ mappings/                             ğŸ§© mapping packs + ETL/QA plans
      â””â”€ ğŸ  local/                             ğŸ›ï¸ local/partner/API-driven mappings
         â””â”€ ğŸ§± usda_soils/                      ğŸŒ¾ USDA soils mapping bundle
            â””â”€ ğŸ“„ README.md                     ğŸ‘ˆ you are here
```

> [!TIP]
> If youâ€™re unsure whether something belongs in `raw/` vs `processed/`:
> - **raw** = â€œas downloadedâ€
> - **processed** = â€œstandardized + validated + reproducibleâ€

---

## ğŸš€ Access modes

| Mode | Best for | What you store locally | Notes |
|---|---|---:|---|
| ğŸŒ **A. API-first (recommended)** | Point/polygon queries, interactive UI | Cached query outputs (small) | Lean + always current |
| ğŸ§Š **B. AOI / County cache** | Repeated use for same areas | AOI extracts + indexes | Great for Kansas county workflows |
| ğŸ“¦ **C. Bulk snapshot** | Offline workflows, heavy batch analytics | SSURGO zips or gSSURGO FGDB | Large; treat as â€œexternal storage + pointersâ€ |

---

## ğŸŒ Mode A: Soil Data Access (SDA) â€” minimal working recipe

### Endpoints (official)

```text
Tabular REST/POST (SQL + AOI services):
  https://SDMDataAccess.sc.egov.usda.gov/Tabular/post.rest

WFS (vector features):
  https://SDMDataAccess.sc.egov.usda.gov/Spatial/SDMWGS84Geographic.wfs   (EPSG:4326)
  https://SDMDataAccess.sc.egov.usda.gov/Spatial/SDMNAD83Geographic.wfs   (EPSG:4269)
  https://SDMDataAccess.sc.egov.usda.gov/Spatial/SDMWM.wfs                (EPSG:3857)

WMS (map images):
  https://SDMDataAccess.sc.egov.usda.gov/Spatial/SDM.wms
```

### Query Service (POST) â€” template

SDAâ€™s `post.rest` supports a **Query Service** where you POST parameters and receive XML/JSON.

```bash
SDA_POST="https://SDMDataAccess.sc.egov.usda.gov/Tabular/post.rest"

# NOTE: SDA expects POST parameters like service/request/query/format.
# Keep queries bounded: limit AOI, filter by areasymbol/mukey, etc.

curl -sS -X POST "$SDA_POST" \
  --data-urlencode "service=query" \
  --data-urlencode "request=query" \
  --data-urlencode "format=JSON" \
  --data-urlencode "query=SELECT TOP 5 * FROM mapunit;"
```

> [!IMPORTANT]
> Cache every API call you intend to reuse. Store:
> - request params (including the SQL)
> - response payload
> - timestamp + dataset version context
> - a short â€œwhy we pulled thisâ€

---

## ğŸ“¦ Mode C: Bulk datasets (SSURGO + gSSURGO)

### SSURGO (vector + tabular packages)
- Distributed as **soil survey areas** (often county-sized, but not always).
- Typical bulk export includes spatial + tabular + metadata.

### gSSURGO (statewide / CONUS)
- Packaged as an **ESRI file geodatabase** with statewide extents.
- Includes a gridded/raster layer derived from SSURGO and retains tabular attributes.
- Heavier than SSURGO AOI pulls, but efficient for statewide modeling.

> [!CAUTION]
> Bulk soils datasets can be **large**. Prefer:
> - storing them outside Git (object storage / shared drive)
> - committing only **checksums + manifests + metadata**
> - using Git LFS only if the repo policy supports it

---

## ğŸ§ª Processing expectations (when you *do* store local data)

When materializing local soil layers, use this checklist:

### âœ… Transform rules
- **Reproject** into the repoâ€™s standard CRS (or clearly document exceptions).
- **Standardize outputs** into project-friendly formats (e.g., GeoPackage, Parquet).
- **Clip / tile** to Kansas AOIs when possible (donâ€™t carry CONUS unless you need it).
- **Validate** geometry + schema (no invalid polys, no broken joins, no empty AOIs).

### ğŸ§¾ Metadata & provenance (non-negotiable)
Create/update:
- A dataset entry in the projectâ€™s catalog
- A provenance record describing:
  - source system (SDA / SSURGO zip / gSSURGO)
  - download date
  - query/AOI definition
  - processing steps + tool versions

---

## ğŸ§Š Caching & naming conventions

Cache files should be **stable + searchable**.

Suggested pattern:

```text
<source>__<product>__<aoi>__<crs>__<date>__<hash>.<ext>

Examples:
sda__mapunitpoly__kansas-allen__epsg4326__2026-01-29__a1b2c3.gpkg
sda__muaggatt__bbox_-96.75_38.85_-96.60_39.00__json__2026-01-29__d4e5f6.json
```

---

## ğŸ·ï¸ Attribution

Every published layer or UI panel that uses this data should include:
- â€œUSDA NRCS Soil Survey (SSURGO / gSSURGO)â€ attribution
- Retrieval mode (SDA vs bulk download)
- Retrieval date (or release date, if using a snapshot)

---

## âœ… QA quick checks

- [ ] AOI is correct (not flipped lat/lon; not wrong county)
- [ ] CRS is documented and consistent
- [ ] Joins resolve (map-unit keys or other join IDs actually match)
- [ ] Cache hit rate is high for repeated queries
- [ ] Any local snapshot has a manifest + checksum
- [ ] Provenance record exists and points to scripts/commands used

---

## ğŸ“š Glossary

- **SSURGO**: Soil Survey Geographic Database (detailed soil polygons + attributes).
- **gSSURGO**: Gridded SSURGO product (statewide/CONUS-friendly packaging; includes rasterized layers).
- **SDA**: Soil Data Access web services (SQL query + AOI + WFS/WMS endpoints).

---

## ğŸ§© Project integration notes (KFM)

- Implement/extend a **SoilDataAdapter** that:
  - accepts point/polygon AOIs
  - queries SDA (preferred)
  - writes deterministic caches into `data/.../processed/` (or `external_cache/` if used)
  - emits metadata/provenance updates as part of the pipeline

> [!TIP]
> If youâ€™re building â€œsoil summariesâ€ for the UI: store the *raw authoritative response* + a *derived, human-readable summary* side-by-side, and keep the derivation reproducible.

---

