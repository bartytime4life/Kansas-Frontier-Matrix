# ğŸ§© External Dataset Mappings (Ingestion Contracts)

![KFM](https://img.shields.io/badge/KFM-Data%20Contracts-2ea44f?style=for-the-badge)
![Deterministic](https://img.shields.io/badge/Deterministic-Pipelines-blue?style=for-the-badge)
![Provenance](https://img.shields.io/badge/Provenance-STAC%20%7C%20DCAT%20%7C%20PROV-purple?style=for-the-badge)
![No Secrets](https://img.shields.io/badge/ğŸš«%20No%20Secrets-in%20repo-critical?style=for-the-badge)

This folder contains **mapping specs** that translate **external data sources** (CSV/GeoJSON/Shapefile/GeoPackage/COG/etc.) into **KFMâ€™s canonical schemas**.  
Think of these as **ingestion contracts**: config-driven, versioned, and reproducible. âœ…

> ğŸ¯ Goal: make â€œadd a new datasetâ€ mostly a **configuration change** (plus raw data + provenance), not a bespoke code rewrite.

---

## ğŸ—‚ï¸ What belongs here

âœ… **YES** â€” small, versioned, reviewable â€œcontractsâ€:

- `*.yml` / `*.yaml` / `*.json` mapping specs (preferred: YAML for readability)
- Value crosswalks (small): `*.csv` / `*.tsv` (e.g., code âœ label)
- Field dictionaries / rename tables
- CRS/geometry hints that help normalize spatial data
- QA rules / expectations for the pipeline (ranges, not-null, allowed enums)
- Licensing + attribution references (or pointers to where those live)

ğŸš« **NO** â€” not in this folder:

- Raw datasets (put under `data/raw/<domain>/...`)
- Intermediate artifacts (put under `data/work/<domain>/...`)
- Final outputs (put under `data/processed/<domain>/...`)
- UI styling (`style.json`, MapLibre layer styling) â€” belongs in `web/` (or equivalent UI config home)
- Credentials / API keys / tokens (use env vars or secrets management)

---

## ğŸ§­ Where this fits in the KFM pipeline

```mermaid
flowchart LR
  A["ğŸŒ External Source<br/>(download/API/export)"] --> B["ğŸ“¥ Raw intake<br/>data/raw/<domain>/..."]
  B --> C["ğŸ§© Mapping spec<br/>data/external/mappings/..."]
  C --> D["ğŸ§¼ ETL + Normalize<br/>(pipelines)"]
  D --> E["ğŸ“¦ Processed outputs<br/>data/processed/<domain>/..."]
  E --> F["ğŸŒ Catalogs<br/>STAC + DCAT + PROV"]
  F --> G["ğŸ—„ï¸ Datastores<br/>PostGIS / Neo4j"]
  G --> H["ğŸ§° API"]
  H --> I["ğŸ—ºï¸ UI + Story Nodes"]
```

> ğŸ”’ Invariant: **no stage leapfrogs** the prior stage. Mappings are part of making ingestion deterministic and auditable.

---

## ğŸ“ Suggested folder layout

Use either **source-first** or **domain-first**. Pick one and stay consistent.

### Option A â€” Source-first (recommended when many domains share one provider)

```
ğŸ“ data/
â””â”€ ğŸ“ external/
   â””â”€ ğŸ“ mappings/                              ğŸ§© mapping packs + crosswalks for external sources
      â”œâ”€ ğŸ“¦ usgs/                               ğŸ›°ï¸ USGS-derived mappings (hydro, elevation, imagery, etc.)
      â”‚  â”œâ”€ ğŸ§© nhd_flowlines__v1.0.0.yml         ğŸ§  NHD flowlines â†’ KFM canonical hydro schema mapping
      â”‚  â””â”€ ğŸ“„ README.md                        â—»ï¸ optional source notes + quirks + validation guidance
      â”œâ”€ ğŸ“¦ census/                             ğŸ§® U.S. Census / TIGER-derived boundary & tabular mappings
      â”‚  â”œâ”€ ğŸ§© tiger_counties__v1.0.0.yml         ğŸ—ºï¸ TIGER counties â†’ KFM admin-boundary schema mapping
      â”‚  â””â”€ ğŸ§© tiger_tracts__v1.0.0.yml           ğŸ§­ TIGER tracts â†’ KFM census-tract schema mapping
      â””â”€ ğŸ“¦ local/                              ğŸ›ï¸ County/city/local partner mappings + bespoke crosswalks
         â”œâ”€ ğŸ§© county_parcels__v0.3.0.yml         ğŸ§¾ Local parcels â†’ KFM parcel schema mapping (iterating)
         â””â”€ ğŸ§¾ crosswalk_parcel_use_codes.csv     ğŸ” Parcel use codes â†’ KFM land-use domain crosswalk
```

### Option B â€” Domain-first (recommended when domains are â€œownedâ€ by stewards)

```
ğŸ“ data/
â””â”€ ğŸ“ external/
   â””â”€ ğŸ“ mappings/                                   ğŸ§© mapping packs for external thematic sources
      â”œâ”€ ğŸ›ï¸ historical/                               ğŸ“œ historical documents â†’ KFM canonical schemas
      â”‚  â””â”€ ğŸ§© land_treaties_sourceX__v1.0.0.yml        ğŸ§­ Land treaties (Source X) â†’ KFM treaty/land-cession mapping
      â”œâ”€ ğŸŒ¾ agriculture/                               ğŸšœ agriculture datasets â†’ KFM soils/crops/land-use schemas
      â”‚  â””â”€ ğŸ§© sda_soils__v2.1.0.yml                    ğŸ§± Soil survey (SDA) â†’ KFM soils + attributes mapping
      â””â”€ ğŸŒ¦ï¸ climate/                                   ğŸŒ climate grids/time-series â†’ KFM climate schema mapping
         â””â”€ ğŸ§© prism_precip__v1.2.0.yml                 ğŸ’§ PRISM precipitation â†’ KFM climate-precip mapping
```

---

## ğŸ·ï¸ Naming rules (please follow)

**Filename format (recommended):**

`<source>__<dataset>__v<MAJOR.MINOR.PATCH>.yml`

Examples:
- `usgs__nhd_flowlines__v1.0.0.yml`
- `census__tiger_counties__v1.1.0.yml`
- `local__county_parcels__v0.3.0.yml`

**Why?**
- Helps review diffs
- Makes reproducibility easy
- Supports deterministic rebuilds (â€œre-run v1.0.0 mapping against the same raw inputâ€)

---

## ğŸ§¾ Mapping spec: minimal required fields

> This is a pragmatic schema. If/when a canonical JSON Schema exists in `schemas/`, treat that as the source of truth. âœ…

### Minimal contract (YAML)

```yaml
id: usgs__nhd_flowlines
version: 1.0.0

source:
  name: "USGS NHD"
  homepage: "https://www.usgs.gov/"
  license: "Public Domain (verify per dataset)"
  retrieved_at: "2026-01-29"   # ISO date preferred
  citation: "See data/sources/usgs_nhd.md (or equivalent)"

target:
  domain: hydrography
  canonical_schema: "schemas/domains/hydrography/flowline.schema.json"
  output_dataset: "data/processed/hydrography/nhd_flowlines/"

spatial:
  geometry_type: "LineString"
  crs_epsg: 4269   # example: NAD83
  enforce_valid_geometries: true

primary_key:
  source_field: "NHDPlusID"
  target_field: "flowline_id"

field_map:
  flowline_id: "NHDPlusID"
  name: "GNIS_NAME"
  ftype: "FTYPE"
  fcode: "FCODE"
  length_km: "LENGTHKM"

transforms:
  - field: "length_km"
    op: "to_float"
  - field: "name"
    op: "trim"

qa:
  not_null: ["flowline_id"]
  ranges:
    length_km: { min: 0 }

governance:
  sensitivity: "public"  # public | internal | restricted
  notes: "Downstream artifacts must not be less restricted than inputs."
```

---

## ğŸ” Versioning expectations

âœ… **Do:**
- Bump `MAJOR` when the mapping changes meaningfully (field semantics, geometry logic, keys)
- Bump `MINOR` when adding new mapped fields in a backward-compatible way
- Bump `PATCH` for bugfixes (typos, safe transform fixes)

ğŸš« **Donâ€™t:**
- Edit an already-published mapping **in place** if it has produced published outputs  
  â†’ create a new version file and re-run the pipeline.

---

## âœ… â€œDefinition of Doneâ€ for adding a new external mapping

When you add a mapping spec here, the corresponding dataset work should usually include:

- [ ] Raw source landed under `data/raw/<domain>/...` (or referenced via stable retrieval method)
- [ ] Mapping spec created in this folder (versioned + reviewed)
- [ ] Pipeline run produces outputs under `data/processed/<domain>/...`
- [ ] STAC Collection + Item(s) created/updated (`data/stac/...`)
- [ ] DCAT dataset entry created/updated (`data/catalog/dcat/...`)
- [ ] PROV lineage bundle created/updated (`data/prov/...`) referencing:
  - inputs (raw)
  - activity (pipeline run)
  - outputs (processed)
  - **this mapping file** as a configuration artifact âœ…
- [ ] Licensing + attribution validated and preserved end-to-end
- [ ] Sensitivity tags (CARE/FAIR) reviewed where applicable

---

## ğŸ§ª QA & validation (recommended patterns)

### 1) Structural validation
- Ensure required top-level keys exist (`id`, `version`, `source`, `target`, `field_map`).
- Ensure `version` is valid SemVer.

### 2) Schema validation
- `canonical_schema` should exist and be versioned
- mapped fields should be valid for the target schema

### 3) Data validation (during ETL)
- geometry validity checks (fix or reject)
- CRS normalization + explicit `EPSG`
- expected ranges, enums, nullability
- record count sanity checks (optional but useful)

<details>
<summary>ğŸ§° Suggested â€œmapping lintâ€ checklist</summary>

- [ ] No duplicate target fields in `field_map`
- [ ] No silent drops of required fields
- [ ] Primary key is stable + unique
- [ ] All transforms are deterministic (no time-based randomness)
- [ ] Unit conversions documented (feetâœmeters, acresâœhectares, etc.)
- [ ] Enumerations/crosswalks are versioned (CSV committed)
- [ ] Any redactions/aggregations are explicit + justified
</details>

---

## ğŸ” Governance, licensing, and sovereignty (non-negotiable)

- **No secrets** in mapping specs (tokens, passwords, signed URLs).
- **Respect licenses**: mapping a dataset does *not* remove attribution requirements.
- **Restriction propagation**: outputs must be **â‰¥** the restriction level of inputs.
- For culturally sensitive data, prefer:
  - aggregation/generalization
  - access controls via API layer
  - explicit labeling in metadata

> ğŸ§­ If youâ€™re unsure, treat it as **restricted** until reviewed.

---

## ğŸ§  Tips for maintainers

- Keep mappings **small and boring** ğŸ˜„ â€” the boring part is what makes them reproducible.
- If a mapping starts to grow â€œlogic tentacles,â€ consider:
  - extracting transforms into a reusable pipeline step
  - keeping the mapping as a contract and moving heavy logic to code (still deterministic!)
- Prefer explicit `crs_epsg` and documented assumptions; donâ€™t rely on â€œwhatever the file says.â€

---

## ğŸ“Œ FAQ

**Q: Why is this in `data/` instead of `src/`?**  
A: These mappings are **data contracts** that evolve alongside datasets and provenance. Theyâ€™re reviewed and versioned like data artifacts.

**Q: Can I store MapLibre styles here?**  
A: Please donâ€™t. UI styling belongs in the UI subsystem (`web/` or equivalent). This folder is about **ingestion + normalization**.

**Q: What if a source provides multiple variants (county vs statewide extracts)?**  
A: Treat them as different dataset IDs or different versionsâ€”whichever reflects reality more clearly. Consistency beats cleverness.

---

## ğŸ”— Related (project conventions)

- `data/raw/` â†’ immutable source intake  
- `data/work/` â†’ intermediate processing  
- `data/processed/` â†’ served outputs  
- `data/stac/`, `data/catalog/dcat/`, `data/prov/` â†’ publication â€œboundary artifactsâ€  
- `schemas/` â†’ canonical schema contracts

---

*Last updated:* **2026-01-29** ğŸ—“ï¸

