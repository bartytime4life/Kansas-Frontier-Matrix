<a id="top"></a>

<div align="center">

# ğŸ“‘ `data/reports/` â€” KFM Data Reports (Evidence Outputs)

![KFM](https://img.shields.io/badge/KFM-Kansas%20Frontier%20Matrix-222222)
![Artifacts](https://img.shields.io/badge/artifacts-reports%20%7C%20figures%20%7C%20tables-0B7285)
![Traceability](https://img.shields.io/badge/traceability-STAC%20%7C%20DCAT%20%7C%20PROV-6F42C1)
![Atomic Publish](https://img.shields.io/badge/publish-atomic%20bundle%20or%20nothing-0B7285)
![Governance](https://img.shields.io/badge/governance-FAIR%20%2B%20CARE-blueviolet)
![Rule](https://img.shields.io/badge/rule-no%20mystery%20outputs-red)

**A governed home for reviewable analysis outputs** (PDF/MD/HTML/figures/tables/export bundles) **derived from certified KFM datasets** â€” when those outputs need to be reviewed, shared, cited, shipped, or audited. ğŸ§­ğŸ§¾

</div>

> [!IMPORTANT]
> **Reports do not bypass the pipeline.**  
> Canonical ordering (nonâ€‘negotiable): **ETL â†’ Catalogs (STAC/DCAT/PROV) â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**.  
> If a report becomes **public-facing** or **decision-significant**, it must be **discoverable + traceable** through the catalogs (**STAC/DCAT/PROV**) and served via the contracted **API boundary** (never UI â†’ Neo4j direct). ğŸ”ğŸ§¾

---

## âš¡ Quick links

### Evidence chain (what reports must point to)
- ğŸ“¥ Raw inputs (immutable) â†’ [`../raw/`](../raw/)
- ğŸ§° Workbench (WIP / experiments) â†’ [`../work/`](../work/)
- ğŸ“¦ Certified datasets (publish-ready files) â†’ [`../processed/`](../processed/)
- ğŸ›°ï¸ STAC (asset indexing) â†’ [`../stac/`](../stac/) Â· [`../stac/collections/`](../stac/collections/) Â· [`../stac/items/`](../stac/items/)
- ğŸ—‚ï¸ DCAT (dataset discoverability) â†’ [`../catalog/dcat/`](../catalog/dcat/)
- ğŸ§¬ PROV (lineage bundles) â†’ [`../prov/`](../prov/)

### System neighbors (where reports get consumed)
- ğŸ§  Graph build/runtime (if present) â†’ `src/graph/` or `graph/` *(repo-dependent)*
- ğŸ”Œ API boundary (governed access) â†’ `api/` *(preferred in project docs)* or `src/server/` *(if your repo uses that layout)*
- ğŸ–¥ï¸ UI client â†’ `web/`
- ğŸ¬ Story Nodes (runtime/editorial; repo-dependent) â†’ `web/story_nodes/` *(preferred in project docs)* and/or `docs/reports/story_nodes/`

### Upstream metadata (nice-to-have if your repo uses it)
- ğŸ§¾ External dataset manifests â†’ `data/sources/` *(if present)*

### Governance & security
- ğŸ” Security policy / reporting â†’ [`../../SECURITY.md`](../../SECURITY.md) *(or `../../.github/SECURITY.md` if thatâ€™s your canonical location)*
- âœ… CI/QA helpers â†’ `tools/` *(if present)*

---

<details>
<summary><strong>ğŸ“Œ Table of contents</strong></summary>

- [ğŸ§­ What this folder is](#-what-this-folder-is)
- [âœ… What belongs here (and what does not)](#-what-belongs-here-and-what-does-not)
- [ğŸ§© Report taxonomy](#-report-taxonomy)
- [ğŸ§± Where reports fit in the KFM pipeline](#-where-reports-fit-in-the-kfm-pipeline)
- [ğŸ§­ â€œWhere should I put this?â€ decision guide](#-where-should-i-put-this-decision-guide)
- [ğŸ—‚ï¸ Directory layout](#ï¸-directory-layout)
- [ğŸ§¾ Report bundle contract (minimum required)](#-report-bundle-contract-minimum-required)
- [ğŸ§· IDs, naming, and â€œatomic publishâ€](#-ids-naming-and-atomic-publish)
- [ğŸ”— Traceability rules (STAC â†” DCAT â†” PROV â†” Graph)](#-traceability-rules-stac--dcat--prov--graph)
- [ğŸ§ª Reproducibility & scientific integrity](#-reproducibility--scientific-integrity)
- [ğŸ” Security, privacy & sensitive-location handling](#-security-privacy--sensitive-location-handling)
- [âœ… Validation & CI/CD expectations](#-validation--cicd-expectations)
- [ğŸ“š Reference shelf (project library)](#-reference-shelf-project-library)
- [ğŸ•°ï¸ Version history](#-version-history)

</details>

---

## ğŸ§­ What this folder is

`data/reports/` is the canonical place for **reviewable, shareable outputs** derived from KFM data â€” **when the output is not itself the canonical dataset**.

Reports are typically:
- ğŸ“Š *summaries* (EDA, trends, comparisons, diagnostics)
- ğŸ§  *model artifacts* (metrics, calibration, residual plots, posterior summaries)
- ğŸ§ª *simulation outputs* (verification/validation notes, sensitivity analyses, uncertainty runs)
- ğŸ§¼ *validation outputs* (schema checks, geometry validity summaries, link checks, QA diffs)
- ğŸ“¦ *audit bundles* (what a reviewer needs to approve a dataset change)

> [!NOTE]
> This folder is **optional** in the abstract, but the discipline is not.  
> If you keep long-lived analytical artifacts, keep them **provenance-linked**, **reproducible**, and **classification-aware**.

---

## âœ… What belongs here (and what does not)

| âœ… Put it in `data/reports/` whenâ€¦ | ğŸš« Donâ€™t put it here whenâ€¦ |
|---|---|
| You created a PDF/MD/HTML report with charts/tables meant for review, citation, or audit | The output is a **final dataset** meant for downstream computation (â†’ `data/processed/`) |
| You exported figures/tables summarizing a certified dataset version | Youâ€™re storing raw downloads or â€œas receivedâ€ archives (â†’ `data/raw/`) |
| You generated a QA/validation summary you need to keep long-term | Itâ€™s an intermediate transform / scratch join (â†’ `data/work/`) |
| You produced an â€œapproval packetâ€ for maintainers (what changed + impact) | Youâ€™re writing narrative Story content (â†’ `web/story_nodes/` and/or `docs/reports/story_nodes/`) |
| The report is referenced by a Story Node or UI feature **and** you can link it to evidence IDs | It contains secrets/PII/restricted coordinates without protection (â†’ stop, redact, follow governance/security) |

---

## ğŸ§© Report taxonomy

Use this taxonomy to keep report intent consistent (and CI-checkable):

| Type | Examples | Typical audience | Traceability requirement |
|---|---|---|---|
| ğŸ§¼ QA / validation | schema compliance, geometry validity, link checks, catalog QA diffs | maintainers + reviewers | **Required** if used to approve/publish |
| ğŸ“ˆ EDA / analytics | distributions, time-series charts, anomaly summaries | analysts + contributors | Required if cited in Story/UI |
| ğŸ§  Modeling | regression diagnostics, Bayesian posterior plots, drift checks | analysts + maintainers | **Required** (STAC/DCAT/PROV pointers) |
| ğŸ§ª Simulation & V&V | verification notes, sensitivity runs, UQ summaries | analysts + stewards | **Required** for decision-significant outputs |
| ğŸ¨ Cartographic exports | map sheets, legend comps, print layouts, thumbnails | UI/story maintainers | Required if shipped |
| ğŸ“¦ Release evidence bundles | â€œwhat changed / why / impactâ€ with links | maintainers | **Required** for releases |

> [!TIP]
> If the report is going to influence a decision, treat it like a dataset: **IDs, lineage, checksums, and review gates**. âœ…

---

## ğŸ§± Where reports fit in the KFM pipeline

```mermaid
flowchart LR
  ETL["ğŸ§° ETL / Pipelines"] --> CAT["ğŸ—‚ï¸ Catalogs (STAC â€¢ DCAT â€¢ PROV)"]
  CAT --> GRAPH["ğŸ•¸ï¸ Graph (Neo4j)"]
  GRAPH --> API["ğŸ”Œ API Boundary"]
  API --> UI["ğŸ–¥ï¸ UI (Map / Timeline)"]
  UI --> STORY["ğŸ¬ Story Nodes"]
  STORY --> FOCUS["ğŸ§  Focus Mode"]

  REP["ğŸ“‘ data/reports/ (optional)"] -. "references evidence IDs" .-> CAT
  REP -. "can be cited by" .-> STORY
```

**Interpretation:** reports are downstream artifacts that should point back to the canonical evidence chain (**catalogs + provenance**) instead of becoming â€œshadow datasets.â€

---

## ğŸ§­ â€œWhere should I put this?â€ decision guide

```mermaid
flowchart TB
  A["I produced an output artifact"] --> B{Is it a canonical dataset?}
  B -->|Yes| C["â¡ï¸ data/processed/<domain>/... + STAC/DCAT/PROV"]
  B -->|No| D{Is it a raw input snapshot?}
  D -->|Yes| E["â¡ï¸ data/raw/<domain>/... (append-only)"]
  D -->|No| F{Is it intermediate/scratch?}
  F -->|Yes| G["â¡ï¸ data/work/<domain>/... (rebuildable)"]
  F -->|No| H{Is it a reviewable summary/figure/audit bundle?}
  H -->|Yes| I["â¡ï¸ data/reports/<domain>/... (this folder)"]
  H -->|No| J["â¡ï¸ docs/ (specs) or CI artifacts (ephemeral)"]
```

---

## ğŸ—‚ï¸ Directory layout

> [!TIP]
> Keep bundles **small + reviewable**.  
> For large binaries: use pointers + checksums + external storage (DVC/LFS/object storage/releases), but keep the **manifest + README** in Git.

```text
ğŸ“ data/
â””â”€â”€ ğŸ“ reports/
    â”œâ”€â”€ ğŸ“„ README.md                      ğŸ‘ˆ you are here
    â”œâ”€â”€ ğŸ“ registry/                      â­ recommended (discoverability)
    â”‚   â”œâ”€â”€ ğŸ“„ reports_index.md            (human index: browse + links)
    â”‚   â””â”€â”€ ğŸ“„ reports_registry.csv        (machine index: filter/sort/ingest)
    â”œâ”€â”€ ğŸ“ <domain>/
    â”‚   â”œâ”€â”€ ğŸ“„ README.md                  â­ recommended (domain index)
    â”‚   â””â”€â”€ ğŸ“ <YYYY-MM-DD>__<slug>__v<semver>/
    â”‚       â”œâ”€â”€ ğŸ“„ README.md              âœ… required (bundle â€œreport cardâ€)
    â”‚       â”œâ”€â”€ ğŸ“„ REPORT_MANIFEST.json   â­ recommended (machine-readable)
    â”‚       â”œâ”€â”€ ğŸ“„ checksums.sha256       â­ recommended (integrity)
    â”‚       â”œâ”€â”€ ğŸ“„ report.md              (optional)
    â”‚       â”œâ”€â”€ ğŸ“„ report.pdf             (optional)
    â”‚       â”œâ”€â”€ ğŸ“ assets/                (figures, maps, thumbnails)
    â”‚       â”œâ”€â”€ ğŸ“ tables/                (csv/parquet extracts; keep small)
    â”‚       â”œâ”€â”€ ğŸ“ notebooks/             (ipynb / qmd / rmd)
    â”‚       â””â”€â”€ ğŸ“ refs/                  â­ recommended (evidence pointers)
    â”‚           â”œâ”€â”€ ğŸ“„ stac_refs.txt
    â”‚           â”œâ”€â”€ ğŸ“„ dcat_refs.txt
    â”‚           â””â”€â”€ ğŸ“„ prov_refs.txt
    â””â”€â”€ ğŸ“ _shared/                       (optional; avoid unless truly cross-domain)
        â””â”€â”€ ğŸ“„ README.md
```

---

## ğŸ§¾ Report bundle contract (minimum required)

Every report bundle should be auditable like a dataset drop: **human context + machine pointers + integrity**.

| Artifact | Required | Why | Minimum â€œgood enoughâ€ |
|---|---:|---|---|
| `README.md` | âœ… | Human-friendly report card | summary, scope, inputs, outputs, caveats, how to reproduce |
| `REPORT_MANIFEST.json` | â­ recommended | Machine-readable linkage | evidence IDs (STAC/DCAT), PROV activity IDs, file list, checksums |
| `checksums.sha256` | â­ recommended | Tamper-evidence + portability | sha256 for report outputs (and any included tables/figures) |
| `refs/*.txt` | â­ recommended | Evidence pointers (no â€œorphan factsâ€) | list of IDs/paths to STAC/DCAT/PROV used |

> [!IMPORTANT]
> If the report is referenced by a Story Node, a UI feature, or a release note: **evidence pointers become mandatory**.

---

## ğŸ§· IDs, naming, and â€œatomic publishâ€

### âœ… Report ID (stable join key)
Use a stable `report_id` that can be referenced in:
- PR discussions / reviews
- release notes
- Story Nodes
- Graph nodes (as a lightweight evidence pointer)

Suggested pattern:
```text
kfm.report.<domain>.<slug>.v<semver>
# example:
kfm.report.environment.ndvi_qc_summary.v1.2.0
```

### âœ… Bundle folder naming (sortable + grep-friendly)
```text
data/reports/<domain>/<YYYY-MM-DD>__<slug>__v<semver>/
# example:
data/reports/environment/2026-01-12__ndvi-qc-summary__v1.2.0/
```

### ğŸ”’ Atomic publish rule (carry-over from pipeline discipline)
If a report is part of approving or shipping a dataset version:
- **publish as a bundle** (README + manifest + checksums + refs)
- link to the exact dataset version (STAC/DCAT) and lineage (PROV)
- avoid partial updates that leave reviewers guessing

> [!TIP]
> â€œAtomic publishâ€ for reports means: **if the report references evidence, it ships with the pointers and integrity metadataâ€”every time.** âœ…

---

## ğŸ”— Traceability rules (STAC â†” DCAT â†” PROV â†” Graph)

### âœ… Golden rule: pointers > copies ğŸ§·
- Reports should **reference** certified datasets via stable IDs (**STAC/DCAT**) and lineage via **PROV**.
- Avoid duplicating large datasets in report bundles (unless itâ€™s a tiny, explicitly justified review extract).

### âœ… Minimum pointer set (recommended)
A report bundle should be able to answer:

1) **What inputs?** â†’ STAC/DCAT IDs (or paths resolving to them)  
2) **How generated?** â†’ PROV activity/bundle ID (plus run config/commit where possible)  
3) **What outputs?** â†’ files in this bundle + checksums  
4) **Can we reproduce?** â†’ entrypoint + pinned environment

### ğŸ§© `REPORT_MANIFEST.json` starter (copy/paste)

```json
{
  "report_id": "kfm.report.<domain>.<slug>.v1.0.0",
  "title": "Human-readable report title",
  "domain": "<domain>",
  "created": "2026-01-12",
  "classification": "public|internal|confidential|restricted",
  "summary": "1â€“3 sentences explaining why this report exists.",

  "evidence": {
    "stac": ["path:data/stac/items/<...>.json", "path:data/stac/collections/<...>.json"],
    "dcat": ["path:data/catalog/dcat/<...>.jsonld"],
    "prov": ["path:data/prov/<...>.jsonld"]
  },

  "methods": {
    "type": ["eda|regression|bayesian|simulation|qa|cartography"],
    "tools": ["python", "r", "qgis", "gee", "postgis"],
    "notes": "Keep it short; point to README for narrative."
  },

  "repro": {
    "commit_sha": "TBD",
    "entrypoint": "notebooks/report.ipynb",
    "seeds": [42],
    "environment": {
      "method": "pip|conda|docker",
      "lockfiles": ["requirements.txt", "poetry.lock", "environment.yml"],
      "notes": "Pin deps; record runtime + hardware notes if relevant."
    }
  },

  "outputs": [
    { "path": "report.pdf", "media_type": "application/pdf", "sha256": "TBD" },
    { "path": "assets/figure-01.png", "media_type": "image/png", "sha256": "TBD" }
  ]
}
```

### ğŸŒ If a report becomes a â€œshipped evidence assetâ€
Pick one pattern (repo-specific, but keep it deterministic):

- **Pattern A â€” Add report files as STAC Assets** on an existing STAC Item  
  Best when the report documents a specific dataset version/time slice.
- **Pattern B â€” Dedicated STAC Item for the report**  
  Best when the report is a standalone evidence product (e.g., release audit bundle).

Either way:
- add (or update) a **DCAT distribution** for discoverability
- ensure **PROV links** â€œinputs â†’ activity â†’ report outputsâ€
- keep access mediated via **API** if classification requires

---

## ğŸ§ª Reproducibility & scientific integrity

Reports are where â€œit looked right on my machineâ€ goes to die â˜ ï¸ â€” unless we keep them reproducible.

### âœ… Baseline integrity checklist
- [ ] Inputs are certified (prefer `data/processed/<domain>/` + evidence IDs)
- [ ] Sampling/filtering is explained (time window, AOI, inclusion criteria)
- [ ] Metrics/criteria are stated *before* conclusions (avoid post-hoc storytelling)
- [ ] Modeling includes diagnostics/uncertainty (not just point estimates)
- [ ] Simulation includes V&V notes and at least one sensitivity check (when applicable)
- [ ] Outputs are checksummed and versioned
- [ ] Conclusions separate **facts vs interpretation**
- [ ] If AI-assisted: label it and keep every claim evidence-linked (no â€œfree-floatingâ€ summaries)

### ğŸ“Œ Recommended â€œreport cardâ€ headings (`README.md` inside each bundle)
```text
# Report title
## Why this report exists (intent)
## Inputs (STAC/DCAT IDs)
## Methods (tools, parameters, assumptions)
## Outputs (files + checksums)
## Findings (with links to figures/tables)
## Uncertainty / limitations
## Sensitivity / governance notes
## How to reproduce (commands + env)
```

---

## ğŸ” Security, privacy & sensitive-location handling

Reports can leak sensitive information even if the underlying dataset is protected (aggregation + joins can re-identify a place). Treat this as first-class risk. ğŸ§¨

### Hard rules
- ğŸš« No secrets, tokens, credentials, private keys (ever)
- ğŸš« No restricted coordinates or culturally sensitive locations without explicit review
- âœ… Preserve (or increase) classification â€” never â€œdowngradeâ€ sensitivity through reporting
- âœ… When in doubt: generalize (coarse bbox), redact, or keep internal

> [!IMPORTANT]
> If a report involves security-sensitive findings, follow coordinated disclosure (`SECURITY.md`) and do **not** post exploit details in public issues/PRs.

---

## âœ… Validation & CI/CD expectations

### Recommended CI behavior
- **If a report is referenced by Story Nodes / UI / releases:** validate it (pointers exist, links resolve, checksums present).
- **If a report is purely internal and not referenced:** treat it as optional, but keep the bundle contract.

### Suggested automated checks (fast gates)
- [ ] Markdown lint / basic hygiene (links, headings)
- [ ] `REPORT_MANIFEST.json` schema validation *(recommended if you add a schema)*
- [ ] Evidence pointer validation:
  - STAC/DCAT IDs exist (or paths resolve)
  - PROV activity/bundle referenced exists
- [ ] Link checks for internal relative links
- [ ] Secret/PII scanning gates (defense-in-depth)

> [!TIP]
> CI artifacts (Actions-uploaded files) are great for **ephemeral** outputs.  
> Commit to `data/reports/` when the report must be reviewable long-term and referenced by IDs.

---

## ğŸ“š Reference shelf (project library)

> âš ï¸ Reference PDFs may have licenses different from the repository code/data.  
> Treat this as a **reading pack / influence map**, not a redistribution mandate. ğŸ“š

<details>
<summary><strong>ğŸ§­ Core KFM docs (governing context)</strong></summary>

- `Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.docx`
- `ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals.docx`

</details>

<details>
<summary><strong>ğŸ›°ï¸ Remote sensing + GIS (methods + QA habits)</strong></summary>

- `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf`
- `python-geospatial-analysis-cookbook.pdf`
- `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf`
- `making-maps-a-visual-guide-to-map-design-for-gis.pdf`
- `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf`
- `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf`

</details>

<details>
<summary><strong>ğŸ“ˆ Statistics, experiments, inference (report integrity)</strong></summary>

- `Understanding Statistics & Experimental Design.pdf`
- `graphical-data-analysis-with-r.pdf`
- `regression-analysis-with-python.pdf`
- `Regression analysis using Python - slides-linear-regression.pdf`
- `think-bayes-bayesian-statistics-in-python.pdf`

</details>

<details>
<summary><strong>ğŸ§ª Simulation & modeling discipline (V&V, UQ, sensitivity)</strong></summary>

- `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf`
- `Generalized Topology Optimization for Structural Design.pdf`
- `Spectral Geometry of Graphs.pdf`

</details>

<details>
<summary><strong>ğŸŒ Web + visualization (reports often ship into UI workflows)</strong></summary>

- `responsive-web-design-with-html5-and-css3.pdf`
- `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf`

</details>

<details>
<summary><strong>âš™ï¸ Systems + scale + interoperability</strong></summary>

- `Scalable Data Management for Future Hardware.pdf`
- `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf`
- `Data Spaces.pdf`

</details>

<details>
<summary><strong>â¤ï¸ Ethics + accountability</strong></summary>

- `Introduction to Digital Humanism.pdf`
- `Principles of Biological Autonomy - book_9780262381833.pdf`
- `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf`

</details>

<details>
<summary><strong>ğŸ›¡ï¸ Security (defensive mindset only)</strong></summary>

- `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf`
- `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf`

> These inform **defensive controls** (threat modeling, secure coding, incident response).  
> They are **not** a request for offensive tooling contributions.

</details>

<details>
<summary><strong>ğŸ§° General programming shelf (bundles)</strong></summary>

- `A programming Books.pdf`
- `B-C programming Books.pdf`
- `D-E programming Books.pdf`
- `F-H programming Books.pdf`
- `I-L programming Books.pdf`
- `M-N programming Books.pdf`
- `O-R programming Books.pdf`
- `S-T programming Books.pdf`
- `U-X programming Books.pdf`
- `Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf`

</details>

---

## ğŸ•°ï¸ Version history

| Version | Date | Change | Author |
|---|---|---|---|
| v1.0.0 | 2025-12-26 | Initial `data/reports/` README scaffold | TBD |
| v1.1.0 | 2026-01-08 | Align to evidence-first bundles; add manifest + traceability rules | TBD |
| v1.2.0 | 2026-01-12 | Align links to project structure (`api/`, `pipelines/`, `web/story_nodes/`), add atomic publish guidance + registry suggestion | TBD |

---

<p align="right"><a href="#top">â¬†ï¸ Back to top</a></p>
