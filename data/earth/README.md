<div align="center">

# ğŸŒ Kansas Geo Timeline â€” Earth Context Layers

**Earth observation datasets** and **global reference layers**  
that complement the Kansas-focused datasets under `data/`.  

These provide **basemaps, climate context, and environmental indices**  
for comparative analysis in the **Kansas Frontier Matrix**.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-badges.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-badges.yml)
[![Pre-commit](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/pre-commit.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/.pre-commit-config.yaml)

</div>

---

```mermaid
flowchart TD
  A["Sources JSON\n(data/earth/sources/**)"] --> B["Fetch\n(make fetch)"]
  B --> C["Raw downloads\n(data/earth/raw/**)"]
  C --> D["Process (COG, GeoJSON, MBTiles)\n(data/earth/processed/**)"]
  D --> E["STAC Items\n(data/earth/stac/items/**)"]
  E --> F["Validate\n(stac-validate)"]
  F --> G["Viewer integration\n(web/app.config.json)"]

<!-- END OF MERMAID -->



â¸»

ğŸ§­ Scope
	â€¢	ğŸŒ Global context â€” datasets beyond Kansas: NASA/NOAA satellite products, DEMs, land cover, vegetation indices.
	â€¢	ğŸ›°ï¸ Remote sensing â€” MODIS, Sentinel, Landsat, Daymet, NLCD, GEDI, HydroSHEDS.
	â€¢	ğŸŒ± Environmental indices â€” NDVI, EVI, drought indices, fire perimeters, global soils.
	â€¢	ğŸ—ºï¸ Basemaps â€” Natural Earth, coastlines, political boundaries, rivers, global topo backgrounds.

Kansas is the core. These global layers exist only for context and comparison.

â¸»

ğŸ“‚ Structure

data/earth/
â”œâ”€â”€ sources/       # JSON descriptors (STAC-style or source metadata)
â”œâ”€â”€ raw/           # downloaded archives / unprocessed rasters/vectors
â”œâ”€â”€ processed/     # reprojected/cleaned GeoJSON, COGs, vector tiles
â”œâ”€â”€ stac/          # STAC Items & Collections referencing processed assets
â””â”€â”€ README.md

	â€¢	sources/ â†’ *.json descriptors used by scripts/fetch.py + make fetch
	â€¢	raw/ â†’ untouched downloads (tar/zip, HDF, NetCDF, GeoTIFF, etc.)
	â€¢	processed/ â†’ converted outputs (COG, GeoJSON, MBTiles/PMTiles)
	â€¢	stac/ â†’ metadata to connect to the hub

â¸»

âš™ï¸ Conventions
	â€¢	CRS: EPSG:4326 (WGS84) unless justified otherwise.
	â€¢	Raster: Cloud-Optimized GeoTIFF (.tif) with internal overviews.
	â€¢	Vector: GeoJSON (small/medium) or MBTiles/PMTiles (large).
	â€¢	Metadata: Every dataset has a STAC Item in stac/items/.
	â€¢	Checksums: .sha256 sidecars for raw + processed artifacts.

â¸»

ğŸ”— Connections
	â€¢	stac-badges.yml â†’ validates data/earth/stac/** and builds Shields badges.
	â€¢	stac.yml â†’ renders web/app.config.json including earth layers.
	â€¢	site.yml â†’ deploys processed layers into MapLibre viewer.

â¸»

ğŸ“‹ Common tasks

Add a new dataset:
	1.	Create data/earth/sources/<dataset>.json (endpoint, license, bbox, temporal).
	2.	Run make fetch â†’ downloads to data/earth/raw/.
	3.	Convert: make cogs (rasters) / make vectors (shapefiles â†’ GeoJSON).
	4.	Write STAC Item in data/earth/stac/items/.
	5.	Validate with make stac-validate.

Update an existing dataset:
	â€¢	Refresh source JSON â†’ make fetch + reprocess.
	â€¢	Re-run validation.

Link to viewer:
	â€¢	Reference STAC Item in scripts/badges/source_map.json.
	â€¢	Regenerate web/app.config.json with make stac.

â¸»

ğŸ“ Notes
	â€¢	Global datasets can be huge â†’ prefer per-tile or per-year subsets.
	â€¢	Always record license in sources/*.json (e.g., NASA EarthData, Copernicus, CC-BY-4.0).
	â€¢	Use scripts/gen_sha256.sh to hash large files after fetch.

â¸»

âœ… Mission-grade principle: Kansas remains the focus.
Earth layers add the environmental + global context needed for robust historical + geospatial analysis.

