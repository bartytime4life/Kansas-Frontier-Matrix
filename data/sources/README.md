<div align="center">


ğŸ§© Kansas Frontier Matrix â€” Source Manifests

data/sources/

Mission: Document and govern every external data source used by KFM with MCP-grade provenance, licensing, and reproducibility.

</div>



â¸»

ğŸ“š Overview

data/sources/ holds machine-readable JSON manifests that define each external dependency (origin, access, license, cadence), serving as the authoritative registry driving ETL, provenance, and STAC linkages across KFM.

Each manifest captures:
	â€¢	Identity & versioning (id, title, source_version)
	â€¢	Access details (URLs, APIs, auth mode, rate limits, mirrors)
	â€¢	Legal (license, attribution, usage constraints)
	â€¢	Temporal & spatial coverage
	â€¢	Data characteristics (type, format, schema refs)
	â€¢	Operational metadata (update frequency, SLOs, last verified)
	â€¢	Provenance bindings (linked pipeline, outputs, STAC references, checksums)

â¸»

ğŸ—‚ï¸ Directory Layout

data/sources/
â”œâ”€â”€ README.md
â”œâ”€â”€ schema/
â”‚   â””â”€â”€ source.schema.json
â”œâ”€â”€ terrain/               # USGS 3DEP, DASC LiDAR, SRTM
â”‚   â”œâ”€â”€ ks_lidar_2018_2020.json
â”‚   â””â”€â”€ usgs_3dep_dem.json
â”œâ”€â”€ hydrology/             # NHD, WBD, FEMA NFHL
â”‚   â”œâ”€â”€ usgs_nhd_flowlines.json
â”‚   â”œâ”€â”€ epa_wbd_huc12.json
â”‚   â””â”€â”€ fema_nfhl.json
â”œâ”€â”€ landcover/             # NLCD, CDL, historic vegetation
â”‚   â”œâ”€â”€ nlcd_1992_2021.json
â”‚   â””â”€â”€ usda_cdl_2020.json
â”œâ”€â”€ climate/               # Daymet, NOAA Normals, USDM
â”‚   â”œâ”€â”€ nasa_daymet_1980_2024.json
â”‚   â”œâ”€â”€ noaa_normals_1991_2020.json
â”‚   â””â”€â”€ usdm_drought_monitor.json
â”œâ”€â”€ hazards/               # Storm events, wildfire, floods
â”‚   â”œâ”€â”€ noaa_storm_events.json
â”‚   â”œâ”€â”€ usgs_wildfire_perimeters.json
â”‚   â””â”€â”€ fema_flood_events.json
â”œâ”€â”€ tabular/               # Census, USDA, BEA, BLS
â”‚   â”œâ”€â”€ us_census_population.json
â”‚   â”œâ”€â”€ usda_agriculture_production.json
â”‚   â””â”€â”€ bea_economic_indicators.json
â””â”€â”€ text/                  # OCR inputs, transcripts, treaty corpora
    â”œâ”€â”€ loc_chronicling_america.json
    â”œâ”€â”€ kshs_oral_histories.json
    â””â”€â”€ yale_avalon_treaties.json

Note: All manifests must validate against schema/source.schema.json and include last_verified timestamps.

â¸»

ğŸ§­ System Context (GitHub-safe Mermaid)

flowchart TD
  A["Sources\n\"APIs Â· Downloads Â· Feeds\""] --> B["Manifests\n`data/sources/*.json`"]
  B --> C["ETL Pipelines\n`src/pipelines/*`"]
  C --> D["Processed Layers\n`data/processed/`"]
  D --> E["STAC Catalog\n`data/stac/`"]
  E --> F["App Config\n`web/config/*.json`"]
  E --> G["Knowledge Graph\n\"Neo4j Â· CIDOC CRM Â· OWL-Time\""]
  B --> H["CI Checks\n\"Schema Â· Availability Â· Licenses\""]
  H --> I["Badges & Gates\n\"readme Â· PR checks\""]
  C --> J["Checksums\n`data/checksums/`"]
  J --> E
%%END OF MERMAID%%


â¸»

ğŸ§© Source Manifest â€” Extended Example

usgs_3dep_dem.json

{
  "id": "usgs_3dep_dem",
  "title": "USGS 3D Elevation Program (3DEP) LiDAR DEM",
  "provider": "USGS",
  "source_version": "2020.10",
  "description": "1 m LiDAR-derived elevation mosaics from USGS 3DEP.",
  "endpoints": [
    {
      "type": "esri-image-server",
      "url": "https://elevation.nationalmap.gov/arcgis/rest/services/3DEPElevation/ImageServer",
      "auth": "none",
      "rate_limit_rps": 10,
      "notes": "Server-side reprojection allowed; prefer WGS84 output for downstream consistency."
    }
  ],
  "license": {
    "type": "Public Domain",
    "attribution": "U.S. Geological Survey",
    "url": "https://www.usgs.gov/information-policies-and-instructions",
    "use_constraints": "Attribution requested; verify derivative product metadata retains USGS credit."
  },
  "data": {
    "kind": "raster",
    "format": "GeoTIFF",
    "encoding": "COG-ready",
    "resolution": "1 m",
    "crs": "EPSG:4326",
    "vertical_datum": "NAVD88",
    "nodata": -999999,
    "schema_ref": null,
    "quality": { "void_filled": true, "hydro_enforced": false }
  },
  "coverage": {
    "spatial": "Kansas, USA",
    "bbox": [-102.05, 36.99, -94.59, 40.00],
    "temporal": { "start": "2018-01-01", "end": "2020-12-31" }
  },
  "operations": {
    "update_frequency": "on_demand",
    "availability_slo": ">= 99.0%",
    "last_verified": "2025-10-13",
    "mirrors": [],
    "rate_limit_policy": "respect server guidance; default 10 rps; backoff 429/503"
  },
  "provenance": {
    "linked_pipeline": "terrain_pipeline.py",
    "produces": [
      {
        "path": "data/processed/terrain/ks_dem_1m_2018_2020.tif",
        "checksum_sha256": null,
        "expected_asset_type": "COG"
      },
      {
        "path": "data/processed/terrain/ks_hillshade_1m.tif",
        "checksum_sha256": null,
        "expected_asset_type": "COG"
      }
    ],
    "stac_links": ["data/stac/collections/terrain.json"],
    "trace": { "commit": "AUTO@ingest", "runner": "make sources-fetch" }
  },
  "status": "active",
  "notes": "Primary DEM source for hillshade, slope, and hydrology derivatives."
}


â¸»

âœ… Validation & CI

CLI (local):

# Validate JSON manifests against schema
python src/utils/validate_sources.py data/sources/ --schema data/sources/schema/source.schema.json

# Check availability & license fields
python src/utils/check_availability.py data/sources/
python src/utils/check_licenses.py data/sources/

Make targets:

make sources           # validate schema + list deltas
make sources-validate  # schema, availability, license audits
make sources-fetch     # dry-run or execute source pulls (where applicable)
make clean-sources     # remove temp caches

CI gates (PRs):
	â€¢	JSON Schema validate (must pass)
	â€¢	URL availability & rate-limit probe
	â€¢	License compliance (explicit license + attribution)
	â€¢	Change impact report (lists ETL + STAC items affected)

â¸»

âš¡ Quick Start (local dev)

# lint & validate just this folder
pre-commit run --files data/sources/**/*.json

# generate impact report for changed manifests
python src/utils/impact_report.py --paths data/sources/terrain/usgs_3dep_dem.json


â¸»

ğŸ§ª MCP Compliance Matrix

Principle	Implementation
Documentation-first	Canonical, versioned JSON manifests with inline legal & operational fields.
Reproducibility	Deterministic ETL uses manifests; outputs hashed; STAC links preserved.
Open Standards	JSON + JSON Schema; STAC 1.0 alignment; OWL-Time for temporal semantics (KG side).
Provenance	provenance.* links inputs â†’ pipelines â†’ outputs â†’ STAC; checksums + commit IDs in reports.
Auditability	CI badges, per-PR reports, and changelog entries; last_verified timestamps enforced.


â¸»

ğŸ§  AI-Assisted Data Entry (Optional)

Use these prompts to generate draft manifests then validate & review:
	â€¢	â€œDraft a KFM source manifest for NOAA Normals 1991â€“2020 with monthly precipitation and temperature, CSV format, coverage Kansas, license NOAA Open Data.â€
	â€¢	â€œGiven this API URL and docs, infer fields for rate limits, update cadence, and attribution; output JSON validating against source.schema.json.â€

â¸»

ğŸ§© Integration Points

Component	Connection
src/pipelines/*	Reads manifests for fetching, throttling, retries, and attribution.
data/processed/	Outputs linked via provenance.produces.
data/checksums/	SHA-256 tracked; surfaced in PR diffs.
data/stac/	Collections/Items reference the source id in properties.provenance.
web/config/*.json	Layer entries include source_id for traceable UI metadata.
Knowledge Graph (Neo4j)	Nodes: Source â†’ relations: FEEDS â†’ Dataset, DERIVES â†’ Product.


â¸»

ğŸ§­ Update Lifecycle (Mermaid sequence)

sequenceDiagram
  autonumber
  participant Dev as "Contributor"
  participant Repo as "KFM Repo"
  participant CI as "CI Â· Validators"
  participant Pip as "ETL Pipeline"
  participant STAC as "STAC Catalog"

  Dev->>Repo: Add/modify manifest in `data/sources/`
  Repo-->>CI: Pull Request triggers validators
  CI->>CI: Schema âœ” Â· URLs âœ” Â· License âœ” Â· Impact report
  CI-->>Dev: Status checks & review notes
  Dev->>Repo: Merge to main
  Repo->>Pip: `make sources && make fetch`
  Pip->>STAC: Update items with provenance links
  STAC-->>Repo: Publish artifacts & checksums
%%END OF MERMAID%%


â¸»

ğŸ§¹ Maintenance Rules
	â€¢	Add a source: copy template â†’ fill all required fields â†’ run local validators â†’ open PR.
	â€¢	Deprecate: set "status": "deprecated" and point to the successor manifest.
	â€¢	Verify routinely: bump last_verified when checks pass (manual or CI probe).
	â€¢	Legal: include attribution text in license.attribution; add use_constraints if required.

â¸»

ğŸ” Field Reference (Schema Highlights)

Field	Type	Required	Example / Notes
id	string	yes	noaa_normals_1991_2020
source_version	string	no	v1.2, 2024.06
endpoints[].type	enum	yes*	http, s3, esri-image-server, ftp
license.type	string	yes	CC-BY 4.0, Public Domain, Custom
data.kind	enum	yes	raster, vector, tabular, text
coverage.temporal	object	no	{ "start": "YYYY-MM-DD", "end": "YYYY-MM-DD" }
operations.last_verified	date	yes	2025-10-13
provenance.produces[]	array	no	link outputs and optional expected checksums
status	enum	yes	active, deprecated, experimental


â¸»

ğŸ§¾ Changelog

Follow SemVer and update this table on every change impacting structure, fields, or CI.

Version	Date	Changes
v1.2	2025-10-13	Expanded example (crs, vertical_datum, rate_limit_policy, bbox, Quick Start).
v1.1	2025-10-12	Added extended schema fields, CI gates, AI prompts, Mermaid diagrams, and maintenance rules.
v1.0	2025-10-04	Initial creation of Source Manifests README and baseline layout.


â¸»

ğŸ·ï¸ Version Block

Component: data/sources/README.md
SemVer: 1.2.0
Spec Dependencies: MCP v1.0, STAC 1.0
Last Updated: 2025-10-13
Maintainers: @bartytime4life


â¸»


<div align="center">


Kansas Frontier Matrix â€” â€œEvery dataset has a story â€” and every story starts with a source.â€
ğŸ“ data/sources/ Â· Canonical registry of external inputs powering KFM.

</div>
