<div align="center">

# üß© Kansas Frontier Matrix ‚Äî Source Manifests  
`data/sources/`

**Mission:** Document and manage all **external data sources** used within the  
Kansas Frontier Matrix (KFM) ‚Äî capturing origin, licensing, access methods,  
and provenance for every dataset integrated into the system.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../.github/workflows/site.yml)
[![Docs ¬∑ MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../LICENSE)

</div>

---

## üìö Overview

The `data/sources/` directory contains **JSON manifest files** that define  
all raw and reference data sources used throughout the KFM pipelines.  

Each manifest provides:
- **Dataset identification** and versioning  
- **Source URLs** and access endpoints  
- **Licensing and usage terms**  
- **Data type, schema, and temporal coverage**  
- **Provenance details** linking raw inputs to processed outputs  

These manifests serve as the **authoritative source registry** for all external data dependencies,  
ensuring reproducibility and transparency across the project‚Äôs entire ETL ecosystem.

---

## üóÇÔ∏è Directory Layout

```bash
data/sources/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ terrain/             # USGS 3DEP, Kansas DASC elevation data
‚îÇ   ‚îú‚îÄ‚îÄ ks_lidar_2018_2020.json
‚îÇ   ‚îî‚îÄ‚îÄ usgs_3dep_dem.json
‚îú‚îÄ‚îÄ hydrology/           # NHD, WBD, and FEMA NFHL datasets
‚îÇ   ‚îú‚îÄ‚îÄ usgs_nhd_flowlines.json
‚îÇ   ‚îú‚îÄ‚îÄ epa_wbd_huc12.json
‚îÇ   ‚îî‚îÄ‚îÄ fema_nfhl.json
‚îú‚îÄ‚îÄ landcover/           # NLCD, USDA CDL, vegetation maps
‚îÇ   ‚îú‚îÄ‚îÄ nlcd_1992_2021.json
‚îÇ   ‚îî‚îÄ‚îÄ usda_cdl_2020.json
‚îú‚îÄ‚îÄ climate/             # Daymet, NOAA, Drought Monitor
‚îÇ   ‚îú‚îÄ‚îÄ nasa_daymet_1980_2024.json
‚îÇ   ‚îú‚îÄ‚îÄ noaa_normals_1991_2020.json
‚îÇ   ‚îî‚îÄ‚îÄ usdm_drought_monitor.json
‚îú‚îÄ‚îÄ hazards/             # Tornado, wildfire, and flood data
‚îÇ   ‚îú‚îÄ‚îÄ noaa_storm_events.json
‚îÇ   ‚îú‚îÄ‚îÄ usgs_wildfire_perimeters.json
‚îÇ   ‚îî‚îÄ‚îÄ fema_flood_events.json
‚îú‚îÄ‚îÄ tabular/             # Census, USDA, BEA, BLS data
‚îÇ   ‚îú‚îÄ‚îÄ us_census_population.json
‚îÇ   ‚îú‚îÄ‚îÄ usda_agriculture_production.json
‚îÇ   ‚îî‚îÄ‚îÄ bea_economic_indicators.json
‚îî‚îÄ‚îÄ text/                # Historical documents, OCR sources, transcripts
    ‚îú‚îÄ‚îÄ loc_chronicling_america.json
    ‚îú‚îÄ‚îÄ kshs_oral_histories.json
    ‚îî‚îÄ‚îÄ yale_avalon_treaties.json
````

> **Note:**
> Each manifest is a machine-readable `.json` file describing data origin,
> licensing, update cadence, and provenance for reproducibility.

---

## üß© Source Manifest Example

### Example: `usgs_3dep_dem.json`

```json
{
  "id": "usgs_3dep_dem",
  "title": "USGS 3D Elevation Program (3DEP) LiDAR DEM",
  "provider": "USGS",
  "description": "Nationwide LiDAR-derived DEMs providing 1-meter elevation data.",
  "endpoint": "https://elevation.nationalmap.gov/arcgis/rest/services/3DEPElevation/ImageServer",
  "access_method": "REST API",
  "license": "Public Domain (US Government)",
  "data_type": "raster",
  "format": "GeoTIFF",
  "spatial_coverage": "Kansas, USA",
  "temporal_coverage": "2018‚Äì2020",
  "update_frequency": "On Demand",
  "last_verified": "2025-10-04",
  "checksum": null,
  "linked_pipeline": "terrain_pipeline.py",
  "notes": "Used as source for `ks_1m_dem_2018_2020.tif`."
}
```

---

## ‚öôÔ∏è Source Manifest Workflow

**Makefile target:**

```bash
make sources
```

**Manual validation:**

```bash
python src/utils/validate_sources.py data/sources/
```

**Workflow Steps:**

1. Define or update source manifests for new datasets.
2. Validate schema compliance (`source.schema.json`).
3. Fetch raw data via automated ETL pipelines.
4. Store metadata in `data/sources/` for future traceability.
5. Link processed outputs to their source manifests and STAC Items.

---

## üßæ Manifest Schema

| Field               | Description                            | Example                                 |
| :------------------ | :------------------------------------- | :-------------------------------------- |
| `id`                | Unique identifier for the data source. | `usgs_3dep_dem`                         |
| `title`             | Human-readable name.                   | `USGS 3DEP DEM`                         |
| `provider`          | Organization providing the data.       | `USGS`                                  |
| `endpoint`          | URL or API endpoint.                   | `https://elevation.nationalmap.gov/...` |
| `license`           | Data usage license.                    | `Public Domain (US Govt)`               |
| `data_type`         | Type of dataset.                       | `raster`, `vector`, `tabular`, `text`   |
| `format`            | File format.                           | `GeoTIFF`, `CSV`, `JSONL`               |
| `spatial_coverage`  | Geographic extent.                     | `Kansas, USA`                           |
| `temporal_coverage` | Time range.                            | `2018‚Äì2020`                             |
| `update_frequency`  | Refresh interval.                      | `Annual`, `Monthly`, `On Demand`        |
| `linked_pipeline`   | Associated ETL script.                 | `terrain_pipeline.py`                   |
| `notes`             | Optional remarks or usage context.     | `Used for DEM generation.`              |

---

## üß© Integration with KFM Pipelines

| Linked Component                         | Function                                                |
| :--------------------------------------- | :------------------------------------------------------ |
| `src/pipelines/*`                        | Uses source manifests to fetch and register input data. |
| `data/processed/`                        | Outputs derived from these sources.                     |
| `data/checksums/`                        | Verifies raw and processed data integrity.              |
| `data/processed/metadata/`               | STAC metadata links back to source manifests.           |
| `.github/workflows/sources-validate.yml` | CI/CD workflow validating schema and availability.      |

---

## üßπ Maintenance & Versioning

* **Add new sources:** Create a new JSON manifest following `source.schema.json`.
* **Update verification date:** Change `last_verified` after confirming source availability.
* **Deprecate sources:** Mark outdated sources with `"status": "deprecated"`.
* **Revalidate periodically:** Run `make sources-validate` to test URLs and schema.

**Cleanup command:**

```bash
make clean-sources
```

---

## üß† MCP Compliance Summary

| MCP Principle           | Implementation                                                             |
| :---------------------- | :------------------------------------------------------------------------- |
| **Documentation-first** | Each dataset source is fully documented in a JSON manifest.                |
| **Reproducibility**     | Manifest-driven ETL ensures repeatable and deterministic data ingestion.   |
| **Open Standards**      | JSON + JSON Schema compliant; STAC-linked provenance.                      |
| **Provenance**          | Each manifest establishes the link between raw data and processed outputs. |
| **Auditability**        | Sources are versioned, validated, and CI-tested automatically.             |

---

## üìé Related Directories

| Path                       | Description                                         |
| :------------------------- | :-------------------------------------------------- |
| `data/raw/`                | Immutable raw data downloaded from defined sources. |
| `data/processed/`          | Cleaned and validated outputs derived from sources. |
| `data/processed/metadata/` | STAC metadata for processed datasets.               |
| `data/checksums/`          | Validation hashes for source and processed data.    |
| `src/pipelines/`           | ETL scripts referenced by source manifests.         |

---

## üìÖ Version History

| Version | Date       | Summary                                                      |
| :------ | :--------- | :----------------------------------------------------------- |
| v1.0    | 2025-10-04 | Initial creation of source manifest directory documentation. |

---

<div align="center">

**Kansas Frontier Matrix** ‚Äî *‚ÄúEvery Dataset Has a Story ‚Äî and Every Story Starts with a Source.‚Äù*
üìç [`data/sources/`](.) ¬∑ Repository of all raw data origins and provenance manifests powering KFM pipelines.

</div>
