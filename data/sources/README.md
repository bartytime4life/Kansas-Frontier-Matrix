<div align="center">

# ğŸ—‚ï¸ Kansas Geo Timeline â€” Source Descriptors  
`data/sources/`

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../.github/workflows/site.yml)  
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../.github/workflows/stac-validate.yml)  
[![CodeQL](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/codeql.yml/badge.svg)](../../.github/workflows/codeql.yml)  
[![Trivy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../.github/workflows/trivy.yml)  
[![Pre-commit](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/pre-commit.yml/badge.svg)](../../.pre-commit-config.yaml)  
[![Docs](https://img.shields.io/badge/docs-MCP%20Standards-blue.svg)](../../docs/)  
[![Data Provenance](https://img.shields.io/badge/provenance-verifiedâœ…-green.svg)](../../stac/items/)  

**Mission:** This folder contains **small, curated JSON descriptors** for every dataset used in the Kansas Frontier Matrix pipeline.  
They are the **canonical index** of external dependencies: URLs, licenses, provenance, and spatial/temporal extents.  

ğŸ“Œ **Tiny, explicit, hand-edited JSONs** (a few KB).  
ğŸ“Œ **Never** store raw payloads here â†’ those live in `data/raw/**`.  
ğŸ“Œ Validated against [`schema.source.json`](./schema.source.json).  

</div>

---

## ğŸ“ˆ Lifecycle

```mermaid
flowchart TD
  A["Create/Edit Descriptor\n(data/sources/*.json)"] --> B["Validate\n(make validate-sources)"]
  B --> C["Fetch Raw Data\n(make fetch â†’ data/raw/** + checksums)"]
  C --> D["Process\n(make cogs / make vectors â†’ data/processed/**, data/cogs/**)"]
  D --> E["Build STAC\n(make stac â†’ data/stac/items/**)"]
  E --> F["Viewer integration\n(web/config/layers.json)"]

<!-- END OF MERMAID -->



â¸»

ğŸ¯ Purpose
	â€¢	ğŸ“– Document external dependencies (URLs, licenses, provenance).
	â€¢	ğŸ”„ Provide reproducible fetch/ETL recipes.
	â€¢	âš™ï¸ Drive make fetch and make stac jobs.
	â€¢	ğŸ” Guarantee transparency & reproducibility in the historical GIS pipeline.

Descriptors = truth table of inputs â†’ all downstream stages depend on them.

â¸»

ğŸ“‚ Directory Layout

data/sources/
â”œâ”€â”€ schema.source.json   # JSON Schema for validation
â”œâ”€â”€ ks_hydrography.json  # Kansas hydrography example
â”œâ”€â”€ ks_roads_1930s.json  # Historic roads (1930s)
â”œâ”€â”€ ks_landcover_1936.json
â””â”€â”€ README.md


â¸»

ğŸ§­ Schema â€” Core Fields

Field	Type	Description
id	string	Unique ID (lowercase, underscores or hyphens).
title	string	Human-readable dataset title.
type	enum	One of: vector, raster, collection, service.
period	string	Temporal coverage (e.g., 1936, 1930s, 1854â€“1861).
urls	array	Download URLs or service endpoints.
bbox	array	[west, south, east, north] in EPSG:4326.
crs	string	Coordinate system (default: EPSG:4326).
license	object	License name + URL.
provenance	object	Attribution, publisher, DOI, or citation.
retrieved	string	ISO 8601 datetime when last fetched.
confidence	number	(Optional) confidence score (0.0â€“1.0).
notes	string	(Optional) free-form comments.


â¸»

ğŸ”„ Workflow
	1.	Add/Edit descriptor â†’ data/sources/*.json
	2.	Validate

make validate-sources

	3.	Fetch raw data â†’ saves to data/raw/** with checksums

make fetch

	4.	Process â†’ convert into COGs or vectors

make cogs
make vectors

	5.	Build STAC â†’ generate catalog Items

make stac


â¸»

ğŸ“‘ Examples
	â€¢	ks_hydrography.json â†’ Kansas surface water layers
	â€¢	ks_roads_1930s.json â†’ historic road network
	â€¢	ks_landcover_1936.json â†’ land-cover snapshot

ğŸ‘‰ urls[] can include multiple files (e.g., county sheets).
The make fetch step will fan out and merge as required.

â¸»

ğŸ” Git Policy
	â€¢	âœ… Always tracked in git.
	â€¢	ğŸš« data/raw/** ignored by .gitignore.
	â€¢	ğŸ”” CI runs on changes:
	â€¢	Schema validation (make validate-sources)
	â€¢	License/provenance checks
	â€¢	STAC rebuild

â¸»

ğŸš€ Quickstart

# 1. Add descriptor
$EDITOR data/sources/ks_new_dataset.json

# 2. Validate
make validate-sources

# 3. Fetch
make fetch

# 4. Process & publish
make cogs vectors stac


â¸»

âœ… QA Checklist
	â€¢	Descriptor schema validated (schema.source.json)
	â€¢	License and provenance explicitly recorded
	â€¢	Raw payload downloaded into data/raw/ with .sha256 checksum
	â€¢	All downstream outputs trace back to descriptor ID
	â€¢	Descriptor committed to git, reviewed, and approved

â¸»

ğŸ“ TL;DR
	â€¢	data/sources/ = curated index of inputs
	â€¢	Keeps raw payloads out of git while ensuring reproducibility
	â€¢	Bridges source â†’ raw â†’ processed â†’ STAC
	â€¢	Backbone of transparency, traceability, and MCP reproducibility

<div align="center">


âœ… If itâ€™s in the pipeline, it must be listed here.

</div>
```
