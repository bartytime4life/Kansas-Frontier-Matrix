<div align="center">

# ğŸŒ¦ï¸ Kansas Geo Timeline â€” Climate & Weather Sources  
`data/sources/climate/`

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../.github/workflows/site.yml)  
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../.github/workflows/stac-validate.yml)  
[![CodeQL](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/codeql.yml/badge.svg)](../../../.github/workflows/codeql.yml)  
[![Trivy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../.github/workflows/trivy.yml)  
[![Pre-commit](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/pre-commit.yml/badge.svg)](../../../.pre-commit-config.yaml)  
[![Docs](https://img.shields.io/badge/docs-MCP%20Standards-blue.svg)](../../../docs/)  
[![Data Provenance](https://img.shields.io/badge/provenance-verifiedâœ…-green.svg)](../../../stac/items/climate/)  

**Mission:** This folder holds **curated JSON descriptors** for climate, weather, and drought datasets powering the Kansas Frontier Matrix.  

ğŸ“Œ Validated against [`schema.source.json`](../schema.source.json)  
ğŸ“Œ Drive **`make fetch` â†’ `make stac`** workflows  
ğŸ“Œ Guarantee **traceability** from NOAA/NASA sources â†’ reproducible artifacts â†’ discoverable STAC Items  

</div>

---

## ğŸ¯ Purpose

- ğŸ“– Capture **metadata + provenance** for climate datasets.  
- ğŸ”„ Provide reproducible recipes for fetching station records, gridded surfaces, drought monitors, and hazards.  
- âš™ï¸ Feed into `processed/` and `cogs/` pipelines for analysis-ready outputs.  
- ğŸŒ Ensure datasets are discoverable in the **STAC catalog**.  

---

## ğŸ“‚ Typical Datasets

| Dataset                              | Coverage                  | Format(s)          | Notes                                       |
|--------------------------------------|---------------------------|--------------------|---------------------------------------------|
| **NOAA NCEI GHCN-Daily**             | 1880sâ€“present, stations   | CSV, TXT, API      | Daily precip/temp/snow at KS stations       |
| **NASA Daymet (V4)**                 | 1980â€“present, 1 km grid   | NetCDF, WMS/WCS    | Daily gridded weather variables             |
| **NOAA Climate Normals (1991â€“2020)** | 30-year averages          | CSV, GeoTIFF       | Baseline climatology                        |
| **US Drought Monitor**               | 2000â€“present, weekly      | Shapefile, GeoJSON | Weekly drought polygons (D0â€“D4 categories)  |
| **NOAA Storm Events (multi-hazard)** | 1950â€“present              | CSV, SQL           | Tornadoes, floods, drought, wildfires, etc. |

---

## ğŸ“ˆ Workflow

```mermaid
flowchart TD
  A["Add/Edit Descriptor\n(data/sources/climate/*.json)"] --> B["Validate\n(make validate-sources)"]
  B --> C["Fetch Raw Data\n(make fetch â†’ data/raw/climate/**)"]
  C --> D["Process\n(make cogs / make vectors â†’ data/processed/**, data/cogs/**)"]
  D --> E["Build STAC\n(make stac â†’ data/stac/items/climate_*.json)"]
  E --> F["Viewer integration\n(web/config/layers.json)"]

<!-- END OF MERMAID -->



â¸»

ğŸ§­ Conventions
	â€¢	IDs â†’ climate_<dataset>_<period> (lowercase, underscores).
	â€¢	Example: climate_daymet_1980_2025
	â€¢	Periods â†’ YYYY, YYYY-YYYY, 1990s, late-19c
	â€¢	CRS â†’ normalize to EPSG:4326 unless strong reason otherwise
	â€¢	Each descriptor must include:
	â€¢	license â†’ name + URL
	â€¢	provenance â†’ attribution, program, DOI if available
	â€¢	retrieved â†’ ISO 8601 datetime

â¸»

ğŸ” Git Policy
	â€¢	âœ… JSON descriptors in data/sources/climate/ are tracked
	â€¢	ğŸš« Raw downloads â†’ data/raw/climate/** ignored by git
	â€¢	ğŸ“¦ Processed outputs:
	â€¢	data/processed/climate/**, data/cogs/climate/**
	â€¢	Large files â†’ Git LFS
	â€¢	Sidecars (*.meta.json, *.sha256) committed to git

â¸»

ğŸš€ Quickstart

# 1. Add/Edit descriptor
$EDITOR data/sources/climate/ghcn_daily.json

# 2. Validate schema
make validate-sources

# 3. Fetch raw data
make fetch    # saves to data/raw/climate/

# 4. Process into analysis-ready outputs
make cogs     # e.g., NetCDF â†’ COG
make vectors  # e.g., drought polygons

# 5. Build STAC catalog entries
make stac     # updates data/stac/items/climate_*.json


â¸»

âœ… QA Checklist
	â€¢	Descriptor schema validated (schema.source.json)
	â€¢	License and provenance explicitly recorded
	â€¢	Raw payloads downloaded into data/raw/climate/ with .sha256 sidecar
	â€¢	All downstream outputs (processed/COGs) trace back to descriptor ID
	â€¢	STAC Items generated and validated

â¸»

ğŸ“ TL;DR
	â€¢	data/sources/climate/ = blueprints for climate + hazard datasets
	â€¢	Ensures traceability: NOAA/NASA â†’ raw â†’ processed â†’ STAC
	â€¢	Supports reproducible pipelines and discoverable metadata

<div align="center">


âœ… If it tracks Kansas climate, drought, or weather history â†’ it belongs here.

</div>
```
