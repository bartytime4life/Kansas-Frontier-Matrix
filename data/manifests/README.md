---
title: "ğŸ—‚ï¸ data/manifests/ â€” KFM Manifests, Contracts, & Provenance"
path: "data/manifests/README.md"
version: "v11.2.6"
last_updated: "2026-01-10"
review_cycle: "quarterly"
governance: "FAIR+CARE Â· provenance-first Â· contract-first"
audience: ["contributors", "data-stewards", "pipeline-authors", "reviewers"]
license: "CC-BY-4.0"
---

# ğŸ—‚ï¸ `data/manifests/` â€” KFM Manifests, Contracts, & Provenance

![Status](https://img.shields.io/badge/status-active-brightgreen)
![Contracts](https://img.shields.io/badge/contract-first-1f6feb)
![Evidence](https://img.shields.io/badge/evidence-first-8250df)
![Catalogs](https://img.shields.io/badge/catalogs-STAC%20%7C%20DCAT%20%7C%20PROV-orange)
![Governance](https://img.shields.io/badge/governance-FAIR%2BCARE-red)
![Geo](https://img.shields.io/badge/geospatial-PostGIS%20%7C%20COG%20%7C%20GeoParquet%20%7C%20PMTiles-0aa2a2)

> **Purpose:** this folder holds the **human-authored manifests** that define what KFM *has*, where it came from, how it was produced, and how it should be publishedâ€”**before** it becomes a catalog entry, a graph node, an API response, or a Story Node.

---

## ğŸ§­ Why manifests exist (the â€œno black boxesâ€ rule)

KFM treats **metadata, citations, and provenance as first-class data**. A dataset isnâ€™t â€œrealâ€ in KFM until it is:
1) **Declared** (manifest) âœ…  
2) **Validated** (schemas + governance checks) âœ…  
3) **Published** (STAC/DCAT/PROV outputs) âœ…  
4) **Ingested** (graph + search + UI) âœ…  

```mermaid
flowchart LR
  M[ğŸ—‚ï¸ Manifests<br/>human-authored] --> V[âœ… Validate<br/>schema + policy]
  V --> C[ğŸ“š Catalogs<br/>STAC/DCAT/PROV]
  C --> G[ğŸ•¸ï¸ Graph<br/>entities + relations]
  C --> A[ğŸ”Œ API]
  A --> U[ğŸ—ºï¸ UI]
  C --> N[ğŸ“– Story Nodes / Focus Mode]
```

---

## ğŸ§± Folder layout (recommended) ğŸ§©âœ¨

> Keep **manifests** here. Put **generated catalogs** in their own output folder (e.g. `data/catalogs/â€¦`).  
> If your repo currently uses `data/stac/`, `data/dcat/`, etc., treat those as **generated outputs**.

```text
ğŸ“ data/
  â””â”€â”€ ğŸ—‚ï¸ manifests/
      â”œâ”€â”€ ğŸ“„ README.md                              ğŸ‘ˆ you are here ğŸ™‚
      â”œâ”€â”€ ğŸ“ schemas/                               ğŸ“ JSON Schema / YAML schema docs
      â”‚   â”œâ”€â”€ ğŸ“„ dataset.manifest.schema.json
      â”‚   â”œâ”€â”€ ğŸ“„ pipeline.manifest.schema.json
      â”‚   â”œâ”€â”€ ğŸ“„ model.manifest.schema.json
      â”‚   â””â”€â”€ ğŸ“„ doc.manifest.schema.json
      â”œâ”€â”€ ğŸ›°ï¸ datasets/                              ğŸ“¦ dataset declarations (inputs + derived)
      â”‚   â”œâ”€â”€ ğŸ“„ kfm.ks.surficial_geology.v1.manifest.yaml
      â”‚   â””â”€â”€ ğŸ“„ kfm.ks.transit.gtfsrt.v1.manifest.yaml
      â”œâ”€â”€ ğŸ§ª pipelines/                             ğŸ§° reproducible ETL + packaging
      â”‚   â”œâ”€â”€ ğŸ“„ kfm.pipeline.surficial_geology.v1.manifest.yaml
      â”‚   â””â”€â”€ ğŸ“„ kfm.pipeline.gtfsrt_watcher.v1.manifest.yaml
      â”œâ”€â”€ ğŸ§  models/                                ğŸ§¬ simulation/ML model declarations
      â”‚   â””â”€â”€ ğŸ“„ kfm.model.drought_risk.v1.manifest.yaml
      â”œâ”€â”€ ğŸ“š docs/                                  ğŸ“š governed â€œreference libraryâ€ docs
      â”‚   â”œâ”€â”€ ğŸ“„ kfm.doc.nasa_simulation_guide.v1.manifest.yaml
      â”‚   â””â”€â”€ ğŸ“„ kfm.doc.postgresql_notes.v1.manifest.yaml
      â”œâ”€â”€ ğŸ›¡ï¸ policies/                              ğŸ§¾ FAIR/CARE & sensitivity rules (OPA/Rego, etc.)
      â”‚   â”œâ”€â”€ ğŸ“„ README.md
      â”‚   â”œâ”€â”€ ğŸ“„ fairness.rego
      â”‚   â””â”€â”€ ğŸ“„ care_labels.rego
      â””â”€â”€ ğŸ§° _generated/                             âš™ï¸ OPTIONAL local build artifacts (gitignored)
          â”œâ”€â”€ ğŸ“„ index.json
          â””â”€â”€ ğŸ“„ manifest_index.md
```

---

## ğŸ·ï¸ Naming conventions (boringly consistent)

### âœ… IDs
Use stable, globally-unique IDs that can serve as:
- filenames
- STAC IDs / DCAT identifiers
- graph node IDs
- API keys

**Suggested pattern**
```
kfm.<region>.<theme>.<artifact>.<time_or_scope>.v<major>
```

Examples:
- `kfm.ks.landcover.2000_2020.v1`
- `kfm.ks.surficial_geology.statewide.v1`
- `kfm.ks.transit.gtfsrt.kdot.v1`

### âœ… Filenames
- Dataset manifest: `data/manifests/datasets/<id>.manifest.yaml`
- Pipeline manifest: `data/manifests/pipelines/<id>.manifest.yaml`
- Model manifest: `data/manifests/models/<id>.manifest.yaml`
- Doc/library manifest: `data/manifests/docs/<id>.manifest.yaml`

---

## ğŸ“¦ Manifest types (what you can declare)

| Type | What it describes | Typical outputs |
|---|---|---|
| ğŸ›°ï¸ **Dataset manifest** | source + derived data products (rasters, vectors, tables, streams) | STAC Collection/Item + DCAT Dataset/Distributions + PROV lineage |
| ğŸ§ª **Pipeline manifest** | reproducible steps (fetch â†’ transform â†’ package â†’ publish) | PROV Activity chain; build logs; artifact hashes |
| ğŸ§  **Model manifest** | simulation/ML models (training, assumptions, evaluation) | model card + PROV + dataset links |
| ğŸ“š **Doc manifest** | internal reference library PDFs/DOCX + governance metadata | searchable library index; citations into Story Nodes |

---

## âœ… Minimum required fields (baseline contract)

> If a manifest omits these, it should fail validation.

### ğŸ›°ï¸ Dataset manifest (YAML) â€” template

```yaml
# data/manifests/datasets/kfm.ks.example_dataset.v1.manifest.yaml
manifest_version: "1.0"
kind: "dataset"

id: "kfm.ks.example_dataset.1850_1900.v1"
title: "Example Dataset (1850â€“1900)"
summary: "One-liner describing what this dataset is."
description: |
  Longer description. Include context, methodology, and limitations.
  If a claim matters, cite it below.

themes: ["history", "boundaries", "environment"]
tags: ["kansas", "geospatial", "timeline"]

governance:
  fair_category: "FAIR+CARE"
  care_label: "Public"
  sensitivity: "public"          # public | restricted | sensitive
  pii: false
  indigenous_sensitivity: false  # if true, requires extra review gates

license:
  spdx: "CC-BY-4.0"
  attribution: "Source org / author(s)"
  constraints: ["attribution-required"]

extent:
  spatial:
    bbox_wgs84: [-102.051, 36.993, -94.588, 40.003]  # Kansas bbox (example)
    crs: "EPSG:4326"
  temporal:
    start: "1850-01-01"
    end: "1900-12-31"

sources:
  - name: "Primary Source Name"
    type: "web|archive|api|book|internal"
    url: "https://example.org/source"
    retrieved_at: "2026-01-11"
    license: "Public Domain"
    citation: "Author (Year). Title. Publisher/Archive."
    notes: "Any constraints or caveats."

assets:
  - role: "analysis"
    path: "data/processed/example_dataset.parquet"   # or DVC pointer
    format: "parquet"
    sha256: "<fill-me>"
  - role: "visualization"
    path: "data/tiles/example_dataset.pmtiles"
    format: "pmtiles"
    sha256: "<fill-me>"

processing:
  pipeline_id: "kfm.pipeline.example_dataset.v1"
  steps:
    - name: "fetch"
      tool: "python"
      entrypoint: "pipelines/example/fetch.py"
      params: { }
    - name: "transform"
      tool: "python"
      entrypoint: "pipelines/example/transform.py"
      params: { target_crs: "EPSG:4326" }
    - name: "package"
      tool: "python"
      entrypoint: "pipelines/example/package.py"
      params: { out_formats: ["parquet", "pmtiles"] }

publish:
  catalogs:
    stac: { collection_id: "kfm.ks.example_dataset.1850_1900.v1" }
    dcat: { dataset_id: "kfm.ks.example_dataset.1850_1900.v1" }
    prov: { bundle_id: "kfm.prov.kfm.ks.example_dataset.1850_1900.v1" }

contacts:
  maintainer: { name: "KFM Data Team", email: "maintainers@example.org" }
  steward: { name: "Domain Steward", email: "steward@example.org" }

quality:
  validation:
    schema: "data/manifests/schemas/dataset.manifest.schema.json"
  notes: "Known limitations, missing fields, accuracy caveats."
```

### ğŸ§ª Pipeline manifest â€” template (sketch)

```yaml
manifest_version: "1.0"
kind: "pipeline"

id: "kfm.pipeline.example_dataset.v1"
title: "Example Dataset ETL + Packaging"
inputs: ["kfm.ks.example_source.v1"]
outputs: ["kfm.ks.example_dataset.1850_1900.v1"]

execution:
  runtime: "python"
  entrypoint: "pipelines/example/run.py"
  container: null            # or "ghcr.io/org/image:tag"
  reproducibility:
    pinned_deps: true
    deterministic: true

checks:
  - name: "manifest-validate"
  - name: "hash-assets"
  - name: "stac-build"
  - name: "dcat-build"
  - name: "prov-build"
```

### ğŸ§  Model manifest â€” template (sketch)

```yaml
manifest_version: "1.0"
kind: "model"

id: "kfm.model.drought_risk.v1"
title: "Drought Risk Model (Baseline)"
model_type: "statistical|ml|simulation"
training_data: ["kfm.ks.climate_timeseries.v1"]
evaluation:
  metrics: { rmse: 0.0, mae: 0.0 }
governance:
  advisory_only: true
  requires_human_review: true
```

### ğŸ“š Doc/library manifest â€” template (for ALL project PDFs/DOCX)

```yaml
manifest_version: "1.0"
kind: "doc"

id: "kfm.doc.scientific_modeling_simulation_nasa_grade.v1"
title: "Scientific Modeling and Simulation: A Comprehensive NASA-Grade Guide"
format: "pdf"
path: "docs/library/Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf"
topics: ["simulation", "verification", "validation", "reproducibility"]
license_notes: "Reference-only; follow original license terms."
```

---

## ğŸ§ª Validation & build workflow (expected)

> **Goal:** a contributor can add a manifest and the system can **validate â†’ generate catalogs â†’ ingest**.

### Local checks (suggested commands)
```bash
# 1) validate manifests
python -m kfm.manifests.validate data/manifests

# 2) build catalogs (STAC/DCAT/PROV)
python -m kfm.manifests.build \
  --manifests data/manifests \
  --out data/catalogs

# 3) (optional) ingest graph / search indexes
python -m kfm.ingest.run --catalogs data/catalogs
```

### CI gates (minimum)
- âœ… schema validation (all manifests)
- âœ… license + attribution present (datasets/docs)
- âœ… sensitivity labels respected (FAIR/CARE rules)
- âœ… hashes present (or computed deterministically)
- âœ… catalogs generated without warnings
- âœ… â€œno narrative without evidenceâ€ (Story Nodes must reference catalog IDs)

---

## ğŸ§© How manifests connect to data storage (DVC-friendly)

- Manifests should reference **large artifacts** via *paths* that can be backed by **DVC** (or equivalent).
- Manifests must store **content hashes** for integrity (sha256 preferred).
- Derived outputs should be **dual-format** where it helps:
  - **analytics**: `GeoParquet/Parquet`
  - **UI**: `PMTiles` (vector tiles) or `COG` (raster)

---

## ğŸ›¡ï¸ Governance notes (FAIR/CARE + sensitivity)

Use governance fields to make ethical constraints enforceable:
- `sensitivity`: `public | restricted | sensitive`
- `care_label`: `Public | Restricted | Indigenous | ...` (project-defined)
- `pii`: boolean
- `indigenous_sensitivity`: boolean

> [!WARNING]
> If `indigenous_sensitivity: true` or `pii: true`, your manifest **must** trigger review gates and may require aggregation/redaction before publication.

---

## ğŸ§¾ â€œDefinition of Doneâ€ checklist âœ…

Before a manifest can be merged:
- [ ] ID follows naming scheme and is stable
- [ ] License + attribution + constraints are explicit
- [ ] Sources include retrieval dates + citations
- [ ] Spatial + temporal extents are present (or â€œnot applicableâ€ is justified)
- [ ] Assets include hashes (or a deterministic way to compute them)
- [ ] Pipeline is declared (even if â€œmanualâ€), with steps and tools
- [ ] STAC/DCAT/PROV outputs can be generated cleanly
- [ ] Governance labels are set correctly (FAIR/CARE, sensitivity)
- [ ] Nothing depends on unpublished/private artifacts without documentation

---

## ğŸ§¾ Next steps (quick wins) ğŸš€

1) ğŸ“ Add schemas under `data/manifests/schemas/`  
2) ğŸ›°ï¸ Add one â€œgolden pathâ€ dataset manifest + ğŸ§ª pipeline manifest  
3) ğŸ§° Implement `kfm.manifests.validate` + `kfm.manifests.build` (or equivalent scripts)  
4) ğŸ›¡ï¸ Have CI fail on: missing license, missing provenance, missing sensitivity tags  
5) ğŸ§¾ Auto-generate a `manifest_index.md` (nice for humans) and `index.json` (nice for machines)

---

## ğŸ” Glossary (micro)

- **Manifest**: a human-authored contract describing an artifact (dataset/pipeline/model/doc).
- **Catalogs**: machine-generated publishable metadata (STAC/DCAT/PROV).
- **Evidence artifact**: derived output treated as data+metadata, registered before use in narratives.
- **Provenance**: lineage of data and decisions (sources â†’ transforms â†’ outputs), ideally queryable.