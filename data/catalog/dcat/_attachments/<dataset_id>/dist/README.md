# ğŸ“¦ Dataset Distribution (`<dataset_id>`) â€” `dist/` Package

![DCAT](https://img.shields.io/badge/metadata-DCAT%20(JSON--LD)-2b6cb0)
![STAC](https://img.shields.io/badge/metadata-STAC-2f855a)
![PROV](https://img.shields.io/badge/lineage-PROV-805ad5)
![Integrity](https://img.shields.io/badge/integrity-SHA--256-1a202c)
![Policy](https://img.shields.io/badge/governance-fail--closed-9b2c2c)

> ğŸ¯ **Purpose:** This folder contains the **publishable, versioned distribution artifacts** for dataset **`<dataset_id>`**.  
> These files are what the **DCAT catalog entry** should reference as `dcat:distribution` links (direct download artifacts, not raw sources).

---

## ğŸ§  TL;DR (If you just need the files)

1) âœ… Verify integrity: `sha256sum -c checksums.sha256`  
2) ğŸ“¦ Extract the bundle (zip/tar/etc.)  
3) ğŸ§¾ Read `manifest.json` for **whatâ€™s inside**, formats, schemas, and pointers to STAC/DCAT/PROV

---

## ğŸ§­ Where this fits in the KFM pipeline

```mermaid
flowchart LR
  A["ğŸª¨ Raw Sources"] --> B["ğŸ§ª ETL + Normalization"]
  B --> C["âœ… Processed Outputs"]
  C --> D["ğŸ›°ï¸ STAC Items + Collections"]
  C --> E["ğŸ“š DCAT Dataset Views"]
  C --> F["ğŸ§¬ PROV Lineage Bundles"]
  D --> G["ğŸ§  Graph â†” API â†” UI"]
  E --> G
  F --> G
```

---

## ğŸ—‚ï¸ Folder location (repo convention)

```text
ğŸ“ data/catalog/dcat/_attachments/<dataset_id>/dist/
```

This `dist/` directory is intended to hold **distribution-ready artifacts** (bundles + integrity + manifest).  
It is **not** a staging area for raw inputs or intermediate work products.

---

## ğŸ“ Expected contents

> Your dataset may have more than one distribution format (e.g., `.gpkg`, `.parquet`, `.geojson`, `.csv`, `.tif`).  
> If so, keep them all here, and list them in `manifest.json`.

```text
ğŸ“ dist/
â”œâ”€â”€ ğŸ“„ README.md                 # you are here ğŸ™‚
â”œâ”€â”€ ğŸ§¾ manifest.json             # required: distribution manifest + pointers
â”œâ”€â”€ ğŸ” checksums.sha256          # required: sha256 for every shipped artifact
â”œâ”€â”€ ğŸ“¦ <dataset_id>__<ver>__*.zip # example primary distribution bundle
â”œâ”€â”€ ğŸ“¦ <dataset_id>__<ver>__*.gpkg|parquet|tif|csv  # optional direct-format dist(s)
â””â”€â”€ ğŸ§© sbom.spdx.json            # optional: SBOM (recommended if software included)
```

---

## ğŸ“¦ What belongs in `dist/` (âœ…) vs what does not (ğŸš«)

### âœ… Belongs here
- **Distribution bundles** meant for download/transfer
- **Derived, processed outputs** suitable for external users
- **Integrity artifacts**: checksums (and optional signatures)
- **Manifest** describing:
  - formats + MIME types
  - schema references
  - version + run identifiers
  - how this maps back to STAC/DCAT/PROV

### ğŸš« Does NOT belong here
- Raw dumps or vendor source drops
- Intermediate â€œwork/â€ artifacts
- Hand-edited outputs (regen via pipeline)
- Secrets, credentials, or any access tokens

---

## ğŸš€ Quickstart for consumers

### 1) Verify integrity ğŸ”
```bash
cd data/catalog/dcat/_attachments/<dataset_id>/dist
sha256sum -c checksums.sha256
```

### 2) Extract the distribution ğŸ“¦
Examples (use the one that matches your artifact):

```bash
# ZIP
unzip "<dataset_id>__<ver>__dist.zip" -d "./_extracted"

# TAR.GZ
tar -xzf "<dataset_id>__<ver>__dist.tar.gz" -C "./_extracted"
```

### 3) Read the manifest ğŸ§¾
`manifest.json` is the **source of truth** for:
- which file is the â€œprimaryâ€ distribution
- what each file contains
- expected schemas + field meanings
- where to find lineage and discovery metadata

---

## ğŸ§¾ `manifest.json` contract (recommended shape)

> If your pipeline generates a different manifest shape, **document it here** and keep it stable.

```json
{
  "dataset_id": "<dataset_id>",
  "title": "<human title>",
  "version": "<semver or date-tag>",
  "created_at": "<ISO-8601 UTC>",
  "git_commit": "<commit hash>",
  "pipeline_run_id": "<run id>",
  "license": "<SPDX or license id>",
  "sensitivity": "<public|internal|confidential|restricted>",
  "artifacts": [
    {
      "path": "<dataset_id>__<ver>__dist.zip",
      "role": "primary",
      "media_type": "application/zip",
      "sha256": "<hex>",
      "bytes": 123456,
      "contains": [
        {"kind": "data", "format": "parquet", "relative_path": "data/*.parquet"},
        {"kind": "docs", "format": "md", "relative_path": "docs/README.md"}
      ]
    }
  ],
  "links": {
    "dcat_record": "data/catalog/dcat/<dataset_id>.jsonld",
    "stac_collection": "data/stac/collections/<collection_id>.json",
    "stac_items": ["data/stac/items/<item_id>.json"],
    "prov_bundle": "data/prov/<prov_id>.json"
  }
}
```

---

## ğŸ”— Discovery & lineage linkages (DCAT â†” STAC â†” PROV)

KFM expects **all published datasets** to have aligned boundary artifacts:

- ğŸ“š **DCAT** = high-level discovery record (title/description/license/keywords + distribution links)
- ğŸ›°ï¸ **STAC** = spatial/temporal indexing and asset pointers
- ğŸ§¬ **PROV** = end-to-end lineage (inputs â†’ steps â†’ outputs)

### ğŸ” Helpful pointers (typical locations)
- DCAT: `data/catalog/dcat/`
- STAC: `data/stac/collections/` and `data/stac/items/`
- PROV: `data/prov/`

> âœ… If you change whatâ€™s in `dist/`, you must ensure the **DCAT distribution links** and **STAC asset links** still point to the right place, and the **PROV bundle** records the run.

---

## ğŸ·ï¸ Versioning rules (dataset-level)

Recommended conventions:
- Prefer **SemVer** for stable â€œproductsâ€ (e.g., `1.2.0`)
- Use **date tags** for periodic rebuilds when SemVer isnâ€™t meaningful (e.g., `2026.01.29`)
- If a dataset is revised/reprocessed, publish as a **new version** and link revisions in metadata

âœ… **When creating a new version**:
- generate a new `dist/` artifact set
- update DCAT/PROV to reference prior version (revision lineage)
- keep prior version accessible when possible (reproducibility + citations)

---

## ğŸ” Access & sensitivity (quick legend)

Use a simple classification tag in `manifest.json` + DCAT metadata so downstream systems can enforce policy:

| Tag | Meaning | Expected handling |
|---|---|---|
| `public` | Openly shareable | Can be distributed broadly |
| `internal` | Project-only | Donâ€™t publish externally |
| `confidential` | Sensitive | Restricted distribution, extra review |
| `restricted` | High sensitivity | Access-controlled, redaction required |

> ğŸ§¯ Governance tip: default to **fail-closed** â€” if classification/license/metadata is missing, treat as non-publishable until fixed.

---

## ğŸ› ï¸ Rebuild notes (maintainers)

### Non-negotiables âœ…
- Follow the canonical ordering: **Raw â†’ Processed â†’ Catalog/PROV â†’ Database â†’ API â†’ UI**
- Keep pipelines deterministic + replayable (same inputs â‡’ stable outputs)
- Prefer code-driven regeneration over manual edits

### Typical rebuild flow ğŸ§ª
1. Place source data in the domainâ€™s raw area: `data/raw/<domain>/...`
2. Run the dataset pipeline in `src/pipelines/...` to produce outputs in `data/processed/<domain>/...`
3. Generate catalogs:
   - STAC in `data/stac/...`
   - DCAT in `data/catalog/dcat/...`
   - PROV in `data/prov/...`
4. Produce `dist/` artifacts + `manifest.json` + `checksums.sha256`
5. Validate locally + in CI (schemas/profiles)

> ğŸ§© If the repo uses `releases/` for larger aggregated bundles, `dist/` should still remain the dataset-scoped â€œsourceâ€ for DCAT distribution links.

---

## âœ… Maintainer checklist (PR-ready)

- [ ] `manifest.json` updated and reflects every artifact shipped
- [ ] `checksums.sha256` includes **all** artifacts in `dist/`
- [ ] DCAT record references distributions correctly
- [ ] STAC assets point to stable data locations
- [ ] PROV bundle references run config + inputs + outputs
- [ ] `license` present + correct
- [ ] `sensitivity` present + correct
- [ ] CI validators pass (schemas/profiles)
- [ ] Citation guidance present (see repo `CITATION.cff` if applicable)

---

## ğŸ“š Project standards & helpful reading

- ğŸ“˜ Master guide: `docs/MASTER_GUIDE_v13.md`
- ğŸ§· Standards profiles:
  - `docs/standards/KFM_DCAT_PROFILE.md`
  - `docs/standards/KFM_STAC_PROFILE.md`
  - `docs/standards/KFM_PROV_PROFILE.md`
- ğŸ§¾ Schemas (machine validation): `schemas/`
- ğŸ§° Tooling & validators: `tools/`
- ğŸ“¦ Repo-level releases: `releases/`

---

## ğŸ†˜ Support

If anything in this `dist/` package looks wrong (missing files, checksum mismatch, unclear schema):
- open an issue with:
  - dataset id: `<dataset_id>`
  - version: `<ver>`
  - failing file: `<path>`
  - checksum output / error logs

ğŸ‘¤ Maintainer: **`<name or team>`**  
ğŸ“« Contact: **`<email or link>`**

---
