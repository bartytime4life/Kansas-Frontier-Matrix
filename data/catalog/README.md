# ğŸ—‚ï¸ `data/catalog/` â€” Dataset Catalog (ğŸ” DCAT â€¢ ğŸ›°ï¸ STAC â€¢ ğŸ§¬ PROV)

![DCAT](https://img.shields.io/badge/metadata-DCAT%20(JSON--LD)-2b6cb0)
![STAC](https://img.shields.io/badge/assets-STAC-cc5500)
![PROV](https://img.shields.io/badge/lineage-W3C%20PROV-6b46c1)
![Governed](https://img.shields.io/badge/governance-policy%20gated-1f7a1f)
![Evidence-first](https://img.shields.io/badge/principle-evidence--first-111827)

> [!IMPORTANT]
> **This folder is the â€œpublic contractâ€ for datasets.**  
> If itâ€™s not described here (and cross-linked to STAC + PROV), it **doesnâ€™t ship** to downstream systems.

---

## ğŸ¯ What this folder is for

`data/catalog/` holds **discoverable, machine-readable dataset metadata** (primarily **DCAT JSON-LD**) that powers:

- ğŸ” **Search & discovery** (keyword / bbox / time range)
- ğŸŒ **API dataset endpoints** (dataset summaries, links to assets, download formats)
- ğŸ§¾ **Governance & licensing clarity** (who published it, what you can do with it)
- ğŸ§¬ **Traceability** (â€œthe map behind the mapâ€ â†’ every layer ties back to sources + processing steps)

---

## ğŸ§­ The non-negotiable â€œTruth Pathâ€ âœ…

KFM enforces a strict lifecycle so nothing bypasses provenance + governance gates:

```mermaid
flowchart LR
  A["ğŸ“¥ Raw<br/>data/raw/..."] --> B["ğŸ­ Processed<br/>data/processed/..."]
  B --> C["ğŸ—‚ï¸ Catalog<br/>data/catalog (DCAT)"]
  C --> D["ğŸ—ƒ Databases<br/>PostGIS / Graph / Search"]
  D --> E["ğŸŒ API<br/>REST / GraphQL"]
  E --> F["ğŸ—º UI + ğŸ¤– AI<br/>Maps / Focus Mode"]
```

> [!TIP]
> The catalog is a **boundary artifact**: itâ€™s what downstream services trust to exist, be legal to serve, and be explainable.

---

## ğŸ“¦ What lives here (and what does *not*)

### âœ… Lives in `data/catalog/`
- ğŸ§¾ **DCAT Dataset entries** (JSON-LD) used for discovery and API dataset summaries
- ğŸ§© **Profiles / schemas** (so metadata is consistent and validateable)
- ğŸ§° **Templates** (copy/paste starters for new datasets)
- ğŸ§± **Index artifacts** (optional) to speed local search or docs builds

### âŒ Does *not* live here
- ğŸ§± Raw downloads â†’ put in `data/raw/<domain>/...`
- ğŸ Final deliverables (COGs, GeoParquet, GeoJSON, etc.) â†’ `data/processed/<domain>/...`
- ğŸ›°ï¸ STAC Collections/Items â†’ `data/stac/...`
- ğŸ§¬ PROV lineage bundles â†’ `data/prov/...`

---

## ğŸ—ƒï¸ Expected layout

This is the **recommended canonical structure** (create folders if missing):

```text
ğŸ“ data/
  ğŸ“ catalog/
    ğŸ“„ README.md                      ğŸ‘ˆ you are here
    ğŸ“ dcat/
      ğŸ“ datasets/                    ğŸ‘ˆ one file per dataset (JSON-LD)
      ğŸ“„ catalog.jsonld               ğŸ‘ˆ optional rollup (generated/maintained)
    ğŸ“ schemas/
      ğŸ“„ dcat.dataset.schema.json     ğŸ‘ˆ validation schema(s)
      ğŸ“„ dcat.distribution.schema.json
    ğŸ“ templates/
      ğŸ“„ dataset.template.jsonld
    ğŸ“ profiles/
      ğŸ“„ KFM_DCAT_PROFILE.md          ğŸ‘ˆ human-readable rules
```

> [!NOTE]
> Keep **data** and **metadata** separate: metadata changes often and is small; data can be huge and may be tracked via DVC or object storage.

---

## ğŸ§¾ DCAT records: rules of the road

### 1) One dataset = one DCAT file ğŸ“„
Create a single JSON-LD file per dataset:

- **Path:** `data/catalog/dcat/datasets/<dataset_id>.jsonld`
- **Dataset ID:** stable, lowercase, snake_case  
  Example: `ks_hydrology_1880`

### 2) Required fields (minimum viable governance) âœ…
Your DCAT dataset entry must include, at minimum:

- `dct:identifier` (must match `<dataset_id>`)
- `dct:title`
- `dct:description`
- `dct:license` (or `dct:rights`)
- `dct:publisher` (org/agent)
- `dct:spatial` (bbox or geometry reference)
- `dct:temporal` (start/end or interval)
- `dcat:distribution[]` (links to assets + access patterns)
- Cross-links to:
  - ğŸ›°ï¸ **STAC** (collection/items that describe the actual assets)
  - ğŸ§¬ **PROV** (how it was produced)

---

## ğŸ§© Minimal DCAT JSON-LD template (copy/paste)

Create: `data/catalog/dcat/datasets/<dataset_id>.jsonld`

```json
{
  "@context": {
    "dcat": "http://www.w3.org/ns/dcat#",
    "dct": "http://purl.org/dc/terms/",
    "prov": "http://www.w3.org/ns/prov#"
  },
  "@type": "dcat:Dataset",
  "dct:identifier": "ks_example_dataset_1900",
  "dct:title": "Kansas Example Dataset (1900)",
  "dct:description": "Short, evidence-first description. What is it, why it exists, what it is not.",
  "dct:license": "SPDX-OR-URL-HERE",
  "dct:publisher": {
    "@type": "prov:Agent",
    "dct:title": "Kansas Frontier Matrix"
  },
  "dct:spatial": {
    "type": "Polygon",
    "coordinates": [[[ -102.051, 36.993 ], [ -94.588, 36.993 ], [ -94.588, 40.003 ], [ -102.051, 40.003 ], [ -102.051, 36.993 ]]]
  },
  "dct:temporal": {
    "startDate": "1900-01-01",
    "endDate": "1900-12-31"
  },
  "dcat:distribution": [
    {
      "@type": "dcat:Distribution",
      "dct:title": "STAC Collection",
      "dcat:accessURL": "data/stac/collections/ks_example_dataset_1900.collection.json",
      "dct:format": "application/json"
    },
    {
      "@type": "dcat:Distribution",
      "dct:title": "GeoJSON Download",
      "dcat:downloadURL": "data/processed/example/ks_example_dataset_1900.geojson",
      "dct:format": "application/geo+json"
    }
  ],
  "prov:wasDerivedFrom": [
    {
      "@type": "prov:Entity",
      "dct:identifier": "source:agency_or_archive:record_id_or_url"
    }
  ]
}
```

> [!TIP]
> If you donâ€™t have precise spatial/temporal bounds yet, keep them **honest** (coarse is fine) and tighten laterâ€”donâ€™t fabricate precision.

---

## ğŸ›°ï¸ How DCAT â†” STAC â†” PROV fit together

- **DCAT (this folder)** = *â€œWhat is this dataset?â€* (discovery + governance + how to access it)
- **STAC (`data/stac/`)** = *â€œWhat files/assets exist?â€* (COGs, tiles, GeoParquet, rasters, etc.)
- **PROV (`data/prov/`)** = *â€œHow was it made?â€* (inputs â†’ activities â†’ outputs â†’ agents)

> [!IMPORTANT]
> Any â€œAI-derived layerâ€ (classification, OCR corpus, model output) must be treated as a **first-class dataset**:
> it gets **processed storage**, **DCAT**, **STAC**, and **PROV** like everything else.

---

## ğŸ§ª Validation & CI gates (what will fail your PR) ğŸš¦

Typical failures that should be prevented locally:

- âŒ Missing DCAT dataset entry for a new layer
- âŒ No linked STAC collection/items
- âŒ Missing PROV lineage bundle
- âŒ License/rights unclear or incompatible
- âŒ Broken references (paths/URLs)
- âŒ Schema mismatch (invalid JSON-LD / missing required fields)

> [!NOTE]
> CI is expected to enforce these invariants automatically (schema validation, provenance completeness, and safety checks).

---

## ğŸŒ How the API uses this catalog

Downstream services should treat this folder as the source of truth for *metadata*:

- `GET /api/v1/datasets/{id}` â†’ returns dataset metadata summary (**DCAT**) + links to assets (**STAC**, etc.)
- `GET /api/v1/catalog/search` â†’ search datasets by keyword, bounding box, and/or time range

> [!TIP]
> Keep `dct:identifier` stable: it becomes the **public handle** for API, UI, bookmarks, and citations.

---

## ğŸ§° Add a new dataset: quick checklist âœ…

### 1) Pick an ID ğŸ·ï¸
- `ks_<domain>_<topic>_<time>`
- Examples:
  - `ks_hydrology_1880`
  - `ks_counties_boundaries_current`
  - `ks_newspapers_chronicling_america_1836_1922`

### 2) Place data in the correct stage ğŸ“¦
- `data/raw/<domain>/...` (inputs)
- `data/work/<domain>/...` (intermediate)
- `data/processed/<domain>/...` (final outputs)

### 3) Publish boundary artifacts ğŸ§¾ğŸ›°ï¸ğŸ§¬
- âœ… DCAT: `data/catalog/dcat/datasets/<dataset_id>.jsonld`
- âœ… STAC: `data/stac/collections/...` + `data/stac/items/...`
- âœ… PROV: `data/prov/<dataset_id>.prov.json` (or similar)

### 4) Validate locally ğŸ§ª
Run the repoâ€™s catalog validation command(s) (see root tooling / CI config).  
If none exist yet, add a lightweight validator before scaling ingestion.

---

## ğŸ§  Practical tips (battle-tested) ğŸ§·

- ğŸ§· **Prefer links over copies**: DCAT can point to STAC + processed assets without duplicating metadata everywhere.
- ğŸ§· **Keep descriptions evidence-first**: define scope, known limitations, and intended use.
- ğŸ§· **Never hide licensing**: if you canâ€™t state the license, you canâ€™t responsibly publish the dataset.
- ğŸ§· **Treat the catalog as code**: small PRs, reviewable diffs, consistent schema, automated checks.

---

## ğŸ“š Related folders (recommended reading)

- ğŸ›°ï¸ `data/stac/` â€” asset catalog (collections/items)
- ğŸ§¬ `data/prov/` â€” provenance / lineage bundles
- ğŸ­ `pipelines/` â€” ingestion + processing workflows
- ğŸŒ `src/server/api/` â€” API contracts that expose catalog + data

---

*â€œIf itâ€™s not traceable, itâ€™s not shippable.â€* âœ…