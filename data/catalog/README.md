# ğŸ“š Data Catalog (`data/catalog/`)

![Metadata](https://img.shields.io/badge/metadata-DCAT%20%7C%20STAC%20%7C%20PROV-blue)
![Governance](https://img.shields.io/badge/governance-fail--closed-important)
![Principles](https://img.shields.io/badge/principles-FAIR%20%2B%20CARE-success)
![Status](https://img.shields.io/badge/role-discovery%20%26%20trust-informational)

> ğŸ—ºï¸ **â€œThe map behind the map.â€**  
> This folder is the **discovery layer** for KFM datasets: it makes data *findable*, *auditable*, and *reusable* across pipelines, databases, APIs, and the UI.

---

## ğŸ¯ What this folder is for

`data/catalog/` holds **catalog-grade metadata** used to:
- **List & search datasets** (humans + API + UI)
- Provide **high-level dataset summaries** (title, description, licensing, distributions)
- Power exports/harvesters (optional) for external catalogs
- Enforce **governance + reproducibility** by making metadata mandatory

In KFM, metadata is not optionalâ€”**catalog + provenance are part of the â€œpublishâ€ step**, not a nice-to-have.

---

## ğŸ§¬ Canonical lifecycle (where `data/catalog/` sits)

```mermaid
flowchart LR
  A[ğŸ“¥ data/raw/<domain>/] --> B[ğŸ§¹ data/work/<domain>/]
  B --> C[âœ… data/processed/<domain>/]
  C --> D[ğŸ§¾ data/catalog/ + ğŸ§¾ data/provenance/]
  D --> E[ğŸ—„ï¸ Database layers]
  E --> F[ğŸ§© API layer]
  F --> G[ğŸ—ºï¸ UI + Story Nodes + Focus Mode]
```

âœ… **Rule of thumb:** if it shows up in the UI, it must be backed by **processed data + catalog metadata + provenance**.

---

## ğŸ§± Expected folder layout

This repo may evolve over time, but the intent stays consistent:

```text
data/
â”œâ”€â”€ catalog/
â”‚   â”œâ”€â”€ dcat/                 # âœ… DCAT dataset entries (JSON-LD recommended)
â”‚   â”œâ”€â”€ exports/              # (optional) generated indexes/aggregations (do not hand-edit)
â”‚   â””â”€â”€ README.md             # you are here
â”œâ”€â”€ stac/
â”‚   â”œâ”€â”€ collections/          # âœ… STAC Collections (geospatial discovery metadata)
â”‚   â””â”€â”€ items/                # âœ… STAC Items (asset-level metadata)
â””â”€â”€ provenance/               # âœ… PROV activity bundles (lineage)
```

> ğŸ’¡ If your repo currently stores STAC under `data/catalog/` instead of `data/stac/`, thatâ€™s okayâ€”**the contract is â€œSTAC exists + is linked,â€** not the exact directory name.

---

## ğŸ“¦ What belongs in `data/catalog/`

### âœ… DCAT dataset entries (required)
Store one record per dataset (or per dataset â€œrelease unitâ€) under:

- `data/catalog/dcat/<dataset_id>.jsonld`

DCAT records should be:
- human-readable enough for browsing
- machine-readable for indexing
- link-rich (point to STAC, processed assets, docs, and provenance)

### ğŸ§© Optional: generated indexes
If you build an aggregate catalog view:
- `data/catalog/exports/datasets.index.json`
- `data/catalog/exports/keywords.index.json`

âœ… Treat these as **build artifacts**.

---

## ğŸ”— Cross-linking rules (non-negotiable)

KFM expects **STAC + DCAT + PROV to agree** and cross-reference:

- **STAC Items â†’ assets** (usually files in `data/processed/**` or stable external storage)
- **DCAT â†’ distributions** (link to STAC and/or the underlying downloadable asset)
- **PROV â†’ full lineage** (raw â†’ work â†’ processed, plus pipeline run/config/commit)
- Downstream graph/database nodes should **reference catalog IDs**, not duplicate metadata

---

## âœ… Definition of Done (DoD) for adding a dataset

When you add or update a dataset, youâ€™re done only when all of these are true:

### 1) âœ… Processed data exists
- Output(s) live in `data/processed/<domain>/...`
- Data is clean, normalized, and ready for API/UI consumption

### 2) âœ… STAC exists (Collection + Item(s))
- Collection describes the dataset group (theme, extent, time range)
- Item(s) describe each asset (file/API endpoint), including bbox/time/license attribution

### 3) âœ… DCAT exists (this folder)
- `data/catalog/dcat/<dataset_id>.jsonld`
- Contains: **title**, **description**, **license**, **keywords**, **distributions**
- Distributions point to STAC and/or direct downloads

### 4) âœ… PROV exists
- `data/provenance/<dataset_id>.prov.json` (or similar convention)
- Captures inputs, processing activity, agents, timestamps, parameters/config

### 5) âœ… Validation passes (CI is the gatekeeper ğŸš¦)
- Schema checks, provenance completeness, and security checks must pass
- Missing metadata/provenance should be treated as a **blocker**

---

## ğŸ§¾ Minimal DCAT starter (JSON-LD)

> âš ï¸ This is a **starter skeleton**, not the full project profile.

```json
{
  "@context": {
    "dcat": "http://www.w3.org/ns/dcat#",
    "dct": "http://purl.org/dc/terms/"
  },
  "@id": "kfm:dataset/<dataset_id>",
  "@type": "dcat:Dataset",
  "dct:title": "Human-readable dataset title",
  "dct:description": "What this dataset is, what it contains, and how it can be used.",
  "dct:license": "SPDX identifier or license URL",
  "dcat:keyword": ["kansas", "frontier", "railroad", "1860s"],
  "dcat:distribution": [
    {
      "@type": "dcat:Distribution",
      "dct:title": "STAC entry",
      "dcat:accessURL": "relative/or/absolute/link/to/stac/item-or-collection"
    }
  ]
}
```

---

## ğŸ§  Naming & stability conventions

Keep identifiers stable and boring ğŸ˜„:
- Prefer `snake_case` or `kebab-case` slugs
- Reuse the same `dataset_id` across:
  - DCAT filename
  - STAC `id`
  - PROV `entity/activity` IDs
  - pipeline outputs (where possible)

âœ… If you version data, version **distributions**, not the dataset identity:
- dataset stays stable
- distributions point to versioned STAC items / processed files

---

## ğŸš« Anti-patterns (please donâ€™t)

- âŒ Dropping â€œfinalâ€ data into `data/processed/` **without** DCAT/STAC/PROV
- âŒ Writing DCAT records that donâ€™t link to distributions
- âŒ â€œMystery dataâ€ (no license, no source attribution, no provenance)
- âŒ Copy/pasting external metadata without adapting it to KFM profiles
- âŒ Treating the catalog as â€œdocumentation onlyâ€ (itâ€™s executable discovery metadata)

---

## ğŸ§° Helpful pointers

- ğŸ“Œ **Profiles live in** `docs/standards/` (project-specific STAC/DCAT/PROV extensions)
- ğŸ§ª **Validation is enforced by CI** â€” assume missing metadata will fail builds
- ğŸ§­ When in doubt: **link more** (processed asset, STAC, provenance, upstream sources, docs)

---

## ğŸ¤ Contributing checklist (quick copy/paste)

- [ ] Processed output written to `data/processed/<domain>/...`
- [ ] STAC Collection created/updated
- [ ] STAC Item(s) created/updated
- [ ] DCAT JSON-LD created/updated in `data/catalog/dcat/`
- [ ] PROV bundle created/updated in `data/provenance/`
- [ ] Links verified (STAC â†” DCAT â†” PROV)
- [ ] CI checks pass âœ…

---

## ğŸ§¾ Why all this ceremony?

Because KFM is built to be:
- **reproducible** (same inputs â†’ same outputs)
- **auditable** (every dataset has a lineage story)
- **publishable** (metadata supports internal + external discovery)
- **trustworthy** (governance-by-default, fail-closed)