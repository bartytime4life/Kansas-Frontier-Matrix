# ğŸ“¦ `data/` â€” Kansas Frontier Matrix Data & Metadata Hub ğŸ§­ğŸ—ºï¸

<p align="left">
  <img alt="KFM" src="https://img.shields.io/badge/KFM-data%20%26%20metadata-2b6cb0" />
  <img alt="Pipeline" src="https://img.shields.io/badge/pipeline-ETL%E2%86%92Catalogs%E2%86%92Graph%E2%86%92API%E2%86%92UI%E2%86%92Story%E2%86%92Focus-111827" />
  <img alt="STAC" src="https://img.shields.io/badge/STAC-Collections%20%26%20Items-845ef7" />
  <img alt="DCAT" src="https://img.shields.io/badge/DCAT-JSON--LD-845ef7" />
  <img alt="PROV" src="https://img.shields.io/badge/PROV-lineage%20bundles-845ef7" />
  <img alt="Formats" src="https://img.shields.io/badge/formats-GeoJSON%20%7C%20COG%20%7C%20Tiles-2b9348" />
  <img alt="DB" src="https://img.shields.io/badge/storage-PostGIS%20%7C%20Object%20Store-informational" />
  <img alt="Governance" src="https://img.shields.io/badge/governance-FAIR%20%2B%20CARE%20%2B%20Sovereignty-2ea043" />
  <img alt="Security" src="https://img.shields.io/badge/security-deny--by--default-critical" />
</p>

> **Last reviewed:** 2026-01-06  
> âœ… **Purpose:** `data/` is the canonical home for **raw inputs**, **intermediate work**, **processed outputs**, and the **metadata boundary artifacts** (STAC/DCAT/PROV) that make KFM traceable, governed, and shippable.  
> âš ï¸ **Rule:** If it isnâ€™t **cataloged + provenanceâ€‘linked**, it isnâ€™t **published** in KFM.  
> ğŸ§  **Data Spaces mindset:** KFM treats metadata + identifiers + provenance as the *interface*; big binaries can live elsewhere as long as pointers are stable and auditable.  

**â¬…ï¸ Back to repo overview:** [`../README.md`](../README.md)  
**ğŸ¤ Collaboration & automation:** [`../.github/README.md`](../.github/README.md) *(if present)*  
**ğŸ§­ MCP governance layer:** [`../mcp/MCP-README.md`](../mcp/MCP-README.md) *(recommended)*  

---

## ğŸ§­ Quick Nav
- [ğŸ 5â€‘minute publish checklist](#-5minute-publish-checklist)
- [ğŸ§  KFM pipeline snapshot](#-kfm-pipeline-snapshot)
- [ğŸš¦ Nonâ€‘negotiables](#-nonnegotiables)
- [âœ… What â€œpublishedâ€ means in KFM](#-what-published-means-in-kfm)
- [ğŸ—‚ï¸ Directory layout](#ï¸-directory-layout)
- [ğŸ” Data lifecycle](#-data-lifecycle)
- [ğŸ·ï¸ Metadata boundary artifacts](#ï¸-metadata-boundary-artifacts)
- [ğŸ“ Formats & performance rules](#-formats--performance-rules)
- [ğŸ§¾ Evidence artifacts (AI + analysis outputs)](#-evidence-artifacts-ai--analysis-outputs)
- [ğŸ§· Stable IDs + naming + hashing](#-stable-ids--naming--hashing)
- [ğŸ§ª Validation & CI gates](#-validation--ci-gates)
- [â• Adding a new dataset / domain](#-adding-a-new-dataset--domain)
- [ğŸ› ï¸ Toolchain](#ï¸-toolchain)
- [ğŸ“š Project file influence map](#-project-file-influence-map-uses-all-project-files)
- [ğŸ§· Footnotes](#-footnotes)

---

## ğŸ 5â€‘minute publish checklist

> [!IMPORTANT]
> **Publishing** = **processed output + boundary artifacts + validation**.  
> Raw files alone are *never* â€œpublishedâ€ in KFM.

### âœ… Minimum bar (per dataset)
- [ ] Place sources under `data/raw/<domain>/â€¦` *(stay close to original; preserve reprocessing baseline)*
- [ ] Generate intermediates under `data/work/<domain>/â€¦` *(temporary joins, clipped AOIs, staging rasters)*
- [ ] Produce publishable outputs under `data/processed/<domain>/â€¦`
- [ ] Write boundary artifacts:
  - [ ] **STAC Collection** â†’ `data/stac/collections/<collection-id>.json`
  - [ ] **STAC Item(s)** â†’ `data/stac/items/<item-id>.json`
  - [ ] **DCAT Dataset (JSONâ€‘LD)** â†’ `data/catalog/dcat/<dataset-id>.jsonld`
  - [ ] **PROV bundle (JSONâ€‘LD)** â†’ `data/prov/<run-id>.jsonld`
- [ ] Record hashes (SHA256) for processed outputs *(and raw when feasible)*
- [ ] Add QA evidence to `data/qa/<domain>/â€¦` *(bbox sanity, quicklook screenshot, validation report)*
- [ ] Run validators (local or CI) and confirm all links + schemas pass

### ğŸ¥‡ Optional â€œquality tiersâ€ (useful for expectations)
| Tier | What it means | Required |
|---|---|---|
| ğŸ¥‰ Bronze | Raw + minimal metadata | Raw preserved + classification + source/terms |
| ğŸ¥ˆ Silver | Publishable output + STAC | Processed output + STAC + QA note |
| ğŸ¥‡ Gold | Fully governed + discoverable | STAC + DCAT + PROV + strong QA + hashes |

---

## ğŸ§  KFM pipeline snapshot

KFM enforces strict ordering from **data â†’ catalogs â†’ graph â†’ API â†’ UI â†’ narrative**, ensuring endâ€‘toâ€‘end traceability.

```mermaid
flowchart LR
  subgraph Data["ğŸ“¦ Data & Metadata"]
    A["Raw Sources"] --> B["ETL + Normalization"]
    B --> C["STAC Items + Collections"]
    C --> D["DCAT Dataset Views"]
    C --> E["PROV Lineage Bundles"]
  end

  C --> G["ğŸ•¸ï¸ Graph (references back to catalogs)"]
  G --> H["ğŸ›°ï¸ API Layer (contracts + auth + redaction)"]
  H --> I["ğŸ—ºï¸ Map UI â€” React Â· MapLibre Â· (optional) WebGL/3D"]
  I --> J["ğŸ“š Story Nodes (governed narratives)"]
  J --> K["ğŸ¯ Focus Mode (provenance-linked context bundle)"]
```

---

## ğŸš¦ Nonâ€‘negotiables

- â›“ï¸ **Pipeline ordering is absolute:** `ETL â†’ Catalogs (STAC/DCAT/PROV) â†’ Graph â†’ API â†’ UI â†’ Story â†’ Focus`.  
- ğŸšª **API boundary rule:** UI never queries internal stores/graph directly; all access goes through governed API endpoints.
- ğŸ” **Deterministic + idempotent ETL:** config-driven, repeatable runs with stable IDs, run logs, and hashes.
- ğŸ§¾ **Evidence-first narrative:** Story/Fâ€‹ocus must cite evidence; AI outputs must be labeled + provenance-linked.
- ğŸ·ï¸ **Sovereignty & classification propagation:** outputs cannot become *less restricted* than any input without an approved redaction step.
- ğŸ”’ **Treat inputs as hostile:** GeoJSON, CSV, PDFs, rasters, and â€œmetadata from the internetâ€ can be attack surfacesâ€”validate and bound.

> [!TIP]
> **FAIR** makes data *findable/accessible/interoperable/reusable*.  
> **CARE** keeps it *ethical and accountable*.  
> **Sovereignty** ensures the right people control sensitive data.

---

## âœ… What â€œpublishedâ€ means in KFM

KFM uses explicit **stages** and **contracts** (so we donâ€™t ship â€œmystery layersâ€).

### ğŸ§Š Stages (data state)
- **Raw** (`data/raw/**`) â†’ source snapshot; minimally transformed; reprocessing baseline.
- **Work** (`data/work/**`) â†’ intermediate artifacts; not stable; may be deleted/regenerated.
- **Processed** (`data/processed/**`) â†’ final outputs meant to be served/used downstream.
- **Published** âœ… â†’ processed outputs that have:
  - STAC/DCAT/PROV boundary artifacts **and**
  - passing validations/CI gates **and**
  - classification/handling rules applied.

### ğŸ§¾ Boundary artifacts (metadata state)
- **STAC** = asset-level + spatial/temporal indexing
- **DCAT** = dataset/distribution discovery entry
- **PROV** = lineage graph: inputs â†’ activities â†’ outputs

> [!WARNING]
> If you ship a file without a STAC/DCAT/PROV trail, you ship an **orphan**. Orphans do not go to prod.

---

## ğŸ—‚ï¸ Directory layout

> KFMâ€™s **canonical layout** keeps both humans and automation sane.

```text
data/
  raw/                         # 1) Raw, minimally transformed inputs (per domain)
    <domain>/

  work/                        # 2) Intermediate artifacts produced during ETL (per domain)
    <domain>/

  processed/                   # 3) Final, publishable outputs (per domain)
    <domain>/

  stac/                        # âœ… Required: STAC catalog artifacts
    catalog.json               # â­ Recommended: root STAC catalog entrypoint
    collections/               # STAC Collections (dataset-level)
    items/                     # STAC Items (asset-level)

  catalog/
    dcat/                      # âœ… Required: DCAT JSON-LD dataset entries

  prov/                        # âœ… Required: PROV lineage bundles (inputs â†’ activities â†’ outputs)

  manifests/                   # â­ Recommended: dataset manifests, dictionaries, contracts
  qa/                          # â­ Recommended: validation reports + â€œlooks-rightâ€ evidence

  graph/                       # â­ Optional: graph import/export artifacts (reference index only)
    csv/
    cypher/

  README.md                    # ğŸ“ you are here
```

> [!NOTE]
> Some teams prefer `data/<domain>/{raw,work,processed}`. Thatâ€™s fineâ€”just keep the same intent and keep catalogs/prov discoverable.

---

## ğŸ” Data lifecycle

KFM supports **batch** and **event-driven** pipelines (depending on source scale and cadence).

### 1) Ingestion ğŸ“¥
- Batch pulls (scheduled) for known sources.
- Manual uploads (expert CSVs/surveys) into staging with controlled import.
- Preserve raw inputs as a reprocessing anchor.

### 2) Processing ğŸ§°
Cleaning, joins, georeferencing, derived layers, modeling, simulation outputs.

- Prefer â€œcompute close to dataâ€ when appropriate (e.g., PostGIS spatial SQL + indices).
- Use distributed patterns when spatiotemporal archives grow (chunking, partitions, caching).
- Keep transforms explicit and repeatable (scripts/configs captured by PROV).

### 3) Storage & indexing ğŸ—„ï¸
Processed outputs live in:
- Queryable stores (PostGIS tables + spatial indices)
- Web-friendly geospatial files (COG/GeoJSON/tiles) optimized for streaming
- Evidence artifacts for modeling/simulation (plots, summaries, uncertainty notes)

### 4) Publication / serving ğŸŒ
- UI consumes **governed API outputs** (authZ + redaction + classification propagation).
- â€œNew data availableâ€ signals can trigger graph refresh and UI indexing.

---

## ğŸ·ï¸ Metadata boundary artifacts

> [!IMPORTANT]
> Boundary artifacts are the **interfaces** downstream layers consume.  
> Graph/API/UI/story must reference **catalog IDs**, not ad-hoc local paths.

### âœ… Required metadata outputs
- **STAC (Collections + Items)** for geospatial assets (vectors, rasters, tiles, and related artifacts).
- **DCAT dataset entry (JSONâ€‘LD)** for discovery: title/description/license/keywords/distributions.
- **PROV lineage bundle** capturing inputs â†’ activities â†’ outputs with configs/params and run identifiers.

### ğŸ”— Cross-layer linkage expectations (do not break)
- STAC Items must link to stable assets (usually under `data/processed/**`).
- DCAT must link to distributions (STAC collection and/or direct downloads).
- PROV must link raw â†’ work â†’ processed and record run/config identifiers.
- Graph stores references to catalog IDs (avoid storing bulky payloads in the graph).

### ğŸ” Classification propagation (always-on)
- Carry classification/handling labels through STAC, DCAT, and PROV.
- Outputs cannot be published at a lower restriction than any input without a documented redaction step.

> [!CAUTION]
> Public repo = public download. Treat â€œeasy to copyâ€ formats (GeoJSON/CSV) as disclosure boundaries.

---

## ğŸ“ Formats & performance rules

KFM is map-first and time-aware. Formats must support streaming, indexing, and honest representation.

### ğŸ—ºï¸ Vector
| Use case | Recommended format | Why |
|---|---|---|
| Small inspectable overlays | GeoJSON | debuggable; works everywhere |
| Medium/large boundaries | TopoJSON | smaller wire size |
| Dense/large features | Vector tiles (PMTiles/MBTiles) | pan/zoom performance |
| Authority edits / storage | PostGIS | constraints + indices + query power |

**Vector must-haves âœ…**
- stable feature IDs (`kfm_id` or equivalent)
- geometry validity checks + CRS explicit
- simplification/topology preserved for UI layers

### ğŸ›°ï¸ Raster
| Use case | Recommended format | Why |
|---|---|---|
| Web streaming | **COG** (Cloud Optimized GeoTIFF) | range requests; pyramids |
| Quicklook | PNG/JPEG (small) | QA + previews |
| Time-series stacks | chunked/partitioned storage | scalability + partial reads |

**Raster must-haves âœ…**
- overviews/pyramids (when needed)
- nodata defined, units documented
- QA â€œlooks-rightâ€ screenshot at known zoom + bbox

### ğŸ“¦ Big data posture (keep git healthy)
- Git stores **metadata + small samples + QA**, not the entire state of the world.
- Heavy assets can live in object storage or release artifacts as long as:
  - STAC/DCAT pointers are stable,
  - hashes exist,
  - licensing allows distribution.

---

## ğŸ§¾ Evidence artifacts (AI + analysis outputs)

KFM treats **analysis outputs** (including AI-assisted artifacts and simulations) as first-class datasets:

âœ… Requirements:
- Stored in `data/processed/<domain>/...` (or `data/processed/evidence/...` if cross-domain)
- Cataloged in STAC/DCAT and flagged as derived (`kfm:derived=true`)
- Traced in PROV with:
  - input dataset IDs,
  - model/version + parameters,
  - uncertainty/limits where applicable,
  - classification propagation rationale
- Served only via governed APIs (redaction + role checks)

> [!TIP]
> If AI participates: label **AI-assisted**, store prompt/config when allowed, and record model version + constraints in PROV.

---

## ğŸ§· Stable IDs + naming + hashing

Stable IDs make the system queryable, debuggable, and safe to automate.

### âœ… ID patterns (recommended)
- **Dataset/Collection ID:** `kfm.ks.<domain>.<dataset>`
- **Item ID:** `kfm.ks.<domain>.<dataset>.<yyyymmdd|yyyymm>.<variant>.v<major>`
- **Run ID:** `etl_<yyyymmdd>_<hhmmss>_<shortgitsha>` *(or similar)*

### ğŸ“› File naming (processed outputs)
Use names that support routing and reproducibility:
- `<domain>__<dataset>__<yyyymmdd|yyyymm>__<epsg>__<resolution>__v<major.minor>.<ext>`
- Example: `agriculture__ndvi__20250301__epsg4326__30m__v1.0.tif`

### ğŸ”’ Hashing rule
Record **SHA256** for:
- processed outputs (required)
- raw inputs (recommended when feasible)
- ETL configs / parameter snapshots (recommended)

Where to store hashes:
- STAC `assets` (via `file:checksum` or a KFM profile field)
- PROV `Entity` records
- `data/manifests/**` (audit-friendly index)

---

## ğŸ§ª Validation & CI gates

KFM expects automated validation and governance checks to prevent regressions and sensitive leaks.

### âœ… Typical gates
- STAC/DCAT/PROV schema validation
- Link checks:
  - STAC assets exist
  - DCAT distributions resolve
  - PROV locations present and coherent
- Classification-consistency checks (no downgrades without redaction approval)
- Secret scanning + sensitive data scanning
- â€œLooks-rightâ€ QA checks for map layers (bbox, zoom, quicklook)

### ğŸ§° Starter local checks (example)
```bash
# 1) JSON sanity
find data/stac data/catalog/dcat data/prov -name "*.json*" -print0 | xargs -0 -n 1 jq empty

# 2) Broken links (STAC assets exist)
python tools/validate_stac_links.py data/stac/items

# 3) Provenance completeness (rawâ†’workâ†’processed)
python tools/validate_prov.py data/prov

# 4) Governance scan (example placeholder)
python tools/scan_sensitive.py data/processed
```

> â­ Keep CI fast: run heavy geospatial validations nightly when needed.

---

## â• Adding a new dataset / domain

Follow the domain expansion pattern and keep domains isolated.

### âœ… Checklist
- [ ] Create folders:
  - [ ] `data/raw/<new-domain>/`
  - [ ] `data/work/<new-domain>/`
  - [ ] `data/processed/<new-domain>/`
- [ ] Add ETL config (idempotent, logged, hashable)
- [ ] Produce boundary artifacts:
  - [ ] STAC Collection + Item(s)
  - [ ] DCAT JSONâ€‘LD entry
  - [ ] PROV run bundle
- [ ] Validate schemas + links in CI
- [ ] (Optional) Sync references into graph (after catalogs exist)
- [ ] Expose via governed API (redaction/classification)
- [ ] Add a domain runbook under docs (recommended)

<details>
<summary><strong>ğŸ§± Dataset skeleton (copy/paste)</strong></summary>

```text
data/raw/<domain>/<source>/
data/work/<domain>/<dataset>/
data/processed/<domain>/<dataset>/

data/stac/collections/kfm.ks.<domain>.<dataset>.json
data/stac/items/kfm.ks.<domain>.<dataset>.<yyyymmdd>.<variant>.v1.json

data/catalog/dcat/kfm.ks.<domain>.<dataset>.jsonld
data/prov/etl_<yyyymmdd>_<hhmmss>_<shortgitsha>.jsonld

data/qa/<domain>/<dataset>__<yyyymmdd>__qa.md
data/manifests/kfm.ks.<domain>.<dataset>.yml   # optional, recommended
```
</details>

---

## ğŸ› ï¸ Toolchain

KFMâ€™s data layer interoperates across geospatial + ML + simulation + web delivery:

- ğŸ **Python geospatial stack:** geopandas / rasterio / pyproj + PostGIS adapters
- ğŸ˜ **PostgreSQL + PostGIS:** spatial SQL + indices for scalable queries
- ğŸ§° **GDAL/OGR CLI:** `gdalwarp`, `gdal_translate`, `ogr2ogr` (repeatable transforms)
- ğŸ§© **Orchestration:** scheduled runs + event-driven jobs (queues/workers)
- ğŸŒ **Serving:** governed API returns GeoJSON/tiles/evidence bundles to UI
- ğŸ—ºï¸ **Visualization constraints:** web mapping is performance-bound; optimize early

---

## ğŸ“š Project file influence map (uses all project files)

> âœ… This README is informed by the full KFM reference pack.  
> The table below maps **every project file** to a concrete data-layer requirement or convention.

<details>
<summary><strong>ğŸ“¦ Expand: Influence map (all project files)</strong></summary>

| Project file | How it shapes `data/` (policy, formats, metadata, QA) |
|---|---|
| `Kansas Frontier Matrix (KFM) â€“ Comprehensive Engineering Design.docx` | Defines the canonical pipeline order, â€œpublished means cataloged,â€ evidence bundles, and API boundary posture |
| `Latest Ideas.docx` | Drives pragmatic staging: prototype in `work/`, graduate into `processed/` with catalogs + QA when it becomes real |
| `Data Spaces.pdf` | Metadata-as-interface mindset: pointer-over-payload, stable IDs, and â€œtrust signalsâ€ (provenance, checksums, distributions) |
| `Scalable Data Management for Future Hardware.pdf` | Informs big-data posture: partitioning, streaming-friendly formats, caching, and keeping git lean while preserving auditability |
| `PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf` | Guides PostGIS usage for spatial indexing, schema discipline, and operational patterns (migrations/backups/roles) |
| `python-geospatial-analysis-cookbook.pdf` | Anchors CRS sanity, vector/raster IO discipline, and transform-at-boundaries conventions |
| `Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf` | Shapes remote sensing pipelines: time-series outputs, export tracking, and derived raster governance (NDVI/composites) |
| `making-maps-a-visual-guide-to-map-design-for-gis.pdf` | Treats symbology/legends as truth claims; requires QA quicklooks and non-misleading map outputs |
| `Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf` | Adds mobile/offline considerations: tile bundles, reduced payloads, and location sensitivity awareness |
| `responsive-web-design-with-html5-and-css3.pdf` | Reinforces performance constraints that influence data packaging (tiles over blobs, previews, and payload budgets) |
| `webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf` | Motivates GPU-friendly formats/tiling and careful handling of large visual datasets; â€œgraceful degradationâ€ impacts what we store/ship |
| `compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf` | Governs image/quicklook optimization and avoiding repo bloat for QA assets |
| `ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf` | Threat-models the data pipeline: hostile inputs, safe ops, least privilege, and disclosure boundaries |
| `Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf` | Adds adversarial mindset: parsing risks, file validation, and â€œtreat inputs as hostileâ€ as a default |
| `concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf` | Informs event-driven + worker pipeline discipline: bounded work, timeouts, backpressure, and deterministic job outputs |
| `Introduction to Digital Humanism.pdf` | Defines human-centered governance: transparency, accountability, privacy, and resisting â€œautomation theaterâ€ |
| `Principles of Biological Autonomy - book_9780262381833.pdf` | Systems thinking: feedback loops, closure, and keeping humans in control of what becomes â€œtruthâ€ |
| `On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf` | Adds auditability expectations for AI-derived artifacts: labeling, provenance, and governance-friendly documentation |
| `Understanding Statistics & Experimental Design.pdf` | Requires experimental rigor and explicit assumptions for published analysis outputs; informs QA expectations |
| `graphical-data-analysis-with-r.pdf` | Promotes â€œlook firstâ€ EDA and honest visual diagnostics; supports QA artifact expectations |
| `regression-analysis-with-python.pdf` | Drives regression artifact discipline: diagnostics, assumptions, and reproducible baselines as governed evidence |
| `Regression analysis using Python - slides-linear-regression.pdf` | Standardizes lightweight baseline workflows and minimal outputs for quick, reproducible checks |
| `think-bayes-bayesian-statistics-in-python.pdf` | Requires uncertainty-forward reporting and provenance of priors/posteriors for Bayesian evidence artifacts |
| `Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf` | Simulation governance: V&V status, sensitivity analysis, and run manifests captured in PROV |
| `Generalized Topology Optimization for Structural Design.pdf` | Optimization outputs as data: objective/constraints, parameter sweeps, and artifact traceability |
| `Spectral Geometry of Graphs.pdf` | Graph analytics caution: interpretability and avoiding opaque metrics; reinforces â€œgraph references catalogsâ€ (donâ€™t hide truth in graph math) |
| `Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf` | ML outputs as governed data: model cards, artifacts, reproducibility, and separating training evidence from serving |
| `A programming Books.pdf` | Broad toolchain literacy supporting data tooling choices and scripting discipline |
| `B-C programming Books.pdf` | Broad toolchain literacy (Bâ€“C) |
| `D-E programming Books.pdf` | Broad toolchain literacy (Dâ€“E) |
| `F-H programming Books.pdf` | Broad toolchain literacy (Fâ€“H) |
| `I-L programming Books.pdf` | Broad toolchain literacy (Iâ€“L) |
| `M-N programming Books.pdf` | Broad toolchain literacy (Mâ€“N) |
| `O-R programming Books.pdf` | Broad toolchain literacy (Oâ€“R) |
| `S-T programming Books.pdf` | Broad toolchain literacy (Sâ€“T) |
| `U-X programming Books.pdf` | Broad toolchain literacy (Uâ€“X) |

</details>

---

## ğŸ§· Footnotes

- This READMEâ€™s â€œpublished means catalogedâ€ and strict pipeline ordering are rooted in KFMâ€™s system design and governance posture (see KFM engineering design + MCP docs).
- The â€œmetadata boundary artifactsâ€ standard aligns with the projectâ€™s STAC/DCAT/PROV-first discipline and the â€œdata spacesâ€ interoperability mindset.
- The security posture (treat inputs as hostile) is intentionally conservative because geospatial pipelines frequently process complex, parser-heavy formats.