# ğŸ“¥ `data/raw/` â€” Immutable Source Snapshots

![Stage](https://img.shields.io/badge/data%20stage-raw-informational)
![Provenance](https://img.shields.io/badge/provenance-required-success)
![Policy](https://img.shields.io/badge/pipelines-deterministic-blue)
![Rule](https://img.shields.io/badge/editing-write--once%20%26%20read--only-important)

Raw data is **evidence**. This folder stores **exact, unmodified** source artifacts as obtained from the world (downloads, scans, exports, scraped files, etc.) so the rest of KFM can always answer: **â€œWhat did we start from?â€** ğŸ§¾ğŸ—ºï¸

---

## ğŸ§­ The Canonical Data Flow

> **Do not shortcut the pipeline.** Raw data becomes trustworthy knowledge only after processing + metadata + provenance.

```mermaid
flowchart LR
  A["ğŸ“¥ data/raw â€” immutable inputs"] --> B["ğŸ§ª pipelines/ â€” ETL + normalization"]
  B --> C["âœ… data/processed â€” ready-to-serve outputs"]
  C --> D["ğŸ§¾ data/catalog + data/provenance (or data/stac + data/prov)"]
  D --> E["ğŸ—„ï¸ Spatial/Graph DBs"]
  E --> F["ğŸŒ API"]
  F --> G["ğŸ—ºï¸ UI / Stories / Focus Mode"]
```

---

## âœ… What belongs in `data/raw/`

Typical raw artifacts (examples, not exhaustive):

- ğŸ§¾ **Tabular:** `.csv`, `.tsv`, `.xlsx` (only if thatâ€™s how the source ships)
- ğŸ—ºï¸ **Vector:** shapefiles (`.shp/.dbf/.shx/.prj` + friends), `.geojson` (if delivered as GeoJSON)
- ğŸ›°ï¸ **Raster:** `.tif/.tiff`, imagery exports, DEMs, scanned maps
- ğŸ“„ **Documents:** `.pdf`, `.txt`, `.xml`, `.html` (source docs to be OCRâ€™d / parsed)
- ğŸ“¦ **Archives:** `.zip`, `.7z` (especially when sources distribute bundles)

**Rule of thumb:** if a source gives it to you *that way*, it can live here.

---

## âŒ What does *not* belong in `data/raw/`

- ğŸš« Cleaned/standardized outputs (those go in `data/processed/`)
- ğŸš« Intermediate scratch files (use `data/work/` if present)
- ğŸš« Hand-edited â€œfixesâ€ to raw evidence (fix in pipeline logic instead)
- ğŸš« Anything that canâ€™t be redistributed (license/permissions issue) â€” store a **fetch script + checksum** instead

---

## ğŸ§± Folder conventions

Raw can be grouped **by topic** or **by source**. Keep it predictable and greppable.

### Recommended patterns

**Option A â€” by domain then dataset (preferred for scaling):**
```
data/raw/
  weather/ ğŸŒ¦ï¸
    rainfall_1850_2020/
      rainfall_1850_2020.csv
      checksums.sha256
      SOURCE.md
```

**Option B â€” by source system (often best for agencies/vendors):**
```
data/raw/
  usgs_water/ ğŸ’§
    ...
  noaa_climate/ ğŸŒªï¸
    ...
```

**Option C â€” by artifact type (good for scanned map libraries):**
```
data/raw/
  historical_maps/ ğŸ—ºï¸
    1930_county_map.pdf
    1885_rr_atlas.tif
```

---

## ğŸ”’ Immutability rules (nonâ€‘negotiable)

### ğŸ” Raw is write-once, then read-only

- **Pipelines must never edit raw files.**
- Treat raw as *sacrosanct evidence* â€” the â€œmap behind the map.â€ ğŸ§­

### ğŸ§¯ If a raw error is discovered

Pick one path:

1) âœ… **Preferred:** Fix the pipeline to handle the issue (nulls, outliers, projection quirks, etc.)  
2) ğŸŸ¡ If the source itself was wrong and later corrected:
   - Replace raw with the corrected version **and** document the change (Git history is part of the audit trail)
   - Ensure provenance reflects the update

---

## ğŸ·ï¸ Naming conventions

Keep names boring and durable:

- `snake_case` only
- Include year ranges when relevant: `rainfall_1850_2020`
- Avoid spaces, avoid â€œfinal_v3_reallyfinalâ€ ğŸ˜…
- Preserve original filenames *inside* the folder when they matter, but keep the folder name stable

**Good**
- `census_1900/`
- `rainfall_1850_2020/`
- `historical_maps/1930_county_map.pdf`

**Avoid**
- `Stuff/`
- `new data/`
- `Map (Kansas) FINAL!!.tif`

---

## ğŸ§¾ Minimum â€œsource contextâ€ you should include

For each dataset folder, add **at least one** of these:

- `SOURCE.md` (human-friendly)
- `source.json` / `source.yml` (machine-friendly)
- `checksums.sha256` (recommended)

### Example `SOURCE.md` template

```md
# Source

- **Title:** <dataset title>
- **Publisher / Owner:** <agency/org/person>
- **Retrieved:** <YYYY-MM-DD>
- **Source URL(s):**
  - <url>
- **License:** <license name / link>
- **Notes:** <anything weird about formats/fields/projection>
```

### Example `checksums.sha256`

```bash
# generate (from repo root)
sha256sum data/raw/<domain>/<dataset>/* > data/raw/<domain>/<dataset>/checksums.sha256
```

---

## ğŸ§ª Contributor checklist: adding a new dataset

> Raw is only step 1. A â€œrealâ€ dataset lands with processed outputs + metadata + provenance.

- [ ] Add raw source files under `data/raw/<...>/`
- [ ] Add `SOURCE.md` and (ideally) `checksums.sha256`
- [ ] Create/extend a deterministic pipeline in `pipelines/`  
- [ ] Run the pipeline locally (Docker-first if thatâ€™s the standard setup)
- [ ] Produce outputs in `data/processed/<domain>/...`
- [ ] Generate/update metadata:
  - STAC + DCAT (where applicable)
  - PROV lineage (required)
- [ ] Open a PR with raw + processed + metadata/prov changes together âœ…

---

## ğŸŒ§ï¸ Worked example: â€œRainfall 1850â€“2020â€ (shape of the workflow)

```text
data/raw/rainfall/
  rainfall_1850_2020.csv

pipelines/
  import_rainfall.py

data/processed/weather/
  rainfall_1850_2020.geojson   (or parquet/csv depending on design)

data/catalog/  +  data/provenance/
  rainfall_1850_2020.(stac json / dcat ttl / prov json)
```

---

## ğŸ§  Sensitive / restricted data

KFM is **provenance-first**, not â€œupload-first.â€ If the dataset contains:

- ğŸ§ personally identifying info (PII)
- ğŸ›ï¸ culturally sensitive records
- ğŸ” restricted/contracted data

â€¦then it may **not** belong in `data/raw/` at all. Prefer:
- redacted derivative outputs (with documented rules), or
- secure external storage with **access-controlled** fetch processes

When in doubt, **escalate before committing**.

---

## ğŸ§° Helpful links (repo-relative)

- ğŸ§ª Pipelines: `../../pipelines/`
- âœ… Processed outputs: `../processed/`
- ğŸ§¾ Catalog/metadata (varies by module): `../catalog/`, `../stac/`
- ğŸ§¾ Provenance (varies by module): `../provenance/`, `../prov/`

---

## ğŸ§© Philosophy (why weâ€™re strict)

Raw data is the bedrock that lets KFM stay transparent and reproducible:
- Anyone can inspect the original artifact ğŸ§¾
- Anyone can rerun the pipeline ğŸ§ª
- Everyone can trust the lineage ğŸ§¬

If youâ€™re ever tempted to â€œjust tweak the CSVâ€â€¦ resist ğŸ˜„ â€” write a pipeline step instead.
