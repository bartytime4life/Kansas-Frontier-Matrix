<div align="center">

# ğŸ“¥ `data/raw/` â€” Raw Data (Immutable Inputs)

![stage](https://img.shields.io/badge/data%20stage-raw-2563EB)
![policy](https://img.shields.io/badge/policy-append--only-16A34A)
![integrity](https://img.shields.io/badge/integrity-checksums%20%2B%20receipts-7C3AED)
![provenance](https://img.shields.io/badge/provenance-source.json%20%2B%20PROV-0EA5E9)
![governance](https://img.shields.io/badge/governance-FAIR%20%2B%20CARE-8B5CF6)
![security](https://img.shields.io/badge/security-no%20secrets%20in%20git-DC2626)

**Raw data is KFMâ€™s first trust boundary.**  
We ingest external sources here **as-received**, preserve them **immutably**, then perform deterministic ETL in `data/work/` and publish stable products in `data/processed/`. ğŸ§¾â¡ï¸ğŸ› ï¸â¡ï¸ğŸ“¦

</div>

> [!IMPORTANT]
> **If you changed bytes, itâ€™s not raw anymore.**  
> Reprojection, cleanup, OCR, tiling, resampling, column edits, format conversion â†’ belongs in `data/work/` or `data/processed/`.

---

## ğŸ”— Quick links

- ğŸ§­ Repo overview â†’ `../../README.md`
- ğŸ§ª Intermediate artifacts â†’ [`../work/`](../work/)
- ğŸ“¦ Final products â†’ [`../processed/`](../processed/)
- âœ… QA runbooks & validators â†’ [`../qa/`](../qa/) *(create if missing)*
- ğŸ—‚ï¸ Discovery metadata (DCAT) â†’ [`../catalog/`](../catalog/)
- ğŸ›°ï¸ Geospatial indexing (STAC) â†’ [`../stac/`](../stac/)
- ğŸ§¬ Lineage bundles (PROV) â†’ [`../prov/`](../prov/)
- ğŸ›¡ï¸ Vulnerability reporting â†’ `../../SECURITY.md` *(or `../../.github/SECURITY.md`)*

---

<details>
<summary><strong>ğŸ“Œ Table of contents</strong></summary>

- [ğŸ§­ Where raw fits in the KFM pipeline](#pipeline)
- [âœ… What belongs here](#allowed)
- [ğŸš« What does NOT belong here](#not-allowed)
- [â­ Raw-stage non-negotiables](#non-negotiables)
- [ğŸ—‚ï¸ Directory layout](#layout)
- [ğŸ§¾ Raw drop contract](#drop-contract)
- [ğŸ“„ `source.json` template](#source-json)
- [ğŸ”‘ Checksums](#checksums)
- [ğŸ“¦ Large files & restricted redistribution](#large-files)
- [ğŸ—ºï¸ Geospatial + document specifics](#geo-specifics)
- [ğŸ” Security, privacy, sovereignty](#security)
- [ğŸ§ª QA & CI expectations](#qa)
- [ğŸ§° Intake SOP: add a new raw drop](#sop)
- [ğŸ™ƒ Common anti-patterns](#anti-patterns)
- [ğŸ“š Project reference shelf](#reference-shelf)

</details>

---

<a id="pipeline"></a>

## ğŸ§­ Where raw fits in the KFM pipeline

**Canonical ordering (nonâ€‘negotiable):**  
**Raw â†’ Work/ETL â†’ Processed â†’ STAC/DCAT/PROV â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**

```mermaid
flowchart LR
  RAW[ğŸ“¥ Raw inputs<br/>data/raw/] --> WORK[ğŸ§ª Work / ETL<br/>data/work/]
  WORK --> PROC[ğŸ“¦ Processed outputs<br/>data/processed/]
  PROC --> STAC[ğŸ›°ï¸ STAC catalogs<br/>data/stac/]
  PROC --> DCAT[ğŸ—‚ï¸ DCAT datasets<br/>data/catalog/dcat/]
  PROC --> PROV[ğŸ§¬ PROV lineage<br/>data/prov/]
  STAC --> GRAPH[ğŸ•¸ï¸ Graph (Neo4j)]
  DCAT --> GRAPH
  PROV --> GRAPH
  GRAPH --> API[ğŸ”Œ Governed API]
  API --> UI[ğŸ—ºï¸ Web UI]
  UI --> STORY[ğŸ¬ Story Nodes]
  STORY --> FOCUS[ğŸ§  Focus Mode]
```

> [!NOTE]
> Raw is not â€œless important.â€ Itâ€™s the foundation for **reproducibility**, **auditability**, and **tamper-evidence** across catalogs, models, and narratives.

---

<a id="allowed"></a>

## âœ… What belongs here

**Allowed raw inputs (as-received):**
- ğŸ“¦ Vendor/agency deliveries (ZIP/TAR bundles, exports, archives)
- ğŸ—ºï¸ Original GIS deliveries (GeoTIFF, SHP, GPKG, CSV, JSON, KML, etc.)
- ğŸ§¾ Documents & scans (PDFs, TIFF/JPEG/PNG masters)
- ğŸ›°ï¸ Remote sensing exports / pulls where you can persist **the exported files** and/or **the original response payload**
- ğŸ§ª Sensor dumps / logs (when permitted) â€” stored â€œas recordedâ€

**Also allowed (with strict rules):**
- ğŸ“ **Lossless extraction** into `extracted/` **only if** you also keep the original archive in `original/`
  - unzip/untar is allowed; *editing content is not*

---

<a id="not-allowed"></a>

## ğŸš« What does NOT belong here

**Not allowed in `data/raw/`:**
- ğŸ§¼ Cleaned tables, renamed columns, changed encodings
- ğŸ§­ Reprojection, resampling, tiling, simplification, topology repair
- ğŸ§Š â€œMake it a COGâ€, â€œmake it Parquetâ€, â€œmake it GeoJSONâ€
- ğŸ§  Analysis outputs / model outputs / simulation outputs / reports  
  â†’ these are first-class datasets in `data/processed/` and must ship with STAC/DCAT/PROV

> [!WARNING]
> If the only explanation for a file is â€œtrust me,â€ it will fail review (and often CI).

---

<a id="non-negotiables"></a>

## â­ Raw-stage non-negotiables

These rules keep the pipeline deterministic and governance-safe:

- ğŸ§± **Append-only**: never mutate an existing drop; new pull â†’ new folder
- ğŸ§Š **Bytes preserved**: keep originals + sidecars; donâ€™t â€œhelpfully convertâ€
- ğŸ§¾ **Receipts required**: every drop has `README.md`, `source.json`, `checksums.sha256`
- ğŸ·ï¸ **Stable identity**: `dataset_id` + `drop_id` become PROV keys later
- ğŸ›¡ï¸ **Governance up front**: license, classification, sensitivity declared at ingest time
- ğŸ” **No secrets in Git**: use `.env` + secret stores; rotate if exposed

---

<a id="layout"></a>

## ğŸ—‚ï¸ Directory layout

Organize raw data by **domain â†’ dataset â†’ immutable drop**:

```text
data/raw/
â””â”€â”€ <domain>/                         # imagery, hydro, census, docs, etc.
    â””â”€â”€ <dataset_slug>/               # kebab-case, stable (no dates inside)
        â””â”€â”€ <drop_id>/                # YYYY-MM-DD | vX | YYYY-MM-DDa
            â”œâ”€â”€ ğŸ“„ README.md
            â”œâ”€â”€ ğŸ“„ source.json
            â”œâ”€â”€ ğŸ”‘ checksums.sha256
            â”œâ”€â”€ ğŸ“ original/          # upstream bundle(s) exactly as received
            â”œâ”€â”€ ğŸ“ extracted/         # optional: lossless unpack output (no transforms)
            â””â”€â”€ ğŸ“ notes/             # optional: landing pages, emails (NO secrets)
```

### ğŸ·ï¸ Naming guidance

- `<domain>`: broad, stable bucket (donâ€™t overfit)
- `<dataset_slug>`: stable handle (`kebab-case`)
- `<drop_id>`:
  - `YYYY-MM-DD` for dated pulls/deliveries
  - `vX` for upstream versioned releases
  - if re-pulling â€œthe sameâ€ drop: `YYYY-MM-DDa`, `YYYY-MM-DDb` (never overwrite)

> [!TIP]
> â€œBoring namingâ€ is a feature: it makes automation, QA, and provenance simpler.

---

<a id="drop-contract"></a>

## ğŸ§¾ Raw drop contract

Every raw drop is a **reviewable, machine-validatable boundary**.

| Artifact | Required | Why it exists | Minimum contents |
|---|---:|---|---|
| ğŸ“„ `README.md` | âœ… | Human context | what it is, where it came from, whatâ€™s inside, caveats |
| ğŸ“„ `source.json` | âœ… | Machine provenance | source URLs, license, retrieval time/method, classification, extents |
| ğŸ”‘ `checksums.sha256` | âœ… | Integrity + tamper evidence | sha256 of all files in the drop (except itself) |
| ğŸ“ `original/` | â—»ï¸ | â€œAs receivedâ€ archive(s) | ZIP/TAR/PDF bundles, vendor deliveries |
| ğŸ“ `extracted/` | â—»ï¸ | Lossless unpack only | unzip/untar output (no semantic changes) |

> [!CAUTION]
> If redistribution is restricted: keep **only receipts** (README + source.json) in Git, store bytes in restricted storage, and document access.

---

<a id="source-json"></a>

## ğŸ“„ `source.json` template

`source.json` is the raw-stage **receipt** ğŸ§¾ â€” it should let a reviewer (or future-you) re-acquire and re-verify the same inputs.

```json
{
  "dataset_id": "<domain>/<dataset_slug>",
  "domain": "<domain>",
  "dataset_slug": "<dataset_slug>",
  "drop_id": "<YYYY-MM-DD_or_vX>",

  "title": "Human-friendly dataset name",
  "description": "What this drop contains (1â€“3 sentences).",

  "upstream": {
    "publisher": "Agency / org / vendor",
    "source_urls": ["https://â€¦"],
    "retrieved_from": "https://â€¦",
    "license": "SPDX id or URL or text statement",
    "citation": "Preferred citation string (if provided)",
    "terms_notes": "Redistribution limits / constraints."
  },

  "retrieval": {
    "retrieved_at": "YYYY-MM-DDTHH:MM:SSZ",
    "method": "manual|script|api|mirror",
    "performed_by": "name_or_handle",
    "tooling": {
      "script_path": "tools/fetch/<something>.sh",
      "container": "docker image tag (if used)",
      "commit": "git commit hash (if applicable)"
    }
  },

  "coverage": {
    "spatial": {
      "crs": "EPSG:4326 | unknown",
      "bbox_wgs84": [-102.05, 36.99, -94.59, 40.00]
    },
    "temporal": {
      "start": "YYYY-MM-DD",
      "end": "YYYY-MM-DD"
    }
  },

  "sensitivity": {
    "classification": "public|internal|confidential|restricted",
    "care_label": "TBD",
    "notes": "Sovereignty, sensitive sites, PII risk, redaction expectations."
  },

  "files": [
    {
      "path": "original/source_bundle.zip",
      "media_type": "application/zip",
      "size_bytes": 0,
      "sha256": "<optional duplicate of checksums.sha256>"
    }
  ]
}
```

> [!TIP]
> Keep `README.md` **human**, keep `source.json` **machine**. Donâ€™t hide licensing or sensitivity only in prose.

---

<a id="checksums"></a>

## ğŸ”‘ Checksums

### Generate (macOS/Linux)

```bash
# from inside the drop directory: .../<drop_id>/
find . -type f \
  ! -name 'checksums.sha256' \
  -print0 | sort -z | xargs -0 sha256sum > checksums.sha256
```

### Verify (macOS/Linux)

```bash
sha256sum -c checksums.sha256
```

### Windows (PowerShell)

```powershell
Get-ChildItem -Recurse -File |
  Where-Object { $_.Name -ne "checksums.sha256" } |
  ForEach-Object {
    $h = (Get-FileHash $_.FullName -Algorithm SHA256).Hash.ToLower()
    "$h  $($_.FullName.Replace((Get-Location).Path + '\','').Replace('\','/'))"
  } | Set-Content checksums.sha256
```

> [!NOTE]
> Checksums are practical tamper-evidence **and** a fast way to debug data drift.

---

<a id="large-files"></a>

## ğŸ“¦ Large files & restricted redistribution

Raw often includes huge rasters and long time-series.

### Recommended patterns

- ğŸ§³ **Small/medium files**: store directly in Git (still include checksums)
- ğŸ§± **Large binaries**: consider DVC (or similar) for versioned pointers
- ğŸ”’ **Redistribution restricted**: keep only receipts in Git; store bytes in restricted storage

> [!IMPORTANT]
> The **drop folder** is still the contract boundary even if the bytes live elsewhere.

---

<a id="geo-specifics"></a>

## ğŸ—ºï¸ Geospatial + document specifics

### ğŸ›°ï¸ Raster deliveries (GeoTIFF/IMG/etc.)
âœ… Raw: keep â€œas delivered,â€ including `.aux.xml`, `.tfw`, metadata sidecars  
âŒ Not raw: COG conversion, resampling, overviews, tiling (do this in `data/work/`)

### ğŸ§­ Vector deliveries (SHP/GPKG/GeoJSON/CSV)
âœ… Raw: keep as delivered, preserve encoding + schema  
âŒ Not raw: reprojection, geometry fixes, attribute normalization

### ğŸ§¾ Documents & scans (PDF/JPEG/PNG/TIFF)
âœ… Raw: keep original masters (donâ€™t OCR in place)  
âŒ Not raw: OCR text outputs, rotated/cleaned images, compressed previews  
â¡ï¸ Put OCR + derivatives in `data/work/` (publish in `data/processed/` if they ship)

### ğŸ§Š 3D / graphics assets (glTF / 3D Tiles / meshes)
Treat as **untrusted inputs**:
- store raw assets unchanged
- validate parsers and conversion steps in `data/work/`
- never execute embedded scripts/macros; strip or sandbox during ETL

### ğŸ›°ï¸ API pulls (remote sensing, web services)
If you pull via API:
- store the **raw payload** (or exported files) if possible
- store the **exact request parameters** (query, filters, time window)
- store the script path + commit hash in `source.json`

> [!TIP]
> â€œReproducible retrievalâ€ is part of provenance. If a pull canâ€™t be repeated, document why (rate limits, paid access, ephemeral tokens, etc.).

---

<a id="security"></a>

## ğŸ” Security, privacy, sovereignty

Geospatial raw data can carry real-world risk.

### Hard rules
- ğŸ” **No secrets in Git**: tokens/keys go in `.env` + secret stores
- ğŸ§ **No PII in public repos** unless explicitly governed and approved
- ğŸ§­ **No restricted coordinates** in public drops when locations are sensitive
- ğŸ·ï¸ **Declare classification** in `source.json` (and donâ€™t â€œdowngradeâ€ later)

### If in doubt
- open a PR with only the receipts (no binaries)
- flag the concern clearly
- route sensitive details via private channels per `SECURITY.md`

> [!WARNING]
> â€œProcessed outputs can still leak.â€ Even aggregated or derived data can reveal sensitive patterns. Raw discipline is the first step; API governance is the last.

---

<a id="qa"></a>

## ğŸ§ª QA & CI expectations

Raw changes should be easy to validate automatically.

**Minimum checks for PRs touching `data/raw/**`:**
- [ ] Drop is append-only (no edits to existing drops)
- [ ] `README.md`, `source.json`, `checksums.sha256` exist
- [ ] `checksums.sha256` verifies locally
- [ ] `source.json` includes license + classification
- [ ] No secrets/credentials committed
- [ ] Sensitive data is flagged and handled per governance

> [!NOTE]
> Deeper geospatial QA (CRS checks, geometry validity, bounds) usually happens in `data/work/` and `data/processed/`â€”but raw must still declare what it *claims* to be.

---

<a id="sop"></a>

## ğŸ§° Intake SOP: add a new raw drop

### 1) Create the drop boundary ğŸ§±
- choose `<domain>/<dataset_slug>/<drop_id>/`
- never overwrite an existing drop

### 2) Acquire upstream bytes ğŸ“¥
- place the upstream bundle in `original/`
- optional: losslessly extract into `extracted/`

### 3) Write the receipts ğŸ§¾
- `README.md` (human: what/where/why/caveats)
- `source.json` (machine: license, retrieval, classification, extents)

### 4) Lock integrity ğŸ”’
- generate `checksums.sha256`
- verify it locally

### 5) Open a PR âœ…
Include:
- what changed (new dataset vs new drop)
- any licensing/sensitivity concerns
- how to reproduce retrieval (if applicable)

---

<a id="anti-patterns"></a>

## ğŸ™ƒ Common anti-patterns

- â€œI fixed the CSV in placeâ€ â†’ new drop; do cleanup in `data/work/`
- â€œI reprojected it so it lines upâ€ â†’ `data/work/` / `data/processed/`
- â€œI renamed files for convenienceâ€ â†’ keep originals; map names in docs
- â€œI added a token to a download scriptâ€ â†’ use `.env`; rotate exposed tokens
- â€œI posted sensitive coordinates in a public dropâ€ â†’ stop, remove, report privately

---

<a id="reference-shelf"></a>

## ğŸ“š Project reference shelf

<details>
<summary><strong>ğŸ“– Reference library (all project files)</strong></summary>

> âš ï¸ Reference PDFs may have licenses different from repository code. Keep them in `docs/library/` (or outside the repo) and respect upstream terms.

### ğŸ§­ Core KFM system docs
- Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation  [oai_citation:0â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.docx](file-service://file-PaBDqECcJe7NbC8hvXNGDS)

### ğŸ—ºï¸ GIS, mapping, cartography, geospatial tooling
- making-maps-a-visual-guide-to-map-design-for-gis.pdf
- Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf  [oai_citation:1â€¡Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf](file-service://file-AkVmsLhdFzwie5Gco3zgYj)
- python-geospatial-analysis-cookbook.pdf
- PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf

### ğŸ›°ï¸ Remote sensing workflows
- Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf

### ğŸ–¼ï¸ Documents, scans & file formats
- compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf  [oai_citation:2â€¡compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf](file-service://file-Y6V94sFtV6sy3w63LDy9fi)

### ğŸ“Š Statistics, experiments, inference & modeling integrity
- Understanding Statistics & Experimental Design.pdf
- regression-analysis-with-python.pdf
- Regression analysis using Python - slides-linear-regression.pdf  [oai_citation:3â€¡Regression analysis using Python - slides-linear-regression.pdf](file-service://file-Ekbky5FwpaPHfZC2ttv6xR)
- graphical-data-analysis-with-r.pdf
- think-bayes-bayesian-statistics-in-python.pdf  [oai_citation:4â€¡think-bayes-bayesian-statistics-in-python.pdf](file-service://file-LXwJApPMVhRZgyqLb9eg7c)
- Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf
- Deep Learning for Coders with fastai and PyTorch - Deep.Learning.for.Coders.with.fastai.and.PyTorchpdf *(file name as provided)*

### âš™ï¸ Systems, scale, interoperability
- Scalable Data Management for Future Hardware.pdf
- Data Spaces.pdf
- concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf  [oai_citation:5â€¡concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf](file-service://file-Y45SvXbmLoZL1MNmrcyqz6)

### ğŸŒ Web UI & 3D graphics
- responsive-web-design-with-html5-and-css3.pdf
- webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf

### ğŸ§® Advanced math & optimization (optional deep dives)
- Spectral Geometry of Graphs.pdf
- Generalized Topology Optimization for Structural Design.pdf

### â¤ï¸ Ethics, autonomy, AI law
- Introduction to Digital Humanism.pdf
- Principles of Biological Autonomy - book_9780262381833.pdf
- On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf

### ğŸ›¡ï¸ Security (defensive references)
- ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf  [oai_citation:6â€¡ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf](file-service://file-Q7EeqPb17SD9sV8Fb12LQX)
- Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf  [oai_citation:7â€¡Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf](file-service://file-Mu6zixTqF9Lubf5QMjepRg)

### ğŸ§° General programming shelf (bundles)
- A programming Books.pdf
- B-C programming Books.pdf
- D-E programming Books.pdf
- F-H programming Books.pdf
- I-L programming Books.pdf
- M-N programming Books.pdf
- O-R programming Books.pdf
- S-T programming Books.pdf
- U-X programming Books.pdf

</details>

---

## âœ… Definition of Done (for this README)

- [x] â€œRaw means bytes preservedâ€ rule is explicit
- [x] Append-only + checksums + receipts contract defined
- [x] Layout + naming guidance included
- [x] Security/privacy/sovereignty guardrails included
- [ ] Linked from `data/README.md` (recommended)
- [ ] Reviewed by maintainers / data stewards (recommended)

<p align="right"><a href="#pipeline">â¬†ï¸ Back to top</a></p>