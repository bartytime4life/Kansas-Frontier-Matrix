# ğŸ—ƒï¸ `data/raw/` â€” Raw Data (Immutable Inputs)

![stage](https://img.shields.io/badge/data%20stage-raw-blue)
![policy](https://img.shields.io/badge/policy-append--only-success)
![lineage](https://img.shields.io/badge/lineage-provenance--first-informational)
![governance](https://img.shields.io/badge/governance-FAIR%2BCARE-purple)

Raw data is the **first boundary** of the KFM pipeline: we ingest external sources here, keep them **as raw as possible**, and only then run deterministic ETL into `data/work/` and publish outputs in `data/processed/`. ğŸ“¦â¡ï¸ğŸ› ï¸â¡ï¸âœ… [oai_citation:0â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU) [oai_citation:1â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-Bro83fTiCi9UUVVno1fL6L)

> ğŸ§Š **Rule of thumb:** If you changed bytes, *itâ€™s not raw anymore* â€” it belongs in `data/work/` or `data/processed/`.

---

## ğŸ¯ What belongs in `data/raw/`

âœ… **Allowed**
- Vendor dumps, agency downloads, scans, exports, archives, sensor drops
- API pulls (when you can persist the response payloads without semantic edits)
- Delivered bundles in their **original format** (ZIP/TAR, GeoTIFF, CSV, JSON, PDF, etc.)
- Lossless extraction output (unzip/untar) **without transformation** (see `extracted/` rules)

âŒ **Not allowed**
- Reprojected rasters, cleaned/normalized tables, renamed columns, â€œfixedâ€ geometries
- Re-encoded/converted formats (COG conversion, Parquet conversion, OCR text, etc.)
- Anything that is an **analysis/evidence artifact** (those are first-class datasets in `data/processed/`) [oai_citation:2â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ—‚ï¸ Folder layout (recommended)

Raw data should be **organized by domain**, then **dataset**, then **version/date**.

```text
data/raw/
â””â”€â”€ <domain>/                      # e.g., land_treaties, imagery, census, hydro, documents, sensors
    â””â”€â”€ <dataset_slug>/            # kebab-case, stable ID
        â””â”€â”€ <YYYY-MM-DD_or_vX>/    # immutable drop boundary
            â”œâ”€â”€ ğŸ“„ README.md
            â”œâ”€â”€ ğŸ“„ source.json
            â”œâ”€â”€ ğŸ“„ checksums.sha256
            â”œâ”€â”€ ğŸ“ original/       # optional: the exact upstream archive(s) or delivered bundle
            â””â”€â”€ ğŸ“ extracted/      # optional: extraction output (ONLY lossless unpacking; no transforms)
```

### ğŸ·ï¸ Naming rules (keep it boring = keep it reproducible)
- **`<domain>/`**: short, meaningful bucket (team-agreed). Donâ€™t overfit.
- **`<dataset_slug>/`**: `kebab-case`, stable identifier (no dates inside the slug).
- **`<YYYY-MM-DD_or_vX>/`**: immutable â€œdrop boundaryâ€
  - Use `YYYY-MM-DD` when the source is a dated pull/delivery.
  - Use `vX` when the upstream has explicit releases (or youâ€™re mirroring a versioned archive).
  - If you re-pull the same upstream date, create a new boundary: `YYYY-MM-DDb` (or bump `vX`), donâ€™t overwrite.

---

## ğŸ“„ Raw drop contract (what every drop MUST contain)

Each immutable drop is a **contract boundary**: a human can understand it and a machine can validate it. This matches KFMâ€™s **contract-first** and **deterministic pipeline** expectations. [oai_citation:3â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

| Artifact | Required | Why it exists | â€œGood enoughâ€ contents |
|---|---:|---|---|
| ğŸ“„ `README.md` | âœ… | Human context & caveats | what it is, where it came from, whatâ€™s inside, how to reproduce |
| ğŸ“„ `source.json` | âœ… | Machine-readable provenance | source URLs, license, retrieval method/time, classification, extents |
| ğŸ“„ `checksums.sha256` | âœ… | Integrity & tamper-evidence | sha256 over all files in the drop (excluding itself) |
| ğŸ“ `original/` | â—»ï¸ | Exact upstream bundle | ZIP/TAR/PDFs, vendor delivery, â€œas receivedâ€ |
| ğŸ“ `extracted/` | â—»ï¸ | Lossless unpack only | unzip/untar output ONLY (no reprojection, no cleaning) |

> âš ï¸ **Append-only policy:** never mutate an existing drop. If something changes, create a new drop boundary and document why.

---

## ğŸ§¾ `source.json` template (recommended)

`source.json` is the â€œreceiptâ€ ğŸ§¾ â€” it should let future-you re-acquire and re-verify the same raw inputs.

```json
{
  "dataset_id": "<domain>/<dataset_slug>",
  "domain": "<domain>",
  "dataset_slug": "<dataset_slug>",
  "drop_id": "<YYYY-MM-DD_or_vX>",

  "title": "Human-friendly dataset name",
  "description": "What this drop contains (1â€“3 sentences).",

  "upstream": {
    "publisher": "Agency / org / vendor",
    "source_urls": ["https://â€¦"],
    "retrieved_from": "https://â€¦",
    "license": "SPDX or link / statement",
    "citation": "Preferred citation string (if provided)"
  },

  "retrieval": {
    "retrieved_at": "YYYY-MM-DDTHH:MM:SSZ",
    "method": "manual|script|api|mirror",
    "performed_by": "name_or_handle",
    "tooling": {
      "script_path": "tools/fetch/<something>.sh",
      "container": "docker image tag (if used)",
      "commit": "git commit hash (if applicable)"
    }
  },

  "coverage": {
    "spatial": {
      "crs": "EPSG:4326 (if known; otherwise 'unknown')",
      "bbox_wgs84": [-180.0, -90.0, 180.0, 90.0]
    },
    "temporal": {
      "start": "YYYY-MM-DD",
      "end": "YYYY-MM-DD"
    }
  },

  "sensitivity": {
    "classification": "public|restricted|confidential",
    "notes": "Anything about privacy, sovereignty, access constraints, redactions."
  },

  "files": [
    {
      "path": "original/source_bundle.zip",
      "media_type": "application/zip",
      "size_bytes": 0,
      "sha256": "<optional duplicate of checksums.sha256>"
    }
  ]
}
```

> ğŸ§  Tip: keep **README.md human**, keep **source.json machine**. Donâ€™t hide critical licensing/sensitivity notes in prose only.

---

## ğŸ”‘ `checksums.sha256` (how to generate + verify)

### Generate (macOS/Linux)
```bash
# from inside the drop directory (â€¦/<YYYY-MM-DD_or_vX>/)
find . -type f \
  ! -name 'checksums.sha256' \
  -print0 | sort -z | xargs -0 sha256sum > checksums.sha256
```

### Verify (macOS/Linux)
```bash
sha256sum -c checksums.sha256
```

### Windows (PowerShell)
```powershell
Get-ChildItem -Recurse -File |
  Where-Object { $_.Name -ne "checksums.sha256" } |
  ForEach-Object {
    $h = (Get-FileHash $_.FullName -Algorithm SHA256).Hash.ToLower()
    "$h  $($_.FullName.Replace((Get-Location).Path + '\','').Replace('\','/'))"
  } | Set-Content checksums.sha256
```

---

## ğŸ“¦ Large files (recommended: DVC)

For big rasters / imagery / long time-series, prefer **DVC** so Git stays fast while datasets remain reproducible. The project design explicitly suggests DVC for large artifacts and reproducible data versioning. [oai_citation:4â€¡Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf](file-service://file-64djFYQUCmxN1h6L6X7KUw) [oai_citation:5â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)

**Pattern**
- Keep `source.json` + `checksums.sha256` **in Git**
- Store heavy binaries in DVC remote (or equivalent artifact storage)
- Treat each `<drop_id>/` as immutable even when tracked by DVC

> ğŸ§¯ If the upstream license forbids redistribution: store *only* metadata + retrieval instructions in Git, and keep the data in restricted storage.

---

## ğŸ—ºï¸ Geospatial specifics (raw-stage rules)

### âœ… In raw
- Keep original CRS, resolution, and encoding (â€œas deliveredâ€)
- Store upstream metadata sidecars exactly (e.g., `.xml`, `.aux`, `.tfw`)
- Record bbox/time coverage in `source.json`

### âŒ Not in raw
- Reprojection, resampling, tiling, simplification, topology repair
- â€œMake it a COGâ€ conversions
- â€œCleanedâ€ geometries or normalized attribute schemas

When publishing, KFM expects metadata boundary artifacts (STAC/DCAT/PROV) **before** downstream use. [oai_citation:6â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ§¬ Metadata, standards, and interoperability

Good raw stewardship starts with **metadata discipline**:
- Metadata categories commonly include: identification, distribution, data quality, spatial reference, entity/attribute information, and metadata reference info. [oai_citation:7â€¡making-maps-a-visual-guide-to-map-design-for-gis.pdf](file-service://file-51FgWTn7uFXenxztXw29bP)
- Interoperability is the ability of systems to exchange information and then use it (not just â€œsend filesâ€). [oai_citation:8â€¡making-maps-a-visual-guide-to-map-design-for-gis.pdf](file-service://file-51FgWTn7uFXenxztXw29bP)

### ğŸ“œ Copyright & licensing (common gotcha)
A key distinction in cartography is between:
- the **data** (facts/coordinates), and
- the **map** as a **cartographic representation** (creative work). This affects what you can redistribute and how you cite/attribute. [oai_citation:9â€¡making-maps-a-visual-guide-to-map-design-for-gis.pdf](file-service://file-51FgWTn7uFXenxztXw29bP)

---

## ğŸ” Privacy, security, sovereignty (FAIR+CARE mindset)

Geospatial and historical data can carry real-world risk:
- Digital geographic data can implicate **locational privacy** (e.g., data from phones/vehicles/sensors). Treat raw drops as potentially sensitive by default. [oai_citation:10â€¡making-maps-a-visual-guide-to-map-design-for-gis.pdf](file-service://file-51FgWTn7uFXenxztXw29bP)
- Security is commonly framed around protecting **confidentiality, integrity, availability**; privacy includes the right to determine/limit access to personal information. [oai_citation:11â€¡Introduction to Digital Humanism.pdf](file-service://file-HC311tLjkcn1yRbyTBLJQQ)

KFM also expects governance and sovereignty considerations to be stated explicitly (FAIR/CARE alignment). [oai_citation:12â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

### ğŸ›¡ï¸ CI / review expectations (donâ€™t skip)
The repo standards include automated scanning for:
- secrets,
- PII/sensitive data,
- classification downgrade issues, etc. [oai_citation:13â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

---

## ğŸ§° Intake workflow (drop SOP)

### 1) Create the directory ğŸ§±
- Choose `<domain>/` and `<dataset_slug>/`
- Create the immutable drop boundary folder

### 2) Acquire upstream data ğŸ“¥
- Put delivered bundle(s) in `original/` (recommended)
- If you extract, extract **losslessly** into `extracted/`

### 3) Document it ğŸ§¾
- Write dataset-drop `README.md`
- Create `source.json` (include license + sensitivity)

### 4) Lock integrity ğŸ”’
- Generate `checksums.sha256`
- If large: DVC-track the data files (keep manifests in Git)

### 5) Submit for review âœ…
Open a PR with:
- What changed (new drop, new domain, license notes)
- Any sensitivity/sovereignty flags
- Reproduction steps (how to re-download / re-verify)

> ğŸ§ª Design reminder: the project audit calls out missing reproducibility workflows as a risk; this SOP is the antidote. ğŸ§¯ [oai_citation:14â€¡Kansas-Frontier-Matrix Design Audit â€“ Gaps and Enhancement Opportunities.pdf](file-service://file-TkRzAfTnxCYDUHauCf1NcH)

---

## ğŸ§­ Where does raw data go next?

KFM uses required staging:
- `data/raw/<domain>/` â†’ `data/work/<domain>/` â†’ `data/processed/<domain>/` [oai_citation:15â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

And publication requires boundary metadata outputs:
- STAC, DCAT, PROV (catalog + lineage) [oai_citation:16â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

```mermaid
flowchart LR
  A[Raw Sources<br/>data/raw/] --> B[ETL + Normalization<br/>data/work/]
  B --> C[Published Outputs<br/>data/processed/]
  C --> D[STAC / DCAT / PROV<br/>catalog + lineage]
```

---

## ğŸš« Common anti-patterns (please donâ€™t ğŸ™ƒ)

- â€œI fixed the CSV in placeâ€ (â¡ï¸ new drop boundary instead)
- â€œI reprojected it so it lines upâ€ (â¡ï¸ do it in `data/work/` / `data/processed/`)
- â€œI renamed files for convenienceâ€ (â¡ï¸ keep original names; add a mapping doc elsewhere)
- â€œI added a secret token to a download scriptâ€ (â¡ï¸ use `.env`, never commit secrets)
- â€œI copied sensitive coordinates into a public dropâ€ (â¡ï¸ classify + restrict + review gates)

---

## ğŸ“š Project reference shelf (local library)

<details>
<summary><b>Open the project library ğŸ“š (reference PDFs & design docs)</b></summary>

### ğŸ§± KFM architecture & governance
- KFM Technical Documentation  [oai_citation:17â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-Bro83fTiCi9UUVVno1fL6L)  
- KFM Open-Source Geospatial Historical Mapping Hub Design  [oai_citation:18â€¡Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf](file-service://file-64djFYQUCmxN1h6L6X7KUw)  
- KFM Master Guide v13 (repo + pipeline standards)  [oai_citation:19â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)  
- KFM Design Audit (gaps & enhancements)  [oai_citation:20â€¡Kansas-Frontier-Matrix Design Audit â€“ Gaps and Enhancement Opportunities.pdf](file-service://file-TkRzAfTnxCYDUHauCf1NcH)  
- Scientific Method / Research MCP (experiment + versioning discipline)  [oai_citation:21â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)  

### ğŸ—ºï¸ GIS / mapping / geospatial processing
- Making Maps (map design, metadata, copyright)  [oai_citation:22â€¡making-maps-a-visual-guide-to-map-design-for-gis.pdf](file-service://file-51FgWTn7uFXenxztXw29bP)  
- Python Geospatial Analysis Cookbook  [oai_citation:23â€¡python-geospatial-analysis-cookbook.pdf](file-service://file-HT14njz1MhrTZCE7Pwm5Cu)  
- Geoprocessing with Python
- Geographic Information System Basics
- Google Maps API Succinctly
- Google Maps JavaScript API Cookbook

### ğŸŒ Remote sensing / Earth Engine
- Cloud-Based Remote Sensing with Google Earth Engine  [oai_citation:24â€¡Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf](file-service://file-CXGLTw8wpR4uKWWqjrGkyk)  
- Google Earth Engine Applications

### ğŸ“Š Stats / ML (keep raw clean so analysis stays honest)
- Data Science & Machine Learning (Math & Stats Methods)  [oai_citation:25â€¡Data Science &-  Machine Learning (Mathematical & Statistical Methods).pdf](file-service://file-MRNb2uGPEwpkSDsxF983PC)  
- Statistics Done Wrong
- Regression Analysis with Python
- Bayesian Computational Methods
- Understanding Statistics & Experimental Design
- Graphical Data Analysis with R
- Deep Learning in Python (prereqs)
- Artificial Neural Networks (intro)
- AI Foundations of Computational Agents (3rd ed.)
- Data Mining: Concepts & Applications

### ğŸ§° Engineering / systems / tooling
- Command Line Kung Fu (shell + one-liners)
- Introduction to Docker
- Clean Architectures in Python  [oai_citation:26â€¡clean-architectures-in-python.pdf](file-service://file-6YHot4AqfpdbcrdfiYfpHM)  
- Scalable Data Management for Future Hardware
- PostgreSQL / MySQL / Node.js Notes for Professionals
- Implementing Programming Languages (compilers/interpreters)

### ğŸ¨ Web / visualization / graphics (downstream of processed data)
- Responsive Web Design with HTML5 & CSS3
- WebGL Programming Guide
- Computer Graphics using Java 2D & 3D

### ğŸ§‘â€âš–ï¸ Ethics / human-centered constraints
- Introduction to Digital Humanism  [oai_citation:27â€¡Introduction to Digital Humanism.pdf](file-service://file-HC311tLjkcn1yRbyTBLJQQ)  
- Principles of Biological Autonomy

</details>

---

## ğŸ§· Footnotes (evidence anchors)

[^pipeline]: KFMâ€™s repo standards require raw â†’ work â†’ processed staging, and emphasize deterministic, contract-first data handling. [oai_citation:28â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU) [oai_citation:29â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

[^kfmraw]: KFM ingestion guidance explicitly emphasizes keeping data as raw as possible and storing raw data reliably before transformations. [oai_citation:30â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.pdf](file-service://file-Bro83fTiCi9UUVVno1fL6L)

[^catalogs]: At publication boundaries, datasets produce STAC/DCAT/PROV artifacts for discovery and provenance tracing. [oai_citation:31â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)

[^dvc]: The project design + MCP guidance both support dataset versioning and using tools like DVC for large artifacts and reproducibility. [oai_citation:32â€¡Kansas-Frontier-Matrix_ Open-Source Geospatial Historical Mapping Hub Design.pdf](file-service://file-64djFYQUCmxN1h6L6X7KUw) [oai_citation:33â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)

[^privacy]: Security and privacy framing (CIA + privacy as control of personal info) aligns with digital humanismâ€™s human-centered approach and is relevant to raw data handling. [oai_citation:34â€¡Introduction to Digital Humanism.pdf](file-service://file-HC311tLjkcn1yRbyTBLJQQ)

[^maps]: GIS metadata categories, interoperability expectations, and copyright distinctions matter for how we store and redistribute cartographic data. [oai_citation:35â€¡making-maps-a-visual-guide-to-map-design-for-gis.pdf](file-service://file-51FgWTn7uFXenxztXw29bP) [oai_citation:36â€¡making-maps-a-visual-guide-to-map-design-for-gis.pdf](file-service://file-51FgWTn7uFXenxztXw29bP)

[^scans]: KFM repo standards call for automated scanning for secrets/PII/sensitive data and classification consistency to prevent leaks and unsafe publication. [oai_citation:37â€¡MARKDOWN_GUIDE_v13.md.gdoc](file-service://file-UYVruFXfueR8veHMUKeugU)