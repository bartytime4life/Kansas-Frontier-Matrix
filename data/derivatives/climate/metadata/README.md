<div align="center">

# ğŸ§® Kansas Frontier Matrix â€” Climate Derivative Metadata  
`data/derivatives/climate/metadata/`

**Purpose:** Store structured metadata describing each processed **climate derivative artifact**  
(COG, GeoJSON, Parquet, CSV), linking them to their provenance, checksum, and STAC representation.

[![Build & Deploy](https://img.shields.io/github/actions/workflow/status/bartytime4life/Kansas-Frontier-Matrix/site.yml?label=Build%20%26%20Deploy)](../../../../../.github/workflows/site.yml)
[![STAC Validate](https://img.shields.io/badge/STAC-validate-blue)](../../../../../.github/workflows/stac-validate.yml)
[![CodeQL](https://img.shields.io/github/actions/workflow/status/bartytime4life/Kansas-Frontier-Matrix/codeql.yml?label=CodeQL)](../../../../../.github/workflows/codeql.yml)
[![Trivy](https://img.shields.io/badge/Container-Scan-informational)](../../../../../.github/workflows/trivy.yml)
[![Docs Â· MCP](https://img.shields.io/badge/Docs-MCP-brightgreen)](../../../../../docs/)
[![License: CC-BY 4.0](https://img.shields.io/badge/License-CC-BY%204.0-lightgrey)](../../../../../LICENSE)

</div>

---

## ğŸ“š Overview

This directory contains **machine-readable metadata JSON files** for all climate derivative outputs generated under  
`data/derivatives/climate/`. Each metadata file defines a datasetâ€™s **origin, variables, temporal range, CRS, and relationships** to its checksum and STAC item.  

Metadata here serves as a bridge between the raw derivative files, their checksum manifests (`/checksums`),  
and the **STAC catalog** (`data/stac/`). It ensures the **traceability, reproducibility, and semantic integrity**  
of all derived climate products within the Kansas Frontier Matrix (KFM) pipeline.  

---

## ğŸ§­ Metadata generation flow

```mermaid
flowchart TD
  A["Sources\nNOAA Â· Daymet Â· Normals"] --> B["ETL\nNormalize Â· Derive"]
  B --> C["Climate Derivatives\nCOG Â· GeoJSON Â· Parquet Â· CSV"]
  C --> D["Metadata JSONs\nvariables Â· CRS Â· temporal range Â· provenance"]
  D --> E["Checksums\n*.sha256 (validation)"]
  D --> F["STAC Items\nassets + metadata"]
  F --> G["Knowledge Graph\nnodes + relations"]
  G --> H["API + Web UI\ntimeline Â· search Â· layer metadata"]
%% END OF MERMAID

<!-- END OF MERMAID -->



â¸»

ğŸ—‚ Directory layout

data/derivatives/climate/
â”œâ”€â”€ metadata/
â”‚   â”œâ”€â”€ daymet_1980_2024_tmin_ks.json
â”‚   â”œâ”€â”€ daymet_1980_2024_prcp_ks.json
â”‚   â”œâ”€â”€ normals_1991_2020_prcp.json
â”‚   â”œâ”€â”€ drought_index_annual_ks.json
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ checksums/
â””â”€â”€ *.tif Â· *.geojson Â· *.parquet Â· *.csv

Each .json metadata file corresponds directly to a processed artifact,
providing structured details aligned with STAC and DCAT schemas.

â¸»

ğŸ§¾ Metadata schema (JSON structure)

Each metadata file follows this standardized schema:

{
  "id": "daymet_1980_2024_tmin_ks",
  "title": "Daily Minimum Temperature (Daymet, 1980â€“2024, Kansas)",
  "description": "Derived daily minimum temperature (tmin) dataset aggregated for Kansas from NASA Daymet v4.",
  "type": "raster",
  "format": "COG",
  "file": "../daymet_1980_2024_tmin_ks_cog.tif",
  "checksum": "../checksums/daymet_1980_2024_tmin_ks_cog.tif.sha256",
  "source": "../../../sources/daymet.json",
  "stac_item": "../../../stac/items/daymet_1980_2024_tmin_ks.json",
  "spatial": {
    "crs": "EPSG:4326",
    "bbox": [-102.05, 36.99, -94.59, 40.00]
  },
  "temporal": {
    "start": "1980-01-01",
    "end": "2024-12-31"
  },
  "variables": [
    {
      "name": "tmin",
      "units": "Â°C",
      "description": "Daily minimum temperature"
    }
  ],
  "license": "CC-BY-4.0",
  "created": "2025-10-10",
  "mcp_stage": "derivatives"
}

ğŸ” Tip: Include human-readable descriptions and ensure field alignment with
data/sources/<source>.json and data/stac/items/<id>.json for STAC validation consistency.

â¸»

ğŸ§© Relationship to other metadata layers

Layer	Path	Purpose
Source Metadata	data/sources/	Defines raw dataset provenance (e.g., Daymet, NOAA).
Derivative Metadata	data/derivatives/climate/metadata/	Documents ETL-transformed products.
Checksums	data/derivatives/climate/checksums/	Ensures file integrity.
STAC Catalog	data/stac/	Registers assets with temporal & spatial metadata.
Knowledge Graph	(Neo4j)	Stores semantic links (HAS_DERIVATIVE, HAS_PROVENANCE).


â¸»

ğŸ§  Usage in pipeline
	â€¢	ETL stage: Python ETL scripts create or update these .json metadata files automatically.
	â€¢	Validation: STAC and JSON Schema validators confirm field presence, type, and alignment.
	â€¢	CI/CD: The stac-validate.yml GitHub Action cross-checks that each derivative file has a metadata JSON entry and a matching checksum.
	â€¢	Graph Load: During Neo4j ingestion, metadata properties are parsed to enrich graph nodes (e.g., temporal.start, variables.name).

â¸»

ğŸ§± Metadata best practices

Category	Guideline
âœ… Completeness	Every climate derivative must have a metadata JSON file.
ğŸ”— Linkage	Always reference its checksum, STAC item, and source manifest.
ğŸ•“ Timestamps	Include created and last_updated in ISO 8601 format.
ğŸ§® Variables	Explicitly list all measured/derived variables with units.
ğŸ§¾ Licensing	Record dataset-specific license terms (default: CC-BY-4.0).
ğŸ§ª Validation	Run make validate or CI to enforce schema conformity.


â¸»

ğŸ”’ Reproducibility & MCP alignment

These metadata files fulfill MCPâ€™s documentation-first requirement by encoding data provenance and semantics
in open formats (JSON, STAC, DCAT).
They make every derived dataset self-describing, verifiable, and linkable to its lineage,
as emphasized in KFMâ€™s File and Data Architecture and Monorepo Design docs.

â¸»

ğŸ§± Related docs
	â€¢	data/derivatives/climate/checksums/README.md â€” hash integrity workflow
	â€¢	docs/architecture.md â€” ETL & data provenance chain
	â€¢	data/stac/README.md â€” STAC catalog design
	â€¢	data/sources/README.md â€” source manifest conventions

â¸»

ğŸ—“ Version History

Version	Date	Notes
0.1.0	2025-10-10	Initial creation of climate derivative metadata schema & examples.