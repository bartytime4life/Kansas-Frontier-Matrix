<div align="center">

# üßæ Kansas Frontier Matrix ‚Äî Hazards ETL Logs  
`data/work/tmp/hazards/logs/`

**Mission:** Store **temporary ETL and QA logs** generated during hazard data processing ‚Äî  
including tornado, flood, wildfire, and drought datasets ‚Äî to provide full traceability  
and diagnostic transparency within the Kansas Frontier Matrix (KFM) data pipeline.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../../../../.github/workflows/site.yml)
[![STAC Validate](https://img.shields.io/badge/STAC-validate-blue)](../../../../../../.github/workflows/stac-validate.yml)
[![CodeQL](https://img.shields.io/github/actions/workflow/status/bartytime4life/Kansas-Frontier-Matrix/codeql.yml?label=CodeQL)](../../../../../../.github/workflows/codeql.yml)
[![Trivy](https://img.shields.io/badge/container-scan-informational)](../../../../../../.github/workflows/trivy.yml)
[![Docs ¬∑ MCP](https://img.shields.io/badge/Docs-MCP-green)](../../../../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-blue)](../../../../../../LICENSE)

</div>

---

## üìö Overview

The `data/work/tmp/hazards/logs/` directory temporarily stores **pipeline and validation logs**  
created during hazard data ETL and QA workflows.  

These logs capture:
- ETL operations for tornado, flood, wildfire, and drought datasets  
- CRS reprojection, resampling, and raster/vector conversion steps  
- STAC metadata validation and checksum verification outcomes  
- Diagnostic messages from hazard metadata generation  

Logs are **ephemeral**, **not version-controlled**, and **automatically regenerable** with every ETL cycle.

---

## üóÇÔ∏è Directory Layout

```bash
data/work/tmp/hazards/logs/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ hazards_etl_debug.log
‚îú‚îÄ‚îÄ flood_validation_report.log
‚îú‚îÄ‚îÄ wildfire_projection_test.log
‚îî‚îÄ‚îÄ drought_index_checksum_audit.log
````

> **Note:** Log filenames vary depending on the dataset or ETL stage.
> Files are replaced between runs and omitted from permanent storage.

---

## ‚öôÔ∏è Logging Guidelines

| Log Type                      | Purpose                                                              |
| :---------------------------- | :------------------------------------------------------------------- |
| **`*_etl_debug.log`**         | Records ETL operations (file ingest, reprojection, tiling, exports). |
| **`*_validation_report.log`** | Summarizes QA/QC outcomes and STAC/schema conformity results.        |
| **`*_projection_test.log`**   | Documents reprojection tests and CRS alignment diagnostics.          |
| **`*_checksum_audit.log`**    | Captures reproducibility verification via checksum comparisons.      |

All logs are written in **UTF-8 text format** to ensure open review and platform independence.

---

## ‚öôÔ∏è Log Generation Workflow

Logs are automatically generated by the hazards ETL pipeline and can also be triggered manually.

**Makefile target**

```bash
make hazards
```

**Python command**

```bash
python src/pipelines/hazards/hazards_pipeline.py --log data/work/tmp/hazards/logs/hazards_etl_debug.log
```

**Lifecycle**

1. Pipeline initializes and begins writing logs.
2. Each stage (ETL, validation, checksum) appends updates.
3. Logs can be inspected for debugging or CI/CD validation.
4. Cleared after successful execution or during cleanup.

---

## üßπ Cleanup Policy

This directory is **temporary** and purged automatically between runs.

**Makefile target**

```bash
make clean-logs
```

**Manual cleanup**

```bash
rm -rf data/work/tmp/hazards/logs/*
```

Permanent outputs reside in:

* `data/processed/hazards/` ‚Äî validated hazard datasets
* `data/checksums/hazards/` ‚Äî reproducibility checksum records
* `data/processed/metadata/hazards/` ‚Äî STAC metadata for hazard layers

---

## üß© Integration with Pipelines

| Linked Component                            | Function                                             |
| :------------------------------------------ | :--------------------------------------------------- |
| `src/pipelines/hazards/hazards_pipeline.py` | Generates ETL, validation, and checksum audit logs.  |
| `.github/workflows/stac-validate.yml`       | References logs for checksum and schema diagnostics. |
| `data/work/tmp/hazards/`                    | Parent workspace for hazard ETL intermediates.       |
| `data/processed/hazards/`                   | Final repository for processed hazard outputs.       |

---

## üß† MCP Compliance Summary

| MCP Principle           | Implementation                                                   |
| :---------------------- | :--------------------------------------------------------------- |
| **Documentation-first** | README defines structure, workflow, and cleanup for hazard logs. |
| **Reproducibility**     | Log generation is deterministic and regenerable.                 |
| **Open Standards**      | UTF-8 text format; aligned with STAC/DCAT metadata frameworks.   |
| **Provenance**          | Logs timestamp and trace each ETL step to its data output.       |
| **Auditability**        | CI/CD workflows use logs to validate checksums and QA results.   |

---

## üìé Related Directories

| Path                               | Description                                           |
| :--------------------------------- | :---------------------------------------------------- |
| `data/work/tmp/hazards/`           | Temporary workspace for hazard ETL intermediates.     |
| `data/processed/hazards/`          | Finalized tornado, flood, wildfire, and drought data. |
| `data/checksums/hazards/`          | Integrity hashes for reproducibility tracking.        |
| `data/processed/metadata/hazards/` | STAC metadata documentation for hazard datasets.      |

---

## üìÖ Version History

| Version | Date       | Summary                                                              |
| :------ | :--------- | :------------------------------------------------------------------- |
| v1.0    | 2025-10-04 | Initial hazards ETL log documentation created.                       |
| v1.0.1  | 2025-10-09 | Added YAML/JSON-LD metadata, MCP badges, provenance, and CI updates. |

---

<div align="center">

**Kansas Frontier Matrix** ‚Äî *‚ÄúLogging Every Storm, Fire, and Flood ‚Äî Integrity in Every Line.‚Äù*
üìç [`data/work/tmp/hazards/logs/`](.) ¬∑ Temporary ETL and QA logging workspace for hazard datasets.

</div>
