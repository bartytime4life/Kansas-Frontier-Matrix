---
title: "KFM Workbench & Experiment Sandbox"
path: "data/work/README.md"
version: "v1.1.0"
last_updated: "2026-01-11"
status: "draft"
doc_kind: "Guide"
license: "CC-BY-4.0"

markdown_protocol_version: "KFM-MDP v11.2.6"
mcp_version: "MCP-DL v6.3"
ontology_protocol_version: "KFM-ONTO v4.1.0"
pipeline_contract_version: "KFM-PPC v11.0.0"
stac_profile: "KFM-STAC v11.0.0"
dcat_profile: "KFM-DCAT v11.0.0"
prov_profile: "KFM-PROV v11.0.0"

governance_ref: "docs/governance/ROOT_GOVERNANCE.md"
ethics_ref: "docs/governance/ETHICS.md"
sovereignty_policy: "docs/governance/SOVEREIGNTY.md"
fair_category: "FAIR+CARE"
care_label: "TBD"
sensitivity: "mixed"          # mixed | public | internal | restricted
classification: "internal"     # open | internal | confidential | restricted
jurisdiction: "US-KS"

doc_uuid: "urn:kfm:doc:data:work:readme:v1.1.0"
semantic_document_id: "kfm-data-work-readme-v1.1.0"
event_source_id: "ledger:kfm:doc:data:work:readme:v1.1.0"
commit_sha: "<latest-commit-hash>"

ai_transform_permissions:
  - "summarize"
  - "structure_extract"
  - "translate"
  - "keyword_index"
ai_transform_prohibited:
  - "generate_policy"
  - "infer_sensitive_locations"

doc_integrity_checksum: "sha256:<calculate-and-fill>"
---

<div align="center">
<a id="top"></a>

# ğŸ§° `data/work/` â€” Workbench & Experiment Sandbox

![Scope](https://img.shields.io/badge/scope-data%2Fwork-1f6feb?style=flat-square)
![Stage](https://img.shields.io/badge/stage-intermediate%20%2F%20WIP-f59f00?style=flat-square)
![Repro](https://img.shields.io/badge/principle-reproducible-2da44e?style=flat-square)
![Evidence](https://img.shields.io/badge/evidence-first-STAC%20%2B%20DCAT%20%2B%20PROV-6f42c1?style=flat-square)
![Governance](https://img.shields.io/badge/governance-FAIR%2BCARE-8250df?style=flat-square)
![Security](https://img.shields.io/badge/security-no%20secrets%20%7C%20no%20PII%20by%20default-d1242f?style=flat-square)

**Controlled chaos with receipts** ğŸ§ªğŸ§¾  
`data/work/` is where experiments become deterministic, validated, and governable **before** promotion to `data/processed/` + catalogs.

</div>

> [!IMPORTANT]
> âœ… If it canâ€™t be reproduced, it doesnâ€™t count. ğŸ”¬  
> âœ… If itâ€™s used downstream (Graph/API/UI/Story/Focus), it **must be promoted** and shipped as an **evidence artifact** (STAC + DCAT + PROV).  
> âŒ No â€œsneakyâ€ UI reads from file paths or Neo4j: the **API boundary** mediates access.

---

## ğŸš€ Quick links (jump out of the sandbox)

- ğŸ“¥ Raw inputs (immutable) â†’ [`../raw/`](../raw/)
- ğŸ§¾ Source manifests (recommended for large externals) â†’ [`../sources/`](../sources/) *(if present)*
- ğŸ“¦ Processed / publishable outputs â†’ [`../processed/`](../processed/)
- ğŸ›°ï¸ STAC â†’ [`../stac/`](../stac/) *(Collections/Items/Assets)*
- ğŸ—‚ï¸ DCAT â†’ [`../catalog/`](../catalog/) â†’ [`../catalog/dcat/`](../catalog/dcat/)
- ğŸ§¬ PROV â†’ [`../prov/`](../prov/)
- ğŸ•¸ï¸ Graph exports (optional) â†’ [`../graph/`](../graph/)
- ğŸ§ª Validation tooling (recommended) â†’ [`../../tools/validation/`](../../tools/validation/)
- ğŸ§­ Master Guide (canonical order + invariants) â†’ `docs/MASTER_GUIDE_v13.md` *(or equivalent)*
- ğŸ” Security policy â†’ [`../../SECURITY.md`](../../SECURITY.md)

---

<details>
<summary><strong>ğŸ“Œ Table of contents</strong></summary>

- [ğŸ¯ What belongs here](#-what-belongs-here)
- [ğŸš« What must NOT belong here](#-what-must-not-belong-here)
- [ğŸ§­ Canonical pipeline order](#-canonical-pipeline-order-non-negotiable)
- [ğŸ—ºï¸ Folder map](#ï¸-folder-map)
- [ğŸ“¦ Work Package Standard](#-work-package-standard-wps)
- [ğŸ§¬ Reproducibility & provenance](#-reproducibility--provenance)
- [âœ… Quality checklists](#-quality-checklists-fast-but-real)
- [ğŸš€ Promotion rules](#-promotion-rules-work--processed--catalogs)
- [ğŸ§· Domain expansion pattern](#-domain-expansion-pattern-add-a-new-domain-safely)
- [ğŸ” Governance & â€œdonâ€™t be creepyâ€ rules](#-governance--dont-be-creepy-rules)
- [ğŸ¤– Automation hooks](#-automation-hooks-optional-roadmap)
- [ğŸ“š Reference shelf](#-reference-shelf-project-library)
- [ğŸ•°ï¸ Version history](#ï¸-version-history)

</details>

---

## ğŸ¯ What belongs here

âœ… Put **intermediate** and **work-in-progress** artifacts here, organized by **domain**:

- ğŸ§ª **Repeatable experiment runs**  
  Regression studies, Bayesian inference, statistical EDA, drift checks, model evaluation outputs
- ğŸ›°ï¸ **GIS/remote sensing scratch work**  
  Clips, reprojection trials, NDVI derivations, mosaics, tiling prototypes, pyramids/overviews tests
- ğŸ§± **Intermediate transform products**  
  Normalized tables, feature engineering outputs, QA fixtures, â€œcandidateâ€ layers
- ğŸ“Š **Run-scoped plots & mini-reports**  
  Figures/tables to decide whether something is ready for promotion
- ğŸ§° **Prototype bundles for promotion**  
  `exports/` folder containing a *candidate* processed artifact + metadata drafts

> [!TIP]
> Treat `data/work/` as a **staging lane** between `data/raw/` and `data/processed/`â€”not as a permanent home.  
> If it becomes evidence, it gets promoted. ğŸ“¦âœ…

---

## ğŸš« What must NOT belong here

ğŸš« Never commit these to `data/work/` (or anywhere in the repo):

- ğŸ”‘ **Secrets / tokens / credentials** *(ever)*
- ğŸ§ **PII** *(unless explicitly permitted + classified + controlled)*
- ğŸ§¨ **Sensitive locations** or culturally protected knowledge in a form that enables harm
- ğŸ•³ï¸ â€œMystery filesâ€ with no manifest, provenance, or explanation
- ğŸ›ï¸ Any â€œofficialâ€ dataset that the UI/Graph/Story/Focus depends on (promote it)

> [!CAUTION]
> `data/work/` is allowed to be messy, but it must never be **unsafe**. ğŸ”’

---

## ğŸ§­ Canonical pipeline order (non-negotiable)

KFM stays stable by being strict about ordering:

**ETL â†’ STAC/DCAT/PROV â†’ Graph â†’ API â†’ UI â†’ Story Nodes â†’ Focus Mode**

`data/work/` sits **upstream** of the evidence boundary. Itâ€™s where we prove something can be deterministic and governed before it becomes â€œreal.â€

```mermaid
flowchart LR
  RAW["ğŸ“¥ data/raw/<domain>/\nimmutable inputs"] --> WORK["ğŸ§° data/work/<domain>/\nintermediate + WIP"]
  WORK --> PROC["ğŸ“¦ data/processed/<domain>/\npublishable outputs"]
  PROC --> CATS["ğŸ§¾ Catalogs\nSTAC + DCAT + PROV"]
  CATS --> GRAPH["ğŸ•¸ï¸ Graph\nIDs + relationships"]
  GRAPH --> API["ğŸ”Œ API boundary\ncontracts + redaction"]
  API --> UI["ğŸ—ºï¸ UI\nmap + timeline + downloads"]
  UI --> STORY["ğŸ¬ Story Nodes\ncurated narrative"]
  STORY --> FOCUS["ğŸ§  Focus Mode\nprovenance-linked only"]
```

> [!IMPORTANT]
> **Evidence artifact rule:** if an analysis output (including AI-derived artifacts) is used as evidence, it must live in `data/processed/` and be registered via **STAC/DCAT** with **PROV** lineage. ğŸ§¾ğŸ§¬

---

## ğŸ—ºï¸ Folder map

### Recommended layout (domain-first)

```text
ğŸ“ data/work/
â”œâ”€â”€ ğŸ“ _templates/                    ğŸ§© copy/paste manifests + checklists
â”œâ”€â”€ ğŸ“ _scratch/                      âš ï¸ gitignored throwaway (keep empty in PRs)
â”œâ”€â”€ ğŸ“ <domain>/                      ğŸŒ¾ğŸ™ï¸ğŸŒ one folder per domain
â”‚   â”œâ”€â”€ ğŸ“ experiments/               ğŸ§ª reproducible runs (preferred)
â”‚   â”œâ”€â”€ ğŸ“ etl_runs/                  ğŸ§° transform trials + intermediate outputs
â”‚   â”œâ”€â”€ ğŸ“ datasets/                  ğŸ“¦ curated WIP datasets (not published)
â”‚   â”œâ”€â”€ ğŸ“ qa/                        âœ… run-scoped QA outputs (small + useful)
â”‚   â”œâ”€â”€ ğŸ“ exports/                   ğŸ“¤ candidate promotion bundles
â”‚   â”œâ”€â”€ ğŸ“ _archive/                  ğŸ§¹ cold storage (optional)
â”‚   â””â”€â”€ ğŸ“„ README.md                  ğŸ“Œ domain-specific notes
â””â”€â”€ ğŸ“„ README.md                      ğŸ‘ˆ you are here
```

### Where do notebooks / code live?

- **Preferred (v13-style):** `mcp/` for methods + computational experiments (protocols, notebooks, run records, model cards, SOPs) ğŸ§ ğŸ““  
- **Also common:** `notebooks/` for exploratory EDA (if the repo has that pattern) âœï¸  
- `data/work/` should store **data artifacts + run outputs**, not be your only code home.

> [!TIP]
> Keep a clean separation:
> - `mcp/` = method + narrative of the experiment (how/why)
> - `data/work/` = intermediate artifacts (what it produced)
> - `data/processed/` + catalogs = publishable evidence (what we stand behind)

---

## ğŸ“¦ Work Package Standard (WPS)

A **Work Package** is any folder under `data/work/<domain>/...` that others are expected to rerun, review, or build on.

### âœ… Naming convention

Use date + domain + slug + version:

- `YYYY-MM-DD__<domain>__<short_slug>__vNN/`

Examples:
- `2026-01-02__remote_sensing__ndvi_landsat8__v01/`
- `2026-01-04__stats__soil_moisture_regression__v02/`
- `2026-01-10__viz__webgl_tileset_prototype__v01/`

### âœ… Required files (minimum bar)

Every Work Package **must** contain:

- `README.md` â€” purpose, scope, results, next steps
- `manifest.yaml` â€” inputs, parameters, outputs, environment, hashes
- `inputs/` â€” small fixtures **or** pointer manifests (when data is too large/restricted)
- `src/` and/or `notebooks/` â€” runnable code to generate outputs
- `outputs/` â€” artifacts produced by the run (keep bounded)

### ğŸ”¥ Strongly recommended

- `environment/` â€” `requirements.txt`, `environment.yml`, `poetry.lock`, `package-lock.json`, etc.
- `checksums.sha256` â€” integrity list for key artifacts
- `data_dictionary.md` â€” fields, units, codes, value ranges
- `PROV_HINT.yaml` â€” minimal mapping from run â†’ intended PROV fields
- `openlineage.json` â€” optional lineage event export (if adopted)
- `PROMOTION.md` â€” if promoted, record dataset IDs + final paths + commit hash

---

## ğŸ§¬ Reproducibility & provenance

> [!IMPORTANT]
> **Reproducibility is a security feature.**  
> It enables audit, rollback, and tamper detectionâ€”not just â€œnice science.â€ ğŸ›¡ï¸ğŸ”

### âœ… Scientific-method spine (what every Work Package should capture)

1) **Question / problem statement** â“  
2) **Background research** ğŸ“š *(cite relevant references)*  
3) **Hypothesis** ğŸ¯ *(testable expectation)*  
4) **Method / protocol** ğŸ§ª *(written before the run, updated with deviations)*  
5) **Data collection & labeling** ğŸ·ï¸  
6) **Analysis** ğŸ“ˆ *(tests, visuals, model choices)*  
7) **Results** âœ… *(linked artifacts + metrics)*  
8) **Conclusion + limitations** ğŸ§©  
9) **Next steps** â¡ï¸

### `manifest.yaml` starter (WPS)

```yaml
id: 2026-01-04__stats__soil_moisture_regression__v02
run_uuid: "urn:uuid:<generate>"
owner: "@your-handle"
created_at: "2026-01-04"
status: wip  # wip | review | archived | promoted

governance:
  classification: internal     # open | internal | confidential | restricted
  sensitivity: mixed           # mixed because workbench may contain sensitive intermediates
  sovereignty_notes: "TBD (add if dataset involves consent/sovereignty constraints)"

question:
  problem: "How does soil moisture relate to vegetation index over time in region X?"
  hypothesis: "Soil moisture explains part of NDVI variance with a lag."

inputs:
  - name: soil_moisture_source
    type: table
    pointer: "data/raw/hydro/soil_moisture/<drop_id>/ (or data/sources manifest)"
    immutability: pinned
    checksums:
      - algo: sha256
        value: "<hash>"
    license: "<SPDX or URL>"
    notes: "Prefer receipts (download log, ETag) + checksum."

  - name: ndvi_candidate
    type: raster
    pointer: "data/work/remote_sensing/experiments/2026-01-02__remote_sensing__ndvi_landsat8__v01/outputs/ndvi_cog.tif"
    immutability: local
    notes: "If promoted later, this becomes a STAC asset."

process:
  steps:
    - validate: ["schema", "ranges", "missingness", "crs"]
    - feature_engineer: ["lag_features", "seasonality_terms"]
    - model: ["baseline_linear_regression", "robust_regression_optional"]
    - evaluate: ["residuals", "outliers", "uncertainty"]
parameters:
  region: "AOI slug or file path"
  date_range: ["YYYY-MM-DD", "YYYY-MM-DD"]
  random_seed: 1337

environment:
  runtime: "python"
  python: "3.11"
  lockfiles:
    - environment/requirements.txt
    - environment/poetry.lock
  container:
    image: "<optional: ghcr.io/...:tag>"

outputs:
  - name: metrics
    path: outputs/metrics.json
  - name: model_summary
    path: outputs/model_summary.md
  - name: plots
    path: viz/
  - name: logs
    path: logs/

promotion_intent:
  candidate_dataset_id: "kfm.ks.<domain>.<product>.<time_range>.v1"
  requires_evidence_bundle: true  # STAC + DCAT + PROV
  notes: "Promote only after QA + steward review."
```

> [!TIP]
> If a run is meant to be replayable, treat it like a mini-pipeline:
> **idempotent inputs + pinned environment + deterministic outputs** ğŸ”

---

## âœ… Quality checklists (fast, but real)

### ğŸ—ºï¸ Geospatial sanity (raster/vector)

- [ ] CRS explicitly stated (no silent EPSG drift)
- [ ] Units documented (meters vs degrees, mm vs inches, etc.)
- [ ] Geometry validity checks pass (no self-intersections, no empty geoms)
- [ ] Raster `nodata` defined and preserved
- [ ] For web use, produce (or plan to produce) an **EPSG:4326** representation (or documented web CRS path)
- [ ] Interactive outputs include overviews/pyramids when appropriate (COG best practices)
- [ ] Cartography choices recorded (symbology, classification, legends)

### ğŸ“ˆ Statistics & experimental design (donâ€™t fool yourself)

- [ ] Label the work: **exploration** vs **confirmation**
- [ ] Check assumptions (residuals, heteroskedasticity, independence)
- [ ] Avoid leakage (train/val/test boundaries explicit)
- [ ] Report effect sizes + uncertainty (not just p-values)
- [ ] Document multiple comparisons risk (if applicable)

### ğŸ›°ï¸ Simulation & modeling integrity (V&V + UQ)

- [ ] Inputs/initial conditions captured
- [ ] Validation plan stated (what would falsify the model?)
- [ ] Sensitivity sweeps documented (even a minimal one)
- [ ] Outputs include units, coordinate frames, and metadata
- [ ] Results reproducible from config + seed + environment

### ğŸŒ Visualization prototypes (Web + WebGL)

- [ ] Save screenshots + â€œwhat this provesâ€ note
- [ ] Provide a minimal entry point (`index.html` or `README.md`)
- [ ] Consider mobile-first constraints early ğŸ“±
- [ ] Treat 3D assets/parsers as **untrusted inputs** (security boundary)

---

## ğŸš€ Promotion rules (`work` â†’ `processed` â†’ catalogs)

### When do we promote?

Promote when **any** of the following becomes true:

- A dataset is stable enough to be reused across multiple work packages
- A derived layer should appear in map/timeline exploration
- A result is referenced in Story Nodes or decision-facing docs
- We need the artifact to be audited, cited, or externally shared

### Promotion â€œdefinition of doneâ€ âœ…

- [ ] Output moved (or re-generated) into `data/processed/<domain>/â€¦`
- [ ] Evidence bundle produced: **STAC + DCAT + PROV**
- [ ] QA checks captured (ideally automated)
- [ ] Sensitivity/classification reviewed (no â€œdowngrade by accidentâ€)
- [ ] A thin pointer remains in `data/work/` linking to the canonical artifact

### Promotion bundle (typical)

- ğŸ›°ï¸ `data/stac/collections/<collection_id>/collection.json`
- ğŸ“¦ `data/stac/items/<collection_id>/<item_id>.json`
- ğŸ—‚ï¸ `data/catalog/dcat/<dataset_id>.jsonld`
- ğŸ§¬ `data/prov/<run_id>/prov.jsonld` *(or bundle)*
- âœ… checksums + receipts (recommended)
- ğŸ” optional signing/attestation (future: `releases/`)

> [!TIP]
> Think of `data/work/` as rehearsal ğŸ­ and `data/processed/` as opening night ğŸŸï¸

---

## ğŸ§· Domain expansion pattern (add a new domain safely)

When introducing a new domain (e.g., `public_health`, `energy`, `hydrology`):

1) Create lifecycle folders:
   - `data/raw/<domain>/`
   - `data/work/<domain>/`
   - `data/processed/<domain>/`

2) Add domain docs:
   - `docs/data/<domain>/README.md` *(runbook: sources, licenses, stewards, risks)*

3) Ensure the domain can publish evidence:
   - STAC (if spatial assets exist)
   - DCAT (always for discoverability)
   - PROV (always for lineage)

4) Add validation hooks:
   - schema checks
   - link integrity checks
   - governance/policy checks (classification, sovereignty, licensing)

> [!NOTE]
> Domain growth is welcomeâ€”**but only through contracts + governance**. ğŸŒ±âœ…

---

## ğŸ” Governance & â€œdonâ€™t be creepyâ€ rules

KFM is evidence-first **and** human-centered. Maps and datasets can cause harm if handled carelessly.

### Non-negotiables

- âŒ No secrets or credentials in `data/work/`
- âŒ No publishing precise sensitive locations without explicit review
- âœ… Always document provenance + licensing constraints
- âœ… Treat derived outputs as potentially sensitive (inference risk is real)

### Practical classification model (recommended)

| Classification | Typical in `data/work/` | Safe distribution pattern |
|---|---:|---|
| **Open** ğŸŒ | Rare | public files ok |
| **Internal** ğŸ¢ | Common | private storage + governed API |
| **Confidential** ğŸ” | Allowed with controls | no direct download URLs; gated access |
| **Restricted** ğŸ§¨ | Avoid in Git | minimal disclosure; landing page only |

> [!CAUTION]
> Even â€œjust metadataâ€ can leak. Reduce precision, redact where needed, and document why.

### AI constraints (still apply in the sandbox)

- AI must not infer or reconstruct sensitive locations from partial artifacts.
- If you use AI to draft summaries/labels, keep outputs attributable and **upgrade to evidence artifacts** before anything is shown in Focus Mode.

---

## ğŸ¤– Automation hooks (optional roadmap)

If/when automation touches `data/work/`, it must be **auditable** and **safe**:

- ğŸ›°ï¸ **Detect â†’ Validate â†’ Promote** workflows (fast checks + deterministic promotion)
- ğŸ§¾ Checksums/ETags for change detection
- ğŸ§  Watcherâ€“Plannerâ€“Executor agents:
  - Watcher emits immutable alerts
  - Planner generates deterministic change plans
  - Executor opens PRs (never auto-merges)
  - includes idempotency keys + kill-switch

> [!NOTE]
> Automation is welcome **only** when it strengthens governance (not bypasses it). âœ…

---

## ğŸ“š Reference shelf (project library)

> [!NOTE]
> These files are a **reading pack / influence map**. Their licenses may differ from the repoâ€™s code/data. Respect upstream terms. ğŸ“œ

<details>
<summary><strong>ğŸ§­ Canonical KFM docs</strong></summary>

- `docs/MASTER_GUIDE_v13.md` *(or current Master Guide file)*
- `docs/specs/Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Documentation.docx`
- `docs/specs/ğŸŒŸ Kansas Frontier Matrix â€“ Latest Ideas & Future Proposals.docx`
- `docs/glossary.md`
- `docs/templates/`
- `docs/standards/`
- `docs/governance/`

</details>

<details>
<summary><strong>ğŸ§ª Scientific method + reproducible coding discipline</strong></summary>

- `docs/library/Scientific Method _ Research _ Master Coder Protocol Documentation.pdf`
- `docs/library/Scientific Modeling and Simulation_ A Comprehensive NASA-Grade Guide.pdf`

</details>

<details>
<summary><strong>ğŸ—ºï¸ GIS, spatial ops, cartography</strong></summary>

- `docs/library/python-geospatial-analysis-cookbook.pdf`
- `docs/library/PostgreSQL Notes for Professionals - PostgreSQLNotesForProfessionals.pdf`
- `docs/library/making-maps-a-visual-guide-to-map-design-for-gis.pdf`
- `docs/library/Mobile Mapping_ Space, Cartography and the Digital - 9789048535217.pdf`
- `docs/library/compressed-image-file-formats-jpeg-png-gif-xbm-bmp.pdf`
- `docs/library/Cloud-Based Remote Sensing with Google Earth Engine-Fundamentals and Applications.pdf`

</details>

<details>
<summary><strong>ğŸ“ˆ Stats, inference, modeling</strong></summary>

- `docs/library/Understanding Statistics & Experimental Design.pdf`
- `docs/library/regression-analysis-with-python.pdf`
- `docs/library/Regression analysis using Python - slides-linear-regression.pdf`
- `docs/library/graphical-data-analysis-with-r.pdf`
- `docs/library/think-bayes-bayesian-statistics-in-python.pdf`

</details>

<details>
<summary><strong>ğŸŒ Web UI + 3D/graphics</strong></summary>

- `docs/library/responsive-web-design-with-html5-and-css3.pdf`
- `docs/library/webgl-programming-guide-interactive-3d-graphics-programming-with-webgl.pdf`

</details>

<details>
<summary><strong>âš™ï¸ Systems, scalability, interoperability</strong></summary>

- `docs/library/Scalable Data Management for Future Hardware.pdf`
- `docs/library/concurrent-real-time-and-distributed-programming-in-java-threads-rtsj-and-rmi.pdf`
- `docs/library/Data Spaces.pdf`

</details>

<details>
<summary><strong>â¤ï¸ Ethics, autonomy, governance</strong></summary>

- `docs/library/Introduction to Digital Humanism.pdf`
- `docs/library/Principles of Biological Autonomy - book_9780262381833.pdf`
- `docs/library/On the path to AI Lawâ€™s prophecies and the conceptual foundations of the machine learning age.pdf`

</details>

<details>
<summary><strong>ğŸ›¡ï¸ Security (defensive reference only)</strong></summary>

- `docs/library/ethical-hacking-and-countermeasures-secure-network-infrastructures.pdf`
- `docs/library/Gray Hat Python - Python Programming for Hackers and Reverse Engineers (2009).pdf`

> Used to inform **defensive controls** (threat modeling, incident response, secure coding).  
> Not a request for offensive tooling contributions.

</details>

<details>
<summary><strong>ğŸ§° General programming shelf (bundles)</strong></summary>

- `docs/library/A programming Books.pdf`
- `docs/library/B-C programming Books.pdf`
- `docs/library/D-E programming Books.pdf`
- `docs/library/F-H programming Books.pdf`
- `docs/library/I-L programming Books.pdf`
- `docs/library/M-N programming Books.pdf`
- `docs/library/O-R programming Books.pdf`
- `docs/library/S-T programming Books.pdf`
- `docs/library/U-X programming Books.pdf`

</details>

---

## ğŸ•°ï¸ Version history

| Version | Date | Summary |
|---|---|---|
| v1.1.0 | 2026-01-11 | Aligned `data/work/` with v13 staging semantics, evidence artifact rule, WPS manifest upgrades, domain-first layout, governance + automation hooks ğŸ¤–âœ… |
| v1.0.0 | 2026-01-08 | Initial sandbox README: controlled chaos, promotion rules, reproducibility checklists ğŸ§ª |

---

<p align="right"><a href="#top">â¬†ï¸ Back to top</a></p>
