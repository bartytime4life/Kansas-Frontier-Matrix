<div align="center">


ğŸ§­ Kansas Frontier Matrix â€” Data & Catalog Architecture

Time Â· Terrain Â· History Â· Knowledge Graphs

</div>



â¸»

Overview

This document defines the mission-grade data architecture for the Kansas-Frontier-Matrix (KFM). It explains how sources are described, fetched, transformed into open formats, cataloged with STAC, and wired into CI for provenance, integrity, and reproducibility. The design follows the projectâ€™s documentation-first / MCP principles and the end-to-end stack shown in the Architecture docs.  ï¿¼  ï¿¼

â¸»

ğŸ“š Table of Contents
	â€¢	Directory Structure
	â€¢	data/sources/ Â· data/raw/ Â· data/processed/ Â· data/stac/
	â€¢	Data Processing Pipeline
	â€¢	Spatial Catalog (STAC)
	â€¢	Provenance & Reproducibility
	â€¢	Open Formats & Interoperability
	â€¢	Tooling & Automation
	â€¢	Contributing New Data

â¸»

Directory Structure

In KFM, all datasets and metadata live under data/, split by lifecycle stage.  ï¿¼

data/
â”œâ”€ sources/     # JSON manifests (external pointers + metadata)
â”œâ”€ raw/         # fetched originals (DVC/LFS pointers)
â”œâ”€ processed/   # COGs, GeoJSON, CSV/Parquet â€” analysis-ready
â””â”€ stac/        # STAC catalog (collections/items/assets)

data/sources/ {#datasources}

What it is: a lightweight catalog of manifests (JSON) that declare what a dataset is, where it comes from (URLs/APIs), license, spatial/temporal extent, and expected outputs. Pipelines read these to fetch/convert data without committing bulky binaries.  ï¿¼

Why: keeps the repo lean and reproducible; every dataset starts with documented provenance.

â¸»

data/raw/ {#dataraw}

What it is: a workspace for downloaded originals (archives, shapefiles, GeoTIFFs). We track pointers via DVC/Git LFS; not the bytes. Integrity sidecars (.sha256) accompany files.  ï¿¼

Why: avoid repo bloat while retaining versioned, re-fetchable inputs.

â¸»

data/processed/ {#dataprocessed}

What it is: analysis- and web-ready outputs in open formats:
	â€¢	rasters â†’ COG GeoTIFF (with internal overviews)
	â€¢	vectors â†’ GeoJSON/TopoJSON
	â€¢	tables â†’ CSV/Parquet

Consistent CRS (EPSG:4326) unless noted.  ï¿¼

Why: interoperable, streamable layers for MapLibre, notebooks, and exports.  ï¿¼

â¸»

data/stac/ {#datastac}

What it is: a STAC catalog (collections/items) indexing every processed asset with time, space, hrefs, media types, and provenance. Drives discoverability and UI layer config.  ï¿¼  ï¿¼

â¸»

Data Processing Pipeline

The ETL pipeline converts sources/ manifests into processed layers and STAC entries; it is Makefile-orchestrated with Python scripts.  ï¿¼

flowchart TD
  A["Manifest JSON<br/>(data/sources/*.json)"] -->|make fetch| B["Raw Files<br/>(data/raw/)"]
  B -->|make cogs / make vectors| C["Processed Outputs<br/>(data/processed/)"]
  C -->|make stac| D["STAC Catalog<br/>(data/stac/)"]
  B --> E["SHA-256 Sidecars"]
  C --> E

<!-- END OF MERMAID -->


	â€¢	Fetch â€” declarative downloads (HTTP/ArcGIS REST/API) with checksum verification.  ï¿¼
	â€¢	Transform â€” reprojection to WGS84, COG creation (rio-cogeo), GeoJSON conversion (ogr2ogr), attribute cleaning.
	â€¢	Catalog â€” STAC item/collection generation + schema validation in CI.  ï¿¼

â¸»

Spatial Catalog (STAC)

KFM uses STAC 1.x to index all geospatial assets:
	â€¢	Collections group related items (e.g., â€œHistoric Topographic Mapsâ€).
	â€¢	Items include id, bbox/geometry, properties.datetime/interval, assets (e.g., COG or GeoJSON with accurate MIME types), and derived-from/source links for traceability.  ï¿¼  ï¿¼

Benefits: machine-readable discovery, consistent temporal/CRS metadata, smooth handoff to the web UI (layers config) and Earth/KML exports.  ï¿¼

â¸»

Provenance & Reproducibility

KFM bakes MCP rigor into data ops:
	â€¢	Checksums â€” .sha256 sidecars for raw & processed artifacts detect drift and enable cacheable builds.  ï¿¼
	â€¢	Versioning â€” DVC/LFS pointers for large files; manifests are Git-tracked; all steps scripted.
	â€¢	CI/Quality â€” GitHub Actions run STAC & JSON Schema validation, unit tests, CodeQL, and Trivy scans on every PR.
	â€¢	Docs-first â€” SOPs, architecture, and experiment logs live in docs/ and are kept current (MCP).

â¸»

Open Formats & Interoperability
	â€¢	COG GeoTIFF / GeoJSON / CSV/Parquet are the canonical outputs for web + analysis.  ï¿¼
	â€¢	STAC powers indexing; metadata can be exposed as DCAT/JSON-LD where needed.  ï¿¼
	â€¢	Temporal semantics align with OWL-Time, and cultural-heritage entities (events/people/places) map into a CIDOC-CRM-aligned knowledge graph (beyond this docâ€™s scope, see Architecture + KG docs).  ï¿¼

â¸»

Tooling & Automation
	â€¢	Makefile targets: fetch, cogs, vectors, stac, checksums, site.  ï¿¼
	â€¢	Python ETL: ingest/*, pipelines/* with modular converters and validators.
	â€¢	GDAL/rio-cogeo for reprojection/COG; ogr2ogr for vector conversion; PySTAC for catalog build.

â¸»

Contributing New Data

Goal: add a dataset once, with complete provenance, and have it appear in the timeline/map automatically.

	1.	Author a source manifest in data/sources/ (id, title, endpoint.urls or service, bbox/crs, temporal coverage, license). Keep CRS/time accurate for the timeline.
	2.	Run ETL â€” make fetch â†’ make cogs/make vectors â†’ make stac. Confirm outputs land in data/processed/ and a new STAC item appears.  ï¿¼
	3.	Verify integrity â€” commit .sha256 sidecars and manifest; let CI validate STAC/schema.  ï¿¼
	4.	(If UI-facing) â€” ensure the collection or item is discoverable by the web config build (layers are generated from STAC).  ï¿¼

Tips
	â€¢	Prefer GeoTIFF â†’ COG and Shapefile â†’ GeoJSON conversions; set output EPSG:4326 unless a different CRS is essential.
	â€¢	Capture a precise time (single date or interval) for map/timeline filtering.  ï¿¼
	â€¢	Cite the original license/source in the manifest and check redistribution terms.

â¸»

Appendix â€” Example minimal source descriptor

{
  "id": "usgs_topo_larned_1894",
  "title": "USGS Topographic Map â€” Larned (1894)",
  "type": "raster",
  "endpoint": { "type": "http", "urls": ["https://example.org/usgs/larned_1894.tif"] },
  "spatial": { "bbox": [-99.4, 38.1, -99.0, 38.4], "crs": "EPSG:4326" },
  "temporal": { "start": "1894-01-01", "end": "1894-12-31" },
  "license": "Public Domain",
  "outputs": { "cog": "data/processed/overlays/usgs_topo_larned_1894.tif" }
}

Processed COG will be referenced by a STAC Item with assets.cog.href pointing to the path above; UI layers are resolved from STAC.  ï¿¼  ï¿¼

â¸»

References
Architecture & ETL/CI:  ï¿¼ Â· Data layout & STAC:  ï¿¼ Â· UI wiring:  Â· Source integration (GIS):  Â· Project docs/MCP:
