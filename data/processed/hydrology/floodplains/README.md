<div align="center">

# ğŸŒŠ Kansas Geo Timeline â€” Floodplains

This folder contains **processed floodplain datasets** for Kansas.  

It includes both **authoritative FEMA maps** and **historic floodplain reconstructions**  
derived from DEMs, hydrological models, and archival maps (e.g., 1890s Kansas River).  

All datasets are **reproducible**, **provenance-linked**, and registered in the  
**STAC catalog** (`data/stac/items/hydrology/floodplains/`).  

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-badges.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-badges.yml)
[![Pre-commit](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/pre-commit.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/.pre-commit-config.yaml)

</div>

---

```mermaid
flowchart TD
  A["Raw sources\n(FEMA NFHL/FIRM, historic scans, DEM runs)"] --> B["Process & convert\n(reproject EPSG:4326, clean)"]
  B --> C["Outputs\n(data/processed/hydrology/floodplains/**)"]
  C --> D["Checksums + meta\n(.sha256 Â· .meta.json)"]
  C --> E["STAC Items\n(data/stac/items/hydrology/floodplains/**)"]
  E --> F["Validate\n(stac-validate)"]
  F --> G["Integration\n(web configs, experiments, Knowledge Hub)"]

<!-- END OF MERMAID -->



â¸»

ğŸ“‚ Typical contents

data/processed/hydrology/floodplains/
â”œâ”€â”€ fema_floodplain_2020.json
â”œâ”€â”€ fema_floodplain_2022.json
â”œâ”€â”€ kansas_river_floodplain_1890s.json
â”œâ”€â”€ statewide_flood_zones.json
â””â”€â”€ README.md

	â€¢	FEMA layers â†’ official datasets by year/version (FIRM, NFHL).
	â€¢	Historic reconstructions â†’ polygons digitized from archival maps.
	â€¢	Modeled layers â†’ DEM-based flood depth/extent grids.

â¸»

ğŸ”„ Workflow
	1.	Acquire raw sources
	â€¢	FEMA NFHL/FIRM (shapefiles, GDBs) from FEMA Map Service Center.
	â€¢	Historical maps (USGS / Kansas archives, stored under data/raw/).
	â€¢	DEM-based hydrology models (TauDEM, WhiteboxTools, GRASS).
	2.	Process & convert
	â€¢	Reproject â†’ EPSG:4326 (WGS84).
	â€¢	Clean/dissolve polygons if needed.
	â€¢	Export â†’ GeoJSON for vectors, COG for rasters.
	3.	Checksums

scripts/gen_sha256.sh data/processed/hydrology/floodplains/*


	4.	Register in STAC
	â€¢	Create STAC Item in data/stac/items/hydrology/floodplains/.
	â€¢	Example asset entry:

"fema_floodplain_2020": {
  "href": "../../../processed/hydrology/floodplains/fema_floodplain_2020.json",
  "title": "FEMA Floodplain (2020)",
  "type": "application/geo+json",
  "roles": ["data"],
  "checksum:sha256": "<sha256sum>"
}


	5.	Validate

make stac-validate
pre-commit run --all-files



â¸»

ğŸ”— Integration
	â€¢	Web viewer â†’ floodplain layers toggle in web/config/layers.json.
	â€¢	Experiments â†’ inputs for flood risk analysis, treaty overlays, vulnerability studies.
	â€¢	Knowledge Hub â†’ linked with Kansas River hydrology, climate datasets, and historical flood events.

â¸»

ğŸ“ Notes
	â€¢	Naming convention â†’ <source>_<theme>_<year>.json
	â€¢	Example: fema_floodplain_2020.json, kansas_river_floodplain_1890s.json.
	â€¢	Provenance required â†’ document sources (FEMA, USGS, archives) in experiment.md or STAC.
	â€¢	Large rasters â†’ store as COGs, track with Git LFS / DVC.
	â€¢	âŒ Never hand-edit; always regenerate via pipeline.

â¸»

âœ… Mission-grade principle: Floodplain datasets must be traceable, reproducible, and STAC-linked, ready for use in research, visualization, and the Kansas Frontier Matrix web map.

