<div align="center">

# ğŸ’§ Kansas Geo Timeline â€” Hydrology

This folder contains **processed hydrological datasets**  
derived from DEMs, USGS/NHD, FEMA flood maps, and Kansas GIS Hub sources.  

Outputs are stored in **open formats** (GeoJSON, CSV, Cloud-Optimized GeoTIFFs) and are  
**reproducible** from raw inputs in `data/raw/`.  

All datasets must be registered in the **STAC catalog** (`data/stac/items/hydrology/`)  
with metadata, checksums, and provenance.  

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-badges.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-badges.yml)
[![Pre-commit](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/pre-commit.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/.pre-commit-config.yaml)

</div>

---

```mermaid
flowchart TD
  A["Raw hydrology sources\n(data/raw/hydrology/**)"] --> B["Process\n(clean Â· reproject Â· simplify)"]
  B --> C["Processed outputs\n(data/processed/hydrology/**)"]
  C --> D["Checksums + meta\n(.sha256 Â· .meta.json)"]
  C --> E["STAC Items\n(data/stac/items/hydrology/**)"]
  E --> F["Validate\n(stac-validate)"]
  F --> G["Viewer integration\n(web/config/layers.json)"]

<!-- END OF MERMAID -->



â¸»

ğŸ“‚ Structure

data/processed/hydrology/
â”œâ”€â”€ kansas_river/        # Kansas River centerlines, watershed, floodplains, gauges
â”œâ”€â”€ watersheds/          # HUC-based watershed polygons (HUC8, HUC12)
â”œâ”€â”€ floodplains/         # FEMA + historic floodplain extents
â”œâ”€â”€ stream_networks.json # generalized statewide stream network
â”œâ”€â”€ lakes_wetlands.json  # major lakes & wetlands polygons
â””â”€â”€ README.md

	â€¢	kansas_river/ â†’ Kansas Riverâ€“specific hydrology datasets.
	â€¢	watersheds/ â†’ statewide or regional HUC-based polygons.
	â€¢	floodplains/ â†’ FEMA and reconstructed floodplain layers.
	â€¢	Other files â†’ generalized or statewide hydrology vectors.

â¸»

ğŸ§­ File conventions
	â€¢	Vectors â†’ GeoJSON (*.json, *.geojson)
	â€¢	Rasters â†’ Cloud-Optimized GeoTIFFs (*.tif) for flood models, depth grids
	â€¢	Tables â†’ CSV for gauges, time series, metadata
	â€¢	Projection â†’ EPSG:4326 (WGS84 lat/long) required for all outputs

â¸»

ğŸ”„ Workflow
	1.	Acquire raw sources â†’ data/raw/
	â€¢	Sources: USGS NHD, NOAA NWIS, FEMA, Kansas GIS Hub.
	2.	Process
	â€¢	Clean, reproject to EPSG:4326
	â€¢	Simplify/dissolve geometries as needed
	â€¢	Export to GeoJSON/COG/CSV
	3.	Checksums

scripts/gen_sha256.sh data/processed/hydrology/*


	4.	Register in STAC
	â€¢	Add/update Item JSON under data/stac/items/hydrology/
	â€¢	Link assets with roles: ["data"] + checksum:sha256
	5.	Validate

pre-commit run stac-validate --all-files



â¸»

ğŸ”— Integration
	â€¢	Web Viewer â†’ layers referenced in web/config/layers.json for MapLibre visualization.
	â€¢	Experiments â†’ used in floodplain reconstruction, treaty overlays, archaeological + erosion studies.
	â€¢	Knowledge Hub â†’ cross-links hydrology with treaties, settlements, geology, environment.

â¸»

ğŸ“ Notes
	â€¢	âŒ Do not manually edit processed outputs.
	â€¢	âœ… Always regenerate from raw + documented scripts or notebooks.
	â€¢	Use stable filenames (<theme>_<year>.json) so STAC + web configs remain valid.
	â€¢	Track large files with Git LFS / DVC.
	â€¢	Document provenance and methods in experiments/<ID>_.../experiment.md.

â¸»

âœ… Mission-grade principle: Hydrology datasets must be consistent, reproducible, STAC-linked, and ready for cross-domain analysis in the Kansas Frontier Matrix.

