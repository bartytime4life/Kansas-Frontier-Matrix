<div align="center">

# âš ï¸ Kansas Frontier Matrix â€” Hazards Checksums

`data/processed/checksums/hazards/`

**Mission:** Maintain and verify the **integrity, provenance, and reproducibility** of all processed **natural hazard datasets** â€”
including tornadoes, floods, wildfires, and drought layers â€” ensuring confidence in the Kansas Frontier Matrix (KFM)
geospatial and temporal record of extreme events.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../../.github/workflows/site.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../../.github/workflows/stac-validate.yml)
[![Trivy Security](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../../.github/workflows/trivy.yml)
[![Docs Â· MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../../LICENSE)
[![License: Code](https://img.shields.io/badge/License-MIT-yellow)](../../../../LICENSE)

</div>

---

## ğŸ§© Versioning

| Field            | Value                                                  |
| :--------------- | :----------------------------------------------------- |
| **Version**      | `v1.0.2`                                               |
| **Status**       | Stable                                                 |
| **Maintainer**   | KFM Hazards & Environmental Data Team                  |
| **Last Updated** | 2025-10-12                                             |
| **Scope**        | Processed hazard datasets (`.geojson`, `.tif`, `.csv`) |
| **Compliance**   | MCP v1.0 Â· STAC 1.0.0 Â· SHA-256 Validated              |

---

## ğŸ“š Overview

This directory stores **SHA-256 checksum manifests (`.sha256`)** that function as **cryptographic fingerprints**
for every processed hazard dataset in KFM.
These ensure end-to-end verification of **data integrity**, **reproducibility**, and **scientific transparency**.

---

## ğŸ—‚ï¸ Directory Layout

```bash
data/processed/checksums/hazards/
â”œâ”€â”€ README.md
â”œâ”€â”€ tornado_tracks_1950_2024.geojson.sha256
â”œâ”€â”€ flood_events_1900_2025.geojson.sha256
â”œâ”€â”€ wildfire_perimeters_2000_2024.geojson.sha256
â””â”€â”€ drought_index_2000_2025.tif.sha256
```

Each `.sha256` file maps 1 : 1 to its dataset in `data/processed/hazards/`.
CI workflows (`stac-validate.yml`) recompute and verify these at every build and deployment.

---

## ğŸ¯ Purpose

| Objective                     | Description                                                  |
| :---------------------------- | :----------------------------------------------------------- |
| ğŸ§© **Integrity Verification** | Detects file corruption or unauthorized edits.               |
| ğŸ” **Reproducibility**        | Confirms deterministic ETL outputs.                          |
| ğŸ”— **Provenance**             | Links digests across metadata, STAC, and source descriptors. |
| âš™ï¸ **CI Enforcement**         | CI pipelines block merges when mismatches occur.             |

---

## ğŸ§® Example `.sha256` Manifest

```bash
# File: tornado_tracks_1950_2024.geojson.sha256
8fb29cda3d0e44182f26c7bceff74b2c81b83e742d47d836b33151f871bb69d1  tornado_tracks_1950_2024.geojson
```

This digest certifies
`data/processed/hazards/tornado_tracks_1950_2024.geojson`
as **byte-for-byte identical** to its validated release artifact.

---

## âš™ï¸ Checksum Generation Workflow

Checksums are generated automatically during hazard ETL post-processing.

### Makefile Target

```bash
make hazards-checksums
```

### Python Utility

```bash
python src/utils/generate_checksums.py data/processed/hazards/ --algo sha256
```

**Workflow Steps**

1. Scan all processed hazard files (`.geojson`, `.tif`, `.csv`, â€¦).
2. Compute SHA-256 using `hashlib` or `sha256sum --binary`.
3. Write `<filename>.sha256` into this directory.
4. Validate automatically in CI/CD pipelines.

ğŸ’¡ Use `--binary` mode for cross-platform consistency and line-ending independence.

---

## ğŸ” CI/CD Validation

During builds, GitHub Actions re-verify all hazard checksums:

```bash
sha256sum -c data/processed/checksums/hazards/*.sha256
```

Any mismatch **fails the workflow**, blocking deployment until data are re-hashed.
Logs are archived to maintain an **MCP-compliant audit trail**.

---

## ğŸ§© Integration with Metadata & STAC

| Linked Component                            | Purpose                                                  |
| :------------------------------------------ | :------------------------------------------------------- |
| `data/processed/metadata/hazards/`          | Metadata + STAC Items reference SHA-256 for validation.  |
| `src/pipelines/hazards/hazards_pipeline.py` | Handles hash generation / verification in ETL.           |
| `.github/workflows/stac-validate.yml`       | CI workflow re-hashes and validates datasets.            |
| `data/stac/hazards/`                        | STAC catalog embeds digests in `assets.checksum:sha256`. |

---

## ğŸ§­ Mermaid Data Flow

```mermaid
flowchart TD
  A["Hazard Sources<br/>NOAA Â· FEMA Â· MODIS Â· USGS"] --> B["ETL Process<br/>extract Â· normalize Â· analyze"]
  B --> C["Processed Hazard Data<br/>GeoJSON Â· TIFF Â· CSV"]
  C --> D["Checksum Generation<br/>sha256sum per file"]
  D --> E["Verification<br/>CI/CD Â· manual audit"]
  E --> F["Catalog & Provenance<br/>STAC Â· MCP metadata"]
  F --> G["Publication<br/>Data Hub Â· GitHub Pages Â· Research APIs"]
%% END OF MERMAID %%
```

---

## ğŸ§  MCP Compliance Summary

| MCP Principle       | Implementation                                            |
| :------------------ | :-------------------------------------------------------- |
| Documentation-first | Each dataset includes `.sha256` + metadata.               |
| Reproducibility     | Deterministic ETL validated through hashes.               |
| Open Standards      | SHA-256 (FIPS 180-4) + STAC 1.0 + JSON Schema compliance. |
| Provenance          | Hashes trace lineage (source â†’ ETL â†’ STAC).               |
| Auditability        | CI/CD pipelines maintain transparent logs.                |

---

## ğŸ§® Maintenance & Best Practices

* ğŸ”„ **After updates:** Regenerate checksums after any reprocessing.
* ğŸ§© **Manifest control:** Maintain `_manifest_all.sha256` for batch verification.
* âš™ï¸ **Consistency:** Dataset + checksum filenames must match exactly.
* ğŸ“œ **Transparency:** Document checksum changes in PRs + STAC changelogs.
* ğŸ§° **Pre-commit hooks:** Prevent commits with missing or outdated `.sha256` files.

---

## ğŸ“… Version History

| Version   | Date       | Summary                                            |
| :-------- | :--------- | :------------------------------------------------- |
| **1.0.2** | 2025-10-12 | Added Mermaid visualization + versioning metadata. |
| **1.0.1** | 2025-10-10 | Expanded CI workflow + MCP compliance sections.    |
| **1.0.0** | 2025-10-04 | Initial hazards checksum documentation.            |

---

## ğŸ“– References

* ğŸ”— [GNU Coreutils â€” SHA Utilities](https://www.gnu.org/software/coreutils/manual/html_node/sha2-utilities.html)
* ğŸŒ [STAC 1.0 Specification](https://stacspec.org)
* ğŸ§© [JSON Schema](https://json-schema.org)
* ğŸ“˜ [MCP Standards (KFM)](../../../../docs/standards/)
* ğŸ§­ [Provenance in Open Science](https://www.nature.com/articles/s41597-019-0193-2)

---

<div align="center">

> **Kansas Frontier Matrix â€” â€œEvery Storm Verified: Data Integrity for a Changing Kansas.â€**
> ğŸ“ `data/processed/checksums/hazards/` Â· Linked to the Hazards STAC Collection

</div>
