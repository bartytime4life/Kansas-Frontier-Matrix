<div align="center">

# ğŸŒ¦ï¸ Kansas Frontier Matrix â€” Climate Checksums  
`data/processed/checksums/climate/`

**Mission:** Guarantee the **integrity, reproducibility, and provenance**  
of all processed climate datasets within Kansas Frontier Matrix â€” ensuring that temperature, precipitation,  
and drought data remain verifiable across the projectâ€™s full historical and spatial range.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../../.github/workflows/site.yml)
[![Trivy Security](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../../.github/workflows/trivy.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../../.github/workflows/stac-validate.yml)
[![Docs Â· MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../../LICENSE)

</div>

---

## ğŸ“š Overview

This folder contains **SHA-256 checksum files (`.sha256`)** for all processed **climate datasets**  
in the Kansas Frontier Matrix (KFM).  

Checksums establish a **verifiable link** between raw inputs, processed outputs, and published STAC metadata â€”  
ensuring data integrity and reproducibility throughout the system.

These checksum files are automatically generated by the **climate ETL pipeline** (`make climate`)  
and validated during CI/CD operations to detect any drift or corruption.

---

## ğŸ—‚ï¸ Directory Layout

```bash
data/processed/checksums/climate/
â”œâ”€â”€ README.md
â”œâ”€â”€ daymet_1980_2024.tif.sha256
â”œâ”€â”€ noaa_normals_1991_2020.geojson.sha256
â””â”€â”€ drought_monitor_2000_2025.tif.sha256
````

> **Note:** Each `.sha256` file contains the verified SHA-256 hash
> for its associated data product in `data/processed/climate/`.
> CI workflows (`stac-validate.yml`) automatically re-compute and compare hashes on build.

---

## ğŸ” Purpose of Checksums

| Objective               | Description                                                                   |
| :---------------------- | :---------------------------------------------------------------------------- |
| **Integrity Assurance** | Detects changes or corruption in raster and vector climate datasets.          |
| **Reproducibility**     | Confirms that pipeline outputs are identical when rerun with the same inputs. |
| **Provenance Chain**    | Links climate data artifacts to their metadata and STAC entries.              |
| **CI Enforcement**      | Validated through automated GitHub Actions workflows.                         |

---

## ğŸ§® Example `.sha256` File

```bash
# File: daymet_1980_2024.tif.sha256
a7f9132dfe5b16c9783f3f0ec4a2f4da8a9bb5e7b739c3477325dcb0df836f41  daymet_1980_2024.tif
```

This checksum verifies the integrity of
`data/processed/climate/daymet_1980_2024.tif`.

---

## âš™ï¸ Checksum Generation Workflow

Checksums are created during or after the ETL process for climate data.

**Makefile target:**

```bash
make climate-checksums
```

**Equivalent Python command:**

```bash
python src/utils/generate_checksums.py data/processed/climate/ --algo sha256
```

**Steps:**

1. Scan all climate outputs (`.tif`, `.geojson`, `.csv`, etc.)
2. Compute SHA-256 hash using the Python `hashlib` module.
3. Write results as `<filename>.sha256` into this folder.
4. Validate these hashes in CI/CD builds.

---

## ğŸ§° CI/CD Validation

Checksum verification is automatically executed in GitHub Actions workflows.

**Example command:**

```bash
sha256sum -c data/processed/checksums/climate/*.sha256
```

If a mismatch occurs, the workflow fails â€” halting deployment
until the data is regenerated and the checksums are updated.

---

## ğŸ§© Integration with Metadata & STAC

| Linked Component                            | Purpose                                              |
| :------------------------------------------ | :--------------------------------------------------- |
| `data/processed/metadata/climate/`          | Metadata entries reference these checksum files      |
| `src/pipelines/climate/climate_pipeline.py` | Handles checksum generation and verification         |
| `.github/workflows/stac-validate.yml`       | Automates STAC + integrity checks in CI/CD           |
| `data/stac/climate/`                        | STAC catalog includes hash-based provenance metadata |

---

## ğŸ§  MCP Compliance Summary

| MCP Principle           | Implementation                                                            |
| :---------------------- | :------------------------------------------------------------------------ |
| **Documentation-first** | Each processed dataset has a dedicated `.sha256` file and metadata record |
| **Reproducibility**     | Checksum validation confirms deterministic ETL outputs                    |
| **Open Standards**      | Uses SHA-256 (FIPS 180-4 compliant cryptographic hash)                    |
| **Provenance**          | Links checksums with STAC and source metadata                             |
| **Auditability**        | Verified through CI/CD validation and MCP-compliant logs                  |

---

## ğŸ“… Version History

| Version | Date       | Summary                                                          |
| :------ | :--------- | :--------------------------------------------------------------- |
| v1.0    | 2025-10-04 | Initial release of climate checksum documentation and hash files |

---

<div align="center">

**Kansas Frontier Matrix** â€” *â€œClimate Integrity: Verifying Every Degree and Drop.â€*
ğŸ“ [`data/processed/checksums/climate/`](.) Â· Linked to the **Climate STAC Collection**

</div>
