<div align="center">

# 💧 Kansas Frontier Matrix — Hydrology Checksums  
`data/processed/checksums/hydrology/`

**Mission:** Verify and preserve the **integrity and reproducibility** of all processed hydrology datasets  
via **SHA-256 checksums**, ensuring consistent lineage and provenance across the Kansas Frontier Matrix.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../../.github/workflows/site.yml)
[![Trivy Security](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../../.github/workflows/trivy.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../../.github/workflows/stac-validate.yml)
[![Docs · MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../../LICENSE)

</div>

---

## 📚 Overview

This folder contains **SHA-256 checksum files (`.sha256`)** for all processed **hydrology datasets**  
in the Kansas Frontier Matrix (KFM). Checksums provide a **verifiable audit chain** from inputs → ETL outputs → catalog publication,  
ensuring **data integrity**, **reproducibility**, and **traceable provenance**.

All hashes are generated by the **hydrology ETL pipeline** (`make hydrology`) and validated in CI/CD.

---

## 🗂️ Directory Layout

```bash
data/processed/checksums/hydrology/
├── README.md
├── nhd_flowlines_ks.geojson.sha256
├── watersheds_huc12_ks.geojson.sha256
├── fema_nfhl_ks.geojson.sha256
├── groundwater_levels_ks.geojson.sha256
└── flood_events_ks.geojson.sha256

Each checksum corresponds 1:1 to its data product in data/processed/hydrology/ and is re-verified in CI via sha256sum -c.

⸻

🎯 Purpose

Objective	Description
Data Integrity	Detects accidental corruption or unauthorized edits to GeoJSON/COG outputs.
Reproducibility	Confirms pipeline outputs are deterministic given identical inputs/config.
Provenance Tracking	Connects hashes to STAC Items and source descriptors for end-to-end lineage.
CI Enforcement	GitHub Actions halt merges/deploys when checksum mismatches are detected.


⸻

🧮 Example .sha256 File

# File: watersheds_huc12_ks.geojson.sha256
d2a9e4b1f97c3aa923f9025b2cf2058c477f01e8c024a07f68b992b04d789e5f  watersheds_huc12_ks.geojson

This digest authenticates data/processed/hydrology/watersheds_huc12_ks.geojson.

⸻

⚙️ Checksum Generation

Checksums are produced automatically at the end of each hydrology ETL run.

Makefile target

make hydrology-checksums

Equivalent Python utility

python src/utils/generate_checksums.py data/processed/hydrology/ --algo sha256

Steps
	1.	Locate processed hydrology datasets (.geojson, .tif, .csv, …)
	2.	Compute SHA-256 in binary mode (for cross-platform consistency)
	3.	Write <filename>.sha256 into this directory
	4.	Validate in CI/CD and fail on mismatch

💡 Prefer sha256sum --binary (GNU Coreutils) or the Python tool above to avoid platform-specific line-ending issues.

⸻

🔎 Validation in CI/CD

GitHub Actions re-verify all hydrology checksums during validation:

sha256sum -c data/processed/checksums/hydrology/*.sha256

On mismatch, the workflow fails — blocking merges and deployments until the affected dataset is reprocessed and re-hashed.

⸻

🧩 Integration with Metadata & STAC

Linked Component	Purpose
data/processed/metadata/hydrology/	Metadata/STAC Items include each artifact’s SHA-256 digest.
src/pipelines/hydrology/hydrology_pipeline.py	Orchestrates digest generation & verification during ETL.
.github/workflows/stac-validate.yml	CI job validating hashes and STAC compliance on every PR/push.
data/stac/hydrology/	STAC catalog references SHA-256 in assets or properties for provenance.


⸻

🧠 MCP Compliance Summary

MCP Principle	Implementation
Documentation-first	Every hydrology product has a .sha256 and a metadata record.
Reproducibility	Deterministic ETL outputs are verified via SHA-256 digests.
Open Standards	Uses SHA-256 (FIPS 180-4), STAC 1.0, JSON Schema-aligned metadata.
Provenance	Hashes link source → processed → catalog (STAC) for full lineage.
Auditability	CI/CD workflows log verification results for transparent review.


⸻

🧮 Maintenance & Best Practices
	•	🔄 After updates: Recompute checksums after intentional data changes; bump dataset version in metadata.
	•	🧩 File pairing: Keep checksum filenames exactly aligned with their data filenames.
	•	📝 Manifests: Use a rolling _manifest_all.sha256 for batch audits during releases.
	•	🧪 Pre-commit hook (optional): Add a local hook to reject staged changes if checksum pairs are missing or stale.

⸻

📅 Version History

Version	Date	Summary
1.0.1	2025-10-10	Upgraded README (CI enforcement, maintenance tips, MCP/metadata linkage).
1.0.0	2025-10-04	Initial hydrology checksum documentation and SHA-256 files.


⸻

📖 References
	•	GNU Coreutils — SHA utilities: https://www.gnu.org/software/coreutils/manual/html_node/sha2-utilities.html
	•	STAC 1.0 Specification: https://stacspec.org
	•	JSON Schema: https://json-schema.org
	•	MCP Standards: ../../../../docs/standards/
	•	Open Data Provenance: https://www.nature.com/articles/s41597-019-0193-2

⸻


<div align="center">


Kansas Frontier Matrix — “Flowing Data, Verified Integrity.”
📍 data/processed/checksums/hydrology/

</div>
```