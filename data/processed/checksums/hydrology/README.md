<div align="center">

# ğŸ’§ Kansas Frontier Matrix â€” Hydrology Checksums  
`data/processed/checksums/hydrology/`

**Mission:** Verify and preserve the **integrity and reproducibility** of all processed hydrology datasets  
via **SHA-256 checksums**, ensuring consistent lineage and provenance across the Kansas Frontier Matrix.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../../.github/workflows/site.yml)
[![Trivy Security](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../../.github/workflows/trivy.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../../.github/workflows/stac-validate.yml)
[![Docs Â· MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../../LICENSE)

</div>

---

## ğŸ“š Overview

This folder contains **SHA-256 checksum files (`.sha256`)** for all processed **hydrology datasets**  
in the Kansas Frontier Matrix (KFM). Checksums provide a **verifiable audit chain** from inputs â†’ ETL outputs â†’ catalog publication,  
ensuring **data integrity**, **reproducibility**, and **traceable provenance**.

All hashes are generated by the **hydrology ETL pipeline** (`make hydrology`) and validated in CI/CD.

---

## ğŸ—‚ï¸ Directory Layout

```bash
data/processed/checksums/hydrology/
â”œâ”€â”€ README.md
â”œâ”€â”€ nhd_flowlines_ks.geojson.sha256
â”œâ”€â”€ watersheds_huc12_ks.geojson.sha256
â”œâ”€â”€ fema_nfhl_ks.geojson.sha256
â”œâ”€â”€ groundwater_levels_ks.geojson.sha256
â””â”€â”€ flood_events_ks.geojson.sha256

Each checksum corresponds 1:1 to its data product in data/processed/hydrology/ and is re-verified in CI via sha256sum -c.

â¸»

ğŸ¯ Purpose

Objective	Description
Data Integrity	Detects accidental corruption or unauthorized edits to GeoJSON/COG outputs.
Reproducibility	Confirms pipeline outputs are deterministic given identical inputs/config.
Provenance Tracking	Connects hashes to STAC Items and source descriptors for end-to-end lineage.
CI Enforcement	GitHub Actions halt merges/deploys when checksum mismatches are detected.


â¸»

ğŸ§® Example .sha256 File

# File: watersheds_huc12_ks.geojson.sha256
d2a9e4b1f97c3aa923f9025b2cf2058c477f01e8c024a07f68b992b04d789e5f  watersheds_huc12_ks.geojson

This digest authenticates data/processed/hydrology/watersheds_huc12_ks.geojson.

â¸»

âš™ï¸ Checksum Generation

Checksums are produced automatically at the end of each hydrology ETL run.

Makefile target

make hydrology-checksums

Equivalent Python utility

python src/utils/generate_checksums.py data/processed/hydrology/ --algo sha256

Steps
	1.	Locate processed hydrology datasets (.geojson, .tif, .csv, â€¦)
	2.	Compute SHA-256 in binary mode (for cross-platform consistency)
	3.	Write <filename>.sha256 into this directory
	4.	Validate in CI/CD and fail on mismatch

ğŸ’¡ Prefer sha256sum --binary (GNU Coreutils) or the Python tool above to avoid platform-specific line-ending issues.

â¸»

ğŸ” Validation in CI/CD

GitHub Actions re-verify all hydrology checksums during validation:

sha256sum -c data/processed/checksums/hydrology/*.sha256

On mismatch, the workflow fails â€” blocking merges and deployments until the affected dataset is reprocessed and re-hashed.

â¸»

ğŸ§© Integration with Metadata & STAC

Linked Component	Purpose
data/processed/metadata/hydrology/	Metadata/STAC Items include each artifactâ€™s SHA-256 digest.
src/pipelines/hydrology/hydrology_pipeline.py	Orchestrates digest generation & verification during ETL.
.github/workflows/stac-validate.yml	CI job validating hashes and STAC compliance on every PR/push.
data/stac/hydrology/	STAC catalog references SHA-256 in assets or properties for provenance.


â¸»

ğŸ§  MCP Compliance Summary

MCP Principle	Implementation
Documentation-first	Every hydrology product has a .sha256 and a metadata record.
Reproducibility	Deterministic ETL outputs are verified via SHA-256 digests.
Open Standards	Uses SHA-256 (FIPS 180-4), STAC 1.0, JSON Schema-aligned metadata.
Provenance	Hashes link source â†’ processed â†’ catalog (STAC) for full lineage.
Auditability	CI/CD workflows log verification results for transparent review.


â¸»

ğŸ§® Maintenance & Best Practices
	â€¢	ğŸ”„ After updates: Recompute checksums after intentional data changes; bump dataset version in metadata.
	â€¢	ğŸ§© File pairing: Keep checksum filenames exactly aligned with their data filenames.
	â€¢	ğŸ“ Manifests: Use a rolling _manifest_all.sha256 for batch audits during releases.
	â€¢	ğŸ§ª Pre-commit hook (optional): Add a local hook to reject staged changes if checksum pairs are missing or stale.

â¸»

ğŸ“… Version History

Version	Date	Summary
1.0.1	2025-10-10	Upgraded README (CI enforcement, maintenance tips, MCP/metadata linkage).
1.0.0	2025-10-04	Initial hydrology checksum documentation and SHA-256 files.


â¸»

ğŸ“– References
	â€¢	GNU Coreutils â€” SHA utilities: https://www.gnu.org/software/coreutils/manual/html_node/sha2-utilities.html
	â€¢	STAC 1.0 Specification: https://stacspec.org
	â€¢	JSON Schema: https://json-schema.org
	â€¢	MCP Standards: ../../../../docs/standards/
	â€¢	Open Data Provenance: https://www.nature.com/articles/s41597-019-0193-2

â¸»


<div align="center">


Kansas Frontier Matrix â€” â€œFlowing Data, Verified Integrity.â€
ğŸ“ data/processed/checksums/hydrology/

</div>
```