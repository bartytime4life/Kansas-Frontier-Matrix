# ğŸ“¦ `data/processed/` â€” Curated, Ready-to-Serve Datasets

![status](https://img.shields.io/badge/status-active-brightgreen)
![data](https://img.shields.io/badge/data-processed-blue)
![repro](https://img.shields.io/badge/reproducibility-pipeline%E2%86%92artifact-orange)
![metadata](https://img.shields.io/badge/metadata-STAC%20%2B%20PROV-required-purple)

> **Purpose:** This folder holds **pipeline outputs** â€” cleaned, standardized datasets that are **ready for the Kansas Frontier Matrix (KFM) API/UI** (or downstream loaders like PostGIS). [oai_citation:0â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

---

## ğŸ” Quick Links

- ğŸ“¥ Raw inputs: [`../raw/`](../raw/)
- ğŸ—‚ï¸ Dataset metadata (catalog): [`../catalog/`](../catalog/)
- ğŸ§¾ Lineage & provenance logs: [`../provenance/`](../provenance/)

---

## âœ… What belongs here?

**Everything in `data/processed/` should be â€œready-to-use.â€** That means:

- cleaned columns / normalized units âœ…
- correct spatial reference / CRS âœ…
- consistent date/time formats âœ…
- stable identifiers (where applicable) âœ…
- stored in a format appropriate to the dataset (GeoJSON/Parquet/GeoTIFF/etc.) âœ… [oai_citation:1â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

Typical examples include:
- `data/processed/census/1900_population.geojson` (vector)
- `data/processed/weather/daily_rainfall.parquet` (tabular time series) [oai_citation:2â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

---

## ğŸš« What does *not* belong here?

### âŒ Manually edited artifacts
Processed data should be **generated by scripts/pipelines**, not hand-modified.

### âŒ Source-of-truth evidence
That belongs in `data/raw/`. Raw files are treated as **preserved evidence** and generally **not edited by pipelines** (read-only in spirit). [oai_citation:3â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

### âŒ Mystery datasets
If we canâ€™t explain **where it came from**, **how it was produced**, and **how it should be used**, it doesnâ€™t ship.

---

## ğŸ§­ Directory Structure (Recommended)

Organize by **theme** or **source family** (mirroring or complementing `data/raw/`). [oai_citation:4â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

Example layout:

```text
data/processed/
â”œâ”€ ğŸ§‘â€ğŸŒ¾ census/
â”‚  â”œâ”€ 1900_population.geojson
â”‚  â”œâ”€ 1910_population.geojson
â”‚  â””â”€ schema.json
â”œâ”€ ğŸŒ¦ï¸ weather/
â”‚  â”œâ”€ daily_rainfall.parquet
â”‚  â””â”€ stations.geojson
â”œâ”€ ğŸ›°ï¸ imagery/
â”‚  â”œâ”€ landsat_2010_kansas.tif
â”‚  â””â”€ landsat_2010_kansas.stac-item.json
â””â”€ ğŸ—ºï¸ boundaries/
   â”œâ”€ counties_1900.geojson
   â””â”€ README.md
```

---

## ğŸ“Œ â€œDataset Contractâ€ (What each dataset should ship with)

For each dataset you add here, include:

### 1) The processed artifact(s)
- `.geojson`, `.parquet`, `.csv`, `.tif` (GeoTIFF/COG), etc. [oai_citation:5â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

### 2) Metadata in `data/catalog/` (Required)
The pipeline must create/update a catalog record (commonly **STAC Item/Collection**, and optionally **DCAT**). [oai_citation:6â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d) [oai_citation:7â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

### 3) Provenance in `data/provenance/` (Required)
Include lineage such as: raw inputs used, script version/commit, run date, and outputs produced (often W3C PROV-style JSON). [oai_citation:8â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

> ğŸ’¡ Expectation: **CI may reject contributions** if processed outputs do not have matching catalog + provenance documentation. [oai_citation:9â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d) [oai_citation:10â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

---

## ğŸ” Data Flow (How `processed` fits into the system)

```mermaid
flowchart LR
  A[ğŸ“¥ data/raw<br/>source artifacts] -->|ETL / import scripts| B[ğŸ§ª pipelines<br/>clean + standardize]
  B --> C[ğŸ“¦ data/processed<br/>ready-to-serve datasets]
  B --> D[ğŸ—‚ï¸ data/catalog<br/>STAC/DCAT metadata]
  B --> E[ğŸ§¾ data/provenance<br/>PROV lineage]
  C --> F[ğŸ›¢ï¸ PostGIS loader<br/>or direct API read]
  F --> G[ğŸ§­ KFM API/UI]
```

- After PR merge, processed datasets become part of KFM and are either loaded into PostGIS or read directly by the API depending on deployment configuration. [oai_citation:11â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

---

## ğŸ§° Adding or Updating a Dataset

### ğŸªœ Standard workflow
1. **Drop new source** into `data/raw/` (keep it intact; do not â€œcleanâ€ raw by hand). [oai_citation:12â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
2. **Run the processing pipeline**:
   - parse/normalize dates
   - convert / standardize CRS
   - normalize units
   - join/merge (if needed)
   - validate expected columns/ranges [oai_citation:13â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d) [oai_citation:14â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
3. **Write outputs here**: `data/processed/...` [oai_citation:15â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
4. **Update required documentation**:
   - `data/catalog/...` (STAC/DCAT)
   - `data/provenance/...` (PROV lineage) [oai_citation:16â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d) [oai_citation:17â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
5. **Commit + PR**
   - CI checks may validate artifacts + verify catalog/provenance presence. [oai_citation:18â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

### â™»ï¸ Updates (new years, corrections, reprocessing)
Processed datasets are version-controlled so diffs can be reviewed; updates follow the same pipeline-and-documentation flow. [oai_citation:19â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

---

## ğŸ§ª Quality & Validation Guidelines

Recommended checks (lightweight but high-value):

- âœ… Schema sanity: required fields exist, correct types
- âœ… Spatial sanity: coordinates plausible; geometry valid
- âœ… Temporal sanity: time ranges match dataset claim
- âœ… Unit sanity: documented units; normalized where possible
- âœ… Summary stats: record counts, min/max, null rate (in logs or a small report) [oai_citation:20â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)

---

## ğŸ“ Pipeline Documentation Expectations

Any process that transforms data should be documented clearly:

- document each pipeline stage
- list inputs/outputs per stage
- describe implementation details (scripts/configs) [oai_citation:21â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)

> ğŸ” Tip: Keep pipelines deterministic and rerunnable. If a dataset canâ€™t be reproduced, itâ€™s not â€œprocessedâ€ â€” itâ€™s a surprise.

---

## ğŸ§· Naming Conventions (Strongly Recommended)

| Item | Convention | Example |
|------|------------|---------|
| Folder names | `lower_snake_case/` | `census/`, `historical_maps/` |
| File names | `lower_snake_case` + meaningful suffixes | `1900_population.geojson` |
| Dates | ISO-ish when relevant | `1880-01-01`, `1900` |
| CRS | Documented in catalog metadata | `EPSG:4326` (or project standard) |

---

## âœ… â€œBefore you PRâ€ Checklist

- [ ] Processed artifact written to `data/processed/...` [oai_citation:22â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
- [ ] Matching STAC/DCAT entry added/updated in `data/catalog/...` [oai_citation:23â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
- [ ] Matching PROV lineage added/updated in `data/provenance/...` [oai_citation:24â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
- [ ] Basic validation performed (schema, geometry, ranges) [oai_citation:25â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
- [ ] PR explains source, method, and intended use

---

## ğŸ“š Sources

- KFM data lifecycle + processed/raw definitions, required catalog/provenance, and CI expectations. [oai_citation:26â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d) [oai_citation:27â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d) [oai_citation:28â€¡Kansas Frontier Matrix (KFM) â€“ Comprehensive Technical Blueprint.pdf](sediment://file_000000006dbc71f89a5094ce310a452d)
- Internal protocol guidance for documenting ETL/pipelines (stages, inputs/outputs, implementation notes). [oai_citation:29â€¡Scientific Method _ Research _ Master Coder Protocol Documentation.pdf](file-service://file-HTpax4QbDgguDwxwwyiS32)