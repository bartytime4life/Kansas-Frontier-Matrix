# ğŸ§ª `data/processed/` â€” Processed Data Zone

![Layer](https://img.shields.io/badge/data%20layer-processed-2b6cb0)
![Invariant](https://img.shields.io/badge/invariant-provenance%20required-16a34a)
![Invariant](https://img.shields.io/badge/invariant-deterministic%20outputs-16a34a)
![Policy](https://img.shields.io/badge/policy-no%20manual%20edits%20in%20place-f97316)
![Downstream](https://img.shields.io/badge/feeds-catalog%20%E2%86%92%20db%20%E2%86%92%20api%20%E2%86%92%20ui%2Fai-7c3aed)

Welcome to the **Processed** zone ğŸ­ â€” the â€œclean, standardized, validatedâ€ middle layer of the Kansas Frontier Matrix data pipeline.

**Goal:** turn messy, disparate *raw* inputs into **trusted, analysis-ready artifacts** that are:
- âœ… **reproducible** (same inputs + same pipeline = same outputs)
- âœ… **versioned** (no silent overwrites)
- âœ… **traceable** (â€œthe map behind the mapâ€ â€” every output points back to sources)
- âœ… **ready for cataloging** (STAC/DCAT metadata + provenance attachments)
- âœ… **safe to serve** (after governance checks)

---

## ğŸ§­ The Truth Path (Nonâ€‘Negotiable)

Processed data exists because we enforce a single governed path:

```mermaid
flowchart LR
  A[ğŸ“¥ data/raw<br/>immutable source drops] --> B[ğŸ­ data/processed<br/>clean + normalized + validated]
  B --> C[ğŸ—‚ï¸ data/catalog<br/>STAC/DCAT + indexing records]
  C --> D[ğŸ—ƒï¸ runtime stores<br/>PostGIS / graph / search / object]
  D --> E[ğŸŒ API layer<br/>policy enforced]
  E --> F[ğŸ—ºï¸ UI & ğŸ¤– AI<br/>evidence-first outputs]
```

**No shortcuts.** Nothing jumps from `raw/` straight into databases, tiles, UI, or AI.

---

## âœ… What Belongs Here (and what doesnâ€™t)

### âœ… Belongs in `data/processed/`
- Cleaned and standardized **tables** (typed, normalized, unit-consistent)
- Spatially validated **vector layers** (valid geometry, known CRS, stable IDs)
- Web-ready **raster assets** (COG, pyramids, tile packages) produced from raw rasters
- Derived **analysis layers** (indices, classifications, change detection outputs) with full provenance
- Companion metadata + manifests that make the dataset **auditable**

### âŒ Does *not* belong in `data/processed/`
- Ad-hoc scratch files (use `data/_tmp/` or local workspace)
- Hand-edited â€œfinalâ€ datasets (all changes must be in pipeline code/config)
- Secrets, tokens, credentials ğŸ”’
- Unversioned overwrites (â€œlatest.csvâ€) that destroy history

---

## ğŸ“ Recommended Folder Layout

> This layout is a **contract**: predictable structure = faster pipelines + easier governance + safer serving.

```text
data/processed/
  ğŸ“¦ <dataset_slug>/
    ğŸ·ï¸ <version>/                       # ex: v1.0.0 or 2026-02-03
      ğŸ“„ README.md                      # dataset-specific notes (optional but recommended)
      ğŸ“„ manifest.json                  # required: what files are here + counts + hashes
      ğŸ“„ provenance.jsonld              # required: W3C PROV-ish lineage + source pointers
      ğŸ“„ checksums.txt                  # required: sha256 for key artifacts
      ğŸ“„ schema.json                    # required for tabular data; recommended for geo too
      ğŸ“„ qa_report.json                 # required: validation summary + stats
      ğŸ“ data/
        ğŸ§¾ table.parquet
        ğŸ—ºï¸ layer.geoparquet
        ğŸ—ºï¸ layer.gpkg
        ğŸ–¼ï¸ raster.cog.tif
        ğŸ§± tiles.pmtiles
      ğŸ“ logs/
        ğŸ§° pipeline_run.log             # optional: keep if useful for auditing
      ğŸ“ meta/
        ğŸ§¾ fields.md                    # optional: human-friendly field dictionary
        ğŸ—“ï¸ temporal.md                  # optional: time semantics + caveats
```

---

## ğŸ§± Dataset Contract (Required Files)

Every processed dataset version **must** include:

| File | Required | Purpose |
|---|---:|---|
| `manifest.json` | âœ… | The authoritative â€œinventoryâ€ of artifacts (names, sizes, hashes, row counts, bbox, time range). |
| `provenance.jsonld` | âœ… | Lineage: raw inputs, pipeline name/version, parameters, processing steps, citations. |
| `checksums.txt` | âœ… | Quick integrity verification (sha256). |
| `qa_report.json` | âœ… | Proof itâ€™s valid: schema checks, geometry checks, null rates, duplicates, CRS, etc. |
| `schema.json` | âœ… (tabular) | A machine-readable contract for downstream loading (DB/tiles/index). |

> Tip ğŸ’¡: include a dataset-specific `README.md` when there are non-obvious joins, caveats, or domain rules.

---

## ğŸ§¾ Formats We Prefer (Interoperable + Web-Friendly)

### Tabular ğŸ“Š
- âœ… **Parquet** (preferred), optionally partitioned  
- âœ… **CSV** only for *small/simple* exports (avoid for large or typed datasets)
- âœ… **GeoParquet** for large spatial tables (preferred when available)

### Vector ğŸ—ºï¸
- âœ… **GeoPackage (`.gpkg`)** for portable GIS interchange  
- âœ… **GeoParquet** for analytics and fast IO  
- âš ï¸ **GeoJSON** only for small layers (large GeoJSON is slow + huge)

### Raster ğŸ›°ï¸
- âœ… **Cloud-Optimized GeoTIFF (COG)** for serving + partial reads  
- âœ… **PMTiles / XYZ tile packages** when pre-tiling is required

---

## ğŸ·ï¸ Naming & Versioning Rules

### Dataset slugs
Keep dataset slugs:
- lowercase
- hyphenated
- stable over time  
Example: `ks-counties`, `landsat-ndvi`, `historic-newspapers-index`

### Versions
Pick **one** versioning strategy per dataset:
- `vMAJOR.MINOR.PATCH` (semantic versioning) for curated datasets  
- `YYYY-MM-DD` for daily/periodic refreshes  
- `run_<timestamp>_<shortgitsha>` for experimental outputs (avoid publishing)

ğŸš« Never overwrite an existing version folder.

---

## ğŸ” Provenance Rules (â€œMap Behind the Mapâ€)

Processed outputs must be traceable to:
1) **Source** (where the raw data came from)  
2) **Method** (what pipeline transformed it)  
3) **Parameters** (what configuration produced this output)  
4) **Identity** (who/what ran it + when)  
5) **Integrity** (hashes + row counts + bounding boxes)

### Minimum provenance fields (recommended)
- `dataset_slug`, `version`
- `created_at`, `pipeline_name`, `pipeline_version` (git SHA ok)
- `inputs[]`: path(s) in `data/raw/...` + hashes
- `steps[]`: normalized step list (clean â†’ transform â†’ validate â†’ export)
- `outputs[]`: generated files + hashes
- `citations[]`: URLs/DOIs/agency references (and access date)
- `license`: inherited or derived, with proof

---

## âœ… QA / Validation Expectations

At minimum, **every processed dataset** should pass:

### General
- âœ… schema validation (types, required fields)
- âœ… null-rate report per field
- âœ… duplicate key checks (if an ID exists)
- âœ… range checks for known numeric fields (e.g., lat/long bounds)

### Spatial (if geometry exists)
- âœ… geometry validity (no self-intersections unless allowed)
- âœ… CRS is declared and consistent
- âœ… bounding box is computed + stored
- âœ… topology rules (when relevant) documented or enforced

### Raster
- âœ… CRS, nodata, pixel size documented
- âœ… COG validity checks (internal tiling + overviews)
- âœ… stats/percentiles computed (optional but useful)

---

## ğŸ” How to Add or Refresh a Dataset

1. **Ingest raw** into `data/raw/<source>/<date>/...` ğŸ“¥  
2. **Run pipeline** to generate processed outputs ğŸ­  
3. **Write manifests + provenance** (auto-generated preferred) ğŸ§¾  
4. **Run QA** and store `qa_report.json` âœ…  
5. **Promote to catalog** by adding/updating the STAC/DCAT record ğŸ—‚ï¸  
6. **Load to runtime** stores via governed loaders ğŸ—ƒï¸  
7. **Serve via API** (never direct DB access from UI) ğŸŒ

> If you canâ€™t re-run it, itâ€™s not processed â€” itâ€™s a one-off.

---

## ğŸ§¯ Common Mistakes (Avoid These)

- âŒ Editing a processed file manually â€œjust to fix one valueâ€
- âŒ Storing outputs without hashes
- âŒ Missing CRS / unclear units
- âŒ Publishing â€œlatestâ€ without pinning a version
- âŒ Writing outputs that cannot be linked to raw inputs

---

## â“FAQ

### â€œCan I store intermediate pipeline outputs here?â€
Prefer **no**. If itâ€™s not intended to be cataloged and validated, use a temp area (`data/_tmp/`) or pipeline workspace.

### â€œDo we keep *all* processed versions forever?â€
Default is **yes** (append-only history). If storage becomes an issue, define a retention policy per dataset *explicitly*.

### â€œHow does this relate to AI answers?â€
AI outputs must cite **cataloged/served** artifacts. Processed is upstream of that trust boundary, ensuring everything has lineage before it becomes â€œanswerable.â€

---

## ğŸ§  Design Philosophy

Processed data is where Kansas Frontier Matrix becomes *trustworthy*:
- evidence-first âœ…  
- provenance-by-default âœ…  
- governed promotion âœ…  
- reproducible pipelines âœ…

If youâ€™re unsure where something goes, follow the Truth Path diagram above. ğŸ§­