<div align="center">

# ðŸ§¾ Kansas-Frontier-Matrix â€” Data Provenance  
`data/provenance/`

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml)  
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml)  
[![CodeQL](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/codeql.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/codeql.yml)  
[![Trivy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml)

**Mission:** Track **provenance, lineage, and licensing**  
for all datasets in the **Kansas Frontier Matrix** knowledge hub.  

This directory provides a **mission-grade audit trail** of dataset origins, transformations, and integrity checks.  
Provenance is the **backbone of MCP reproducibility**:  
every file in `data/` must map to a record here and to its corresponding **STAC Item/Collection**.  

</div>

---

## ðŸ“ˆ Lifecycle

```mermaid
flowchart TD
  A["Raw sources\n(data/raw/**)"] --> B["Provenance logging\n(data/provenance/registry.json)"]
  B --> C["Processed outputs\n(data/processed/**, data/cogs/**)"]
  C --> D["Checksums + licenses\n(data/provenance/*.json, LICENSES.md)"]
  C --> E["STAC Items\n(data/stac/items/**)"]
  E --> F["Validate\n(stac-validate)"]
  F --> G["Viewer + exports\n(web/config/** Â· data/kml/**)"]

<!-- END OF MERMAID -->



â¸»

ðŸŽ¯ Purpose
	â€¢	Guarantee reproducibility â†’ every dataset is traceable from raw â†’ processed â†’ published
	â€¢	Maintain lineage â†’ record transformations (GCP warps, reprojections, clipping, etc.)
	â€¢	Track checksums & sizes â†’ ensure file integrity
	â€¢	Record licenses â†’ comply with open-data usage
	â€¢	Provide audit logs aligned with the Master Coder Protocol (MCP)

â¸»

ðŸ“‚ Directory Layout

data/provenance/
â”œâ”€â”€ registry.json      # Master dataset registry (IDs â†’ URLs, checksums, lineage)
â”œâ”€â”€ LICENSES.md        # License texts & attribution notes
â”œâ”€â”€ audits/            # Per-dataset audit logs (e.g., GCP reports, ETL configs)
â””â”€â”€ README.md


â¸»

ðŸ”„ Provenance Workflow
	1.	Fetch raw data
	â€¢	Record source URLs, retrieval date, metadata
	â€¢	Save unmodified files in data/raw/
	2.	Checksums
	â€¢	Compute SHA256 + file size

scripts/gen_sha256.sh data/raw/<file>
scripts/gen_sha256.sh data/processed/<file>

	â€¢	Store in registry.json keyed by dataset ID

	3.	Process
	â€¢	Document transformations (reprojection, clipping, OCR, GCPs)
	â€¢	Record Makefile targets, script parameters, or experiment IDs
	4.	STAC entry
	â€¢	Add metadata in data/stac/items/ or data/stac/collections/
	â€¢	Each Item must link back to provenance (href, checksum)
	5.	License & attribution
	â€¢	Record license text in LICENSES.md
	â€¢	Note terms (Public Domain, CC-BY, CC0, etc.)

â¸»

ðŸ“‘ Example Provenance Entry (registry.json)

{
  "id": "usgs_topo_1894_larned",
  "version": "1.1.0",
  "source_url": "https://prd-tnm.s3.amazonaws.com/StagedProducts/Maps/HistoricalTopo/GeoTIFF/KS/USGS_15x15_1894_Larned_Geo.tif",
  "retrieved": "2025-09-20",
  "checksum_sha256": "abc123def456...",
  "filesize_bytes": 104857600,
  "license": "public-domain",
  "lineage": [
    "download raw GeoTIFF from USGS TNM",
    "apply GCP warp to EPSG:4326 using 10 control points",
    "convert to Cloud-Optimized GeoTIFF with rio-cogeo"
  ],
  "stac_item": "data/stac/items/topo/usgs_topo_1894_larned.json"
}


â¸»

ðŸ“Œ Best Practices
	â€¢	Every dataset must have a provenance record (registry + audit if needed)
	â€¢	Mark uncertain data (OCR, ambiguous features) with a confidence flag
	â€¢	Keep audit logs human-readable and long-term accessible
	â€¢	Prefer authoritative sources (USGS, NOAA, FEMA, Kansas GIS Hub, KGS)
	â€¢	Dataset IDs must be stable to avoid breaking STAC/web references
	â€¢	Sync registry updates with Makefile pipelines for integrity

â¸»

ðŸ”— Connections
	â€¢	STAC catalog â†’ Items reference provenance checksums + lineage
	â€¢	Makefile workflows â†’ provenance updated after make fetch, make terrain, make stac
	â€¢	Web configs â†’ every web layer traces back to provenance
	â€¢	Experiments â†’ MCP experiment logs must cite provenance IDs
	â€¢	KML exports â†’ KMZ overlays must link back to provenance records

â¸»

ðŸ“š References
	â€¢	STAC 1.0.0 specification
	â€¢	MCP templates â†’ docs/mcp_templates/ (Scientific Method & Experiment Logs)
	â€¢	Kansas Frontier Matrix â€” Design Audit Report
	â€¢	Data Resource Analysis Report

â¸»

âœ… Mission Principle

All datasets must be auditable, reproducible, and MCP-compliant.
This directory is the single source of truth for lineage + licensing across the Kansas Frontier Matrix.