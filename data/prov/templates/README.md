# ğŸ§¬ PROV Templates (KFM)

![Standard](https://img.shields.io/badge/standard-W3C%20PROV-005A9C?style=flat-square)
![Policy](https://img.shields.io/badge/policy-provenance--first-7B2CBF?style=flat-square)
![Stage](https://img.shields.io/badge/pipeline-boundary%20artifact-0B7285?style=flat-square)
![Format](https://img.shields.io/badge/templates-PROV%20JSON%20%2F%20JSON--LD-495057?style=flat-square)

> âœ… **Purpose:** This folder contains **reusable templates** for authoring **PROV lineage records** (W3C PROV) in Kansas Frontier Matrix (KFM).  
> ğŸ§¾ These templates are used to generate the real provenance bundles stored in `data/prov/`.

---

## ğŸ“ What belongs in `data/prov/templates/`

### âœ… Yes â€” keep here
- **Template PROV bundles** for common scenarios:
  - ğŸ§ª ETL runs (raw âœ processed)
  - ğŸ§  AI/analysis artifacts (model run âœ derived dataset)
  - ğŸ§¹ Manual curation steps (human edits âœ revised dataset)
- **Reusable PROV patterns** that match KFM profiles and schema expectations

### âŒ No â€” donâ€™t keep here
- ğŸš« Actual lineage outputs for a specific run (those go in `data/prov/`)
- ğŸš« Secrets / tokens / private keys (PROV is metadata, not a vault)
- ğŸš« Ad-hoc one-off formats that bypass KFM profiles

---

## ğŸ—‚ï¸ Directory map

```text
ğŸ“¦ repo-root/
â””â”€ ğŸ—ƒï¸ data/
   â””â”€ ğŸ§¬ prov/
      â”œâ”€ ğŸ“„ README.md                 â† PROV overview (parent folder)
      â”œâ”€ ğŸ§¾ <generated lineage>.json   â† real outputs (per dataset/run)
      â””â”€ ğŸ§© templates/
         â””â”€ ğŸ“„ README.md              â† you are here âœ¨
```

> ğŸ•°ï¸ **Note on naming:** Some older docs refer to `data/provenance/`.  
> In v13+ structure, provenance outputs live under `data/prov/`.

---

## ğŸ§­ The KFM â€œtruth pathâ€ (nonâ€‘negotiable)

KFM treats provenance as a **boundary artifact**: data is not considered â€œpublishableâ€ until metadata and lineage are in place.

```mermaid
flowchart LR
  Raw["ğŸ§Š Raw data"] --> Processed["ğŸ§ª Processed data"]
  Processed --> Catalog["ğŸ—‚ï¸ Catalogs (STAC / DCAT / PROV)"]
  Catalog --> DB["ğŸ§  Graph/DB"]
  DB --> API["ğŸ§° Governed API"]
  API --> UI["ğŸ—ºï¸ UI / Story Nodes / AI"]
```

---

## ğŸ§± Minimum PROV model used in KFM

Every PROV record should answer:

> **â€œHow was this data produced?â€** ğŸ”

### Core PROV objects
- **Entities** ğŸ§©  
  Inputs (raw files / source URLs / upstream datasets) and outputs (processed artifacts)
- **Activities** âš™ï¸  
  The transformation step(s): pipeline run, model execution, manual edit session
- **Agents** ğŸ§‘â€ğŸ’»ğŸ¤–  
  Who/what performed the activity: person + software (script/tool), optionally organization

### Core relations (typical)
- `used` â†’ activity used input entity  
- `wasGeneratedBy` â†’ output entity created by activity  
- `wasAssociatedWith` â†’ activity associated with agent  
- `wasDerivedFrom` â†’ output entity derived from input entity (optional but useful)  

---

## ğŸ”— Crossâ€‘layer linkage (STAC + DCAT + PROV)

KFM policy expects **STAC/DCAT/PROV alignment** for each dataset/evidence artifact:

- ğŸ›°ï¸ **STAC**: spatial/temporal asset metadata (`data/stac/â€¦`)
- ğŸ§¾ **DCAT**: dataset-level catalog entry (`data/catalog/dcat/â€¦`)
- ğŸ§¬ **PROV**: lineage bundle (`data/prov/â€¦`)

âœ… **Template rule:** every PROV template should include placeholders for:
- **Dataset stable ID** (the canonical dataset identifier)
- **Run ID / commit hash** (reproducibility anchor)
- **Pointers to STAC/DCAT identifiers** (do not duplicate everything, link it)

---

## ğŸ·ï¸ ID & naming conventions (recommended)

> These are **recommendations** to keep provenance consistent and grep-able across domains.

### File naming (generated outputs)
- `data/prov/<dataset_id>__<run_id>.prov.json`
- `data/prov/<domain>/<dataset_id>/<run_id>.prov.json` (if the repo uses domain subfolders)

### PROV identifiers (inside the file)
Use stable, explicit IDs that wonâ€™t collide:

- **Entities**
  - `kfm:entity:raw:<sha256>`  
  - `kfm:entity:processed:<dataset_id>@<version>`
- **Activities**
  - `kfm:activity:etl:<pipeline_name>:<run_id>`
  - `kfm:activity:analysis:<notebook_or_model>:<run_id>`
- **Agents**
  - `kfm:agent:software:<tool>@<version>`
  - `kfm:agent:person:<github_handle_or_orcid>`

âœ… Prefer **hashes** (sha256) or **content-addressed IDs** for file entities.

---

## âœ… Definition of Done (DoD) for a template

A PROV template is â€œreadyâ€ when it:

- [ ] Encodes **Entities / Activities / Agents** clearly
- [ ] Has obvious placeholders for:
  - [ ] dataset_id
  - [ ] run_id
  - [ ] git commit hash
  - [ ] timestamps (start/end)
  - [ ] input/output checksums
  - [ ] parameters / notes (optional but encouraged)
- [ ] Includes a section/placeholders to link **STAC + DCAT** IDs
- [ ] Matches the **KFM PROV profile** direction (even if the profile is still evolving)
- [ ] Does **not** include secrets, PII, or restricted content
- [ ] Is formatted so it can be validated by CI/schema tooling (where present)

---

## ğŸ§© Example: PROV bundle skeleton (PROVâ€‘JSON style)

> ğŸ“Œ This is a **template skeleton**, not a final run output. Replace placeholders like `__DATASET_ID__`.

```json
{
  "prefix": {
    "kfm": "https://kansasfrontiermatrix.org/id/",
    "prov": "http://www.w3.org/ns/prov#"
  },

  "entity": {
    "kfm:entity:raw:__INPUT_SHA256__": {
      "prov:label": "data/raw/__DOMAIN__/__SOURCE_FILE__",
      "prov:type": "kfm:RawFile",
      "kfm:sha256": "__INPUT_SHA256__",
      "kfm:source_url": "__OPTIONAL_SOURCE_URL__",
      "kfm:retrieved_at": "__OPTIONAL_ISO8601__"
    },

    "kfm:entity:processed:__DATASET_ID__@__VERSION__": {
      "prov:label": "data/processed/__DOMAIN__/__OUTPUT_FILE__",
      "prov:type": "kfm:ProcessedDataset",
      "kfm:dataset_id": "__DATASET_ID__",
      "kfm:version": "__VERSION__",
      "kfm:sha256": "__OUTPUT_SHA256__",
      "kfm:stac_item_id": "__STAC_ITEM_ID__",
      "kfm:dcat_dataset_id": "__DCAT_DATASET_ID__"
    }
  },

  "activity": {
    "kfm:activity:etl:__PIPELINE_NAME__:__RUN_ID__": {
      "prov:label": "__PIPELINE_NAME__",
      "prov:startTime": "__START_ISO8601__",
      "prov:endTime": "__END_ISO8601__",

      "kfm:run_id": "__RUN_ID__",
      "kfm:git_commit": "__GIT_SHA__",
      "kfm:runtime": {
        "os": "__OS__",
        "python": "__PYTHON_VERSION__",
        "container": "__CONTAINER_TAG_OR_DIGEST__"
      },
      "kfm:parameters": {
        "__PARAM_1__": "__VALUE__"
      },
      "kfm:notes": "__OPTIONAL_FREE_TEXT__"
    }
  },

  "agent": {
    "kfm:agent:software:__PIPELINE_NAME__@__TOOL_VERSION__": {
      "prov:type": "prov:SoftwareAgent",
      "prov:label": "__PIPELINE_NAME__",
      "kfm:version": "__TOOL_VERSION__"
    },

    "kfm:agent:person:__OPERATOR__": {
      "prov:type": "prov:Person",
      "prov:label": "__HUMAN_NAME__",
      "kfm:handle": "__OPERATOR__"
    }
  },

  "used": {
    "_:u1": {
      "prov:activity": "kfm:activity:etl:__PIPELINE_NAME__:__RUN_ID__",
      "prov:entity": "kfm:entity:raw:__INPUT_SHA256__"
    }
  },

  "wasGeneratedBy": {
    "_:g1": {
      "prov:entity": "kfm:entity:processed:__DATASET_ID__@__VERSION__",
      "prov:activity": "kfm:activity:etl:__PIPELINE_NAME__:__RUN_ID__"
    }
  },

  "wasAssociatedWith": {
    "_:a1": {
      "prov:activity": "kfm:activity:etl:__PIPELINE_NAME__:__RUN_ID__",
      "prov:agent": "kfm:agent:software:__PIPELINE_NAME__@__TOOL_VERSION__"
    },
    "_:a2": {
      "prov:activity": "kfm:activity:etl:__PIPELINE_NAME__:__RUN_ID__",
      "prov:agent": "kfm:agent:person:__OPERATOR__"
    }
  }
}
```

---

## ğŸ§  AI / analysis artifacts (special notes)

KFM treats AI/model outputs as **first-class datasets** with full provenance.

When creating templates for AI-derived artifacts, include placeholders for:
- ğŸ¤– model/tool identifier + version
- ğŸ›ï¸ hyperparameters / prompts (sanitized if needed)
- ğŸ“ input dataset IDs (entities)
- ğŸ“Š confidence metrics (where applicable)
- ğŸ§¾ citations / references to method (if required)

---

## ğŸ§ª Validation & CI expectations (what templates enable)

Even if templates arenâ€™t executed directly, they must be structured so that **generated PROV outputs** can pass CI checks, including:
- âœ… presence of provenance for processed data
- âœ… linkage consistency with STAC/DCAT
- âœ… deterministic/reproducible anchors (run_id, hashes, commit)

> ğŸ§¯ If provenance is missing, KFM treats it as a red flag â€” â€œnot publishableâ€ until corrected.

---

## ğŸ¤ Contributing a new template

1. ğŸ§© Add a new template file under this folder (use `TEMPLATE__...` naming).
2. ğŸ“ Document its use case in this README (add it to â€œTemplate catalogâ€ below).
3. ğŸ” Keep it generic: no dataset-specific IDs, no real secrets, no real file paths unless examples.
4. ğŸ§· Prefer placeholders: `__LIKE_THIS__` (consistent + searchable).

### ğŸ“š Template catalog (add entries here)
- `TEMPLATE__PROV_ETL_BUNDLE.prov.json` *(recommended)*
- `TEMPLATE__PROV_AI_ACTIVITY.prov.json` *(recommended)*
- `TEMPLATE__PROV_MANUAL_CURATION.prov.json` *(recommended)*

---

## ğŸ” Quick checklist (copy/paste)

- [ ] Inputs listed as **Entities** (with hashes + optional source URLs)
- [ ] Output listed as an **Entity** (with hash)
- [ ] Processing step is an **Activity** (with timestamps)
- [ ] Pipeline tool is a **SoftwareAgent**
- [ ] Human operator (if any) is a **Person** Agent
- [ ] Relations: `used`, `wasGeneratedBy`, `wasAssociatedWith`
- [ ] Links to **STAC + DCAT** identifiers included
- [ ] Run anchored to **run_id + git commit**
- [ ] No secrets / sensitive data embedded

---

### ğŸ§­ Related docs (in-repo)
- `../../../docs/MASTER_GUIDE_v13.md` ğŸ“˜
- `../../../docs/standards/KFM_PROV_PROFILE.md` ğŸ§¬
- `../../../docs/standards/KFM_DCAT_PROFILE.md` ğŸ§¾
- `../../../docs/standards/KFM_STAC_PROFILE.md` ğŸ›°ï¸