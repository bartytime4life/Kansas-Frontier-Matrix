<div align="center">

# üíß Kansas Frontier Matrix ‚Äî Hydrology Checksums  
`data/checksums/hydrology/`

**Mission:** Guarantee **data integrity, reproducibility, and provenance**  
for all processed hydrology datasets in Kansas Frontier Matrix ‚Äî including rivers, watersheds,  
flood zones, and groundwater layers ‚Äî through SHA-256 checksum verification and continuous validation.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../.github/workflows/site.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../.github/workflows/stac-validate.yml)
[![Trivy Security](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../.github/workflows/trivy.yml)
[![Docs ¬∑ MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../LICENSE)

</div>

---

## üìö Overview

This directory stores **SHA-256 checksum files (`.sha256`)**  
for all processed **hydrology datasets** within the Kansas Frontier Matrix (KFM).  

Checksums provide a cryptographic fingerprint ensuring:
- **Integrity** ‚Äî No corruption or alteration of hydrologic datasets.  
- **Reproducibility** ‚Äî Identical pipeline results across processing environments.  
- **Provenance** ‚Äî Direct linkage between datasets, STAC items, and metadata.  
- **Auditability** ‚Äî Verified continuously in CI/CD pipelines for complete traceability.  

All files are generated by the hydrology ETL pipeline (`make hydrology`)  
and validated automatically during continuous integration.

---

## üóÇÔ∏è Directory Layout

```bash
data/checksums/hydrology/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ nhd_flowlines_ks.geojson.sha256
‚îú‚îÄ‚îÄ watersheds_huc12_ks.geojson.sha256
‚îú‚îÄ‚îÄ fema_nfhl_ks.geojson.sha256
‚îú‚îÄ‚îÄ groundwater_levels_ks.geojson.sha256
‚îî‚îÄ‚îÄ flood_events_ks.geojson.sha256
````

> **Note:** Each `.sha256` file represents a verified hash for a processed hydrology dataset
> located in `data/processed/hydrology/`, and all are validated automatically via `sha256sum -c`.

---

## üîê Purpose of Checksums

| Objective           | Description                                                       |
| :------------------ | :---------------------------------------------------------------- |
| **Data Integrity**  | Detects corruption or tampering in hydrology datasets.            |
| **Reproducibility** | Ensures consistent ETL outputs between runs.                      |
| **Provenance**      | Links datasets to metadata, STAC records, and sources.            |
| **Automation**      | Hash verification runs automatically in GitHub Actions pipelines. |

---

## üßÆ Example `.sha256` File

```bash
# File: watersheds_huc12_ks.geojson.sha256
a30f8ccbd7f2b6171cbfe38bb99a4c28a7f26dcbf2a032dcac34d79b94cf6a0f  watersheds_huc12_ks.geojson
```

This checksum verifies the file
`data/processed/hydrology/watersheds_huc12_ks.geojson`
has not changed since it was last validated.

---

## ‚öôÔ∏è Checksum Generation Workflow

Checksums are generated automatically after each ETL pipeline run.

**Makefile target:**

```bash
make hydrology-checksums
```

**Python command:**

```bash
python src/utils/generate_checksums.py data/processed/hydrology/ --algo sha256
```

**Workflow Steps:**

1. Locate processed hydrology outputs (`.geojson`, `.tif`, `.csv`).
2. Compute SHA-256 hashes using `hashlib`.
3. Write `<filename>.sha256` into this directory.
4. Validate hashes during CI/CD pipeline execution.

---

## üß∞ CI/CD Validation

Checksum verification runs automatically during CI builds.

**Validation command:**

```bash
sha256sum -c data/checksums/hydrology/*.sha256
```

If any checksum fails validation, the build halts ‚Äî
preventing the publication of altered or corrupted data.

---

## üß© Integration with Metadata & STAC

| Linked Component                                | Purpose                                                          |
| :---------------------------------------------- | :--------------------------------------------------------------- |
| `data/processed/metadata/hydrology/`            | STAC Items reference checksum files for data verification.       |
| `src/pipelines/hydrology/hydrology_pipeline.py` | Generates and validates hashes during ETL.                       |
| `.github/workflows/stac-validate.yml`           | CI/CD automation for integrity testing.                          |
| `data/stac/hydrology/`                          | STAC catalog embeds checksum references for provenance tracking. |

---

## üß† MCP Compliance Summary

| MCP Principle           | Implementation                                              |
| :---------------------- | :---------------------------------------------------------- |
| **Documentation-first** | README + checksum records for every hydrology dataset.      |
| **Reproducibility**     | Deterministic ETL with hash-based verification.             |
| **Open Standards**      | SHA-256 (FIPS 180-4) algorithm for global consistency.      |
| **Provenance**          | Hashes connect processed data to metadata and STAC records. |
| **Auditability**        | CI/CD workflows enforce continuous checksum verification.   |

---

## üìÖ Version History

| Version | Date       | Summary                                                                                                 |
| :------ | :--------- | :------------------------------------------------------------------------------------------------------ |
| v1.0    | 2025-10-04 | Initial hydrology checksum documentation ‚Äî rivers, watersheds, floods, and groundwater layers verified. |

---

<div align="center">

**Kansas Frontier Matrix** ‚Äî *‚ÄúEvery River Verified: Data Integrity That Flows.‚Äù*
üìç [`data/checksums/hydrology/`](.) ¬∑ Linked to the **Hydrology STAC Collection**

</div>
