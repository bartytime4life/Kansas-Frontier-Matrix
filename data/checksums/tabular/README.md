<div align="center">

# üìä Kansas Frontier Matrix ‚Äî Tabular Checksums  
`data/checksums/tabular/`

**Mission:** Maintain and verify the **integrity, reproducibility, and provenance**  
of all **tabular datasets** ‚Äî including census, agricultural, demographic, and economic data ‚Äî  
within the Kansas Frontier Matrix (KFM) through automated **SHA-256 checksum validation** and MCP-compliant governance.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../.github/workflows/site.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../.github/workflows/stac-validate.yml)
[![CodeQL](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/codeql.yml/badge.svg)](../../../.github/workflows/codeql.yml)
[![Trivy Security](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../.github/workflows/trivy.yml)
[![Docs ¬∑ MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../LICENSE)

</div>

---

## üìö Overview

The `data/checksums/tabular/` directory contains **SHA-256 checksum files (`.sha256`)**  
for all **processed tabular datasets** in the Kansas Frontier Matrix (KFM).  

These checksums provide immutable digital fingerprints that confirm:
- üìà **Integrity** ‚Äî Detects corruption or unauthorized edits.  
- üîÅ **Reproducibility** ‚Äî Ensures identical ETL output across environments.  
- üîó **Provenance** ‚Äî Connects data, metadata, and STAC entries for full lineage tracking.  
- üßæ **Auditability** ‚Äî Automates verification during CI/CD for scientific transparency.  

Checksums are automatically generated by the **Tabular ETL pipeline (`make tabular`)**  
and validated continuously via GitHub Actions on every commit.

---

## üóÇÔ∏è Directory Layout

```bash
data/checksums/tabular/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ census_population_1860_2020.parquet.sha256
‚îú‚îÄ‚îÄ agricultural_production_1870_2020.parquet.sha256
‚îú‚îÄ‚îÄ economic_indicators_1900_2025.parquet.sha256
‚îî‚îÄ‚îÄ demographic_statistics_1850_2025.parquet.sha256
````

> **Note:** Each `.sha256` file corresponds to a dataset in
> `data/processed/tabular/` and is verified automatically via CI/CD (`sha256sum -c`).

---

## üîê Purpose & Function

| Objective           | Description                                                                      |
| :------------------ | :------------------------------------------------------------------------------- |
| **Data Integrity**  | Detects corruption or tampering of tabular data files (.csv, .parquet, .json).   |
| **Reproducibility** | Ensures deterministic outputs verified by identical SHA-256 digests.             |
| **Provenance**      | Establishes verifiable linkage between data, metadata, and STAC catalog entries. |
| **Automation**      | Enables continuous CI/CD integrity validation and logging.                       |
| **Transparency**    | Ensures public trust through verifiable data consistency and documentation.      |

---

## üßÆ Example `.sha256` File

```bash
# File: census_population_1860_2020.parquet.sha256
ca03d2fb389314a0ee43525a0eac0b422518a329c8a6f4c482c6c0a12cbb6aa7  census_population_1860_2020.parquet
```

This checksum validates that
`data/processed/tabular/census_population_1860_2020.parquet`
has not been altered since its verification.

---

## ‚öôÔ∏è Generation Workflow

Checksums are generated automatically after pipeline execution but can also be triggered manually.

**Makefile target:**

```bash
make tabular-checksums
```

**Python command:**

```bash
python src/utils/generate_checksums.py data/processed/tabular/ --algo sha256
```

### Workflow Steps:

1. Scan `data/processed/tabular/` for files (`.csv`, `.parquet`, `.json`).
2. Compute hashes via Python‚Äôs `hashlib` module.
3. Output `.sha256` checksum files to this directory.
4. Validate each checksum via CI/CD using `sha256sum -c`.
5. Store logs under `data/work/logs/tabular_checksums.log`.

---

## üß∞ CI/CD Validation

**Validation Command:**

```bash
sha256sum -c data/checksums/tabular/*.sha256
```

**Behavior:**

* ‚úÖ Pass ‚Üí Hashes match expected values; build proceeds.
* ‚ùå Fail ‚Üí CI halts; dataset must be reprocessed and rehashed.
* üßæ Logs ‚Üí Results archived under `data/work/logs/` for MCP audit compliance.

These validations are integrated into the **STAC validation workflow (`.github/workflows/stac-validate.yml`)**
to synchronize checksum validation with metadata verification.

---

## üîó Integration with Metadata & STAC

| Linked Component                      | Purpose                                                             |
| :------------------------------------ | :------------------------------------------------------------------ |
| `data/processed/metadata/tabular/`    | STAC Items include `"checksum:sha256"` for every asset.             |
| `src/pipelines/tabular_pipeline.py`   | Generates and verifies hashes post-ETL.                             |
| `.github/workflows/stac-validate.yml` | Automates consistency checks between checksums and STAC entries.    |
| `data/stac/tabular/`                  | STAC catalog embeds checksums for transparency and discoverability. |
| `data/checksums/manifest.sha256`      | Global manifest referencing all domain checksum records.            |

---

## üß© Troubleshooting & Maintenance

| Issue                        | Likely Cause                                 | Resolution                                                      |
| :--------------------------- | :------------------------------------------- | :-------------------------------------------------------------- |
| CI fails checksum validation | Dataset updated but checksum not refreshed.  | Re-run `make tabular-checksums` and commit new `.sha256` files. |
| Missing `.sha256` file       | New dataset added but hash not generated.    | Execute `python src/utils/generate_checksums.py` manually.      |
| STAC mismatch                | STAC `checksum:sha256` not updated post-ETL. | Run `make stac` to regenerate metadata.                         |
| Cross-platform mismatch      | Line ending or path encoding differences.    | Use LF line endings and POSIX paths for consistency.            |

---

## üß† MCP Compliance Summary

| MCP Principle           | Implementation                                                   |
| :---------------------- | :--------------------------------------------------------------- |
| **Documentation-first** | Each dataset includes README and checksum verification record.   |
| **Reproducibility**     | Deterministic ETL with SHA-256 guarantees identical outputs.     |
| **Open Standards**      | SHA-256 (FIPS 180-4) + STAC Checksum extension adopted.          |
| **Provenance**          | Connects tabular data, metadata, and STAC for traceable lineage. |
| **Auditability**        | Continuous validation and log retention under CI/CD.             |

---

## üìÖ Version History

| Version | Date       | Summary                                                                                          |
| :------ | :--------- | :----------------------------------------------------------------------------------------------- |
| v1.0.0  | 2025-10-04 | Initial tabular checksum documentation ‚Äî population, agriculture, and economy datasets verified. |
| v1.1.0  | 2025-10-10 | Added demographic dataset, improved CI logging, troubleshooting, and manifest linkage.           |

---

<div align="center">

**Kansas Frontier Matrix** ‚Äî *‚ÄúIntegrity in Every Table: Verifying the Numbers that Define History.‚Äù*
üìç [`data/checksums/tabular/`](.) ¬∑ Linked to the **Tabular STAC Collection** and Global Checksum Registry.

</div>
```
