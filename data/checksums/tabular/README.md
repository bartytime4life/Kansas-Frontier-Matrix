<div align="center">

# üìä Kansas Frontier Matrix ‚Äî Tabular Checksums  
`data/checksums/tabular/`

**Mission:** Maintain and verify the **integrity, reproducibility, and provenance**  
of all tabular datasets ‚Äî including census, agricultural, and economic data ‚Äî  
within the Kansas Frontier Matrix (KFM) through SHA-256 checksum validation.

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../.github/workflows/site.yml)
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../.github/workflows/stac-validate.yml)
[![Trivy Security](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../.github/workflows/trivy.yml)
[![Docs ¬∑ MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../docs/)
[![License: Data](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../LICENSE)

</div>

---

## üìö Overview

This directory contains **SHA-256 checksum files (`.sha256`)**  
for all processed **tabular datasets** in Kansas Frontier Matrix (KFM).  

Checksums ensure:
- **Integrity** ‚Äî Detect and prevent data corruption or tampering.  
- **Reproducibility** ‚Äî Validate that identical datasets are regenerated across pipeline runs.  
- **Provenance** ‚Äî Link tabular datasets to their metadata and STAC records.  
- **Auditability** ‚Äî Enable continuous validation via CI/CD for transparency and traceability.  

Checksums are automatically generated by the **tabular ETL pipeline (`make tabular`)**  
and validated as part of the KFM continuous integration workflow.

---

## üóÇÔ∏è Directory Layout

```bash
data/checksums/tabular/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ census_population_1860_2020.parquet.sha256
‚îú‚îÄ‚îÄ agricultural_production_1870_2020.parquet.sha256
‚îî‚îÄ‚îÄ economic_indicators_1900_2025.parquet.sha256
````

> **Note:** Each `.sha256` file verifies the integrity of a dataset
> stored under `data/processed/tabular/` and is validated automatically via `sha256sum -c` in CI/CD.

---

## üîê Purpose of Checksums

| Objective           | Description                                                               |
| :------------------ | :------------------------------------------------------------------------ |
| **Data Integrity**  | Prevents silent corruption or unauthorized modification of tabular files. |
| **Reproducibility** | Ensures deterministic pipeline results verified via matching hashes.      |
| **Provenance**      | Links each dataset to its STAC metadata and checksum record.              |
| **Automation**      | CI/CD workflows continuously validate checksums across builds.            |

---

## üßÆ Example `.sha256` File

```bash
# File: census_population_1860_2020.parquet.sha256
ca03d2fb389314a0ee43525a0eac0b422518a329c8a6f4c482c6c0a12cbb6aa7  census_population_1860_2020.parquet
```

This checksum validates the file
`data/processed/tabular/census_population_1860_2020.parquet`.

---

## ‚öôÔ∏è Checksum Generation Workflow

Checksums are created automatically after ETL completion or can be generated manually.

**Makefile target:**

```bash
make tabular-checksums
```

**Python command:**

```bash
python src/utils/generate_checksums.py data/processed/tabular/ --algo sha256
```

**Steps:**

1. Locate processed tabular datasets (`.csv`, `.parquet`, `.json`).
2. Compute SHA-256 hashes using Python‚Äôs `hashlib` library.
3. Save each hash as `<filename>.sha256` in this directory.
4. CI/CD workflows automatically verify hashes for consistency.

---

## üß∞ CI/CD Validation

Checksum validation is performed automatically via GitHub Actions workflows.

**Example validation command:**

```bash
sha256sum -c data/checksums/tabular/*.sha256
```

**If validation fails:**

* The pipeline halts and logs the affected file.
* The dataset must be reprocessed and its checksum regenerated.
* CI logs provide a traceable verification record for reproducibility.

---

## üß© Integration with Metadata & STAC

| Linked Component                            | Purpose                                                          |
| :------------------------------------------ | :--------------------------------------------------------------- |
| `data/processed/tabular/metadata/`          | STAC metadata references these checksum files for validation.    |
| `src/pipelines/tabular/tabular_pipeline.py` | Handles checksum generation and verification automatically.      |
| `.github/workflows/stac-validate.yml`       | CI/CD job validating STAC and checksum consistency.              |
| `data/stac/tabular/`                        | STAC catalog embeds checksum references for provenance tracking. |

---

## üß† MCP Compliance Summary

| MCP Principle           | Implementation                                                 |
| :---------------------- | :------------------------------------------------------------- |
| **Documentation-first** | Every tabular dataset has an accompanying checksum and README. |
| **Reproducibility**     | Deterministic ETL pipelines verified through hash checks.      |
| **Open Standards**      | SHA-256 (FIPS 180-4) cryptographic algorithm.                  |
| **Provenance**          | Hashes link tabular data to metadata and STAC entries.         |
| **Auditability**        | Continuous validation via GitHub Actions ensures transparency. |

---

## üìÖ Version History

| Version | Date       | Summary                                                                                          |
| :------ | :--------- | :----------------------------------------------------------------------------------------------- |
| v1.0    | 2025-10-04 | Initial tabular checksum documentation ‚Äî includes population, agriculture, and economy datasets. |

---

<div align="center">

**Kansas Frontier Matrix** ‚Äî *‚ÄúIntegrity in Every Table: Verifying the Numbers that Define History.‚Äù*
üìç [`data/checksums/tabular/`](.) ¬∑ Linked to the **Tabular STAC Collection**

</div>
