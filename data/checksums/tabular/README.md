<div align="center">

# üìä Kansas Frontier Matrix ‚Äî Tabular Checksums  
`data/checksums/tabular/`

**Mission:** Maintain and verify the **integrity, reproducibility, and provenance** of all **tabular datasets**  
(census, agricultural, demographic, economic, etc.) via automated **SHA-256** validation and MCP governance.

[![Build & Deploy](https://img.shields.io/github/actions/workflow/status/bartytime4life/Kansas-Frontier-Matrix/site.yml?label=Build%20%26%20Deploy)](../../../.github/workflows/site.yml)  
[![STAC Validate](https://img.shields.io/badge/STAC-validate-blue)](../../../.github/workflows/stac-validate.yml)  
[![CodeQL](https://img.shields.io/github/actions/workflow/status/bartytime4life/Kansas-Frontier-Matrix/codeql.yml?label=CodeQL)](../../../.github/workflows/codeql.yml)  
[![Trivy Security](https://img.shields.io/github/actions/workflow/status/bartytime4life/Kansas-Frontier-Matrix/trivy.yml?label=Trivy%20Security)](../../../.github/workflows/trivy.yml)  
[![Docs ¬∑ MCP](https://img.shields.io/badge/Docs-MCP-blue)](../../../docs/)  
[![License: CC-BY 4.0](https://img.shields.io/badge/License-CC--BY%204.0-green)](../../../LICENSE)

</div>

---

## üìö Overview

The `data/checksums/tabular/` directory stores **SHA-256 checksum files (`.sha256`)**  
for all **processed tabular datasets** in KFM. These immutable digests enable:

- üìà **Integrity** ‚Äî detect corruption or unauthorized edits.  
- üîÅ **Reproducibility** ‚Äî confirm identical ETL outputs across environments.  
- üîó **Provenance** ‚Äî bind data files to **STAC Items** and source manifests.  
- üßæ **Auditability** ‚Äî surface divergences in CI/CD before release.

Checksums are generated by the **Tabular ETL** and validated on every commit.

---

## üß≠ Tabular Integrity Workflow

```mermaid
flowchart LR
  S["data/sources/tabular/*.json\nSource Manifests"] --> R["data/raw/tabular/**\nCSV ¬∑ XLSX ¬∑ JSON"]
  R --> P["src/pipelines/tabular_pipeline.py\nETL ¬∑ Normalize ¬∑ Validate"]
  P --> O["data/processed/tabular/**\nParquet ¬∑ CSV ¬∑ JSON"]
  O --> C["data/checksums/tabular/*.sha256\nPer-asset digests"]
  O --> T["data/stac/tabular/**.json\nSTAC Items (checksum:sha256)"]
  C --> V["CI Validation\nsha256sum -c + STAC parity"]
%% END OF MERMAID
````

<!-- END OF MERMAID -->

---

## üóÇÔ∏è Directory Layout

```bash
data/checksums/tabular/
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ census_population_1860_2020.parquet.sha256
‚îú‚îÄ‚îÄ agricultural_production_1870_2020.parquet.sha256
‚îú‚îÄ‚îÄ economic_indicators_1900_2025.parquet.sha256
‚îî‚îÄ‚îÄ demographic_statistics_1850_2025.parquet.sha256
```

> Each `.sha256` corresponds to a dataset in `data/processed/tabular/` and is verified in CI.

---

## üßÆ Example `.sha256` File

```bash
# File: census_population_1860_2020.parquet.sha256
ca03d2fb389314a0ee43525a0eac0b422518a329c8a6f4c482c6c0a12cbb6aa7  census_population_1860_2020.parquet
```

This certifies that `data/processed/tabular/census_population_1860_2020.parquet`
matches the expected, reproducible output.

---

## ‚öôÔ∏è Generation & Verification

**Make targets**

```bash
make tabular-checksums          # generate checksums
make tabular-checksums-verify   # verify checksums (used by CI)
```

**Python CLI**

```bash
python src/utils/generate_checksums.py data/processed/tabular/ --algo sha256
```

**Steps**

1. Scan `data/processed/tabular/` for `.parquet`, `.csv`, `.json` (configurable).
2. Compute SHA-256 (Python `hashlib` or system `sha256sum`).
3. Write `<filename>.sha256` to `data/checksums/tabular/`.
4. CI runs `sha256sum -c data/checksums/tabular/*.sha256`; logs ‚Üí `data/work/logs/tabular_checksums.log`.

---

## üîê Purpose & Function

| Objective           | Description                                                 |
| :------------------ | :---------------------------------------------------------- |
| **Data Integrity**  | Detect corruption/tampering across tabular assets.          |
| **Reproducibility** | Validate deterministic ETL outputs via stable digests.      |
| **Provenance**      | Maintain verifiable linkage among data, metadata, and STAC. |
| **Automation**      | Enforce integrity gates in CI/CD with clear failure modes.  |
| **Transparency**    | Public, verifiable governance aligned to MCP standards.     |

---

## üîó Integration with Metadata & STAC

| Linked Component                      | Purpose                                                    |
| :------------------------------------ | :--------------------------------------------------------- |
| `data/stac/tabular/**.json`           | STAC Items embed `"checksum:sha256"` for every asset.      |
| `src/pipelines/tabular_pipeline.py`   | Generates/validates checksums; emits logs for audits.      |
| `.github/workflows/stac-validate.yml` | Ensures parity between STAC checksum fields and `.sha256`. |
| `data/checksums/manifest.sha256`      | Global roll-up manifest referencing tabular digests.       |

---

## üß∞ CI/CD Validation

**Command executed by CI**

```bash
sha256sum -c data/checksums/tabular/*.sha256
```

**Behavior**

* ‚úÖ **Pass:** hashes match; build proceeds.
* ‚ùå **Fail:** pipeline halts; reprocess and regenerate digests.
* üßæ **Logs:** results archived under `data/work/logs/` for MCP audits.

---

## üß© Troubleshooting & Maintenance

| Issue                        | Likely Cause                        | Resolution                                                      |
| :--------------------------- | :---------------------------------- | :-------------------------------------------------------------- |
| CI fails checksum validation | Dataset updated without new digest  | Run `make tabular-checksums` and commit updated `.sha256`.      |
| Missing `.sha256` file       | New dataset not hashed              | Execute generator command; add file to repo.                    |
| STAC mismatch                | STAC entry not updated              | Run `make stac` or sync STAC from current `.sha256`.            |
| Cross-platform mismatch      | CRLF or path drift                  | Use LF line endings; POSIX paths; ensure UTF-8.                 |
| Non-deterministic Parquet    | Varying writer metadata/compression | Pin library versions; set stable compression; strip timestamps. |

---

## üß† MCP Compliance Matrix

| MCP Principle           | Implementation                                                     |
| :---------------------- | :----------------------------------------------------------------- |
| **Documentation-first** | This README defines policy, structure, and commands.               |
| **Reproducibility**     | Deterministic hashing + CI enforcement on each commit.             |
| **Open Standards**      | SHA-256 (FIPS 180-4), STAC checksum extension, UTF-8, POSIX paths. |
| **Provenance**          | Checksums + STAC Items bind assets to immutable identities.        |
| **Auditability**        | Logs retained; CI failure gates block inconsistent states.         |

---

## üìÖ Version History

| Version  | Date       | Summary                                                                                                |
| :------- | :--------- | :----------------------------------------------------------------------------------------------------- |
| **v1.2** | 2025-10-11 | Protocol v1.1 upgrade: front-matter, Mermaid flow, CI parity clarifications, Parquet determinism tips. |
| **v1.1** | 2025-10-10 | Added demographic dataset, improved CI logging, troubleshooting, manifest linkage.                     |
| **v1.0** | 2025-10-04 | Initial tabular checksum docs for population, agriculture, economy.                                    |

---

<div align="center">

**Kansas Frontier Matrix** ‚Äî *Integrity in Every Table.*
üìç [`data/checksums/tabular/`](.) ¬∑ Linked to **Tabular STAC Collection** and **Global Checksum Registry**.

</div>
```
