<div align="center">

# üó∫Ô∏è Kansas-Frontier-Matrix ‚Äî DEM COGs (`data/cogs/dem/`)

[![Build & Deploy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/site.yml/badge.svg)](../../../.github/workflows/site.yml)  
[![STAC Validate](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/stac-validate.yml/badge.svg)](../../../.github/workflows/stac-validate.yml)  
[![CodeQL](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/codeql.yml/badge.svg)](../../../.github/workflows/codeql.yml)  
[![Trivy](https://github.com/bartytime4life/Kansas-Frontier-Matrix/actions/workflows/trivy.yml/badge.svg)](../../../.github/workflows/trivy.yml)

**Mission:** Store **Cloud-Optimized GeoTIFFs (COGs)** for **Digital Elevation Models (DEMs)**.  
These rasters power terrain visualizations (hillshade, slope, aspect), time-aware overlays,  
and downstream analysis in the Frontier-Matrix web app + Google Earth integration.  

</div>

---

## üîÑ DEM Lifecycle

```mermaid
flowchart LR
  A["Raw DEM tiles\n(data/raw/dem/**)"] --> B["Mosaic / Reproject\n(gdalbuildvrt ¬∑ gdalwarp)"]
  B --> C["COG (EPSG:4326)\n(data/cogs/dem/**)"]
  C --> D["Checksums\n(.sha256)"]
  C --> E["STAC Items\n(stac/items)"]
  C --> F["Derivatives\n(hillshade ¬∑ slope ¬∑ aspect)"]
  F --> G["Web viewer\n(MapLibre / KML)"]
  E --> H["Validate\n(stac-validate)"]

<!-- END OF MERMAID -->



‚∏ª

üìÇ Directory Layout

data/cogs/dem/
‚îú‚îÄ‚îÄ ks_1m_dem_2018_2020.tif         # statewide mosaic (COG)
‚îú‚îÄ‚îÄ ks_1m_dem_2018_2020.tif.sha256  # checksum (GNU format)
‚îî‚îÄ‚îÄ README.md

	‚Ä¢	Project-wide metadata lives in STAC items under stac/items/** (source of truth).
	‚Ä¢	A local .meta.json is optional for extra notes.

‚∏ª

üß≠ Conventions
	‚Ä¢	COG layout ‚Üí internal tiles 512√ó512, overviews down to ~512 px
	‚Ä¢	CRS (web copy) ‚Üí EPSG:4326 (WGS84); use projected CRS (e.g. EPSG:26914 UTM 14N, EPSG:6344) for analysis
	‚Ä¢	NoData ‚Üí set to safe value (e.g., -9999) and record in STAC
	‚Ä¢	Compression ‚Üí DEFLATE + PREDICTOR=2 for continuous rasters
	‚Ä¢	Integrity ‚Üí every .tif must have a .tif.sha256 sidecar

Naming convention:

<region>_<resolution>_<theme>_<temporal>.tif

Example: ks_1m_dem_2018_2020.tif
For tiled mosaics, suffix with tile keys (e.g. _w98n39).

‚∏ª

üõ†Ô∏è Reproducible Build

Option A ‚Äî Project script

python scripts/convert.py raster-to-cog \
  data/raw/dem/ks_1m_dem_2018_2020.tif \
  data/cogs/dem/ks_1m_dem_2018_2020.tif
# ‚Üí Writes COG + .sha256

Option B ‚Äî Canonical GDAL flow

# 1. Build VRT
gdalbuildvrt dem.vrt data/raw/dem/*.tif

# 2. Reproject to UTM (analysis CRS)
gdalwarp -t_srs EPSG:26914 -r bilinear -dstnodata -9999 -multi -wo NUM_THREADS=ALL_CPUS \
  dem.vrt dem_utm14.tif

# 3. Create web copy (WGS84 COG)
gdalwarp -t_srs EPSG:4326 -r bilinear -dstnodata -9999 dem_utm14.tif /tmp/dem_wgs84.tif

gdal_translate -of COG \
  -co COMPRESS=DEFLATE -co PREDICTOR=2 \
  -co BLOCKSIZE=512 -co OVERVIEW_RESAMPLING=AVERAGE \
  -co NUM_THREADS=ALL_CPUS -co BIGTIFF=IF_SAFER \
  /tmp/dem_wgs84.tif data/cogs/dem/ks_1m_dem_2018_2020.tif

# 4. Checksum
sha256sum data/cogs/dem/ks_1m_dem_2018_2020.tif \
  > data/cogs/dem/ks_1m_dem_2018_2020.tif.sha256


‚∏ª

üèîÔ∏è Derivatives (Terrain Products)

Generate from projected CRS, then COG-ify:

# Hillshade
gdaldem hillshade -az 315 -alt 45 -compute_edges dem_utm14.tif hillshade.tif

# Slope / Aspect
gdaldem slope  dem_utm14.tif slope.tif  -s 1.0
gdaldem aspect dem_utm14.tif aspect.tif

# Publish as COGs
gdal_translate -of COG -co COMPRESS=DEFLATE -co PREDICTOR=2 slope.tif  data/cogs/dem/ks_slope_2018_2020.tif
gdal_translate -of COG -co COMPRESS=DEFLATE -co PREDICTOR=2 aspect.tif data/cogs/dem/ks_aspect_2018_2020.tif

Emit checksums + STAC for each derivative.

‚∏ª

üìá STAC Registration

Record in STAC Item:
	‚Ä¢	datetime or start_datetime‚Äìend_datetime
	‚Ä¢	proj:* (EPSG, transform, shape), raster:* (bands, nodata)
	‚Ä¢	file:* (size), checksum:sha256
	‚Ä¢	Processing notes (warp, resampling, compression)
	‚Ä¢	Providers + license

Fast path (Python API):

from kansas_geo_timeline.ingest import ingest_raster
out, item = ingest_raster(
    "data/cogs/dem/ks_1m_dem_2018_2020.tif",
    stac_items_dir="stac/items",
    stac_collection="kfm-dem"
)
print(out, item["id"])

CLI:

make stac stac-validate-items


‚∏ª

üåê Web & Earth Integration

MapLibre (web viewer):

{
  "id": "ks_1m_dem_2018_2020",
  "title": "DEM (1 m, 2018‚Äì2020)",
  "type": "raster-dem",
  "data": "data/cogs/dem/ks_1m_dem_2018_2020.tif",
  "maxzoom": 14,
  "attribution": "USGS 3DEP / Kansas DASC (Public Domain)"
}

Google Earth / KML:
	‚Ä¢	Export regionated KML/KMZ for large extents
	‚Ä¢	Publish WGS84 COGs for visualization
	‚Ä¢	Keep projected CRS copies for analysis

‚∏ª

üß™ Validation & QA

# Verify checksums
find data/cogs/dem -name "*.tif.sha256" -print0 | xargs -0 sha256sum -c

# Inspect metadata
gdalinfo -checksum data/cogs/dem/ks_1m_dem_2018_2020.tif | head -n 40

# Optional: validate COG structure
rio cogeo validate data/cogs/dem/ks_1m_dem_2018_2020.tif

Document in STAC (and .meta.json if used):
	‚Ä¢	Resolution, transform, vertical units/datum
	‚Ä¢	Resampling details (warp, overviews)
	‚Ä¢	NoData handling & void fill notes
	‚Ä¢	Georeferencing accuracy (RMS or equivalent)

‚∏ª

‚ö° Performance Tips
	‚Ä¢	Use BLOCKSIZE=512 + internal overviews for fast UX
	‚Ä¢	For heavy clients, publish tiled COGs (quad-key or county)
	‚Ä¢	Keep analysis in projected CRS; publish WGS84 copies for web
	‚Ä¢	For distribution, consider PMTiles (raw COGs remain provenance)

‚∏ª

‚úÖ Checklist (New DEM)
	1.	Build/warp DEM to working CRS; set NoData
	2.	Produce web copy as COG (EPSG:4326)
	3.	Write .tif.sha256 sidecar
	4.	Emit STAC Item + validate
	5.	(Optional) Generate derivatives (hillshade, slope, aspect) ‚Üí COG + STAC
	6.	Wire into web viewer (raster-dem or hillshade)
	7.	Run validation (sha256sum -c, gdalinfo, optional rio cogeo validate)
	8.	Commit ‚Üí CI validates & publishes

‚∏ª

‚úÖ Summary

Mission-grade principle: DEM COGs must be fast, verifiable, and fully traceable via STAC.
If it doesn‚Äôt validate or display, fix the metadata first, then the data.